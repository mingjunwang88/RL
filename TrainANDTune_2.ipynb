{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80b8de62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-04 02:15:19,903\tINFO services.py:1252 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n",
      "2021-11-04 02:15:22,142\tINFO trainer.py:741 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2021-11-04 02:15:22,143\tINFO ppo.py:165 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "2021-11-04 02:15:22,144\tINFO trainer.py:760 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=5367)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[2m\u001b[36m(pid=5367)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=5367)\u001b[0m 2021-11-04 02:15:30.985507: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[2m\u001b[36m(pid=5367)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=5367)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=5367)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=5367)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=5367)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=5367)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=5367)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:163: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[2m\u001b[36m(pid=5367)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=5367)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:189: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\u001b[2m\u001b[36m(pid=5367)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=5367)\u001b[0m [2021-11-04 02:15:34.033 ip-172-16-83-177:5367 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=5367)\u001b[0m [2021-11-04 02:15:34.164 ip-172-16-83-177:5367 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:163: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:189: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "[2021-11-04 02:16:09.337 ip-172-16-83-177:130210 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2021-11-04 02:16:09.370 ip-172-16-83-177:130210 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-04 02:16:09,912\tWARNING trainer_template.py:186 -- `execution_plan` functions should accept `trainer`, `workers`, and `config` as args!\n",
      "2021-11-04 02:16:09,913\tINFO trainable.py:112 -- Trainable.setup took 47.772 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG\n",
    "from ray.tune.logger import pretty_print\n",
    "import json\n",
    "import pandas as pd\n",
    "import gym\n",
    "import ray\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "config = DEFAULT_CONFIG.copy()\n",
    "config[\"num_workers\"] = 1\n",
    "config[\"num_sgd_iter\"] = 30\n",
    "config[\"sgd_minibatch_size\"] = 128\n",
    "config[\"model\"][\"fcnet_hiddens\"] = [100, 100]\n",
    "config[\"num_cpus_per_worker\"] = 1\n",
    "\n",
    "agent = PPOTrainer(config, \"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e79f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RL algorithm (Trainer) we would like to use.\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "\n",
    "# Configure the algorithm.\n",
    "config = {\n",
    "    # Environment (RLlib understands openAI gym registered strings).\n",
    "    \"env\": \"Taxi-v3\",\n",
    "    # Use 2 environment workers (aka \"rollout workers\") that parallelly\n",
    "    # collect samples from their own environment clone(s).\n",
    "    \"num_workers\": 2,\n",
    "    # Change this to \"framework: torch\", if you are using PyTorch.\n",
    "    # Also, use \"framework: tf2\" for tf2.x eager execution.\n",
    "    \"framework\": \"tf\",\n",
    "    # Tweak the default model provided automatically by RLlib,\n",
    "    # given the environment's observation- and action spaces.\n",
    "    \"model\": {\n",
    "        \"fcnet_hiddens\": [64, 64],\n",
    "        \"fcnet_activation\": \"relu\",\n",
    "    },\n",
    "    # Set up a separate evaluation worker set for the\n",
    "    # `trainer.evaluate()` call after training (see below).\n",
    "    \"evaluation_num_workers\": 1,\n",
    "    # Only for evaluation runs, render the env.\n",
    "    \"evaluation_config\": {\n",
    "        \"render_env\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create our RLlib Trainer.\n",
    "trainer = PPOTrainer(config=config)\n",
    "#\n",
    "agent = PPOTrainer(config, \"CartPole-v1\")\n",
    "\n",
    "# Run it for n training iterations. A training iteration includes\n",
    "# parallel sample collection by the environment workers as well as\n",
    "# loss calculation on the collected batch and a model update.\n",
    "for _ in range(3):\n",
    "    print(trainer.train())\n",
    "\n",
    "# Evaluate the trained Trainer (and render each timestep to the shell's\n",
    "# output).\n",
    "trainer.evaluate()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd40625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "from ray.tune.logger import pretty_print\n",
    "from ray import tune"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
