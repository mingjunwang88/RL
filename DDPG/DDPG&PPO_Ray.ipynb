{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray.rllib.agents import ppo, ddpg\n",
    "from ray import tune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 16:13:58,196\tINFO services.py:1414 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.16.6.103',\n",
       " 'raylet_ip_address': '172.16.6.103',\n",
       " 'redis_address': None,\n",
       " 'object_store_address': '/tmp/ray/session_2022-03-17_16-13-54_199494_17585/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-03-17_16-13-54_199494_17585/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2022-03-17_16-13-54_199494_17585',\n",
       " 'metrics_export_port': 47720,\n",
       " 'gcs_address': '172.16.6.103:53330',\n",
       " 'address': '172.16.6.103:53330',\n",
       " 'node_id': '396fe4ca597106f69f69aaddba59002fcdd859f4ea56d0b5a0850812'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:14:03 (running for 00:00:00.26)<br>Memory usage on this node: 7.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(bundle_reservation_check_func pid=61074)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[2m\u001b[36m(bundle_reservation_check_func pid=61074)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m 2022-03-17 16:14:07,228\tINFO trainer.py:2141 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m 2022-03-17 16:14:07,229\tINFO simple_q.py:155 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m 2022-03-17 16:14:07,229\tINFO trainer.py:781 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=61052)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[2m\u001b[36m(pid=61052)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=61033)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[2m\u001b[36m(pid=61033)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61052)\u001b[0m 2022-03-17 16:14:11.171645: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61033)\u001b[0m 2022-03-17 16:14:11.171630: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61052)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61052)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61052)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61033)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61033)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61033)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61052)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/rllib/utils/exploration/ornstein_uhlenbeck_noise.py:112: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61052)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61052)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61033)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/rllib/utils/exploration/ornstein_uhlenbeck_noise.py:112: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61033)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61033)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61052)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:163: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61052)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61052)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:189: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61052)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61033)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:163: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61033)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61033)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:189: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61033)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=61033)\u001b[0m [2022-03-17 16:14:14.664 ip-172-16-6-103:61033 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61052)\u001b[0m [2022-03-17 16:14:14.664 ip-172-16-6-103:61052 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61033)\u001b[0m [2022-03-17 16:14:14.758 ip-172-16-6-103:61033 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=61052)\u001b[0m [2022-03-17 16:14:14.758 ip-172-16-6-103:61052 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m 2022-03-17 16:14:15.592037: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/rllib/utils/exploration/ornstein_uhlenbeck_noise.py:112: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m [2022-03-17 16:14:16.539 ip-172-16-6-103:61074 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m [2022-03-17 16:14:16.572 ip-172-16-6-103:61074 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:163: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:189: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:14:17 (running for 00:00:13.89)<br>Memory usage on this node: 8.5/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m 2022-03-17 16:14:17,246\tINFO trainable.py:130 -- Trainable.setup took 10.018 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=61074)\u001b[0m 2022-03-17 16:14:17,246\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:14:18 (running for 00:00:14.90)<br>Memory usage on this node: 8.5/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:14:23 (running for 00:00:19.91)<br>Memory usage on this node: 8.5/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 1500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-14-24\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -907.2904437188645\n",
      "  episode_reward_mean: -1345.3922996034826\n",
      "  episode_reward_min: -1513.5468576236221\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 6\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 1500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 0.29124847054481506\n",
      "          mean_q: 0.0506104901432991\n",
      "          min_q: -0.22915756702423096\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 12.17733383178711\n",
      "        - 0.1952516883611679\n",
      "        - 6.504350662231445\n",
      "        - 9.74008560180664\n",
      "        - 6.667627334594727\n",
      "        - 6.139453887939453\n",
      "        - 5.86619758605957\n",
      "        - 7.5320611000061035\n",
      "        - 1.1785985231399536\n",
      "        - 9.356751441955566\n",
      "        - 7.5442047119140625\n",
      "        - 8.241311073303223\n",
      "        - 7.47584867477417\n",
      "        - 4.964198589324951\n",
      "        - 3.8530430793762207\n",
      "        - 10.692870140075684\n",
      "        - 0.13920924067497253\n",
      "        - 4.474044322967529\n",
      "        - 5.577371120452881\n",
      "        - 6.955558776855469\n",
      "        - 6.359908103942871\n",
      "        - 5.095023155212402\n",
      "        - 9.414117813110352\n",
      "        - 4.6829514503479\n",
      "        - 2.481165885925293\n",
      "        - 4.6996917724609375\n",
      "        - 7.524891376495361\n",
      "        - 9.201681137084961\n",
      "        - 4.904022693634033\n",
      "        - 7.640934944152832\n",
      "        - 4.933590412139893\n",
      "        - 7.973235607147217\n",
      "        - 9.116618156433105\n",
      "        - 4.970206260681152\n",
      "        - 9.518132209777832\n",
      "        - 4.886193752288818\n",
      "        - 0.8501487970352173\n",
      "        - 9.564491271972656\n",
      "        - 8.952692985534668\n",
      "        - 0.7709513306617737\n",
      "        - 7.740545272827148\n",
      "        - 9.049450874328613\n",
      "        - 9.072314262390137\n",
      "        - 4.067814350128174\n",
      "        - 8.134700775146484\n",
      "        - 9.361666679382324\n",
      "        - 7.685883045196533\n",
      "        - 5.308309078216553\n",
      "        - 1.4710923433303833\n",
      "        - 6.896825313568115\n",
      "        - 9.649078369140625\n",
      "        - 2.9821486473083496\n",
      "        - 6.131814956665039\n",
      "        - 5.5353617668151855\n",
      "        - 10.651220321655273\n",
      "        - 6.154831409454346\n",
      "        - 7.685883045196533\n",
      "        - 5.470324993133545\n",
      "        - 5.7022809982299805\n",
      "        - 4.543641090393066\n",
      "        - 9.297179222106934\n",
      "        - 7.412010192871094\n",
      "        - 7.389009952545166\n",
      "        - 9.120059967041016\n",
      "        - 7.8133625984191895\n",
      "        - 7.937350273132324\n",
      "        - 0.36962178349494934\n",
      "        - 7.096859455108643\n",
      "        - 8.196381568908691\n",
      "        - 7.746648788452148\n",
      "        - 14.123205184936523\n",
      "        - 8.824213027954102\n",
      "        - 7.3443989753723145\n",
      "        - 5.308309078216553\n",
      "        - 0.8732413053512573\n",
      "        - 5.307053565979004\n",
      "        - 1.5277082920074463\n",
      "        - 5.891911506652832\n",
      "        - 9.317793846130371\n",
      "        - 7.782449245452881\n",
      "        - 10.827483177185059\n",
      "        - 4.569336891174316\n",
      "        - 5.766858100891113\n",
      "        - 13.606959342956543\n",
      "        - 6.665226936340332\n",
      "        - 8.931625366210938\n",
      "        - 6.412402153015137\n",
      "        - 2.7406461238861084\n",
      "        - 2.3836300373077393\n",
      "        - 5.86619758605957\n",
      "        - 2.9821486473083496\n",
      "        - 7.037632942199707\n",
      "        - 8.558576583862305\n",
      "        - 5.2174763679504395\n",
      "        - 10.235283851623535\n",
      "        - 4.370772838592529\n",
      "        - 0.762922465801239\n",
      "        - 7.609378814697266\n",
      "        - 2.371112585067749\n",
      "        - 1.6601476669311523\n",
      "        - 7.122223854064941\n",
      "        - 2.0375635623931885\n",
      "        - 1.6191376447677612\n",
      "        - 9.32660961151123\n",
      "        - 8.148626327514648\n",
      "        - 7.879037380218506\n",
      "        - 8.611454963684082\n",
      "        - 0.9890162348747253\n",
      "        - 10.37608528137207\n",
      "        - 6.6751322746276855\n",
      "        - 6.130332946777344\n",
      "        - 8.47315502166748\n",
      "        - 0.38962116837501526\n",
      "        - 7.3443989753723145\n",
      "        - 0.9890162348747253\n",
      "        - 7.789837837219238\n",
      "        - 8.685853004455566\n",
      "        - 1.0214053392410278\n",
      "        - 6.184520721435547\n",
      "        - 11.005760192871094\n",
      "        - 3.565300464630127\n",
      "        - 5.297754287719727\n",
      "        - 5.2376508712768555\n",
      "        - 9.085025787353516\n",
      "        - 8.82684326171875\n",
      "        - 10.389728546142578\n",
      "        - 6.062960147857666\n",
      "        - 7.640934944152832\n",
      "        - 6.0941948890686035\n",
      "        - 7.049117088317871\n",
      "        - 5.7201247215271\n",
      "        - 4.473260402679443\n",
      "        - 4.847896099090576\n",
      "        - 3.469440460205078\n",
      "        - 5.317509174346924\n",
      "        - 4.590923309326172\n",
      "        - 9.46106243133545\n",
      "        - 10.045392990112305\n",
      "        - 10.551018714904785\n",
      "        - 7.18699836730957\n",
      "        - 15.909930229187012\n",
      "        - 10.551018714904785\n",
      "        - 6.209277153015137\n",
      "        - 6.476966857910156\n",
      "        - 6.810312271118164\n",
      "        - 4.847896099090576\n",
      "        - 4.043823719024658\n",
      "        - 7.44746208190918\n",
      "        - 4.794099807739258\n",
      "        - 8.952692985534668\n",
      "        - 10.440000534057617\n",
      "        - 10.332096099853516\n",
      "        - 10.001740455627441\n",
      "        - 10.781390190124512\n",
      "        - 9.334766387939453\n",
      "        - 1.2796027660369873\n",
      "        - 1.1798717975616455\n",
      "        - 9.865628242492676\n",
      "        - 2.323667287826538\n",
      "        - 3.5299994945526123\n",
      "        - 9.011905670166016\n",
      "        - 8.040410041809082\n",
      "        - 9.74008560180664\n",
      "        - 6.5302228927612305\n",
      "        - 6.710582256317139\n",
      "        - 8.14570426940918\n",
      "        - 1.083753228187561\n",
      "        - 8.652534484863281\n",
      "        - 10.109892845153809\n",
      "        - 5.513236045837402\n",
      "        - 8.218023300170898\n",
      "        - 4.671075820922852\n",
      "        - 3.0600554943084717\n",
      "        - 7.645890712738037\n",
      "        - 0.456116259098053\n",
      "        - 9.072314262390137\n",
      "        - 7.247593879699707\n",
      "        - 14.185236930847168\n",
      "        - 4.474156379699707\n",
      "        - 1.343974232673645\n",
      "        - 10.985803604125977\n",
      "        - 8.123762130737305\n",
      "        - 6.0941948890686035\n",
      "        - 9.776225090026855\n",
      "        - 8.753846168518066\n",
      "        - 10.068299293518066\n",
      "        - 9.329073905944824\n",
      "        - 2.8271164894104004\n",
      "        - 10.202766418457031\n",
      "        - 6.691264629364014\n",
      "        - 7.536066055297852\n",
      "        - 11.186909675598145\n",
      "        - 8.824213027954102\n",
      "        - 7.402293682098389\n",
      "        - 3.5299994945526123\n",
      "        - 5.307053565979004\n",
      "        - 10.440000534057617\n",
      "        - 4.165669918060303\n",
      "        - 10.694327354431152\n",
      "        - 7.6668291091918945\n",
      "        - 0.4072718918323517\n",
      "        - 6.582873821258545\n",
      "        - 12.076973915100098\n",
      "        - 6.863784313201904\n",
      "        - 10.692870140075684\n",
      "        - 4.023776531219482\n",
      "        - 6.130332946777344\n",
      "        - 3.987919807434082\n",
      "        - 7.084671497344971\n",
      "        - 8.511112213134766\n",
      "        - 6.359908103942871\n",
      "        - 8.253219604492188\n",
      "        - 7.961346626281738\n",
      "        - 8.18506145477295\n",
      "        - 1.3984043598175049\n",
      "        - 10.058839797973633\n",
      "        - 4.461789608001709\n",
      "        - 6.30366325378418\n",
      "        - 7.840137004852295\n",
      "        - 5.944134712219238\n",
      "        - 7.434990406036377\n",
      "        - 5.751570224761963\n",
      "        - 5.571303367614746\n",
      "        - 10.101578712463379\n",
      "        - 6.454614639282227\n",
      "        - 7.528243064880371\n",
      "        - 7.551164627075195\n",
      "        - 8.532220840454102\n",
      "        - 4.955278396606445\n",
      "        - 0.456116259098053\n",
      "        - 0.17259633541107178\n",
      "        - 9.541608810424805\n",
      "        - 9.869865417480469\n",
      "        - 8.558122634887695\n",
      "        - 3.0210673809051514\n",
      "        - 9.4920015335083\n",
      "        - 8.503376007080078\n",
      "        - 9.533523559570312\n",
      "        - 9.707880020141602\n",
      "        - 3.0317678451538086\n",
      "        - 3.0658557415008545\n",
      "        - 10.348373413085938\n",
      "        - 6.593454837799072\n",
      "        - 8.491216659545898\n",
      "        - 5.963688850402832\n",
      "        - 8.615510940551758\n",
      "        - 7.62174129486084\n",
      "        - 7.257261753082275\n",
      "        - 1.4674272537231445\n",
      "        - 7.981897354125977\n",
      "        - 1.2180646657943726\n",
      "        - 4.619821071624756\n",
      "        - 6.6729416847229\n",
      "        - 6.2848334312438965\n",
      "        - 4.597011566162109\n",
      "        - 7.975829601287842\n",
      "    num_agent_steps_sampled: 1500\n",
      "    num_agent_steps_trained: 256\n",
      "    num_steps_sampled: 1500\n",
      "    num_steps_trained: 256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.010000000000005\n",
      "    ram_util_percent: 1.8\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.20458774465060584\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.23752347765845083\n",
      "    mean_inference_ms: 2.551372613157636\n",
      "    mean_raw_obs_processing_ms: 0.6067276635912858\n",
      "  time_since_restore: 6.940832614898682\n",
      "  time_this_iter_s: 6.940832614898682\n",
      "  time_total_s: 6.940832614898682\n",
      "  timers:\n",
      "    learn_throughput: 180.396\n",
      "    learn_time_ms: 1419.1\n",
      "    load_throughput: 379951.105\n",
      "    load_time_ms: 0.674\n",
      "    update_time_ms: 6.381\n",
      "  timestamp: 1647533664\n",
      "  timesteps_since_restore: 256\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 1500\n",
      "  training_iteration: 1\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:14:28 (running for 00:00:24.95)<br>Memory usage on this node: 8.6/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.94083</td><td style=\"text-align: right;\">1500</td><td style=\"text-align: right;\">-1345.39</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1513.55</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:14:33 (running for 00:00:29.96)<br>Memory usage on this node: 8.6/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.94083</td><td style=\"text-align: right;\">1500</td><td style=\"text-align: right;\">-1345.39</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1513.55</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:14:38 (running for 00:00:34.97)<br>Memory usage on this node: 8.6/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.94083</td><td style=\"text-align: right;\">1500</td><td style=\"text-align: right;\">-1345.39</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1513.55</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:14:43 (running for 00:00:39.97)<br>Memory usage on this node: 8.6/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.94083</td><td style=\"text-align: right;\">1500</td><td style=\"text-align: right;\">-1345.39</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1513.55</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 2500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-14-47\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -907.2904437188645\n",
      "  episode_reward_mean: -1379.2939883883835\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 12\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 2500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: -0.24000409245491028\n",
      "          mean_q: -11.391928672790527\n",
      "          min_q: -25.769502639770508\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.14536523818969727\n",
      "        - 0.11539363861083984\n",
      "        - 0.1040048599243164\n",
      "        - -0.023713111877441406\n",
      "        - 0.0889739990234375\n",
      "        - -0.1740589141845703\n",
      "        - 0.0003883838653564453\n",
      "        - -0.1069345474243164\n",
      "        - 0.09739303588867188\n",
      "        - 0.09662246704101562\n",
      "        - -0.1861124038696289\n",
      "        - 0.0889739990234375\n",
      "        - -0.056743621826171875\n",
      "        - -0.22598934173583984\n",
      "        - 0.06747913360595703\n",
      "        - 0.09349516034126282\n",
      "        - -0.21736875176429749\n",
      "        - 0.13353729248046875\n",
      "        - 0.09902477264404297\n",
      "        - -0.18991470336914062\n",
      "        - 0.15287494659423828\n",
      "        - -0.10023665428161621\n",
      "        - 0.09233570098876953\n",
      "        - -0.17934036254882812\n",
      "        - 0.16480255126953125\n",
      "        - 0.16415119171142578\n",
      "        - 0.11329364776611328\n",
      "        - 0.03587055206298828\n",
      "        - -0.07653588056564331\n",
      "        - -0.14699363708496094\n",
      "        - 0.12153816223144531\n",
      "        - -0.057959556579589844\n",
      "        - 0.0608673095703125\n",
      "        - 0.012541770935058594\n",
      "        - 0.06215667724609375\n",
      "        - 0.48478031158447266\n",
      "        - 0.11982536315917969\n",
      "        - 0.06533336639404297\n",
      "        - 0.0475921630859375\n",
      "        - 0.0475921630859375\n",
      "        - -0.12400907278060913\n",
      "        - -0.0894927978515625\n",
      "        - -0.023860931396484375\n",
      "        - -0.013301849365234375\n",
      "        - -0.4316234588623047\n",
      "        - 0.07289981842041016\n",
      "        - 0.21974849700927734\n",
      "        - -0.25318431854248047\n",
      "        - 0.12153816223144531\n",
      "        - 0.10451221466064453\n",
      "        - -0.11384296417236328\n",
      "        - -0.018982887268066406\n",
      "        - -0.24384117126464844\n",
      "        - -0.06947612762451172\n",
      "        - 0.05572509765625\n",
      "        - -0.1683206558227539\n",
      "        - 0.13089847564697266\n",
      "        - 0.02077198028564453\n",
      "        - -0.05808830261230469\n",
      "        - -0.15357398986816406\n",
      "        - 0.10175514221191406\n",
      "        - 0.05893135070800781\n",
      "        - 0.03090381622314453\n",
      "        - -0.008283615112304688\n",
      "        - -0.11277532577514648\n",
      "        - -0.025220870971679688\n",
      "        - -0.06819438934326172\n",
      "        - 0.12856769561767578\n",
      "        - -0.053768157958984375\n",
      "        - 0.114105224609375\n",
      "        - -0.0968790054321289\n",
      "        - -0.023136138916015625\n",
      "        - 0.08932209014892578\n",
      "        - 0.07390689849853516\n",
      "        - 0.2039947509765625\n",
      "        - -0.012659072875976562\n",
      "        - -0.6717071533203125\n",
      "        - 0.07589244842529297\n",
      "        - 0.24031734466552734\n",
      "        - 0.1381397247314453\n",
      "        - 0.07959175109863281\n",
      "        - 0.2188587188720703\n",
      "        - 0.4895362854003906\n",
      "        - -0.03594493865966797\n",
      "        - 0.08216094970703125\n",
      "        - 0.0960235595703125\n",
      "        - -0.0029020309448242188\n",
      "        - 0.027822494506835938\n",
      "        - 0.060669898986816406\n",
      "        - -0.020053863525390625\n",
      "        - -0.003261566162109375\n",
      "        - 0.10643243789672852\n",
      "        - -0.15577411651611328\n",
      "        - 0.07841300964355469\n",
      "        - 0.16029906272888184\n",
      "        - 0.015131950378417969\n",
      "        - -0.03714179992675781\n",
      "        - -0.1504650115966797\n",
      "        - 0.06127738952636719\n",
      "        - -0.1589365005493164\n",
      "        - 0.04730415344238281\n",
      "        - -0.08098125457763672\n",
      "        - -0.10971260070800781\n",
      "        - 0.039938926696777344\n",
      "        - -0.1669907569885254\n",
      "        - 0.20354557037353516\n",
      "        - 0.058562278747558594\n",
      "        - 0.007618904113769531\n",
      "        - -0.1910114288330078\n",
      "        - -0.17906951904296875\n",
      "        - -0.1886911392211914\n",
      "        - -0.25879478454589844\n",
      "        - 0.026836395263671875\n",
      "        - -0.08676433563232422\n",
      "        - 0.0727396011352539\n",
      "        - 0.12318229675292969\n",
      "        - 0.11543846130371094\n",
      "        - 0.04649829864501953\n",
      "        - -0.06041240692138672\n",
      "        - 0.16240596771240234\n",
      "        - -0.10749340057373047\n",
      "        - 0.1040048599243164\n",
      "        - -0.42479515075683594\n",
      "        - -0.01803874969482422\n",
      "        - -0.0918126106262207\n",
      "        - 0.1279745101928711\n",
      "        - 0.034232139587402344\n",
      "        - -0.25488948822021484\n",
      "        - -0.17134475708007812\n",
      "        - -0.01757335662841797\n",
      "        - 0.5346107482910156\n",
      "        - 0.011402130126953125\n",
      "        - 0.09349516034126282\n",
      "        - 0.05694007873535156\n",
      "        - -0.073333740234375\n",
      "        - -0.033626556396484375\n",
      "        - 0.09609222412109375\n",
      "        - 0.48478031158447266\n",
      "        - 0.01047515869140625\n",
      "        - 0.05620765686035156\n",
      "        - -0.32343629002571106\n",
      "        - -0.32573699951171875\n",
      "        - -0.10651302337646484\n",
      "        - 0.033560752868652344\n",
      "        - -0.03594493865966797\n",
      "        - 0.05694007873535156\n",
      "        - -0.0866546630859375\n",
      "        - 0.054589271545410156\n",
      "        - 0.11176776885986328\n",
      "        - 0.3726959228515625\n",
      "        - 0.020015716552734375\n",
      "        - 0.07471084594726562\n",
      "        - 0.042575836181640625\n",
      "        - 0.0940866470336914\n",
      "        - 0.0766439437866211\n",
      "        - 0.10654640197753906\n",
      "        - 0.12347841262817383\n",
      "        - 0.10872173309326172\n",
      "        - -0.09419059753417969\n",
      "        - -0.10369491577148438\n",
      "        - -0.41272926330566406\n",
      "        - 0.037413597106933594\n",
      "        - -0.0672140121459961\n",
      "        - 0.17436885833740234\n",
      "        - 0.033463478088378906\n",
      "        - -0.01041412353515625\n",
      "        - -0.13422679901123047\n",
      "        - -0.044312477111816406\n",
      "        - 0.05504417419433594\n",
      "        - 0.077606201171875\n",
      "        - 0.06218147277832031\n",
      "        - -0.08732414245605469\n",
      "        - 0.05846691131591797\n",
      "        - -0.18505191802978516\n",
      "        - -0.33978843688964844\n",
      "        - 0.005877494812011719\n",
      "        - -0.2710857391357422\n",
      "        - -0.047789573669433594\n",
      "        - 0.02782154083251953\n",
      "        - 0.10549163818359375\n",
      "        - 0.0042552947998046875\n",
      "        - 0.08813762664794922\n",
      "        - -0.1589365005493164\n",
      "        - 0.08668231964111328\n",
      "        - 0.10872173309326172\n",
      "        - 0.2188587188720703\n",
      "        - 0.3978157043457031\n",
      "        - 0.12359952926635742\n",
      "        - -0.048041343688964844\n",
      "        - 0.08063387870788574\n",
      "        - 0.1616058349609375\n",
      "        - 0.17996686697006226\n",
      "        - -0.4233722686767578\n",
      "        - -0.3606474995613098\n",
      "        - -0.2249011993408203\n",
      "        - -0.29003286361694336\n",
      "        - 0.12882328033447266\n",
      "        - 0.077606201171875\n",
      "        - -0.024178504943847656\n",
      "        - 0.11623430252075195\n",
      "        - 0.12006664276123047\n",
      "        - -0.073333740234375\n",
      "        - -0.02875739336013794\n",
      "        - -0.14847183227539062\n",
      "        - -0.09179115295410156\n",
      "        - 0.14569425582885742\n",
      "        - -0.011832714080810547\n",
      "        - 0.0703277587890625\n",
      "        - 0.14848613739013672\n",
      "        - -0.09189891815185547\n",
      "        - -0.1399393081665039\n",
      "        - 0.0036144256591796875\n",
      "        - -0.022475242614746094\n",
      "        - -0.06846141815185547\n",
      "        - 0.07507038116455078\n",
      "        - 0.056336402893066406\n",
      "        - -0.10676193237304688\n",
      "        - -0.04608917236328125\n",
      "        - 0.07452583312988281\n",
      "        - 0.05288529396057129\n",
      "        - -0.011654853820800781\n",
      "        - 0.24864482879638672\n",
      "        - -0.10263502597808838\n",
      "        - -0.1410236358642578\n",
      "        - -0.09532356262207031\n",
      "        - -0.14387130737304688\n",
      "        - 0.06424617767333984\n",
      "        - 0.20703411102294922\n",
      "        - 0.20984888076782227\n",
      "        - -0.1861124038696289\n",
      "        - 0.21790707111358643\n",
      "        - -0.0939321517944336\n",
      "        - 0.031174659729003906\n",
      "        - -0.04925823211669922\n",
      "        - -0.08250808715820312\n",
      "        - 0.13164138793945312\n",
      "        - 0.04983234405517578\n",
      "        - -0.17334747314453125\n",
      "        - 0.169769287109375\n",
      "        - -0.1855459213256836\n",
      "        - -0.13337230682373047\n",
      "        - -0.3037986755371094\n",
      "        - 0.04292488098144531\n",
      "        - 0.31447696685791016\n",
      "        - -0.02684783935546875\n",
      "        - 0.03711986541748047\n",
      "        - -0.0263671875\n",
      "        - 0.1792750358581543\n",
      "        - -0.41967010498046875\n",
      "        - -0.08098125457763672\n",
      "        - -0.1414508819580078\n",
      "        - 0.33154869079589844\n",
      "        - 0.3444223403930664\n",
      "        - 0.3436918258666992\n",
      "        - -0.0987548828125\n",
      "        - -0.019548416137695312\n",
      "    num_agent_steps_sampled: 2500\n",
      "    num_agent_steps_trained: 128256\n",
      "    num_steps_sampled: 2500\n",
      "    num_steps_trained: 128256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 501\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.72941176470588\n",
      "    ram_util_percent: 1.7999999999999998\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.2145971704796262\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.2430024036703994\n",
      "    mean_inference_ms: 2.3010365185814576\n",
      "    mean_raw_obs_processing_ms: 0.6187779376599994\n",
      "  time_since_restore: 30.18429708480835\n",
      "  time_this_iter_s: 23.243464469909668\n",
      "  time_total_s: 30.18429708480835\n",
      "  timers:\n",
      "    learn_throughput: 41915.369\n",
      "    learn_time_ms: 6.108\n",
      "    load_throughput: 577560.015\n",
      "    load_time_ms: 0.443\n",
      "    update_time_ms: 3.767\n",
      "  timestamp: 1647533687\n",
      "  timesteps_since_restore: 512\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 2500\n",
      "  training_iteration: 2\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:14:48 (running for 00:00:45.27)<br>Memory usage on this node: 8.6/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         30.1843</td><td style=\"text-align: right;\">2500</td><td style=\"text-align: right;\">-1379.29</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:14:53 (running for 00:00:50.27)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         30.1843</td><td style=\"text-align: right;\">2500</td><td style=\"text-align: right;\">-1379.29</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:14:58 (running for 00:00:55.28)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         30.1843</td><td style=\"text-align: right;\">2500</td><td style=\"text-align: right;\">-1379.29</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:15:03 (running for 00:01:00.29)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         30.1843</td><td style=\"text-align: right;\">2500</td><td style=\"text-align: right;\">-1379.29</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 3500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-15-04\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -907.2904437188645\n",
      "  episode_reward_mean: -1410.9742945715109\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 16\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 3500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: -0.552304208278656\n",
      "          mean_q: -17.384620666503906\n",
      "          min_q: -36.55169677734375\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.08655452728271484\n",
      "        - -0.017822265625\n",
      "        - 0.2675628662109375\n",
      "        - -0.0034656524658203125\n",
      "        - -0.023311614990234375\n",
      "        - 0.10338401794433594\n",
      "        - 0.04534435272216797\n",
      "        - 0.055816650390625\n",
      "        - -0.08197212219238281\n",
      "        - 0.23122644424438477\n",
      "        - 0.02476978302001953\n",
      "        - -0.08228302001953125\n",
      "        - 0.13578224182128906\n",
      "        - 0.14478492736816406\n",
      "        - 0.04796028137207031\n",
      "        - 0.28287696838378906\n",
      "        - 0.07776641845703125\n",
      "        - -0.05916786193847656\n",
      "        - 0.08923530578613281\n",
      "        - 0.07566642761230469\n",
      "        - -0.0880584716796875\n",
      "        - 0.06345653533935547\n",
      "        - -0.009847640991210938\n",
      "        - 0.08594131469726562\n",
      "        - -0.08629035949707031\n",
      "        - 0.15682697296142578\n",
      "        - -0.0040607452392578125\n",
      "        - 0.24184417724609375\n",
      "        - -0.06310081481933594\n",
      "        - 0.20493125915527344\n",
      "        - 0.1675395965576172\n",
      "        - 0.2873497009277344\n",
      "        - 0.03721809387207031\n",
      "        - -0.14806008338928223\n",
      "        - 0.15212726593017578\n",
      "        - -0.007602691650390625\n",
      "        - 0.23591995239257812\n",
      "        - -0.2417011260986328\n",
      "        - 0.3576812744140625\n",
      "        - -0.1661238670349121\n",
      "        - 0.01517486572265625\n",
      "        - -0.241119384765625\n",
      "        - 0.09998846054077148\n",
      "        - 0.2292652130126953\n",
      "        - -0.12111788988113403\n",
      "        - 0.0384368896484375\n",
      "        - 0.05820655822753906\n",
      "        - 0.09168338775634766\n",
      "        - 0.44252777099609375\n",
      "        - 0.04071044921875\n",
      "        - 0.07931709289550781\n",
      "        - -0.034923553466796875\n",
      "        - 0.06592941284179688\n",
      "        - 0.0050127506256103516\n",
      "        - 0.20914840698242188\n",
      "        - -0.28336238861083984\n",
      "        - 0.0007305145263671875\n",
      "        - -0.20807266235351562\n",
      "        - 0.08420753479003906\n",
      "        - 0.10991668701171875\n",
      "        - -0.023740768432617188\n",
      "        - 0.06798648834228516\n",
      "        - 0.38490867614746094\n",
      "        - -0.12596511840820312\n",
      "        - 0.11346149444580078\n",
      "        - 0.047027587890625\n",
      "        - 0.0231897234916687\n",
      "        - 0.14369583129882812\n",
      "        - 0.08526420593261719\n",
      "        - 0.06633758544921875\n",
      "        - 0.07152748107910156\n",
      "        - -0.1699047088623047\n",
      "        - 0.030918121337890625\n",
      "        - 0.3295755386352539\n",
      "        - 0.09880924224853516\n",
      "        - -0.03177070617675781\n",
      "        - 0.14136123657226562\n",
      "        - 0.09407615661621094\n",
      "        - 0.008225083351135254\n",
      "        - 0.06916189193725586\n",
      "        - 0.14900588989257812\n",
      "        - -0.0651102066040039\n",
      "        - 0.05100059509277344\n",
      "        - -0.015468597412109375\n",
      "        - 0.07367706298828125\n",
      "        - 0.11664199829101562\n",
      "        - 0.09957504272460938\n",
      "        - 0.1851787567138672\n",
      "        - -0.03681755065917969\n",
      "        - 0.0736856460571289\n",
      "        - 0.39943504333496094\n",
      "        - 0.07272624969482422\n",
      "        - -0.14766502380371094\n",
      "        - 0.17339515686035156\n",
      "        - -0.07482624053955078\n",
      "        - 0.19176483154296875\n",
      "        - -0.12596511840820312\n",
      "        - 0.017162322998046875\n",
      "        - 0.08798408508300781\n",
      "        - 0.028929710388183594\n",
      "        - 0.06946754455566406\n",
      "        - -0.060558319091796875\n",
      "        - 0.2022266387939453\n",
      "        - 0.1472644805908203\n",
      "        - 0.11084747314453125\n",
      "        - 0.12074851989746094\n",
      "        - 0.06458091735839844\n",
      "        - -0.015798568725585938\n",
      "        - 0.04770469665527344\n",
      "        - 0.242950439453125\n",
      "        - 0.38490867614746094\n",
      "        - -0.0108184814453125\n",
      "        - 0.1577281951904297\n",
      "        - -0.020824432373046875\n",
      "        - -0.02848052978515625\n",
      "        - 0.242095947265625\n",
      "        - 0.19277191162109375\n",
      "        - 0.10318183898925781\n",
      "        - 0.29388999938964844\n",
      "        - -0.04076385498046875\n",
      "        - 0.050185203552246094\n",
      "        - 0.09941482543945312\n",
      "        - -0.1701984405517578\n",
      "        - -0.07142829895019531\n",
      "        - 0.12379646301269531\n",
      "        - 0.16901016235351562\n",
      "        - -0.016542434692382812\n",
      "        - 0.06253433227539062\n",
      "        - 0.10082244873046875\n",
      "        - -0.0192718505859375\n",
      "        - -0.031103134155273438\n",
      "        - -0.19811248779296875\n",
      "        - 0.07758665084838867\n",
      "        - 0.00629425048828125\n",
      "        - 0.17447853088378906\n",
      "        - -0.0705413818359375\n",
      "        - 0.3465538024902344\n",
      "        - 0.0775146484375\n",
      "        - 0.3753242492675781\n",
      "        - 0.08892631530761719\n",
      "        - -0.3368549346923828\n",
      "        - -0.021070480346679688\n",
      "        - 0.11039352416992188\n",
      "        - 0.26950836181640625\n",
      "        - 0.1678314208984375\n",
      "        - 0.20934677124023438\n",
      "        - -0.006755828857421875\n",
      "        - -0.17735862731933594\n",
      "        - -0.079193115234375\n",
      "        - 0.10538101196289062\n",
      "        - 0.028879165649414062\n",
      "        - -0.1428966522216797\n",
      "        - 0.22175216674804688\n",
      "        - 0.04891204833984375\n",
      "        - 0.14137840270996094\n",
      "        - 0.19583892822265625\n",
      "        - 0.14672470092773438\n",
      "        - -0.0076694488525390625\n",
      "        - 0.12316513061523438\n",
      "        - -0.3368549346923828\n",
      "        - -0.04659271240234375\n",
      "        - 0.12862586975097656\n",
      "        - 0.07447052001953125\n",
      "        - -0.06256484985351562\n",
      "        - -0.1699047088623047\n",
      "        - 0.2400531768798828\n",
      "        - 0.2890167236328125\n",
      "        - 0.09043121337890625\n",
      "        - 0.2749214172363281\n",
      "        - 0.10806083679199219\n",
      "        - 0.06037139892578125\n",
      "        - 0.06592941284179688\n",
      "        - -0.03109145164489746\n",
      "        - 0.23235702514648438\n",
      "        - -0.023349761962890625\n",
      "        - -0.32792186737060547\n",
      "        - 0.019899368286132812\n",
      "        - 0.1793065071105957\n",
      "        - 0.047240257263183594\n",
      "        - -0.013301849365234375\n",
      "        - -0.10372161865234375\n",
      "        - -0.04266357421875\n",
      "        - 0.0922098159790039\n",
      "        - 0.0025482177734375\n",
      "        - -0.19656944274902344\n",
      "        - 0.05737113952636719\n",
      "        - 0.05887794494628906\n",
      "        - 0.09880924224853516\n",
      "        - 0.19452476501464844\n",
      "        - 0.07241249084472656\n",
      "        - 0.2749214172363281\n",
      "        - 0.13171005249023438\n",
      "        - 0.01906585693359375\n",
      "        - -0.1083674430847168\n",
      "        - 0.154022216796875\n",
      "        - 0.0016846656799316406\n",
      "        - 0.06764602661132812\n",
      "        - 0.08258628845214844\n",
      "        - 0.1273517608642578\n",
      "        - 0.11836814880371094\n",
      "        - 0.1596202850341797\n",
      "        - -0.6110038757324219\n",
      "        - 0.045978546142578125\n",
      "        - 0.0320281982421875\n",
      "        - 0.036403656005859375\n",
      "        - 0.32560157775878906\n",
      "        - 0.17420291900634766\n",
      "        - 0.366455078125\n",
      "        - 0.08418846130371094\n",
      "        - -0.396270751953125\n",
      "        - 0.0007305145263671875\n",
      "        - 0.07052135467529297\n",
      "        - 0.006000518798828125\n",
      "        - 0.2628192901611328\n",
      "        - 0.10559272766113281\n",
      "        - -0.0651102066040039\n",
      "        - 0.26886749267578125\n",
      "        - 0.08451461791992188\n",
      "        - 0.05980396270751953\n",
      "        - 0.15906906127929688\n",
      "        - -0.2242412567138672\n",
      "        - 0.15468215942382812\n",
      "        - 0.10752105712890625\n",
      "        - -0.1756153106689453\n",
      "        - 0.3050727844238281\n",
      "        - 0.18001174926757812\n",
      "        - 0.1571178436279297\n",
      "        - -0.001132965087890625\n",
      "        - 0.3335742950439453\n",
      "        - 0.06603527069091797\n",
      "        - 0.4452934265136719\n",
      "        - 0.05864715576171875\n",
      "        - 0.0775146484375\n",
      "        - 0.1517505645751953\n",
      "        - 0.05814552307128906\n",
      "        - -0.06678390502929688\n",
      "        - 0.16901016235351562\n",
      "        - -0.03109145164489746\n",
      "        - 0.3483896255493164\n",
      "        - 0.06239509582519531\n",
      "        - 0.07278823852539062\n",
      "        - 0.07046890258789062\n",
      "        - 0.061499595642089844\n",
      "        - 0.3523979187011719\n",
      "        - 0.04135894775390625\n",
      "        - 0.3530387878417969\n",
      "        - 0.1994152069091797\n",
      "        - 0.16582870483398438\n",
      "        - 0.11279964447021484\n",
      "        - 0.5590591430664062\n",
      "        - 0.05228710174560547\n",
      "        - -0.026227951049804688\n",
      "        - 0.41547393798828125\n",
      "        - 0.07095813751220703\n",
      "        - 0.013263702392578125\n",
      "        - 0.03144264221191406\n",
      "    num_agent_steps_sampled: 3500\n",
      "    num_agent_steps_trained: 256256\n",
      "    num_steps_sampled: 3500\n",
      "    num_steps_trained: 256256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 1001\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.36666666666667\n",
      "    ram_util_percent: 1.7333333333333334\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21540388635474322\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.2413365152927251\n",
      "    mean_inference_ms: 2.165670066703992\n",
      "    mean_raw_obs_processing_ms: 0.612491904303536\n",
      "  time_since_restore: 47.535714864730835\n",
      "  time_this_iter_s: 17.351417779922485\n",
      "  time_total_s: 47.535714864730835\n",
      "  timers:\n",
      "    learn_throughput: 51423.678\n",
      "    learn_time_ms: 4.978\n",
      "    load_throughput: 654880.351\n",
      "    load_time_ms: 0.391\n",
      "    update_time_ms: 2.898\n",
      "  timestamp: 1647533704\n",
      "  timesteps_since_restore: 768\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 3500\n",
      "  training_iteration: 3\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:15:09 (running for 00:01:05.65)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         47.5357</td><td style=\"text-align: right;\">3500</td><td style=\"text-align: right;\">-1410.97</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:15:14 (running for 00:01:10.65)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         47.5357</td><td style=\"text-align: right;\">3500</td><td style=\"text-align: right;\">-1410.97</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:15:19 (running for 00:01:15.66)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         47.5357</td><td style=\"text-align: right;\">3500</td><td style=\"text-align: right;\">-1410.97</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 4500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-15-20\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -907.2904437188645\n",
      "  episode_reward_mean: -1414.8658131809993\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 22\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 4500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 0.11188039928674698\n",
      "          mean_q: -22.615711212158203\n",
      "          min_q: -44.032901763916016\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.2650127410888672\n",
      "        - 0.08176994323730469\n",
      "        - 0.14512252807617188\n",
      "        - 0.2074432373046875\n",
      "        - 0.22929763793945312\n",
      "        - 0.28634071350097656\n",
      "        - 0.32443809509277344\n",
      "        - 0.0805511474609375\n",
      "        - 0.26038360595703125\n",
      "        - 0.09117889404296875\n",
      "        - -0.347442626953125\n",
      "        - 0.35442495346069336\n",
      "        - 0.023097991943359375\n",
      "        - 0.15210723876953125\n",
      "        - 0.12408447265625\n",
      "        - 0.1977825164794922\n",
      "        - 0.13904953002929688\n",
      "        - 0.17742156982421875\n",
      "        - 0.14455509185791016\n",
      "        - 0.1811695098876953\n",
      "        - 0.20153236389160156\n",
      "        - 0.28179359436035156\n",
      "        - 0.27082061767578125\n",
      "        - -0.008774757385253906\n",
      "        - 0.1692657470703125\n",
      "        - 0.2491912841796875\n",
      "        - 0.017496109008789062\n",
      "        - 0.07771110534667969\n",
      "        - 0.13962936401367188\n",
      "        - 0.1848278045654297\n",
      "        - 0.10884976387023926\n",
      "        - 1.0131454467773438\n",
      "        - 0.37011146545410156\n",
      "        - 0.2776927947998047\n",
      "        - 0.18376731872558594\n",
      "        - 0.1651592254638672\n",
      "        - 0.17210960388183594\n",
      "        - 0.3344593048095703\n",
      "        - 0.29331398010253906\n",
      "        - 0.2589836120605469\n",
      "        - 0.5200691223144531\n",
      "        - 0.14058589935302734\n",
      "        - -0.18261337280273438\n",
      "        - -0.16338980197906494\n",
      "        - 0.15860939025878906\n",
      "        - 0.29915809631347656\n",
      "        - 0.2525196075439453\n",
      "        - 0.5252532958984375\n",
      "        - 0.11512374877929688\n",
      "        - 0.05138397216796875\n",
      "        - 0.1822509765625\n",
      "        - 0.2596607208251953\n",
      "        - 0.2553901672363281\n",
      "        - 0.02173614501953125\n",
      "        - 0.31427764892578125\n",
      "        - 0.15340042114257812\n",
      "        - -0.011789321899414062\n",
      "        - 0.08762836456298828\n",
      "        - 0.49563026428222656\n",
      "        - 0.054551124572753906\n",
      "        - 0.1400928497314453\n",
      "        - 0.23455047607421875\n",
      "        - 0.09864425659179688\n",
      "        - 0.3099498748779297\n",
      "        - 0.4508380889892578\n",
      "        - 0.31160736083984375\n",
      "        - 0.1541309356689453\n",
      "        - 0.17568206787109375\n",
      "        - 0.2206897735595703\n",
      "        - -0.009202957153320312\n",
      "        - 0.2243499755859375\n",
      "        - 0.1998729705810547\n",
      "        - 0.1694660186767578\n",
      "        - 0.1622447967529297\n",
      "        - 0.08209037780761719\n",
      "        - 0.05732536315917969\n",
      "        - 0.25008392333984375\n",
      "        - 0.21900177001953125\n",
      "        - 0.1849536895751953\n",
      "        - 0.18718719482421875\n",
      "        - 0.042636871337890625\n",
      "        - 0.25008392333984375\n",
      "        - 0.31696319580078125\n",
      "        - 0.5069808959960938\n",
      "        - 0.2526969909667969\n",
      "        - 0.3700141906738281\n",
      "        - 0.11896705627441406\n",
      "        - 0.062099456787109375\n",
      "        - 0.27752113342285156\n",
      "        - 0.18764877319335938\n",
      "        - 0.19462203979492188\n",
      "        - 0.18085289001464844\n",
      "        - 0.2753753662109375\n",
      "        - 0.46266746520996094\n",
      "        - 0.3344440460205078\n",
      "        - 0.2136249542236328\n",
      "        - 0.24386024475097656\n",
      "        - -0.039681434631347656\n",
      "        - 0.1647624969482422\n",
      "        - 0.17922401428222656\n",
      "        - 0.3051624298095703\n",
      "        - 0.2584495544433594\n",
      "        - 0.21875\n",
      "        - 0.4095649719238281\n",
      "        - 0.09378623962402344\n",
      "        - 0.1658155471086502\n",
      "        - 0.36754608154296875\n",
      "        - 0.14778518676757812\n",
      "        - 0.27686309814453125\n",
      "        - 0.2735786437988281\n",
      "        - -0.011531829833984375\n",
      "        - 0.056427001953125\n",
      "        - 0.21511268615722656\n",
      "        - 0.14950942993164062\n",
      "        - 0.2559089660644531\n",
      "        - 0.2887840270996094\n",
      "        - 0.5252532958984375\n",
      "        - 0.2776641845703125\n",
      "        - 0.3193550109863281\n",
      "        - 0.15438461303710938\n",
      "        - 0.244842529296875\n",
      "        - 0.2515068054199219\n",
      "        - 0.1353588104248047\n",
      "        - 0.086029052734375\n",
      "        - 0.24470901489257812\n",
      "        - 0.18544769287109375\n",
      "        - 0.4329490661621094\n",
      "        - 0.10518836975097656\n",
      "        - 0.03343003988265991\n",
      "        - 0.2315196990966797\n",
      "        - 0.28139305114746094\n",
      "        - 0.2503986358642578\n",
      "        - 0.11995506286621094\n",
      "        - 0.16980743408203125\n",
      "        - 0.22760772705078125\n",
      "        - 0.31072998046875\n",
      "        - 0.31361961364746094\n",
      "        - 0.2524604797363281\n",
      "        - 0.3251781463623047\n",
      "        - -0.013513565063476562\n",
      "        - 0.11440467834472656\n",
      "        - 0.15619659423828125\n",
      "        - 0.190704345703125\n",
      "        - 0.014301300048828125\n",
      "        - 0.26577186584472656\n",
      "        - 0.123077392578125\n",
      "        - 0.17943954467773438\n",
      "        - 0.20583724975585938\n",
      "        - 0.2454547882080078\n",
      "        - 0.20792198181152344\n",
      "        - 0.27831077575683594\n",
      "        - 0.16442489624023438\n",
      "        - -0.10588836669921875\n",
      "        - 0.19763565063476562\n",
      "        - 0.19996261596679688\n",
      "        - 0.11170196533203125\n",
      "        - 0.0316048264503479\n",
      "        - 0.2863197326660156\n",
      "        - 0.21436309814453125\n",
      "        - -0.10214042663574219\n",
      "        - 0.35720252990722656\n",
      "        - 0.42447471618652344\n",
      "        - 0.2117633819580078\n",
      "        - 0.23595809936523438\n",
      "        - 0.09230279922485352\n",
      "        - 0.2454547882080078\n",
      "        - 0.0854959487915039\n",
      "        - 0.2295818328857422\n",
      "        - 0.17210960388183594\n",
      "        - 0.10188484191894531\n",
      "        - 0.071990966796875\n",
      "        - 0.2398815155029297\n",
      "        - 0.21753883361816406\n",
      "        - 0.7923736572265625\n",
      "        - 0.12825393676757812\n",
      "        - 0.16894912719726562\n",
      "        - 0.13368988037109375\n",
      "        - 0.23922157287597656\n",
      "        - 0.032520294189453125\n",
      "        - 0.3651847839355469\n",
      "        - 0.2388935089111328\n",
      "        - 0.08209037780761719\n",
      "        - 0.2977428436279297\n",
      "        - 0.542022705078125\n",
      "        - 0.3381214141845703\n",
      "        - 0.3707084655761719\n",
      "        - 0.08438491821289062\n",
      "        - -0.07910728454589844\n",
      "        - 0.22562026977539062\n",
      "        - 0.3311614990234375\n",
      "        - 0.1579742431640625\n",
      "        - 0.1620769500732422\n",
      "        - 0.1620769500732422\n",
      "        - 0.2722759246826172\n",
      "        - 0.1805419921875\n",
      "        - 0.5315303802490234\n",
      "        - 0.2504730224609375\n",
      "        - 0.10916519165039062\n",
      "        - 0.08826494216918945\n",
      "        - 0.05006694793701172\n",
      "        - 0.0287933349609375\n",
      "        - 0.29760169982910156\n",
      "        - 0.2399578094482422\n",
      "        - 0.5136394500732422\n",
      "        - 0.23844528198242188\n",
      "        - -0.1630258560180664\n",
      "        - 0.3204803466796875\n",
      "        - -0.010162353515625\n",
      "        - 0.12977027893066406\n",
      "        - 0.2668018341064453\n",
      "        - 1.122300148010254\n",
      "        - 0.01829814910888672\n",
      "        - 0.08209037780761719\n",
      "        - 0.029940366744995117\n",
      "        - 0.3193550109863281\n",
      "        - 0.16678619384765625\n",
      "        - 0.46080780029296875\n",
      "        - 0.3049659729003906\n",
      "        - 0.15395164489746094\n",
      "        - 0.20560264587402344\n",
      "        - 0.5315303802490234\n",
      "        - 0.14232254028320312\n",
      "        - 1.0075359344482422\n",
      "        - 0.14242172241210938\n",
      "        - 0.15826034545898438\n",
      "        - 0.33629608154296875\n",
      "        - -0.07910728454589844\n",
      "        - -0.011789321899414062\n",
      "        - 0.22933006286621094\n",
      "        - 0.21651458740234375\n",
      "        - 0.20326995849609375\n",
      "        - 0.20434188842773438\n",
      "        - 0.2185821533203125\n",
      "        - -0.09078598022460938\n",
      "        - 0.22148513793945312\n",
      "        - 0.42041587829589844\n",
      "        - 0.1742267608642578\n",
      "        - 0.2148146629333496\n",
      "        - 0.3066997528076172\n",
      "        - 0.028268814086914062\n",
      "        - 0.3026771545410156\n",
      "        - 0.1869220733642578\n",
      "        - 0.20011329650878906\n",
      "        - 0.14394760131835938\n",
      "        - 0.14726638793945312\n",
      "        - 0.5220832824707031\n",
      "        - 0.14345741271972656\n",
      "        - 0.23943328857421875\n",
      "        - -0.00907135009765625\n",
      "        - 0.1837635040283203\n",
      "        - 0.0193328857421875\n",
      "        - 0.22445106506347656\n",
      "        - 0.2630615234375\n",
      "        - 0.16958999633789062\n",
      "        - 0.14665794372558594\n",
      "        - 0.20434188842773438\n",
      "    num_agent_steps_sampled: 4500\n",
      "    num_agent_steps_trained: 384256\n",
      "    num_steps_sampled: 4500\n",
      "    num_steps_trained: 384256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 1501\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 8.334782608695653\n",
      "    ram_util_percent: 1.7000000000000004\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.2137663872118979\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.23695774862905583\n",
      "    mean_inference_ms: 2.0062302619805985\n",
      "    mean_raw_obs_processing_ms: 0.5987683944504217\n",
      "  time_since_restore: 63.54983592033386\n",
      "  time_this_iter_s: 16.014121055603027\n",
      "  time_total_s: 63.54983592033386\n",
      "  timers:\n",
      "    learn_throughput: 50314.274\n",
      "    learn_time_ms: 5.088\n",
      "    load_throughput: 642151.68\n",
      "    load_time_ms: 0.399\n",
      "    update_time_ms: 2.948\n",
      "  timestamp: 1647533720\n",
      "  timesteps_since_restore: 1024\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 4500\n",
      "  training_iteration: 4\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:15:24 (running for 00:01:20.67)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         63.5498</td><td style=\"text-align: right;\">4500</td><td style=\"text-align: right;\">-1414.87</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:15:29 (running for 00:01:25.88)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         63.5498</td><td style=\"text-align: right;\">4500</td><td style=\"text-align: right;\">-1414.87</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:15:34 (running for 00:01:30.89)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         63.5498</td><td style=\"text-align: right;\">4500</td><td style=\"text-align: right;\">-1414.87</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 5500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-15-37\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -907.2904437188645\n",
      "  episode_reward_mean: -1420.2284547095076\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 26\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 5500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: -0.3962515890598297\n",
      "          mean_q: -27.872631072998047\n",
      "          min_q: -48.663692474365234\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 1.02301025390625\n",
      "        - 1.3535442352294922\n",
      "        - 0.4415931701660156\n",
      "        - 0.9750251770019531\n",
      "        - 0.9488258361816406\n",
      "        - 0.9414138793945312\n",
      "        - 0.6502418518066406\n",
      "        - 0.43612098693847656\n",
      "        - 0.29105186462402344\n",
      "        - -0.14513778686523438\n",
      "        - 0.011669158935546875\n",
      "        - 0.35696983337402344\n",
      "        - 0.3572978973388672\n",
      "        - 0.25618743896484375\n",
      "        - 0.37671661376953125\n",
      "        - 0.22303009033203125\n",
      "        - 0.391021728515625\n",
      "        - 0.33531761169433594\n",
      "        - -0.10361862182617188\n",
      "        - 0.4145240783691406\n",
      "        - 0.568359375\n",
      "        - 0.9411277770996094\n",
      "        - 0.4126243591308594\n",
      "        - 0.20015335083007812\n",
      "        - 0.347198486328125\n",
      "        - 0.2620887756347656\n",
      "        - 0.1705303192138672\n",
      "        - 0.20182418823242188\n",
      "        - 0.3579597473144531\n",
      "        - 0.5125236511230469\n",
      "        - 0.3371238708496094\n",
      "        - 0.16933822631835938\n",
      "        - 0.19531631469726562\n",
      "        - 0.3647193908691406\n",
      "        - 0.3837394714355469\n",
      "        - 0.24616622924804688\n",
      "        - 1.2991180419921875\n",
      "        - 0.26247406005859375\n",
      "        - -0.3318634033203125\n",
      "        - 0.4769439697265625\n",
      "        - -0.19858360290527344\n",
      "        - 0.34958648681640625\n",
      "        - 0.2837104797363281\n",
      "        - 0.5764198303222656\n",
      "        - 0.57000732421875\n",
      "        - 0.14265060424804688\n",
      "        - 0.4754772186279297\n",
      "        - 0.3052940368652344\n",
      "        - 0.2837104797363281\n",
      "        - 0.25618743896484375\n",
      "        - 0.3012847900390625\n",
      "        - 0.6506900787353516\n",
      "        - 0.4457359313964844\n",
      "        - 0.6175537109375\n",
      "        - 0.3088550567626953\n",
      "        - 0.3197975158691406\n",
      "        - 0.11629676818847656\n",
      "        - 0.2994508743286133\n",
      "        - 0.4754772186279297\n",
      "        - 0.015811920166015625\n",
      "        - 0.3943443298339844\n",
      "        - 0.3941612243652344\n",
      "        - 0.22372817993164062\n",
      "        - 0.32329750061035156\n",
      "        - 0.22416114807128906\n",
      "        - 0.6171817779541016\n",
      "        - 0.2957115173339844\n",
      "        - 0.24940872192382812\n",
      "        - 0.08943367004394531\n",
      "        - 0.4042549133300781\n",
      "        - 0.07646560668945312\n",
      "        - 0.4076652526855469\n",
      "        - 0.33162689208984375\n",
      "        - -0.0146942138671875\n",
      "        - 0.40473175048828125\n",
      "        - 0.40903472900390625\n",
      "        - 0.27355194091796875\n",
      "        - 0.6302757263183594\n",
      "        - 0.27025794982910156\n",
      "        - 0.4078636169433594\n",
      "        - 0.108123779296875\n",
      "        - 0.15239381790161133\n",
      "        - 0.3039512634277344\n",
      "        - 0.4397773742675781\n",
      "        - 0.6021137237548828\n",
      "        - 1.307382583618164\n",
      "        - 0.17961502075195312\n",
      "        - 0.39919281005859375\n",
      "        - 0.37134742736816406\n",
      "        - 0.40340614318847656\n",
      "        - 0.09214591979980469\n",
      "        - 0.23472213745117188\n",
      "        - 0.114349365234375\n",
      "        - 0.7959299087524414\n",
      "        - 0.6392593383789062\n",
      "        - 0.5488319396972656\n",
      "        - 0.3764533996582031\n",
      "        - 0.4696979522705078\n",
      "        - 0.39983177185058594\n",
      "        - -0.06651043891906738\n",
      "        - 0.28008079528808594\n",
      "        - 0.3716278076171875\n",
      "        - 0.5353050231933594\n",
      "        - 0.2709026336669922\n",
      "        - 0.6051921844482422\n",
      "        - 0.28862953186035156\n",
      "        - -0.46527862548828125\n",
      "        - 0.36500978469848633\n",
      "        - 0.4029808044433594\n",
      "        - 0.26374244689941406\n",
      "        - 0.5730834007263184\n",
      "        - 0.3269824981689453\n",
      "        - 0.3169231414794922\n",
      "        - 0.40723419189453125\n",
      "        - 0.28316307067871094\n",
      "        - 0.16424942016601562\n",
      "        - 0.20142745971679688\n",
      "        - 0.4522075653076172\n",
      "        - 2.9567394256591797\n",
      "        - 0.4540901184082031\n",
      "        - 0.4128074645996094\n",
      "        - 0.5258750915527344\n",
      "        - 0.032756805419921875\n",
      "        - 0.25188446044921875\n",
      "        - 0.4061851501464844\n",
      "        - 0.40297698974609375\n",
      "        - 0.6053924560546875\n",
      "        - 0.6538758277893066\n",
      "        - 0.15996170043945312\n",
      "        - -0.24343109130859375\n",
      "        - 0.42829132080078125\n",
      "        - 0.7137832641601562\n",
      "        - 0.346221923828125\n",
      "        - 0.5561275482177734\n",
      "        - 0.4266700744628906\n",
      "        - -0.11553764343261719\n",
      "        - 0.5350761413574219\n",
      "        - 0.2416229248046875\n",
      "        - -0.40024518966674805\n",
      "        - 0.3175315856933594\n",
      "        - 0.02919769287109375\n",
      "        - 1.167938232421875\n",
      "        - 0.6197948455810547\n",
      "        - 0.594482421875\n",
      "        - 0.5237350463867188\n",
      "        - 0.2635917663574219\n",
      "        - 0.33574676513671875\n",
      "        - 0.2947578430175781\n",
      "        - 0.3241310119628906\n",
      "        - 0.4134101867675781\n",
      "        - -0.2273322343826294\n",
      "        - 0.3481731414794922\n",
      "        - -0.13405227661132812\n",
      "        - 0.6495456695556641\n",
      "        - 0.6677761077880859\n",
      "        - 0.21611785888671875\n",
      "        - 0.2148609161376953\n",
      "        - 0.5423126220703125\n",
      "        - 0.3116302490234375\n",
      "        - 0.34461307525634766\n",
      "        - 0.34447669982910156\n",
      "        - 0.5158290863037109\n",
      "        - 0.1532745361328125\n",
      "        - 0.4743690490722656\n",
      "        - -0.05344200134277344\n",
      "        - -0.4900970458984375\n",
      "        - 0.11573410034179688\n",
      "        - 0.024169921875\n",
      "        - 0.23822784423828125\n",
      "        - 0.6084671020507812\n",
      "        - 0.014235496520996094\n",
      "        - 0.4392242431640625\n",
      "        - -0.005064427852630615\n",
      "        - 0.6006050109863281\n",
      "        - 0.7535552978515625\n",
      "        - 0.3089637756347656\n",
      "        - 0.48865509033203125\n",
      "        - 0.32329750061035156\n",
      "        - 0.20598220825195312\n",
      "        - 0.5254135131835938\n",
      "        - 0.2841625213623047\n",
      "        - -0.030889511108398438\n",
      "        - 0.4560585021972656\n",
      "        - 0.8523292541503906\n",
      "        - 0.5244026184082031\n",
      "        - 0.5842475891113281\n",
      "        - 0.34014129638671875\n",
      "        - 0.23991012573242188\n",
      "        - 0.3436012268066406\n",
      "        - -0.04498291015625\n",
      "        - 0.17717599868774414\n",
      "        - 0.406005859375\n",
      "        - 0.29052734375\n",
      "        - 0.3949718475341797\n",
      "        - -0.3077220916748047\n",
      "        - 0.12125396728515625\n",
      "        - 0.11573410034179688\n",
      "        - 0.5413150787353516\n",
      "        - 0.2692737579345703\n",
      "        - 0.45104217529296875\n",
      "        - 0.47867393493652344\n",
      "        - 0.45966339111328125\n",
      "        - 0.3695640563964844\n",
      "        - 0.4302864074707031\n",
      "        - 0.5579814910888672\n",
      "        - 0.1005096435546875\n",
      "        - 0.2944488525390625\n",
      "        - 0.4487037658691406\n",
      "        - 0.3552713394165039\n",
      "        - 0.18083572387695312\n",
      "        - -0.10309219360351562\n",
      "        - 0.4505767822265625\n",
      "        - 0.19531631469726562\n",
      "        - -0.03254508972167969\n",
      "        - 1.410430908203125\n",
      "        - 0.2861900329589844\n",
      "        - 0.18984603881835938\n",
      "        - 0.7937469482421875\n",
      "        - 0.2027740478515625\n",
      "        - 0.8510608673095703\n",
      "        - 1.1922931671142578\n",
      "        - -0.046457529067993164\n",
      "        - 0.12536239624023438\n",
      "        - 0.5700092315673828\n",
      "        - 0.744354248046875\n",
      "        - 0.37152099609375\n",
      "        - 0.20589828491210938\n",
      "        - 0.5972501039505005\n",
      "        - 0.5045814514160156\n",
      "        - 0.1444091796875\n",
      "        - 0.4931755065917969\n",
      "        - 0.2621135711669922\n",
      "        - -0.7350654602050781\n",
      "        - 0.6330337524414062\n",
      "        - 0.40340614318847656\n",
      "        - 0.29228973388671875\n",
      "        - 0.4230022430419922\n",
      "        - 0.32201576232910156\n",
      "        - 0.8281631469726562\n",
      "        - 0.6881637573242188\n",
      "        - 0.6431083679199219\n",
      "        - 0.41234779357910156\n",
      "        - 0.6343803405761719\n",
      "        - 0.42087364196777344\n",
      "        - 0.5466136932373047\n",
      "        - 0.5235958099365234\n",
      "        - 0.3691825866699219\n",
      "        - 0.3336753845214844\n",
      "        - 0.28585243225097656\n",
      "        - 0.11140251159667969\n",
      "        - 0.3688812255859375\n",
      "        - 0.33032989501953125\n",
      "        - 0.18317413330078125\n",
      "        - 0.26031494140625\n",
      "        - 0.38843536376953125\n",
      "        - 0.3789710998535156\n",
      "    num_agent_steps_sampled: 5500\n",
      "    num_agent_steps_trained: 512256\n",
      "    num_steps_sampled: 5500\n",
      "    num_steps_trained: 512256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 2001\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 9.621739130434781\n",
      "    ram_util_percent: 1.704347826086957\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21236806972114158\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.23414825652841006\n",
      "    mean_inference_ms: 1.9235404391232818\n",
      "    mean_raw_obs_processing_ms: 0.5901956753485027\n",
      "  time_since_restore: 79.81913661956787\n",
      "  time_this_iter_s: 16.26930069923401\n",
      "  time_total_s: 79.81913661956787\n",
      "  timers:\n",
      "    learn_throughput: 51557.756\n",
      "    learn_time_ms: 4.965\n",
      "    load_throughput: 642190.086\n",
      "    load_time_ms: 0.399\n",
      "    update_time_ms: 2.819\n",
      "  timestamp: 1647533737\n",
      "  timesteps_since_restore: 1280\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 5500\n",
      "  training_iteration: 5\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:15:39 (running for 00:01:36.02)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         79.8191</td><td style=\"text-align: right;\">5500</td><td style=\"text-align: right;\">-1420.23</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:15:44 (running for 00:01:41.03)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         79.8191</td><td style=\"text-align: right;\">5500</td><td style=\"text-align: right;\">-1420.23</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:15:49 (running for 00:01:46.04)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         79.8191</td><td style=\"text-align: right;\">5500</td><td style=\"text-align: right;\">-1420.23</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 6500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-15-53\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -907.2904437188645\n",
      "  episode_reward_mean: -1393.9137075550916\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 32\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 6500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 0.13424217700958252\n",
      "          mean_q: -33.94573211669922\n",
      "          min_q: -62.62337875366211\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.2708740234375\n",
      "        - 0.4028434753417969\n",
      "        - -0.13929367065429688\n",
      "        - -0.17090988159179688\n",
      "        - -0.2635478973388672\n",
      "        - -0.4737281799316406\n",
      "        - -0.5901985168457031\n",
      "        - -0.19623184204101562\n",
      "        - 0.16368484497070312\n",
      "        - -0.22826576232910156\n",
      "        - -0.059947967529296875\n",
      "        - 0.6087055206298828\n",
      "        - -0.16798019409179688\n",
      "        - 0.03287506103515625\n",
      "        - 0.07963180541992188\n",
      "        - 0.07149887084960938\n",
      "        - 0.005603790283203125\n",
      "        - 0.34830474853515625\n",
      "        - -0.039005279541015625\n",
      "        - -0.32115674018859863\n",
      "        - -0.35000038146972656\n",
      "        - -0.32685089111328125\n",
      "        - 0.2871589660644531\n",
      "        - -0.1747589111328125\n",
      "        - -0.13214492797851562\n",
      "        - -0.010456085205078125\n",
      "        - -0.14025497436523438\n",
      "        - 0.49163246154785156\n",
      "        - 0.027385711669921875\n",
      "        - 0.16896438598632812\n",
      "        - -0.08939361572265625\n",
      "        - 0.35878562927246094\n",
      "        - 0.2790508270263672\n",
      "        - -0.09457969665527344\n",
      "        - 0.5108718872070312\n",
      "        - -0.07633590698242188\n",
      "        - -0.9033203125\n",
      "        - 0.12485122680664062\n",
      "        - -0.6518974304199219\n",
      "        - -0.5255584716796875\n",
      "        - -0.06348037719726562\n",
      "        - -0.157379150390625\n",
      "        - -0.22217559814453125\n",
      "        - -0.23853683471679688\n",
      "        - -0.24421310424804688\n",
      "        - 0.2176532745361328\n",
      "        - 0.07179641723632812\n",
      "        - -0.036884307861328125\n",
      "        - -1.0427131652832031\n",
      "        - -0.35820603370666504\n",
      "        - -0.20067214965820312\n",
      "        - 0.14282989501953125\n",
      "        - -0.21844863891601562\n",
      "        - -0.16211318969726562\n",
      "        - -0.3186302185058594\n",
      "        - 0.34329986572265625\n",
      "        - -0.7535400390625\n",
      "        - -0.09109115600585938\n",
      "        - 0.030918121337890625\n",
      "        - -0.05472755432128906\n",
      "        - -0.5756702423095703\n",
      "        - -0.09323501586914062\n",
      "        - -0.06508255004882812\n",
      "        - -0.5058135986328125\n",
      "        - -0.4846343994140625\n",
      "        - -0.21027183532714844\n",
      "        - -0.10105365514755249\n",
      "        - -0.13275909423828125\n",
      "        - -0.13060379028320312\n",
      "        - 0.3748130798339844\n",
      "        - -0.11003494262695312\n",
      "        - 0.17071914672851562\n",
      "        - 0.046192169189453125\n",
      "        - 0.01627349853515625\n",
      "        - 0.34081459045410156\n",
      "        - 0.2799034118652344\n",
      "        - -0.4242515563964844\n",
      "        - -0.5845909118652344\n",
      "        - -0.3388938903808594\n",
      "        - -0.2936744689941406\n",
      "        - -0.05786895751953125\n",
      "        - 0.44652557373046875\n",
      "        - -0.1179962158203125\n",
      "        - -0.3437614440917969\n",
      "        - 0.023956298828125\n",
      "        - 1.1023235321044922\n",
      "        - 0.14938735961914062\n",
      "        - 0.661895751953125\n",
      "        - 0.2624931335449219\n",
      "        - 0.5773544311523438\n",
      "        - -0.18505096435546875\n",
      "        - 0.2960929870605469\n",
      "        - 0.07515335083007812\n",
      "        - -0.14628219604492188\n",
      "        - -0.42575836181640625\n",
      "        - 0.49559593200683594\n",
      "        - 0.49505615234375\n",
      "        - -0.2887306213378906\n",
      "        - -0.1433582305908203\n",
      "        - 0.8895988464355469\n",
      "        - -0.1720256805419922\n",
      "        - 0.5908756256103516\n",
      "        - 0.012935638427734375\n",
      "        - 0.5077743530273438\n",
      "        - -0.1720256805419922\n",
      "        - -0.4277973175048828\n",
      "        - 0.43572044372558594\n",
      "        - -0.05637359619140625\n",
      "        - -0.10841627418994904\n",
      "        - -0.4362907409667969\n",
      "        - -0.22866439819335938\n",
      "        - -0.37755584716796875\n",
      "        - -0.587005615234375\n",
      "        - -0.150909423828125\n",
      "        - 0.4603996276855469\n",
      "        - 0.08470916748046875\n",
      "        - -0.16742324829101562\n",
      "        - 0.039783477783203125\n",
      "        - 0.2101001739501953\n",
      "        - -0.9178123474121094\n",
      "        - 0.2958335876464844\n",
      "        - -1.2216300964355469\n",
      "        - 0.4110527038574219\n",
      "        - -0.7887668609619141\n",
      "        - -0.051158905029296875\n",
      "        - 0.20926284790039062\n",
      "        - -0.4156913757324219\n",
      "        - -0.4158515930175781\n",
      "        - 4.192600250244141\n",
      "        - -0.10556977987289429\n",
      "        - -0.2806892395019531\n",
      "        - 0.47456932067871094\n",
      "        - -0.3927574157714844\n",
      "        - -0.5122413635253906\n",
      "        - -0.3624420166015625\n",
      "        - 0.16139984130859375\n",
      "        - -0.42008209228515625\n",
      "        - -0.9586734771728516\n",
      "        - -0.24014663696289062\n",
      "        - -0.1276416778564453\n",
      "        - 0.6456451416015625\n",
      "        - -0.04640883207321167\n",
      "        - -0.5387458801269531\n",
      "        - -0.49137115478515625\n",
      "        - -0.4133338928222656\n",
      "        - 0.24598312377929688\n",
      "        - 0.19084930419921875\n",
      "        - -0.01761627197265625\n",
      "        - -0.8158760070800781\n",
      "        - -12.158205032348633\n",
      "        - -0.15726852416992188\n",
      "        - -0.25034332275390625\n",
      "        - -0.12431716918945312\n",
      "        - -0.21137619018554688\n",
      "        - 0.6105480194091797\n",
      "        - -0.2592124938964844\n",
      "        - -0.14330673217773438\n",
      "        - -0.70074462890625\n",
      "        - 0.29901123046875\n",
      "        - -2.1239776611328125\n",
      "        - -0.47907257080078125\n",
      "        - 0.005115509033203125\n",
      "        - -0.0618896484375\n",
      "        - -0.19696807861328125\n",
      "        - 0.19433212280273438\n",
      "        - -0.1706829071044922\n",
      "        - -0.2520561218261719\n",
      "        - -17.404781341552734\n",
      "        - 0.21431350708007812\n",
      "        - -1.3235206604003906\n",
      "        - 0.05129282921552658\n",
      "        - -0.3208198547363281\n",
      "        - -0.5845909118652344\n",
      "        - -0.1571197509765625\n",
      "        - -0.15502166748046875\n",
      "        - -0.494537353515625\n",
      "        - -0.16431617736816406\n",
      "        - -0.15578079223632812\n",
      "        - 0.4991321563720703\n",
      "        - 0.054779052734375\n",
      "        - 0.37535667419433594\n",
      "        - 0.4889087677001953\n",
      "        - -0.2986946105957031\n",
      "        - -0.5022315979003906\n",
      "        - 0.4588661193847656\n",
      "        - -0.20201873779296875\n",
      "        - -0.018505096435546875\n",
      "        - -0.3556861877441406\n",
      "        - 0.2641181945800781\n",
      "        - -0.4206695556640625\n",
      "        - -0.05652046203613281\n",
      "        - -0.7890815734863281\n",
      "        - -0.09018325805664062\n",
      "        - 0.42513084411621094\n",
      "        - -0.2565040588378906\n",
      "        - -0.01177215576171875\n",
      "        - -0.10477447509765625\n",
      "        - -0.17029571533203125\n",
      "        - -16.769826889038086\n",
      "        - -0.14353561401367188\n",
      "        - -0.9586734771728516\n",
      "        - 0.1507110595703125\n",
      "        - 0.18444442749023438\n",
      "        - -0.2888946533203125\n",
      "        - 0.44995880126953125\n",
      "        - -0.13116073608398438\n",
      "        - 0.42343902587890625\n",
      "        - -0.8405418395996094\n",
      "        - -0.6083927154541016\n",
      "        - 0.42675209045410156\n",
      "        - -0.22057533264160156\n",
      "        - 0.05129282921552658\n",
      "        - 0.5026359558105469\n",
      "        - 0.027252197265625\n",
      "        - 0.011447906494140625\n",
      "        - -0.046009063720703125\n",
      "        - -0.07101058959960938\n",
      "        - 0.42539024353027344\n",
      "        - 0.241058349609375\n",
      "        - -0.07101058959960938\n",
      "        - -0.4445915222167969\n",
      "        - -0.5167593955993652\n",
      "        - 0.039470672607421875\n",
      "        - 0.4136619567871094\n",
      "        - -0.29155731201171875\n",
      "        - 0.41552734375\n",
      "        - 0.0088043212890625\n",
      "        - -1.0357551574707031\n",
      "        - -0.2761554718017578\n",
      "        - 0.1077117919921875\n",
      "        - -0.05669403076171875\n",
      "        - -0.13116073608398438\n",
      "        - -0.459381103515625\n",
      "        - 0.07190322875976562\n",
      "        - 0.39839935302734375\n",
      "        - -0.2565040588378906\n",
      "        - -0.08869552612304688\n",
      "        - -0.16167449951171875\n",
      "        - -0.554931640625\n",
      "        - -0.5665187835693359\n",
      "        - -0.06679725646972656\n",
      "        - -0.055400848388671875\n",
      "        - 0.2678794860839844\n",
      "        - -0.06538772583007812\n",
      "        - -0.08333778381347656\n",
      "        - 0.7429428100585938\n",
      "        - -0.14002037048339844\n",
      "        - 0.057140350341796875\n",
      "        - -0.20032501220703125\n",
      "        - -0.15124130249023438\n",
      "        - -0.10792160034179688\n",
      "        - -0.28694915771484375\n",
      "        - -0.3322153091430664\n",
      "        - -0.3409709930419922\n",
      "        - -0.5709867477416992\n",
      "        - 0.28261566162109375\n",
      "    num_agent_steps_sampled: 6500\n",
      "    num_agent_steps_trained: 640256\n",
      "    num_steps_sampled: 6500\n",
      "    num_steps_trained: 640256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 2501\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 7.891666666666666\n",
      "    ram_util_percent: 1.7\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.21043904042272243\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.23054880466077088\n",
      "    mean_inference_ms: 1.8241473060144235\n",
      "    mean_raw_obs_processing_ms: 0.5792616002983999\n",
      "  time_since_restore: 96.24966669082642\n",
      "  time_this_iter_s: 16.430530071258545\n",
      "  time_total_s: 96.24966669082642\n",
      "  timers:\n",
      "    learn_throughput: 50501.934\n",
      "    learn_time_ms: 5.069\n",
      "    load_throughput: 631724.318\n",
      "    load_time_ms: 0.405\n",
      "    update_time_ms: 2.992\n",
      "  timestamp: 1647533753\n",
      "  timesteps_since_restore: 1536\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 6500\n",
      "  training_iteration: 6\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:15:54 (running for 00:01:51.47)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         96.2497</td><td style=\"text-align: right;\">6500</td><td style=\"text-align: right;\">-1393.91</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:15:59 (running for 00:01:56.51)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         96.2497</td><td style=\"text-align: right;\">6500</td><td style=\"text-align: right;\">-1393.91</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:16:04 (running for 00:02:01.51)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         96.2497</td><td style=\"text-align: right;\">6500</td><td style=\"text-align: right;\">-1393.91</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:16:09 (running for 00:02:06.52)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         96.2497</td><td style=\"text-align: right;\">6500</td><td style=\"text-align: right;\">-1393.91</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 7500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-16-10\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -907.2904437188645\n",
      "  episode_reward_mean: -1367.3722973278705\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 36\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 7500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: -0.07226397097110748\n",
      "          mean_q: -38.61705780029297\n",
      "          min_q: -62.74257278442383\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.4913673400878906\n",
      "        - 0.906005859375\n",
      "        - 1.119384765625\n",
      "        - 0.2799644470214844\n",
      "        - 0.5257644653320312\n",
      "        - 0.45862579345703125\n",
      "        - 0.8764266967773438\n",
      "        - 1.1780414581298828\n",
      "        - 0.08149147033691406\n",
      "        - 0.76214599609375\n",
      "        - 0.5816993713378906\n",
      "        - 1.0773963928222656\n",
      "        - 0.6199378967285156\n",
      "        - 0.27428436279296875\n",
      "        - -0.13483047485351562\n",
      "        - 0.6761932373046875\n",
      "        - 0.7064971923828125\n",
      "        - 0.8147926330566406\n",
      "        - 1.0188236236572266\n",
      "        - 0.15378952026367188\n",
      "        - 1.0599250793457031\n",
      "        - -0.02597808837890625\n",
      "        - 0.19540786743164062\n",
      "        - 0.45433807373046875\n",
      "        - 0.3969135284423828\n",
      "        - 0.4591636657714844\n",
      "        - 0.60369873046875\n",
      "        - 0.33837890625\n",
      "        - 0.7828483581542969\n",
      "        - 0.2073688507080078\n",
      "        - 0.6028938293457031\n",
      "        - 0.4106788635253906\n",
      "        - 0.4232521057128906\n",
      "        - 0.8275604248046875\n",
      "        - 0.2676200866699219\n",
      "        - 0.378326416015625\n",
      "        - 0.4054450988769531\n",
      "        - 0.7604904174804688\n",
      "        - 0.1980438232421875\n",
      "        - 0.41976165771484375\n",
      "        - 0.7543754577636719\n",
      "        - 0.5859107971191406\n",
      "        - 1.2176132202148438\n",
      "        - 0.8084335327148438\n",
      "        - 1.0285663604736328\n",
      "        - -0.28977203369140625\n",
      "        - 0.3200569152832031\n",
      "        - 0.6964683532714844\n",
      "        - 0.34041595458984375\n",
      "        - 0.7429275512695312\n",
      "        - 0.48249053955078125\n",
      "        - -0.6721935272216797\n",
      "        - 0.21886444091796875\n",
      "        - 1.0871734619140625\n",
      "        - 0.446136474609375\n",
      "        - 0.4845771789550781\n",
      "        - 1.0651817321777344\n",
      "        - 0.8029327392578125\n",
      "        - 0.7191238403320312\n",
      "        - 1.2262992858886719\n",
      "        - 0.40300750732421875\n",
      "        - -0.07044588029384613\n",
      "        - 1.1165695190429688\n",
      "        - 0.45763397216796875\n",
      "        - 0.297393798828125\n",
      "        - 1.3618202209472656\n",
      "        - 1.0368270874023438\n",
      "        - 1.2363967895507812\n",
      "        - 0.5157623291015625\n",
      "        - 0.5283432006835938\n",
      "        - 0.8946247100830078\n",
      "        - 0.6095619201660156\n",
      "        - 0.414642333984375\n",
      "        - 0.8651809692382812\n",
      "        - 1.2984619140625\n",
      "        - 0.14619064331054688\n",
      "        - 0.5643768310546875\n",
      "        - 0.3885841369628906\n",
      "        - 0.3220863342285156\n",
      "        - 0.3895606994628906\n",
      "        - 0.1718292236328125\n",
      "        - 0.2609443664550781\n",
      "        - 0.4991722106933594\n",
      "        - 1.1723880767822266\n",
      "        - 0.16496849060058594\n",
      "        - 0.24085235595703125\n",
      "        - 0.25193214416503906\n",
      "        - 0.7003059387207031\n",
      "        - 0.4038734436035156\n",
      "        - 1.1318855285644531\n",
      "        - 0.5838127136230469\n",
      "        - 0.6475563049316406\n",
      "        - 0.1154022216796875\n",
      "        - 0.6485824584960938\n",
      "        - 0.9690093994140625\n",
      "        - 0.5384063720703125\n",
      "        - 0.35452842712402344\n",
      "        - 0.031375885009765625\n",
      "        - 0.2637977600097656\n",
      "        - 0.4887237548828125\n",
      "        - 0.6006622314453125\n",
      "        - 0.8880577087402344\n",
      "        - 0.5349044799804688\n",
      "        - 0.35768890380859375\n",
      "        - 0.4037895202636719\n",
      "        - 0.2815227508544922\n",
      "        - 0.4814453125\n",
      "        - 1.1436653137207031\n",
      "        - 0.9718055725097656\n",
      "        - 0.9973068237304688\n",
      "        - 0.2618751525878906\n",
      "        - 1.081146240234375\n",
      "        - 1.0068435668945312\n",
      "        - 0.8684425354003906\n",
      "        - 0.3421821594238281\n",
      "        - 0.5574226379394531\n",
      "        - 0.18641281127929688\n",
      "        - 0.5939674377441406\n",
      "        - 0.4213409423828125\n",
      "        - 0.8155517578125\n",
      "        - 0.4820365905761719\n",
      "        - 0.9857654571533203\n",
      "        - 1.0232925415039062\n",
      "        - 0.5674362182617188\n",
      "        - 0.3325538635253906\n",
      "        - 0.613311767578125\n",
      "        - 0.37876129150390625\n",
      "        - 0.41510772705078125\n",
      "        - 0.912750244140625\n",
      "        - -0.365478515625\n",
      "        - 0.1942291259765625\n",
      "        - 0.45404815673828125\n",
      "        - 0.2328624725341797\n",
      "        - 0.2637214660644531\n",
      "        - 0.40300750732421875\n",
      "        - 0.375518798828125\n",
      "        - 0.4728546142578125\n",
      "        - 1.095062255859375\n",
      "        - 0.3477954864501953\n",
      "        - 0.9343109130859375\n",
      "        - -0.09941315650939941\n",
      "        - 1.1777763366699219\n",
      "        - -0.06858015060424805\n",
      "        - 1.03912353515625\n",
      "        - 0.61236572265625\n",
      "        - 0.3043632507324219\n",
      "        - 0.8581085205078125\n",
      "        - 0.3429832458496094\n",
      "        - 0.32498931884765625\n",
      "        - 1.450052261352539\n",
      "        - 1.0435905456542969\n",
      "        - 1.0032615661621094\n",
      "        - -0.0652923583984375\n",
      "        - 0.4426460266113281\n",
      "        - -0.06641769409179688\n",
      "        - 0.2216339111328125\n",
      "        - 1.1518936157226562\n",
      "        - 1.009979248046875\n",
      "        - 0.2765464782714844\n",
      "        - 1.2500534057617188\n",
      "        - 0.3189811706542969\n",
      "        - 0.3516731262207031\n",
      "        - 0.7871437072753906\n",
      "        - 0.9619369506835938\n",
      "        - 0.2905712127685547\n",
      "        - 1.0091323852539062\n",
      "        - 0.12091827392578125\n",
      "        - 0.2008819580078125\n",
      "        - -0.053267478942871094\n",
      "        - 0.683197021484375\n",
      "        - -0.07044588029384613\n",
      "        - 0.9790687561035156\n",
      "        - 0.5469608306884766\n",
      "        - 0.4468421936035156\n",
      "        - 0.6663017272949219\n",
      "        - 0.3614845275878906\n",
      "        - 0.24052047729492188\n",
      "        - 0.39398193359375\n",
      "        - 0.44587135314941406\n",
      "        - 0.32082557678222656\n",
      "        - 1.2689552307128906\n",
      "        - 1.1381416320800781\n",
      "        - 0.59393310546875\n",
      "        - 0.4881095886230469\n",
      "        - 0.17378807067871094\n",
      "        - 0.8087234497070312\n",
      "        - 0.26068115234375\n",
      "        - 0.5150184631347656\n",
      "        - 0.6367721557617188\n",
      "        - 0.6445274353027344\n",
      "        - 0.1269516944885254\n",
      "        - 0.4387550354003906\n",
      "        - 1.0095787048339844\n",
      "        - -0.3179168701171875\n",
      "        - 0.6638946533203125\n",
      "        - 0.3552055358886719\n",
      "        - 0.44939422607421875\n",
      "        - 0.3543128967285156\n",
      "        - 0.9670066833496094\n",
      "        - 1.1408729553222656\n",
      "        - 0.7712936401367188\n",
      "        - 0.307464599609375\n",
      "        - 0.4781227111816406\n",
      "        - 1.548004150390625\n",
      "        - 0.2880363464355469\n",
      "        - 0.11587905883789062\n",
      "        - 0.4985771179199219\n",
      "        - 1.069366455078125\n",
      "        - 1.2351264953613281\n",
      "        - 0.5126724243164062\n",
      "        - 0.48314666748046875\n",
      "        - 0.4133892059326172\n",
      "        - 0.2596893310546875\n",
      "        - 0.18421173095703125\n",
      "        - 0.2880363464355469\n",
      "        - 0.4694480895996094\n",
      "        - 0.8581085205078125\n",
      "        - 0.3378715515136719\n",
      "        - 0.7050018310546875\n",
      "        - 0.80859375\n",
      "        - 0.4787750244140625\n",
      "        - 0.5299453735351562\n",
      "        - 0.5521469116210938\n",
      "        - 0.7745285034179688\n",
      "        - 1.010934829711914\n",
      "        - 0.3986778259277344\n",
      "        - 0.292327880859375\n",
      "        - 0.4715385437011719\n",
      "        - 0.3627967834472656\n",
      "        - 0.6837539672851562\n",
      "        - 1.2070846557617188\n",
      "        - 0.223388671875\n",
      "        - 0.4079456329345703\n",
      "        - 0.5140266418457031\n",
      "        - 0.34922027587890625\n",
      "        - 0.4097023010253906\n",
      "        - 0.2155609130859375\n",
      "        - 0.0946044921875\n",
      "        - 0.5988922119140625\n",
      "        - 0.2863655090332031\n",
      "        - 0.47850799560546875\n",
      "        - 0.45014190673828125\n",
      "        - 0.7831573486328125\n",
      "        - 0.6321868896484375\n",
      "        - 0.5017776489257812\n",
      "        - 0.9304180145263672\n",
      "        - 0.47629547119140625\n",
      "        - 0.3111112117767334\n",
      "        - 1.3321456909179688\n",
      "        - -0.10408782958984375\n",
      "        - 0.5755538940429688\n",
      "        - -0.026391983032226562\n",
      "        - 1.0449180603027344\n",
      "        - 0.5141983032226562\n",
      "        - 0.1673431396484375\n",
      "        - 0.5475654602050781\n",
      "    num_agent_steps_sampled: 7500\n",
      "    num_agent_steps_trained: 768256\n",
      "    num_steps_sampled: 7500\n",
      "    num_steps_trained: 768256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 3001\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 8.31304347826087\n",
      "    ram_util_percent: 1.7000000000000004\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.2092397399958984\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.22845379723178347\n",
      "    mean_inference_ms: 1.7699399912476563\n",
      "    mean_raw_obs_processing_ms: 0.5729369168097852\n",
      "  time_since_restore: 112.52281522750854\n",
      "  time_this_iter_s: 16.27314853668213\n",
      "  time_total_s: 112.52281522750854\n",
      "  timers:\n",
      "    learn_throughput: 51394.142\n",
      "    learn_time_ms: 4.981\n",
      "    load_throughput: 645782.056\n",
      "    load_time_ms: 0.396\n",
      "    update_time_ms: 2.886\n",
      "  timestamp: 1647533770\n",
      "  timesteps_since_restore: 1792\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 7500\n",
      "  training_iteration: 7\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:16:15 (running for 00:02:11.79)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         112.523</td><td style=\"text-align: right;\">7500</td><td style=\"text-align: right;\">-1367.37</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:16:20 (running for 00:02:16.83)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         112.523</td><td style=\"text-align: right;\">7500</td><td style=\"text-align: right;\">-1367.37</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:16:25 (running for 00:02:21.83)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         112.523</td><td style=\"text-align: right;\">7500</td><td style=\"text-align: right;\">-1367.37</td><td style=\"text-align: right;\">             -907.29</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 8500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-16-26\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2.9262292385332898\n",
      "  episode_reward_mean: -1318.1872862066002\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 42\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 8500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 0.34953662753105164\n",
      "          mean_q: -42.73516845703125\n",
      "          min_q: -73.66866302490234\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.5756015777587891\n",
      "        - 0.2679634094238281\n",
      "        - 0.4362506866455078\n",
      "        - 0.0234832763671875\n",
      "        - 0.16850662231445312\n",
      "        - -0.0361175537109375\n",
      "        - 0.7524833679199219\n",
      "        - 0.2939453125\n",
      "        - 0.3799171447753906\n",
      "        - 0.7522659301757812\n",
      "        - -0.1458587646484375\n",
      "        - 0.6802406311035156\n",
      "        - 0.35497283935546875\n",
      "        - 0.04974365234375\n",
      "        - 0.14438247680664062\n",
      "        - -0.10764312744140625\n",
      "        - 0.25396156311035156\n",
      "        - -0.6186866760253906\n",
      "        - 0.534332275390625\n",
      "        - 0.22491836547851562\n",
      "        - -0.5846290588378906\n",
      "        - 0.22834396362304688\n",
      "        - 0.039569854736328125\n",
      "        - 0.4159965515136719\n",
      "        - 0.22364425659179688\n",
      "        - -0.23127365112304688\n",
      "        - -0.1334991455078125\n",
      "        - 0.17492294311523438\n",
      "        - 0.3753204345703125\n",
      "        - 0.26505279541015625\n",
      "        - 0.25495147705078125\n",
      "        - 0.0585479736328125\n",
      "        - -1.6266250610351562\n",
      "        - -0.2853965759277344\n",
      "        - 0.9861373901367188\n",
      "        - -0.1273345947265625\n",
      "        - -0.4255104064941406\n",
      "        - 0.2785301208496094\n",
      "        - 0.3698539733886719\n",
      "        - 0.5210037231445312\n",
      "        - 0.19986534118652344\n",
      "        - -0.39359283447265625\n",
      "        - 0.2959480285644531\n",
      "        - 0.33103179931640625\n",
      "        - 0.4204444885253906\n",
      "        - 0.2364654541015625\n",
      "        - 0.34386444091796875\n",
      "        - -0.12158989906311035\n",
      "        - -0.49572157859802246\n",
      "        - 0.16120147705078125\n",
      "        - 0.3067665100097656\n",
      "        - 0.0217742919921875\n",
      "        - 1.1085662841796875\n",
      "        - 0.129791259765625\n",
      "        - -0.015716552734375\n",
      "        - 0.854888916015625\n",
      "        - 0.8238582611083984\n",
      "        - 0.2524375915527344\n",
      "        - -0.047657012939453125\n",
      "        - 0.5654678344726562\n",
      "        - 0.4261322021484375\n",
      "        - 0.10760879516601562\n",
      "        - -0.02126312255859375\n",
      "        - -0.88421630859375\n",
      "        - -0.062413692474365234\n",
      "        - 0.3347892761230469\n",
      "        - 0.19726181030273438\n",
      "        - 0.024318695068359375\n",
      "        - -0.2538185119628906\n",
      "        - 0.41799163818359375\n",
      "        - 0.17485809326171875\n",
      "        - -0.5236337184906006\n",
      "        - 0.3522529602050781\n",
      "        - 0.14482498168945312\n",
      "        - 0.07207870483398438\n",
      "        - 0.4378318786621094\n",
      "        - -0.07091537863016129\n",
      "        - 0.5202064514160156\n",
      "        - 0.015687942504882812\n",
      "        - 0.19831466674804688\n",
      "        - 0.3038139343261719\n",
      "        - -0.1987285614013672\n",
      "        - 0.033742502331733704\n",
      "        - -0.008457183837890625\n",
      "        - 0.27153778076171875\n",
      "        - 0.14904022216796875\n",
      "        - -0.7295074462890625\n",
      "        - 0.3436927795410156\n",
      "        - 0.17331886291503906\n",
      "        - -0.10507965087890625\n",
      "        - -0.20063018798828125\n",
      "        - 0.29425048828125\n",
      "        - -0.1930694580078125\n",
      "        - 0.49847412109375\n",
      "        - -0.253753662109375\n",
      "        - -0.5622024536132812\n",
      "        - 0.4290924072265625\n",
      "        - 0.3683586120605469\n",
      "        - 0.16778945922851562\n",
      "        - 0.32489776611328125\n",
      "        - 0.46875\n",
      "        - 0.401397705078125\n",
      "        - 0.29207611083984375\n",
      "        - 0.15832138061523438\n",
      "        - -0.18173980712890625\n",
      "        - 0.16805648803710938\n",
      "        - -0.29433441162109375\n",
      "        - -0.14078521728515625\n",
      "        - 0.2885093688964844\n",
      "        - -0.14426803588867188\n",
      "        - 0.3839530944824219\n",
      "        - 0.28221893310546875\n",
      "        - 0.11407089233398438\n",
      "        - -0.27437591552734375\n",
      "        - -0.8736495971679688\n",
      "        - 1.1908760070800781\n",
      "        - 0.21442031860351562\n",
      "        - 0.160186767578125\n",
      "        - 0.23459625244140625\n",
      "        - -0.022241592407226562\n",
      "        - 0.24342727661132812\n",
      "        - 0.01380157470703125\n",
      "        - -0.3029289245605469\n",
      "        - 0.20128631591796875\n",
      "        - 0.4347381591796875\n",
      "        - -0.392578125\n",
      "        - -0.07201766967773438\n",
      "        - 0.02042388916015625\n",
      "        - 0.47045135498046875\n",
      "        - 0.3366355895996094\n",
      "        - -0.13863372802734375\n",
      "        - 0.05069732666015625\n",
      "        - 0.40967559814453125\n",
      "        - 0.19379806518554688\n",
      "        - -0.04868316650390625\n",
      "        - 0.15558624267578125\n",
      "        - 0.1413116455078125\n",
      "        - 0.03338050842285156\n",
      "        - 0.13178634643554688\n",
      "        - 0.3305206298828125\n",
      "        - 0.32525634765625\n",
      "        - 0.2623786926269531\n",
      "        - -0.25527191162109375\n",
      "        - 0.29727935791015625\n",
      "        - 0.5854644775390625\n",
      "        - 0.2686271667480469\n",
      "        - 0.2665824890136719\n",
      "        - 0.0049984753131866455\n",
      "        - -0.07243317365646362\n",
      "        - -0.05648040771484375\n",
      "        - 0.09312820434570312\n",
      "        - -0.14160537719726562\n",
      "        - 0.26268768310546875\n",
      "        - 0.1379547119140625\n",
      "        - 0.29529571533203125\n",
      "        - -0.35955810546875\n",
      "        - 0.21493911743164062\n",
      "        - 0.26644134521484375\n",
      "        - 0.23711395263671875\n",
      "        - 0.20109176635742188\n",
      "        - -0.6837921142578125\n",
      "        - 0.685093879699707\n",
      "        - 0.30316925048828125\n",
      "        - 0.135009765625\n",
      "        - 0.30347251892089844\n",
      "        - 0.4281768798828125\n",
      "        - -0.21579742431640625\n",
      "        - 0.041126251220703125\n",
      "        - -26.485349655151367\n",
      "        - -0.502558708190918\n",
      "        - 0.26551055908203125\n",
      "        - 0.2889976501464844\n",
      "        - 0.21440505981445312\n",
      "        - -0.26500892639160156\n",
      "        - 0.2340087890625\n",
      "        - 0.481231689453125\n",
      "        - 0.0075687021017074585\n",
      "        - 0.35741424560546875\n",
      "        - 0.43259429931640625\n",
      "        - 0.7913494110107422\n",
      "        - 0.3604698181152344\n",
      "        - 0.14754104614257812\n",
      "        - 0.13353347778320312\n",
      "        - 0.5756454467773438\n",
      "        - 0.12736892700195312\n",
      "        - 0.08363723754882812\n",
      "        - 0.05492210388183594\n",
      "        - 1.6004486083984375\n",
      "        - 0.5915069580078125\n",
      "        - 0.18599700927734375\n",
      "        - 0.8280239105224609\n",
      "        - 0.25119781494140625\n",
      "        - -0.1539745330810547\n",
      "        - 0.18749237060546875\n",
      "        - 0.8267898559570312\n",
      "        - 0.5221405029296875\n",
      "        - 0.087005615234375\n",
      "        - 0.2192230224609375\n",
      "        - 0.08246612548828125\n",
      "        - -0.030279487371444702\n",
      "        - 0.435272216796875\n",
      "        - -0.036762237548828125\n",
      "        - 0.13998031616210938\n",
      "        - 0.40686798095703125\n",
      "        - 0.38405609130859375\n",
      "        - 0.7335700988769531\n",
      "        - 0.2823600769042969\n",
      "        - 1.3323822021484375\n",
      "        - 0.3974647521972656\n",
      "        - 0.0059906840324401855\n",
      "        - 0.7526092529296875\n",
      "        - 0.4069061279296875\n",
      "        - 0.19409942626953125\n",
      "        - 0.23055648803710938\n",
      "        - -0.5163497924804688\n",
      "        - 0.49091339111328125\n",
      "        - -0.07829666137695312\n",
      "        - 0.36450958251953125\n",
      "        - -0.0592041015625\n",
      "        - -0.07656097412109375\n",
      "        - 0.38730621337890625\n",
      "        - 0.036746978759765625\n",
      "        - -0.2346343994140625\n",
      "        - 0.17938613891601562\n",
      "        - 0.4520149230957031\n",
      "        - -0.068939208984375\n",
      "        - -0.07114028930664062\n",
      "        - 0.07264328002929688\n",
      "        - 0.7523097991943359\n",
      "        - 0.5066566467285156\n",
      "        - 0.11917877197265625\n",
      "        - -0.040073394775390625\n",
      "        - -0.06682968139648438\n",
      "        - -0.3617420196533203\n",
      "        - 0.48298847675323486\n",
      "        - 0.057308197021484375\n",
      "        - -1.0090713500976562\n",
      "        - -0.9156303405761719\n",
      "        - -1.491241455078125\n",
      "        - 0.46562957763671875\n",
      "        - 0.5096092224121094\n",
      "        - -0.1655712127685547\n",
      "        - 0.4683952331542969\n",
      "        - 0.06627273559570312\n",
      "        - -0.2812690734863281\n",
      "        - 0.01488494873046875\n",
      "        - -0.04553508758544922\n",
      "        - 0.9261207580566406\n",
      "        - 0.5572967529296875\n",
      "        - -0.837921142578125\n",
      "        - 0.2944831848144531\n",
      "        - 0.18691635131835938\n",
      "        - -0.018014028668403625\n",
      "        - 0.3326454162597656\n",
      "        - 0.19831466674804688\n",
      "        - 0.2668304443359375\n",
      "    num_agent_steps_sampled: 8500\n",
      "    num_agent_steps_trained: 896256\n",
      "    num_steps_sampled: 8500\n",
      "    num_steps_trained: 896256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 3501\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 8.14782608695652\n",
      "    ram_util_percent: 1.7000000000000004\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.20754802169954548\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.22565079791707593\n",
      "    mean_inference_ms: 1.7016123784477803\n",
      "    mean_raw_obs_processing_ms: 0.5645775571334531\n",
      "  time_since_restore: 128.7271249294281\n",
      "  time_this_iter_s: 16.204309701919556\n",
      "  time_total_s: 128.7271249294281\n",
      "  timers:\n",
      "    learn_throughput: 50992.156\n",
      "    learn_time_ms: 5.02\n",
      "    load_throughput: 652096.334\n",
      "    load_time_ms: 0.393\n",
      "    update_time_ms: 2.953\n",
      "  timestamp: 1647533786\n",
      "  timesteps_since_restore: 2048\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 8500\n",
      "  training_iteration: 8\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:16:30 (running for 00:02:27.08)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         128.727</td><td style=\"text-align: right;\">8500</td><td style=\"text-align: right;\">-1318.19</td><td style=\"text-align: right;\">            -2.92623</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:16:35 (running for 00:02:32.08)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         128.727</td><td style=\"text-align: right;\">8500</td><td style=\"text-align: right;\">-1318.19</td><td style=\"text-align: right;\">            -2.92623</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:16:40 (running for 00:02:37.09)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         128.727</td><td style=\"text-align: right;\">8500</td><td style=\"text-align: right;\">-1318.19</td><td style=\"text-align: right;\">            -2.92623</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 9500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-16-42\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2.9262292385332898\n",
      "  episode_reward_mean: -1298.6018515741314\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 46\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 9500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 0.6136445999145508\n",
      "          mean_q: -46.840728759765625\n",
      "          min_q: -81.53060150146484\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.07175707817077637\n",
      "        - 1.2354164123535156\n",
      "        - 0.4837455749511719\n",
      "        - 0.3504295349121094\n",
      "        - 0.45600128173828125\n",
      "        - 1.262969970703125\n",
      "        - 0.5240592956542969\n",
      "        - 0.8310832977294922\n",
      "        - 2.1847190856933594\n",
      "        - 0.44432830810546875\n",
      "        - 0.07288169860839844\n",
      "        - 1.2144203186035156\n",
      "        - 1.7632942199707031\n",
      "        - 1.378082275390625\n",
      "        - 0.6025810241699219\n",
      "        - 0.8797798156738281\n",
      "        - 0.4764060974121094\n",
      "        - 0.6758460998535156\n",
      "        - 0.33744049072265625\n",
      "        - -0.26873016357421875\n",
      "        - 0.5931053161621094\n",
      "        - 0.7372665405273438\n",
      "        - 1.0969390869140625\n",
      "        - 2.236034393310547\n",
      "        - 1.1699981689453125\n",
      "        - 0.13480645418167114\n",
      "        - 0.5103378295898438\n",
      "        - -0.19756075739860535\n",
      "        - 0.9667091369628906\n",
      "        - 0.061309814453125\n",
      "        - 0.3651275634765625\n",
      "        - 0.29012298583984375\n",
      "        - -0.26194000244140625\n",
      "        - 0.30810546875\n",
      "        - 0.7323684692382812\n",
      "        - -0.13146066665649414\n",
      "        - 1.5320510864257812\n",
      "        - 1.1232414245605469\n",
      "        - 1.2693710327148438\n",
      "        - 1.1503982543945312\n",
      "        - 0.487335205078125\n",
      "        - 1.1969108581542969\n",
      "        - -0.20246294140815735\n",
      "        - -0.25481414794921875\n",
      "        - 0.19942474365234375\n",
      "        - 1.4074592590332031\n",
      "        - 1.2500038146972656\n",
      "        - 0.22786712646484375\n",
      "        - 0.6523551940917969\n",
      "        - 0.48290252685546875\n",
      "        - -0.2688560485839844\n",
      "        - -0.13219688832759857\n",
      "        - -0.09317618608474731\n",
      "        - 0.5037117004394531\n",
      "        - 0.7821235656738281\n",
      "        - 0.9397659301757812\n",
      "        - 0.10402679443359375\n",
      "        - 0.23888778686523438\n",
      "        - 0.803985595703125\n",
      "        - 0.803985595703125\n",
      "        - 0.40212249755859375\n",
      "        - 1.0012550354003906\n",
      "        - 0.5378532409667969\n",
      "        - 0.8955497741699219\n",
      "        - -0.02924942970275879\n",
      "        - -0.5490226745605469\n",
      "        - 1.4199562072753906\n",
      "        - 0.3114356994628906\n",
      "        - 0.8907546997070312\n",
      "        - 0.5910491943359375\n",
      "        - -0.25487518310546875\n",
      "        - -30.91295051574707\n",
      "        - 1.1066093444824219\n",
      "        - 0.6439437866210938\n",
      "        - 0.9873733520507812\n",
      "        - 1.4458084106445312\n",
      "        - 0.2640533447265625\n",
      "        - 1.8915023803710938\n",
      "        - 1.79010009765625\n",
      "        - 0.5932159423828125\n",
      "        - -0.524871826171875\n",
      "        - 0.7469253540039062\n",
      "        - 0.2981719970703125\n",
      "        - 0.572723388671875\n",
      "        - 2.0183258056640625\n",
      "        - 1.5320510864257812\n",
      "        - -0.173187255859375\n",
      "        - 0.6834602355957031\n",
      "        - 2.064718246459961\n",
      "        - 0.4279899597167969\n",
      "        - 0.6993598937988281\n",
      "        - -0.35125732421875\n",
      "        - 1.1201324462890625\n",
      "        - 0.4960365295410156\n",
      "        - -0.6207618713378906\n",
      "        - 1.8339195251464844\n",
      "        - 0.34191131591796875\n",
      "        - 0.9439048767089844\n",
      "        - 0.2032318115234375\n",
      "        - -0.15941238403320312\n",
      "        - 0.8834648132324219\n",
      "        - 0.810272216796875\n",
      "        - 0.5013847351074219\n",
      "        - 0.8619918823242188\n",
      "        - 0.6087455749511719\n",
      "        - 0.9490127563476562\n",
      "        - 0.8140249252319336\n",
      "        - 0.7286109924316406\n",
      "        - 1.0442276000976562\n",
      "        - 1.029296875\n",
      "        - -0.07539033889770508\n",
      "        - 0.6029281616210938\n",
      "        - 0.5095653533935547\n",
      "        - 0.3084678649902344\n",
      "        - 0.9621086120605469\n",
      "        - -0.17943572998046875\n",
      "        - 0.46100616455078125\n",
      "        - 0.4041633605957031\n",
      "        - 0.17453384399414062\n",
      "        - 0.6495933532714844\n",
      "        - -0.17567992210388184\n",
      "        - 0.5640869140625\n",
      "        - -0.6043167114257812\n",
      "        - 0.7937850952148438\n",
      "        - 0.24643707275390625\n",
      "        - -0.15469105541706085\n",
      "        - -0.146284818649292\n",
      "        - 1.7761573791503906\n",
      "        - 1.1664466857910156\n",
      "        - 0.5240592956542969\n",
      "        - 1.2204818725585938\n",
      "        - 0.34191131591796875\n",
      "        - 1.0563507080078125\n",
      "        - -0.6090621948242188\n",
      "        - 0.3635444641113281\n",
      "        - 0.71429443359375\n",
      "        - 0.4877471923828125\n",
      "        - 1.1868648529052734\n",
      "        - 0.8194961547851562\n",
      "        - 0.2710990905761719\n",
      "        - 0.2938499450683594\n",
      "        - 0.22769927978515625\n",
      "        - -0.5958404541015625\n",
      "        - -0.6141624450683594\n",
      "        - 1.0889701843261719\n",
      "        - 0.8322982788085938\n",
      "        - -0.06946542114019394\n",
      "        - 0.49527740478515625\n",
      "        - -0.6113166809082031\n",
      "        - -0.6106796264648438\n",
      "        - 0.3284149169921875\n",
      "        - -0.6567611694335938\n",
      "        - 1.2564697265625\n",
      "        - -0.09067916870117188\n",
      "        - 0.42694091796875\n",
      "        - 0.9698715209960938\n",
      "        - 0.584228515625\n",
      "        - 0.8235740661621094\n",
      "        - 0.5232124328613281\n",
      "        - 0.0883864164352417\n",
      "        - 0.9390449523925781\n",
      "        - -0.11696004867553711\n",
      "        - 2.4575233459472656\n",
      "        - 0.29819488525390625\n",
      "        - 0.49847412109375\n",
      "        - 0.3546600341796875\n",
      "        - -0.12975606322288513\n",
      "        - 0.368927001953125\n",
      "        - 0.70220947265625\n",
      "        - 0.9050941467285156\n",
      "        - 0.7675056457519531\n",
      "        - 0.1562023162841797\n",
      "        - 2.20025634765625\n",
      "        - 1.6588211059570312\n",
      "        - 1.3502197265625\n",
      "        - 0.7900924682617188\n",
      "        - -0.05643463134765625\n",
      "        - -1.2724056243896484\n",
      "        - 1.86700439453125\n",
      "        - 0.5216445922851562\n",
      "        - -0.21416115760803223\n",
      "        - 0.33312416076660156\n",
      "        - 0.6425628662109375\n",
      "        - 0.07571592926979065\n",
      "        - 1.5798721313476562\n",
      "        - 0.951141357421875\n",
      "        - 0.7685012817382812\n",
      "        - 0.193756103515625\n",
      "        - 0.7035255432128906\n",
      "        - 0.07947540283203125\n",
      "        - 0.16826820373535156\n",
      "        - 0.4172019958496094\n",
      "        - 1.6606407165527344\n",
      "        - -0.2994804382324219\n",
      "        - 1.3316307067871094\n",
      "        - -0.11524581909179688\n",
      "        - 0.421600341796875\n",
      "        - 1.1434402465820312\n",
      "        - 0.6144523620605469\n",
      "        - 0.5573692321777344\n",
      "        - 0.671600341796875\n",
      "        - 0.7520179748535156\n",
      "        - 1.6357650756835938\n",
      "        - 1.4611740112304688\n",
      "        - 0.23157501220703125\n",
      "        - 0.18668746948242188\n",
      "        - 0.9256095886230469\n",
      "        - 0.5503616333007812\n",
      "        - 1.2331161499023438\n",
      "        - 0.0113525390625\n",
      "        - 1.1846580505371094\n",
      "        - -0.5245599746704102\n",
      "        - 0.9182891845703125\n",
      "        - -0.18604278564453125\n",
      "        - 0.17023468017578125\n",
      "        - -0.03694915771484375\n",
      "        - 0.96990966796875\n",
      "        - 0.672332763671875\n",
      "        - 1.2853927612304688\n",
      "        - 0.03045654296875\n",
      "        - 0.4188385009765625\n",
      "        - -0.20501327514648438\n",
      "        - -0.2538719177246094\n",
      "        - 0.4277973175048828\n",
      "        - -0.17615890502929688\n",
      "        - 0.8322601318359375\n",
      "        - 0.454345703125\n",
      "        - 0.8974189758300781\n",
      "        - 0.5249824523925781\n",
      "        - 0.12682846188545227\n",
      "        - 0.8587913513183594\n",
      "        - 1.2684783935546875\n",
      "        - -0.2929115295410156\n",
      "        - 1.4092559814453125\n",
      "        - 0.28417205810546875\n",
      "        - -30.450523376464844\n",
      "        - 0.7819976806640625\n",
      "        - 0.6922264099121094\n",
      "        - 0.27056884765625\n",
      "        - -0.19486236572265625\n",
      "        - -0.09208711981773376\n",
      "        - 0.19371795654296875\n",
      "        - 1.1830062866210938\n",
      "        - 0.4477519989013672\n",
      "        - 0.5861396789550781\n",
      "        - -0.23869705200195312\n",
      "        - 1.7007598876953125\n",
      "        - 1.6240081787109375\n",
      "        - -0.23045244812965393\n",
      "        - 1.683502197265625\n",
      "        - 0.6796073913574219\n",
      "        - -0.233978271484375\n",
      "        - -0.0948638916015625\n",
      "        - 0.7149887084960938\n",
      "        - -0.029901891946792603\n",
      "        - 0.8498191833496094\n",
      "    num_agent_steps_sampled: 9500\n",
      "    num_agent_steps_trained: 1024256\n",
      "    num_steps_sampled: 9500\n",
      "    num_steps_trained: 1024256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 4001\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 8.22608695652174\n",
      "    ram_util_percent: 1.7000000000000004\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.20651241571159704\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.2239939939593194\n",
      "    mean_inference_ms: 1.6629141160696836\n",
      "    mean_raw_obs_processing_ms: 0.5596723650840186\n",
      "  time_since_restore: 144.9513008594513\n",
      "  time_this_iter_s: 16.224175930023193\n",
      "  time_total_s: 144.9513008594513\n",
      "  timers:\n",
      "    learn_throughput: 51289.806\n",
      "    learn_time_ms: 4.991\n",
      "    load_throughput: 634599.187\n",
      "    load_time_ms: 0.403\n",
      "    update_time_ms: 2.859\n",
      "  timestamp: 1647533802\n",
      "  timesteps_since_restore: 2304\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 9500\n",
      "  training_iteration: 9\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:16:45 (running for 00:02:42.31)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         144.951</td><td style=\"text-align: right;\">9500</td><td style=\"text-align: right;\"> -1298.6</td><td style=\"text-align: right;\">            -2.92623</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:16:50 (running for 00:02:47.35)<br>Memory usage on this node: 8.3/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         144.951</td><td style=\"text-align: right;\">9500</td><td style=\"text-align: right;\"> -1298.6</td><td style=\"text-align: right;\">            -2.92623</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:16:55 (running for 00:02:52.36)<br>Memory usage on this node: 8.4/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         144.951</td><td style=\"text-align: right;\">9500</td><td style=\"text-align: right;\"> -1298.6</td><td style=\"text-align: right;\">            -2.92623</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 10500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-17-00\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2.9262292385332898\n",
      "  episode_reward_mean: -1254.9157661072586\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 52\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 10500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 1.5027244091033936\n",
      "          mean_q: -51.03181838989258\n",
      "          min_q: -77.86445617675781\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.01912689208984375\n",
      "        - -0.268341064453125\n",
      "        - 1.2912216186523438\n",
      "        - -0.106842041015625\n",
      "        - 0.36358642578125\n",
      "        - -0.09579393267631531\n",
      "        - -0.289825439453125\n",
      "        - -0.09627532958984375\n",
      "        - 0.3338966369628906\n",
      "        - 0.11520767211914062\n",
      "        - -0.00547027587890625\n",
      "        - 0.48534393310546875\n",
      "        - 0.7797527313232422\n",
      "        - 0.6247406005859375\n",
      "        - 0.4442739486694336\n",
      "        - 1.0850372314453125\n",
      "        - -0.4810333251953125\n",
      "        - 0.48773193359375\n",
      "        - 0.3333587646484375\n",
      "        - 0.4470329284667969\n",
      "        - 0.7940902709960938\n",
      "        - 0.372650146484375\n",
      "        - 0.18106842041015625\n",
      "        - 0.5056228637695312\n",
      "        - 0.77392578125\n",
      "        - 1.1367912292480469\n",
      "        - 0.6668548583984375\n",
      "        - 0.3921089172363281\n",
      "        - 0.36516571044921875\n",
      "        - -0.09908294677734375\n",
      "        - -0.34951019287109375\n",
      "        - 0.6649551391601562\n",
      "        - 0.9781303405761719\n",
      "        - 0.6630020141601562\n",
      "        - -0.6188392639160156\n",
      "        - -0.16669422388076782\n",
      "        - -0.13248062133789062\n",
      "        - 0.042751312255859375\n",
      "        - 0.3346099853515625\n",
      "        - 0.2701072692871094\n",
      "        - 0.4815216064453125\n",
      "        - 0.11900711059570312\n",
      "        - 0.3688087463378906\n",
      "        - -0.3148307800292969\n",
      "        - 0.28616905212402344\n",
      "        - 0.8350770473480225\n",
      "        - 0.24019241333007812\n",
      "        - 0.13871383666992188\n",
      "        - -0.2844424247741699\n",
      "        - 1.4483222961425781\n",
      "        - 0.6399955749511719\n",
      "        - 0.15909576416015625\n",
      "        - 0.6035537719726562\n",
      "        - 0.29695892333984375\n",
      "        - 0.43121337890625\n",
      "        - 0.6533470153808594\n",
      "        - -0.19647979736328125\n",
      "        - 0.215789794921875\n",
      "        - 0.10592937469482422\n",
      "        - -0.0202038437128067\n",
      "        - -0.2593231201171875\n",
      "        - -0.5119400024414062\n",
      "        - -0.05228424072265625\n",
      "        - 1.0530281066894531\n",
      "        - 0.7623481750488281\n",
      "        - -0.002368927001953125\n",
      "        - 1.0282783508300781\n",
      "        - -0.137298583984375\n",
      "        - 0.9005279541015625\n",
      "        - -0.5790863037109375\n",
      "        - 1.0174446105957031\n",
      "        - 0.54132080078125\n",
      "        - 1.0275650024414062\n",
      "        - -0.44179534912109375\n",
      "        - -0.45001983642578125\n",
      "        - 0.8664436340332031\n",
      "        - 0.12216949462890625\n",
      "        - 1.1568679809570312\n",
      "        - 0.89495849609375\n",
      "        - 0.006368368864059448\n",
      "        - 0.6285552978515625\n",
      "        - 0.8373928070068359\n",
      "        - 0.36429595947265625\n",
      "        - 1.2647857666015625\n",
      "        - 1.230173110961914\n",
      "        - -0.15279769897460938\n",
      "        - 0.8169021606445312\n",
      "        - 0.6680660247802734\n",
      "        - 0.8459281921386719\n",
      "        - -0.23374176025390625\n",
      "        - 0.8579864501953125\n",
      "        - 0.26647186279296875\n",
      "        - 0.7365608215332031\n",
      "        - -0.3972320556640625\n",
      "        - -0.5133819580078125\n",
      "        - 0.21417999267578125\n",
      "        - 1.9062042236328125\n",
      "        - 0.638458251953125\n",
      "        - 0.7689437866210938\n",
      "        - 1.1495246887207031\n",
      "        - -1.0505828857421875\n",
      "        - -0.9332046508789062\n",
      "        - 1.1700897216796875\n",
      "        - 0.4882545471191406\n",
      "        - 1.293487548828125\n",
      "        - -0.27890777587890625\n",
      "        - 0.45326995849609375\n",
      "        - 0.6916275024414062\n",
      "        - 0.5141830444335938\n",
      "        - -0.23754501342773438\n",
      "        - 0.3126640319824219\n",
      "        - 1.5457839965820312\n",
      "        - 0.5989799499511719\n",
      "        - 0.16857528686523438\n",
      "        - -0.32393646240234375\n",
      "        - -0.40505218505859375\n",
      "        - 0.9332122802734375\n",
      "        - 0.8394546508789062\n",
      "        - 1.0262107849121094\n",
      "        - 0.10682296752929688\n",
      "        - 0.7481346130371094\n",
      "        - -0.6088790893554688\n",
      "        - -0.06287384033203125\n",
      "        - -0.27972412109375\n",
      "        - 0.6526451110839844\n",
      "        - -0.531036376953125\n",
      "        - -0.33515167236328125\n",
      "        - 0.22919845581054688\n",
      "        - 0.5437164306640625\n",
      "        - 0.5550460815429688\n",
      "        - -0.267791748046875\n",
      "        - 1.2135848999023438\n",
      "        - 0.5211906433105469\n",
      "        - -0.44800567626953125\n",
      "        - -0.10897445678710938\n",
      "        - -0.7626495361328125\n",
      "        - -0.15875244140625\n",
      "        - -0.284820556640625\n",
      "        - 0.33574676513671875\n",
      "        - -0.2401140034198761\n",
      "        - 0.30615997314453125\n",
      "        - 0.407745361328125\n",
      "        - 0.5718002319335938\n",
      "        - 0.47821044921875\n",
      "        - 0.6583061218261719\n",
      "        - 0.8546676635742188\n",
      "        - 0.2501373291015625\n",
      "        - 0.028203636407852173\n",
      "        - 0.6209964752197266\n",
      "        - 0.16650390625\n",
      "        - 0.734748125076294\n",
      "        - 0.7039833068847656\n",
      "        - 0.4632530212402344\n",
      "        - -0.4407310485839844\n",
      "        - -0.0055999755859375\n",
      "        - 1.1442413330078125\n",
      "        - 1.1004524230957031\n",
      "        - -0.470184326171875\n",
      "        - 0.8338165283203125\n",
      "        - -0.6508140563964844\n",
      "        - 0.7654571533203125\n",
      "        - 0.32105255126953125\n",
      "        - -0.36322021484375\n",
      "        - 0.9530220031738281\n",
      "        - -0.06255340576171875\n",
      "        - 0.1885223388671875\n",
      "        - -0.12921574711799622\n",
      "        - 0.6552963256835938\n",
      "        - -0.12082672119140625\n",
      "        - -0.5365562438964844\n",
      "        - 0.6710433959960938\n",
      "        - 0.07254791259765625\n",
      "        - -0.10931199789047241\n",
      "        - 0.21730804443359375\n",
      "        - 0.0616912841796875\n",
      "        - -0.9335708618164062\n",
      "        - 0.9041824340820312\n",
      "        - 0.16263961791992188\n",
      "        - -1.3949012756347656\n",
      "        - 2.1871414184570312\n",
      "        - -0.0292510986328125\n",
      "        - 0.9057655334472656\n",
      "        - 0.9767532348632812\n",
      "        - 0.4723243713378906\n",
      "        - 0.20323944091796875\n",
      "        - 1.072021484375\n",
      "        - 0.1984405517578125\n",
      "        - 0.9472198486328125\n",
      "        - 1.4026117324829102\n",
      "        - 1.0115890502929688\n",
      "        - 1.1608772277832031\n",
      "        - 1.3526676893234253\n",
      "        - -0.06719970703125\n",
      "        - -0.1358184814453125\n",
      "        - 0.5071792602539062\n",
      "        - -0.14243698120117188\n",
      "        - 1.3485336303710938\n",
      "        - -0.20343399047851562\n",
      "        - -0.4488945007324219\n",
      "        - 1.1778297424316406\n",
      "        - 0.766815185546875\n",
      "        - -0.11124801635742188\n",
      "        - -0.4754981994628906\n",
      "        - -0.25189208984375\n",
      "        - 0.02162933349609375\n",
      "        - -1.75335693359375\n",
      "        - -1.0505828857421875\n",
      "        - -0.37957763671875\n",
      "        - -0.04811859130859375\n",
      "        - -0.02733612060546875\n",
      "        - 0.4720001220703125\n",
      "        - 0.699249267578125\n",
      "        - 0.8787956237792969\n",
      "        - 0.4504661560058594\n",
      "        - -0.34331512451171875\n",
      "        - 0.8414459228515625\n",
      "        - 0.9819374084472656\n",
      "        - -0.012366384267807007\n",
      "        - 0.9359703063964844\n",
      "        - 0.48602503538131714\n",
      "        - -0.000518798828125\n",
      "        - 1.0123023986816406\n",
      "        - -0.240203857421875\n",
      "        - 0.8205528259277344\n",
      "        - 1.181166648864746\n",
      "        - -0.17476654052734375\n",
      "        - 0.4860725402832031\n",
      "        - -0.8467254638671875\n",
      "        - -0.20386123657226562\n",
      "        - 0.4459228515625\n",
      "        - 0.8230552673339844\n",
      "        - -0.4566841125488281\n",
      "        - 0.7745437622070312\n",
      "        - 0.6705703735351562\n",
      "        - -0.127471923828125\n",
      "        - -0.5486679077148438\n",
      "        - 0.42101478576660156\n",
      "        - -0.6867942810058594\n",
      "        - -0.1884613037109375\n",
      "        - -0.130523681640625\n",
      "        - -0.6923885345458984\n",
      "        - 0.20354652404785156\n",
      "        - 0.4106903076171875\n",
      "        - 0.9299087524414062\n",
      "        - 0.41519927978515625\n",
      "        - 0.4505767822265625\n",
      "        - -0.8917045593261719\n",
      "        - -0.052690207958221436\n",
      "        - 0.7650337219238281\n",
      "        - 0.000469207763671875\n",
      "        - 0.7141342163085938\n",
      "        - 0.1196746826171875\n",
      "        - 0.383544921875\n",
      "        - 0.5293731689453125\n",
      "        - 0.2138671875\n",
      "        - 1.1676559448242188\n",
      "    num_agent_steps_sampled: 10500\n",
      "    num_agent_steps_trained: 1152256\n",
      "    num_steps_sampled: 10500\n",
      "    num_steps_trained: 1152256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 4501\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 8.504\n",
      "    ram_util_percent: 1.7\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.20528283765636265\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.22199872797699716\n",
      "    mean_inference_ms: 1.6135653195665045\n",
      "    mean_raw_obs_processing_ms: 0.5536759849617943\n",
      "  time_since_restore: 162.33826637268066\n",
      "  time_this_iter_s: 17.38696551322937\n",
      "  time_total_s: 162.33826637268066\n",
      "  timers:\n",
      "    learn_throughput: 51314.808\n",
      "    learn_time_ms: 4.989\n",
      "    load_throughput: 659870.836\n",
      "    load_time_ms: 0.388\n",
      "    update_time_ms: 2.796\n",
      "  timestamp: 1647533820\n",
      "  timesteps_since_restore: 2560\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 10500\n",
      "  training_iteration: 10\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:17:01 (running for 00:02:57.78)<br>Memory usage on this node: 8.4/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         162.338</td><td style=\"text-align: right;\">10500</td><td style=\"text-align: right;\">-1254.92</td><td style=\"text-align: right;\">            -2.92623</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:17:06 (running for 00:03:02.79)<br>Memory usage on this node: 8.4/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         162.338</td><td style=\"text-align: right;\">10500</td><td style=\"text-align: right;\">-1254.92</td><td style=\"text-align: right;\">            -2.92623</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:17:11 (running for 00:03:07.79)<br>Memory usage on this node: 8.5/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         162.338</td><td style=\"text-align: right;\">10500</td><td style=\"text-align: right;\">-1254.92</td><td style=\"text-align: right;\">            -2.92623</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:17:16 (running for 00:03:12.80)<br>Memory usage on this node: 8.5/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         162.338</td><td style=\"text-align: right;\">10500</td><td style=\"text-align: right;\">-1254.92</td><td style=\"text-align: right;\">            -2.92623</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 11500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-17-16\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2.9262292385332898\n",
      "  episode_reward_mean: -1197.6690326739645\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 56\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 11500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 0.18407486379146576\n",
      "          mean_q: -53.26762771606445\n",
      "          min_q: -88.02723693847656\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.010545611381530762\n",
      "        - 0.05004119873046875\n",
      "        - -1.2195453643798828\n",
      "        - -0.29907989501953125\n",
      "        - 0.017183303833007812\n",
      "        - -0.0923614501953125\n",
      "        - -0.5916471481323242\n",
      "        - 0.12460708618164062\n",
      "        - -0.3836345672607422\n",
      "        - 0.4244842529296875\n",
      "        - 0.425933837890625\n",
      "        - 2.055805206298828\n",
      "        - 0.22951126098632812\n",
      "        - 0.1667327880859375\n",
      "        - 0.25046539306640625\n",
      "        - 1.4189987182617188\n",
      "        - 0.6292266845703125\n",
      "        - 0.011749267578125\n",
      "        - 0.050361305475234985\n",
      "        - -0.05442047119140625\n",
      "        - 0.3214149475097656\n",
      "        - 0.24726486206054688\n",
      "        - 0.8409957885742188\n",
      "        - -0.059429168701171875\n",
      "        - -0.13349533081054688\n",
      "        - 0.6535263061523438\n",
      "        - 0.39064788818359375\n",
      "        - 0.5220260620117188\n",
      "        - -0.0399932861328125\n",
      "        - 0.180419921875\n",
      "        - 0.29012298583984375\n",
      "        - 3.5654983520507812\n",
      "        - 0.41777801513671875\n",
      "        - 0.16975784301757812\n",
      "        - 0.6717567443847656\n",
      "        - 0.10987472534179688\n",
      "        - 0.055077433586120605\n",
      "        - -0.012180089950561523\n",
      "        - -0.22168731689453125\n",
      "        - -0.3976478576660156\n",
      "        - -0.17781829833984375\n",
      "        - -0.07122802734375\n",
      "        - 0.4656982421875\n",
      "        - -0.1637420654296875\n",
      "        - -22.247512817382812\n",
      "        - -0.00260162353515625\n",
      "        - -0.21057510375976562\n",
      "        - 0.132904052734375\n",
      "        - 0.7711257934570312\n",
      "        - 0.4519062042236328\n",
      "        - 0.475738525390625\n",
      "        - 0.394256591796875\n",
      "        - 0.3824462890625\n",
      "        - -0.16563034057617188\n",
      "        - 0.5914649963378906\n",
      "        - -0.083282470703125\n",
      "        - 0.26335906982421875\n",
      "        - 0.019824981689453125\n",
      "        - 0.09861373901367188\n",
      "        - 0.116455078125\n",
      "        - -1.1158294677734375\n",
      "        - -0.04799467325210571\n",
      "        - 0.5989990234375\n",
      "        - 0.06890052556991577\n",
      "        - -0.7003402709960938\n",
      "        - -0.2583198547363281\n",
      "        - 0.42449188232421875\n",
      "        - 0.015514072962105274\n",
      "        - -0.18959808349609375\n",
      "        - -0.07224812358617783\n",
      "        - 0.031528353691101074\n",
      "        - 0.4675140380859375\n",
      "        - 0.4618072509765625\n",
      "        - 0.7696075439453125\n",
      "        - -0.4554252624511719\n",
      "        - 1.6388092041015625\n",
      "        - 0.3877601623535156\n",
      "        - -0.7912521362304688\n",
      "        - 0.6722335815429688\n",
      "        - 0.9163818359375\n",
      "        - 1.0457954406738281\n",
      "        - 0.577423095703125\n",
      "        - 0.7295684814453125\n",
      "        - -0.4006500244140625\n",
      "        - -54.68174743652344\n",
      "        - 0.6506328582763672\n",
      "        - 0.10444903373718262\n",
      "        - 0.9893112182617188\n",
      "        - 0.658905029296875\n",
      "        - 0.74346923828125\n",
      "        - 0.7511215209960938\n",
      "        - -0.0402374267578125\n",
      "        - 0.022098541259765625\n",
      "        - -0.3807525634765625\n",
      "        - 0.07563018798828125\n",
      "        - 0.704803466796875\n",
      "        - -0.5740470886230469\n",
      "        - 0.4367103576660156\n",
      "        - 0.5759735107421875\n",
      "        - -0.866424560546875\n",
      "        - -0.14954376220703125\n",
      "        - 0.691375732421875\n",
      "        - -0.059833526611328125\n",
      "        - 0.023624420166015625\n",
      "        - 0.5587081909179688\n",
      "        - 0.4768524169921875\n",
      "        - 0.6251869201660156\n",
      "        - 1.1338157653808594\n",
      "        - 0.6935806274414062\n",
      "        - -0.03574371337890625\n",
      "        - -0.540863037109375\n",
      "        - -0.5759048461914062\n",
      "        - -0.351287841796875\n",
      "        - 0.2365570068359375\n",
      "        - 0.006340775638818741\n",
      "        - 0.43921661376953125\n",
      "        - 0.3865089416503906\n",
      "        - 0.9105072021484375\n",
      "        - -0.08644866943359375\n",
      "        - 0.7553939819335938\n",
      "        - -0.07692718505859375\n",
      "        - -0.0331268310546875\n",
      "        - -0.41262054443359375\n",
      "        - -0.04611968994140625\n",
      "        - 0.12798690795898438\n",
      "        - 0.0183383971452713\n",
      "        - -0.08623504638671875\n",
      "        - -0.07851791381835938\n",
      "        - -0.16200637817382812\n",
      "        - 0.6081008911132812\n",
      "        - 0.021378107368946075\n",
      "        - 0.4202003479003906\n",
      "        - -0.0646209716796875\n",
      "        - -0.11677360534667969\n",
      "        - -0.1903228759765625\n",
      "        - 0.3710899353027344\n",
      "        - 0.5512619018554688\n",
      "        - 0.08323097229003906\n",
      "        - -0.03960418701171875\n",
      "        - -0.14111328125\n",
      "        - 0.2588958740234375\n",
      "        - 1.023651123046875\n",
      "        - 0.1811065673828125\n",
      "        - 0.2578926086425781\n",
      "        - 0.052639007568359375\n",
      "        - -0.5533447265625\n",
      "        - 0.873138427734375\n",
      "        - 2.3519668579101562\n",
      "        - 0.369964599609375\n",
      "        - 0.39505767822265625\n",
      "        - 1.44384765625\n",
      "        - 0.83868408203125\n",
      "        - 0.4150962829589844\n",
      "        - 0.19426727294921875\n",
      "        - 1.4763374328613281\n",
      "        - 0.30681610107421875\n",
      "        - -0.3448486328125\n",
      "        - -0.5585060119628906\n",
      "        - -0.30397462844848633\n",
      "        - 0.09192657470703125\n",
      "        - 0.48471832275390625\n",
      "        - 0.3320770263671875\n",
      "        - -0.18616867065429688\n",
      "        - 1.3774833679199219\n",
      "        - 0.3846282958984375\n",
      "        - 0.702301025390625\n",
      "        - 0.2834434509277344\n",
      "        - -0.09710693359375\n",
      "        - 0.05193936824798584\n",
      "        - 0.014965057373046875\n",
      "        - 0.4937324523925781\n",
      "        - -0.09503555297851562\n",
      "        - -0.257171630859375\n",
      "        - 0.13875511288642883\n",
      "        - 0.7190322875976562\n",
      "        - 0.9557342529296875\n",
      "        - -0.32944488525390625\n",
      "        - 0.5709342956542969\n",
      "        - 0.37009429931640625\n",
      "        - -1.0011520385742188\n",
      "        - -0.084625244140625\n",
      "        - 0.4848976135253906\n",
      "        - 0.7288055419921875\n",
      "        - -0.3381195068359375\n",
      "        - 0.4803466796875\n",
      "        - 0.2222919464111328\n",
      "        - -0.5790939331054688\n",
      "        - -0.1843719482421875\n",
      "        - -0.3032989501953125\n",
      "        - -0.01526641845703125\n",
      "        - 0.7515144348144531\n",
      "        - 0.31234169006347656\n",
      "        - 0.33608293533325195\n",
      "        - 0.18301773071289062\n",
      "        - 0.020249590277671814\n",
      "        - 0.016183681786060333\n",
      "        - 0.143096923828125\n",
      "        - -0.26227569580078125\n",
      "        - 0.55267333984375\n",
      "        - 0.5651092529296875\n",
      "        - 0.013814685866236687\n",
      "        - 0.9714813232421875\n",
      "        - 0.58148193359375\n",
      "        - -0.27008819580078125\n",
      "        - -0.00281524658203125\n",
      "        - -0.2062530517578125\n",
      "        - 0.9249763488769531\n",
      "        - 0.01348852552473545\n",
      "        - 0.202728271484375\n",
      "        - 0.024671446532011032\n",
      "        - -0.0691375732421875\n",
      "        - 0.5651092529296875\n",
      "        - 0.29046630859375\n",
      "        - 0.31555938720703125\n",
      "        - -0.3567924499511719\n",
      "        - -0.19910430908203125\n",
      "        - 0.29541015625\n",
      "        - 0.21298980712890625\n",
      "        - 0.22385787963867188\n",
      "        - -1.0083961486816406\n",
      "        - -0.12683868408203125\n",
      "        - 0.021280888468027115\n",
      "        - 0.41100311279296875\n",
      "        - -0.6106033325195312\n",
      "        - 1.076263427734375\n",
      "        - 0.08129119873046875\n",
      "        - 0.7432708740234375\n",
      "        - 0.08323097229003906\n",
      "        - 0.3917427062988281\n",
      "        - -0.21915054321289062\n",
      "        - 0.7495803833007812\n",
      "        - 1.5604476928710938\n",
      "        - 0.180450439453125\n",
      "        - 0.3247833251953125\n",
      "        - 0.5812759399414062\n",
      "        - -0.8128814697265625\n",
      "        - -0.019779205322265625\n",
      "        - -0.0579071044921875\n",
      "        - 0.11835139989852905\n",
      "        - 1.076263427734375\n",
      "        - 0.11498260498046875\n",
      "        - 0.8278961181640625\n",
      "        - 0.359619140625\n",
      "        - 0.7268905639648438\n",
      "        - 0.9057159423828125\n",
      "        - -0.51959228515625\n",
      "        - 0.98419189453125\n",
      "        - -0.6339073181152344\n",
      "        - 0.2960700988769531\n",
      "        - 0.5093460083007812\n",
      "        - -0.9290084838867188\n",
      "        - -0.16954421997070312\n",
      "        - -0.22069168090820312\n",
      "        - 1.1076736450195312\n",
      "        - 0.3100433349609375\n",
      "        - 0.6027030944824219\n",
      "    num_agent_steps_sampled: 11500\n",
      "    num_agent_steps_trained: 1280256\n",
      "    num_steps_sampled: 11500\n",
      "    num_steps_trained: 1280256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 5001\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 9.365217391304347\n",
      "    ram_util_percent: 1.752173913043478\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.2045402051963278\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.220794568140007\n",
      "    mean_inference_ms: 1.5849537508400822\n",
      "    mean_raw_obs_processing_ms: 0.5500999910652589\n",
      "  time_since_restore: 178.8416042327881\n",
      "  time_this_iter_s: 16.503337860107422\n",
      "  time_total_s: 178.8416042327881\n",
      "  timers:\n",
      "    learn_throughput: 50937.002\n",
      "    learn_time_ms: 5.026\n",
      "    load_throughput: 661415.439\n",
      "    load_time_ms: 0.387\n",
      "    update_time_ms: 2.929\n",
      "  timestamp: 1647533836\n",
      "  timesteps_since_restore: 2816\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 11500\n",
      "  training_iteration: 11\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:17:21 (running for 00:03:18.35)<br>Memory usage on this node: 8.5/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         178.842</td><td style=\"text-align: right;\">11500</td><td style=\"text-align: right;\">-1197.67</td><td style=\"text-align: right;\">            -2.92623</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:17:26 (running for 00:03:23.36)<br>Memory usage on this node: 8.5/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         178.842</td><td style=\"text-align: right;\">11500</td><td style=\"text-align: right;\">-1197.67</td><td style=\"text-align: right;\">            -2.92623</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:17:31 (running for 00:03:28.37)<br>Memory usage on this node: 8.6/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         178.842</td><td style=\"text-align: right;\">11500</td><td style=\"text-align: right;\">-1197.67</td><td style=\"text-align: right;\">            -2.92623</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 12500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-17-33\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.625332495372558\n",
      "  episode_reward_mean: -1101.3853208039902\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 62\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 12500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 1.4363971948623657\n",
      "          mean_q: -50.949554443359375\n",
      "          min_q: -85.39965057373047\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.9984207153320312\n",
      "        - -47.23536682128906\n",
      "        - 1.3550949096679688\n",
      "        - 1.2643890380859375\n",
      "        - 1.6346511840820312\n",
      "        - 0.8126068115234375\n",
      "        - -0.3994789123535156\n",
      "        - 1.0545654296875\n",
      "        - 1.7620391845703125\n",
      "        - 0.00736236572265625\n",
      "        - 0.6077194213867188\n",
      "        - -69.8105239868164\n",
      "        - 1.029541015625\n",
      "        - 1.1880264282226562\n",
      "        - 0.5187159180641174\n",
      "        - 0.03877830505371094\n",
      "        - -0.23114013671875\n",
      "        - 2.527435302734375\n",
      "        - 1.0218353271484375\n",
      "        - 0.9620437622070312\n",
      "        - 0.9499130249023438\n",
      "        - 1.0136795043945312\n",
      "        - -0.1077880859375\n",
      "        - 0.8479156494140625\n",
      "        - 0.8814239501953125\n",
      "        - 0.386688232421875\n",
      "        - -0.16661834716796875\n",
      "        - -0.17744064331054688\n",
      "        - 1.6480216979980469\n",
      "        - 0.8059310913085938\n",
      "        - -0.649688720703125\n",
      "        - -0.2742576599121094\n",
      "        - 0.6621856689453125\n",
      "        - 0.32453984022140503\n",
      "        - 1.1920318603515625\n",
      "        - -0.5294189453125\n",
      "        - -0.34644317626953125\n",
      "        - 0.35237884521484375\n",
      "        - 1.3157501220703125\n",
      "        - 0.2779785394668579\n",
      "        - 1.1098480224609375\n",
      "        - -0.0980987548828125\n",
      "        - 0.9079666137695312\n",
      "        - 0.8313446044921875\n",
      "        - 0.4167514443397522\n",
      "        - 0.6721572875976562\n",
      "        - 0.3666638135910034\n",
      "        - 0.73565673828125\n",
      "        - 0.4048652648925781\n",
      "        - 1.7070388793945312\n",
      "        - 0.36218351125717163\n",
      "        - -0.3618011474609375\n",
      "        - 0.952056884765625\n",
      "        - 0.07663726806640625\n",
      "        - 0.5652694702148438\n",
      "        - -0.7074203491210938\n",
      "        - -0.4377899169921875\n",
      "        - 0.40925294160842896\n",
      "        - 0.6942062377929688\n",
      "        - 0.4416266679763794\n",
      "        - -0.34673309326171875\n",
      "        - 0.860626220703125\n",
      "        - 2.886859893798828\n",
      "        - 1.5012855529785156\n",
      "        - 0.7690353393554688\n",
      "        - 0.6010589599609375\n",
      "        - 1.0540542602539062\n",
      "        - -0.1235504150390625\n",
      "        - 0.4792655110359192\n",
      "        - 0.392477810382843\n",
      "        - 1.9158782958984375\n",
      "        - 0.44641706347465515\n",
      "        - 0.3859405517578125\n",
      "        - 1.0312690734863281\n",
      "        - 1.227081298828125\n",
      "        - -0.6332015991210938\n",
      "        - -1.0788192749023438\n",
      "        - 0.45452073216438293\n",
      "        - 0.19636179506778717\n",
      "        - 0.399244099855423\n",
      "        - 0.31068354845046997\n",
      "        - -0.59368896484375\n",
      "        - 1.3968048095703125\n",
      "        - 0.33605560660362244\n",
      "        - 0.7441400289535522\n",
      "        - -0.07715606689453125\n",
      "        - 0.4353790283203125\n",
      "        - 0.8509979248046875\n",
      "        - 0.7783393859863281\n",
      "        - 1.5102691650390625\n",
      "        - 1.0972213745117188\n",
      "        - 0.9843673706054688\n",
      "        - 0.7918186187744141\n",
      "        - 2.0631370544433594\n",
      "        - 1.036956787109375\n",
      "        - 0.11891233921051025\n",
      "        - 1.3226985931396484\n",
      "        - 0.555463433265686\n",
      "        - 0.36671966314315796\n",
      "        - 1.0189476013183594\n",
      "        - 1.2342758178710938\n",
      "        - 1.1326026916503906\n",
      "        - 1.037933349609375\n",
      "        - 0.3649989068508148\n",
      "        - 1.0853157043457031\n",
      "        - 0.9519271850585938\n",
      "        - 1.0427627563476562\n",
      "        - 1.0929412841796875\n",
      "        - 1.08880615234375\n",
      "        - 0.551239013671875\n",
      "        - 2.1582679748535156\n",
      "        - 0.2468414306640625\n",
      "        - 2.0384254455566406\n",
      "        - 0.3480202853679657\n",
      "        - 1.7501068115234375\n",
      "        - 0.6704730987548828\n",
      "        - 0.4121818542480469\n",
      "        - -0.1190185546875\n",
      "        - 0.0174560546875\n",
      "        - 0.0738525390625\n",
      "        - 2.5208988189697266\n",
      "        - 0.20232510566711426\n",
      "        - 0.8823509216308594\n",
      "        - -0.4189910888671875\n",
      "        - 1.6507034301757812\n",
      "        - -0.038970947265625\n",
      "        - -0.5484504699707031\n",
      "        - 0.8087921142578125\n",
      "        - 0.35889923572540283\n",
      "        - 0.44722747802734375\n",
      "        - 1.4651565551757812\n",
      "        - 0.5033798217773438\n",
      "        - 0.21616685390472412\n",
      "        - 0.4588797092437744\n",
      "        - 0.38848674297332764\n",
      "        - 0.5626314878463745\n",
      "        - 0.11042213439941406\n",
      "        - 0.6260584592819214\n",
      "        - 0.9653244018554688\n",
      "        - 0.3696625232696533\n",
      "        - 0.26554107666015625\n",
      "        - 0.2136383056640625\n",
      "        - 1.046722412109375\n",
      "        - 1.3075790405273438\n",
      "        - 0.5781173706054688\n",
      "        - -0.12374114990234375\n",
      "        - 0.5884170532226562\n",
      "        - -0.009021759033203125\n",
      "        - 0.5246658325195312\n",
      "        - 0.1957855224609375\n",
      "        - 1.3419761657714844\n",
      "        - 1.8618621826171875\n",
      "        - 0.3267742395401001\n",
      "        - 0.5833892822265625\n",
      "        - 0.10628890991210938\n",
      "        - 0.074554443359375\n",
      "        - -0.16085243225097656\n",
      "        - 1.9651832580566406\n",
      "        - 0.6543731689453125\n",
      "        - 0.34895771741867065\n",
      "        - -0.5527267456054688\n",
      "        - -0.9376907348632812\n",
      "        - 2.3998031616210938\n",
      "        - -1.3916435241699219\n",
      "        - 0.4167514443397522\n",
      "        - 1.0602073669433594\n",
      "        - 0.3832658529281616\n",
      "        - 2.1519737243652344\n",
      "        - -0.124786376953125\n",
      "        - -0.18650054931640625\n",
      "        - 0.2907000482082367\n",
      "        - 0.39372751116752625\n",
      "        - 0.5066927075386047\n",
      "        - 1.203521728515625\n",
      "        - 0.2189483642578125\n",
      "        - 0.9386215209960938\n",
      "        - 1.6432647705078125\n",
      "        - -1.0872116088867188\n",
      "        - 0.7111587524414062\n",
      "        - 0.41602838039398193\n",
      "        - 0.37158966064453125\n",
      "        - 0.998809814453125\n",
      "        - 1.5015716552734375\n",
      "        - -0.2400665283203125\n",
      "        - 0.39967575669288635\n",
      "        - 1.1641464233398438\n",
      "        - 0.8153610229492188\n",
      "        - 0.3839762508869171\n",
      "        - -0.6900367736816406\n",
      "        - 0.45218658447265625\n",
      "        - 1.4556961059570312\n",
      "        - 0.5409927368164062\n",
      "        - 0.0348052978515625\n",
      "        - -0.6876602172851562\n",
      "        - 0.033477783203125\n",
      "        - -0.184173583984375\n",
      "        - -0.24121856689453125\n",
      "        - -0.7197036743164062\n",
      "        - 0.25885009765625\n",
      "        - 1.6972389221191406\n",
      "        - 1.0930328369140625\n",
      "        - 0.1425628662109375\n",
      "        - -0.4096641540527344\n",
      "        - 0.29173386096954346\n",
      "        - 1.0444183349609375\n",
      "        - -0.53851318359375\n",
      "        - 0.6961593627929688\n",
      "        - -1.4058303833007812\n",
      "        - 0.9493942260742188\n",
      "        - 0.952972412109375\n",
      "        - 1.2618827819824219\n",
      "        - 0.34589892625808716\n",
      "        - 0.9034194946289062\n",
      "        - -0.4156036376953125\n",
      "        - 0.33211788535118103\n",
      "        - 0.8549585342407227\n",
      "        - 0.4650115966796875\n",
      "        - 0.8687782287597656\n",
      "        - 0.04782867431640625\n",
      "        - 1.716012954711914\n",
      "        - 1.3022994995117188\n",
      "        - 0.3651885986328125\n",
      "        - 2.6679458618164062\n",
      "        - -0.20013427734375\n",
      "        - 1.5177841186523438\n",
      "        - -0.2112884521484375\n",
      "        - 2.255126953125\n",
      "        - 1.17626953125\n",
      "        - 2.3271408081054688\n",
      "        - 0.07849884033203125\n",
      "        - 0.6755142211914062\n",
      "        - 0.40885472297668457\n",
      "        - 0.9349822998046875\n",
      "        - 1.5985908508300781\n",
      "        - 1.0305862426757812\n",
      "        - 0.7633590698242188\n",
      "        - 0.3662310838699341\n",
      "        - 0.8697469234466553\n",
      "        - 0.5707015991210938\n",
      "        - 0.7560195922851562\n",
      "        - 1.143157958984375\n",
      "        - 1.165191650390625\n",
      "        - 0.592503547668457\n",
      "        - 0.9648361206054688\n",
      "        - 0.04216766357421875\n",
      "        - 0.6666412353515625\n",
      "        - 0.39442408084869385\n",
      "        - 0.6346359252929688\n",
      "        - 1.3876075744628906\n",
      "        - 1.681253433227539\n",
      "        - 0.32523345947265625\n",
      "        - 0.49759674072265625\n",
      "        - -0.14632415771484375\n",
      "        - 1.1502609252929688\n",
      "        - -0.37592315673828125\n",
      "        - 0.41759490966796875\n",
      "    num_agent_steps_sampled: 12500\n",
      "    num_agent_steps_trained: 1408256\n",
      "    num_steps_sampled: 12500\n",
      "    num_steps_trained: 1408256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 5501\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 14.12\n",
      "    ram_util_percent: 1.8\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.20356018602532053\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.21921504629024557\n",
      "    mean_inference_ms: 1.5474263481342512\n",
      "    mean_raw_obs_processing_ms: 0.5454274349136874\n",
      "  time_since_restore: 195.9726276397705\n",
      "  time_this_iter_s: 17.131023406982422\n",
      "  time_total_s: 195.9726276397705\n",
      "  timers:\n",
      "    learn_throughput: 42124.372\n",
      "    learn_time_ms: 6.077\n",
      "    load_throughput: 455960.688\n",
      "    load_time_ms: 0.561\n",
      "    update_time_ms: 3.872\n",
      "  timestamp: 1647533853\n",
      "  timesteps_since_restore: 3072\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 12500\n",
      "  training_iteration: 12\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:17:36 (running for 00:03:33.50)<br>Memory usage on this node: 8.6/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         195.973</td><td style=\"text-align: right;\">12500</td><td style=\"text-align: right;\">-1101.39</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:17:41 (running for 00:03:38.56)<br>Memory usage on this node: 8.6/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         195.973</td><td style=\"text-align: right;\">12500</td><td style=\"text-align: right;\">-1101.39</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:17:46 (running for 00:03:43.56)<br>Memory usage on this node: 8.6/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         195.973</td><td style=\"text-align: right;\">12500</td><td style=\"text-align: right;\">-1101.39</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:17:51 (running for 00:03:48.57)<br>Memory usage on this node: 8.6/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         195.973</td><td style=\"text-align: right;\">12500</td><td style=\"text-align: right;\">-1101.39</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 13500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-17-53\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.625332495372558\n",
      "  episode_reward_mean: -1049.0486412870205\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 66\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 13500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 1.1734614372253418\n",
      "          mean_q: -53.836769104003906\n",
      "          min_q: -92.07656860351562\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 1.04052734375\n",
      "        - -0.15813446044921875\n",
      "        - -0.3371315002441406\n",
      "        - 0.2511850595474243\n",
      "        - 0.27287203073501587\n",
      "        - 2.0220565795898438\n",
      "        - 0.386383056640625\n",
      "        - -0.1419219970703125\n",
      "        - 0.7392578125\n",
      "        - 0.5783843994140625\n",
      "        - 0.5663299560546875\n",
      "        - 0.7167930603027344\n",
      "        - -0.0415496826171875\n",
      "        - -0.4320487976074219\n",
      "        - -0.702056884765625\n",
      "        - -0.4181404113769531\n",
      "        - -0.2486114501953125\n",
      "        - -0.49102020263671875\n",
      "        - 0.23302721977233887\n",
      "        - 0.8177261352539062\n",
      "        - -0.9780426025390625\n",
      "        - -0.05034637451171875\n",
      "        - 0.19069969654083252\n",
      "        - 0.16583837568759918\n",
      "        - 0.2531789243221283\n",
      "        - 1.0651168823242188\n",
      "        - 0.8185997009277344\n",
      "        - -0.2576141357421875\n",
      "        - 1.366546630859375\n",
      "        - -0.46120452880859375\n",
      "        - 0.2543487548828125\n",
      "        - 0.14512984454631805\n",
      "        - 0.5177764892578125\n",
      "        - 0.48227691650390625\n",
      "        - 0.93408203125\n",
      "        - 1.225494384765625\n",
      "        - 1.0949935913085938\n",
      "        - 0.4927215576171875\n",
      "        - 0.535552978515625\n",
      "        - -0.6237716674804688\n",
      "        - 0.3914337158203125\n",
      "        - 0.18556949496269226\n",
      "        - 0.6088485717773438\n",
      "        - 0.14157947897911072\n",
      "        - 0.20504909753799438\n",
      "        - 0.582916259765625\n",
      "        - 0.5672378540039062\n",
      "        - 1.4610595703125\n",
      "        - 1.0460739135742188\n",
      "        - 0.3529014587402344\n",
      "        - 0.34255218505859375\n",
      "        - -0.26448917388916016\n",
      "        - 1.0758056640625\n",
      "        - 0.22173789143562317\n",
      "        - 0.31658935546875\n",
      "        - 0.22318267822265625\n",
      "        - 0.15677261352539062\n",
      "        - -0.6534347534179688\n",
      "        - -0.8810272216796875\n",
      "        - 0.5938835144042969\n",
      "        - 1.7907943725585938\n",
      "        - 0.8891754150390625\n",
      "        - 0.20200085639953613\n",
      "        - 0.2481842041015625\n",
      "        - 0.32086873054504395\n",
      "        - 0.5201873779296875\n",
      "        - 0.497161865234375\n",
      "        - 0.14734205603599548\n",
      "        - -0.38314056396484375\n",
      "        - 0.14907822012901306\n",
      "        - 1.296234130859375\n",
      "        - -0.6190948486328125\n",
      "        - 0.3577251434326172\n",
      "        - 0.63665771484375\n",
      "        - 1.9945831298828125\n",
      "        - 0.68792724609375\n",
      "        - -0.1176300048828125\n",
      "        - 0.8965911865234375\n",
      "        - 0.4100341796875\n",
      "        - 0.173736572265625\n",
      "        - 0.47977447509765625\n",
      "        - 0.0957285538315773\n",
      "        - 0.13262939453125\n",
      "        - 0.24822014570236206\n",
      "        - 0.26573047041893005\n",
      "        - 0.4065895080566406\n",
      "        - -0.4929351806640625\n",
      "        - 0.285221666097641\n",
      "        - -0.7347946166992188\n",
      "        - -0.46909332275390625\n",
      "        - 0.6097793579101562\n",
      "        - 1.0484695434570312\n",
      "        - -0.0457916259765625\n",
      "        - 0.2511850595474243\n",
      "        - -0.24433135986328125\n",
      "        - 1.2835540771484375\n",
      "        - 0.4134521484375\n",
      "        - 0.17957273125648499\n",
      "        - -0.5859222412109375\n",
      "        - 1.2620773315429688\n",
      "        - 1.9512100219726562\n",
      "        - 1.4757461547851562\n",
      "        - 0.8029708862304688\n",
      "        - 1.6494712829589844\n",
      "        - 0.4051666259765625\n",
      "        - 0.10930633544921875\n",
      "        - 0.029575586318969727\n",
      "        - 2.7524566650390625\n",
      "        - 0.19385012984275818\n",
      "        - 0.761993408203125\n",
      "        - -0.2576141357421875\n",
      "        - 1.419403076171875\n",
      "        - 0.30098724365234375\n",
      "        - 1.30157470703125\n",
      "        - 1.2971420288085938\n",
      "        - -0.07053756713867188\n",
      "        - -0.16265106201171875\n",
      "        - 0.15530908107757568\n",
      "        - 0.3819847106933594\n",
      "        - 1.3208694458007812\n",
      "        - 0.48270416259765625\n",
      "        - 0.8616828918457031\n",
      "        - 0.2047485113143921\n",
      "        - 0.9982681274414062\n",
      "        - 1.4916000366210938\n",
      "        - 0.3281964957714081\n",
      "        - 0.15525570511817932\n",
      "        - 0.20561203360557556\n",
      "        - 0.2635345458984375\n",
      "        - 0.2065744400024414\n",
      "        - 0.869598388671875\n",
      "        - 0.5206069946289062\n",
      "        - 1.312164306640625\n",
      "        - 0.15212249755859375\n",
      "        - 0.16084209084510803\n",
      "        - -0.5963516235351562\n",
      "        - 0.284284383058548\n",
      "        - -0.7677536010742188\n",
      "        - 0.19279855489730835\n",
      "        - 1.145050048828125\n",
      "        - 0.4615654945373535\n",
      "        - 0.8538742065429688\n",
      "        - 0.7496452331542969\n",
      "        - 0.9098777770996094\n",
      "        - 0.29352569580078125\n",
      "        - 0.07260841131210327\n",
      "        - -0.5416355133056641\n",
      "        - 1.2522125244140625\n",
      "        - 0.08456134796142578\n",
      "        - 0.5667190551757812\n",
      "        - -0.3533515930175781\n",
      "        - 0.7603073120117188\n",
      "        - 0.19227531552314758\n",
      "        - -0.2989044189453125\n",
      "        - 0.48729705810546875\n",
      "        - 1.0836639404296875\n",
      "        - -0.19112396240234375\n",
      "        - 0.1345517635345459\n",
      "        - 1.2268714904785156\n",
      "        - 0.30972301959991455\n",
      "        - 0.5938835144042969\n",
      "        - -0.8340835571289062\n",
      "        - 1.42926025390625\n",
      "        - 2.0220565795898438\n",
      "        - 0.5747833251953125\n",
      "        - 0.2603607177734375\n",
      "        - 0.9776992797851562\n",
      "        - -0.06325653195381165\n",
      "        - -0.41585826873779297\n",
      "        - 0.3839302062988281\n",
      "        - 0.6249008178710938\n",
      "        - 0.03033447265625\n",
      "        - -0.8230171203613281\n",
      "        - 1.9693946838378906\n",
      "        - 0.1869451403617859\n",
      "        - 0.8856773376464844\n",
      "        - -32.14521026611328\n",
      "        - 0.39669036865234375\n",
      "        - 0.055443018674850464\n",
      "        - 0.25573575496673584\n",
      "        - -0.614227294921875\n",
      "        - 0.20381927490234375\n",
      "        - -0.31134796142578125\n",
      "        - 0.2886314392089844\n",
      "        - 0.7392959594726562\n",
      "        - 0.8509597778320312\n",
      "        - 0.33610740303993225\n",
      "        - 0.47025299072265625\n",
      "        - 1.19854736328125\n",
      "        - 0.6302719116210938\n",
      "        - -0.0959625244140625\n",
      "        - -0.3074182868003845\n",
      "        - 0.2454962432384491\n",
      "        - 0.21611088514328003\n",
      "        - 2.4146575927734375\n",
      "        - 0.45308685302734375\n",
      "        - -0.9499588012695312\n",
      "        - 0.7937393188476562\n",
      "        - 0.16644287109375\n",
      "        - 1.7400970458984375\n",
      "        - 0.33193206787109375\n",
      "        - 0.22460320591926575\n",
      "        - 0.0323486328125\n",
      "        - -0.46378326416015625\n",
      "        - -0.12641143798828125\n",
      "        - 0.9512863159179688\n",
      "        - 1.2645797729492188\n",
      "        - 0.24143058061599731\n",
      "        - 1.7877120971679688\n",
      "        - 0.5283050537109375\n",
      "        - 0.628265380859375\n",
      "        - -1.3774948120117188\n",
      "        - 0.40622711181640625\n",
      "        - 0.1365833580493927\n",
      "        - -0.107208251953125\n",
      "        - 0.11126708984375\n",
      "        - 0.16304397583007812\n",
      "        - 0.1392620950937271\n",
      "        - 0.652130126953125\n",
      "        - 0.6803359985351562\n",
      "        - -0.215057373046875\n",
      "        - 1.1258468627929688\n",
      "        - 0.1735006421804428\n",
      "        - 1.2645797729492188\n",
      "        - 0.08273991197347641\n",
      "        - -0.25066375732421875\n",
      "        - 0.11734771728515625\n",
      "        - 0.21717604994773865\n",
      "        - 1.0816268920898438\n",
      "        - 1.2739105224609375\n",
      "        - 0.17351669073104858\n",
      "        - 0.22495627403259277\n",
      "        - 2.2821197509765625\n",
      "        - 0.20175056159496307\n",
      "        - 0.9192733764648438\n",
      "        - -0.11403656005859375\n",
      "        - 0.9265213012695312\n",
      "        - 0.14324951171875\n",
      "        - -0.22791290283203125\n",
      "        - 0.680999755859375\n",
      "        - 0.6474151611328125\n",
      "        - 0.7961578369140625\n",
      "        - -0.363128662109375\n",
      "        - 0.20259229838848114\n",
      "        - 0.2744293212890625\n",
      "        - 0.3310127258300781\n",
      "        - 1.0915260314941406\n",
      "        - 0.9992752075195312\n",
      "        - 0.5159454345703125\n",
      "        - 0.3621826171875\n",
      "        - -0.04293060302734375\n",
      "        - 1.1446151733398438\n",
      "        - 0.5037460327148438\n",
      "        - -0.4335174560546875\n",
      "        - 0.32305145263671875\n",
      "        - 0.7123794555664062\n",
      "    num_agent_steps_sampled: 13500\n",
      "    num_agent_steps_trained: 1536256\n",
      "    num_steps_sampled: 13500\n",
      "    num_steps_trained: 1536256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 6001\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.21851851851852\n",
      "    ram_util_percent: 1.7999999999999998\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.20307270999580318\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.21838739750125633\n",
      "    mean_inference_ms: 1.5258583243136952\n",
      "    mean_raw_obs_processing_ms: 0.5429468922549284\n",
      "  time_since_restore: 215.23861742019653\n",
      "  time_this_iter_s: 19.265989780426025\n",
      "  time_total_s: 215.23861742019653\n",
      "  timers:\n",
      "    learn_throughput: 51597.149\n",
      "    learn_time_ms: 4.962\n",
      "    load_throughput: 647729.881\n",
      "    load_time_ms: 0.395\n",
      "    update_time_ms: 2.934\n",
      "  timestamp: 1647533873\n",
      "  timesteps_since_restore: 3328\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 13500\n",
      "  training_iteration: 13\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:17:57 (running for 00:03:53.81)<br>Memory usage on this node: 8.6/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         215.239</td><td style=\"text-align: right;\">13500</td><td style=\"text-align: right;\">-1049.05</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:18:02 (running for 00:03:58.85)<br>Memory usage on this node: 8.6/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         215.239</td><td style=\"text-align: right;\">13500</td><td style=\"text-align: right;\">-1049.05</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:18:07 (running for 00:04:03.86)<br>Memory usage on this node: 8.6/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         215.239</td><td style=\"text-align: right;\">13500</td><td style=\"text-align: right;\">-1049.05</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 14500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-18-09\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.625332495372558\n",
      "  episode_reward_mean: -976.1355712016242\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 72\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 14500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 0.6166120767593384\n",
      "          mean_q: -53.37394714355469\n",
      "          min_q: -102.97999572753906\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.48944091796875\n",
      "        - 0.5252838134765625\n",
      "        - 1.1026344299316406\n",
      "        - -0.151336669921875\n",
      "        - -1.063827633857727\n",
      "        - -0.7923457622528076\n",
      "        - 0.7573661804199219\n",
      "        - -0.09192383289337158\n",
      "        - 1.1136932373046875\n",
      "        - -2.2226409912109375\n",
      "        - 0.4366779327392578\n",
      "        - 2.507984161376953\n",
      "        - 0.30792999267578125\n",
      "        - 1.9486808776855469\n",
      "        - -0.11092162132263184\n",
      "        - 0.03131866455078125\n",
      "        - 0.7940216064453125\n",
      "        - 1.6833572387695312\n",
      "        - -0.16033849120140076\n",
      "        - 0.800994873046875\n",
      "        - 0.0017818361520767212\n",
      "        - 1.0128173828125\n",
      "        - 0.03156280517578125\n",
      "        - 0.19287109375\n",
      "        - 1.3092803955078125\n",
      "        - 0.490631103515625\n",
      "        - 0.18637847900390625\n",
      "        - -0.04712463542819023\n",
      "        - 0.33060455322265625\n",
      "        - -0.01441192626953125\n",
      "        - 0.9543075561523438\n",
      "        - -0.19597625732421875\n",
      "        - -0.40887451171875\n",
      "        - 0.6232986450195312\n",
      "        - -0.7035140991210938\n",
      "        - -0.24918365478515625\n",
      "        - 0.5050582885742188\n",
      "        - 0.3314666748046875\n",
      "        - 1.5269241333007812\n",
      "        - -0.1532084047794342\n",
      "        - 0.555633544921875\n",
      "        - -0.2670907974243164\n",
      "        - 0.31512451171875\n",
      "        - -0.14037026464939117\n",
      "        - -0.0893707275390625\n",
      "        - 1.141326904296875\n",
      "        - 0.6935958862304688\n",
      "        - 0.21746063232421875\n",
      "        - 1.145843505859375\n",
      "        - 1.14581298828125\n",
      "        - 0.24050521850585938\n",
      "        - -0.1103515625\n",
      "        - 0.16419783234596252\n",
      "        - 0.06621551513671875\n",
      "        - -0.08096690475940704\n",
      "        - -0.21144014596939087\n",
      "        - 0.014832638204097748\n",
      "        - 0.08905029296875\n",
      "        - -0.21155127882957458\n",
      "        - 2.899322509765625\n",
      "        - 0.2917938232421875\n",
      "        - 2.364619255065918\n",
      "        - 0.2659912109375\n",
      "        - -0.7890777587890625\n",
      "        - 1.4417877197265625\n",
      "        - 0.24568939208984375\n",
      "        - -0.00353240966796875\n",
      "        - 0.8580169677734375\n",
      "        - 0.3766937255859375\n",
      "        - -0.999542236328125\n",
      "        - -0.2025718092918396\n",
      "        - -0.7618904113769531\n",
      "        - 1.0508956909179688\n",
      "        - 0.44423675537109375\n",
      "        - 1.932281494140625\n",
      "        - 1.9768714904785156\n",
      "        - 0.23290252685546875\n",
      "        - -0.6727294921875\n",
      "        - 0.43099212646484375\n",
      "        - 1.4724082946777344\n",
      "        - 0.1037980169057846\n",
      "        - -0.09596008062362671\n",
      "        - 0.37328338623046875\n",
      "        - 0.45333099365234375\n",
      "        - 0.4185333251953125\n",
      "        - 0.05385490506887436\n",
      "        - 0.9249114990234375\n",
      "        - -0.0786210373044014\n",
      "        - 0.991424560546875\n",
      "        - 0.06989233195781708\n",
      "        - 0.5772552490234375\n",
      "        - -1.0355415344238281\n",
      "        - -0.4285430908203125\n",
      "        - 0.4697113037109375\n",
      "        - -0.35631561279296875\n",
      "        - 0.9992179870605469\n",
      "        - 2.0845375061035156\n",
      "        - -0.1522492915391922\n",
      "        - -0.2711334228515625\n",
      "        - -0.4373359680175781\n",
      "        - 1.1094627380371094\n",
      "        - 1.1363906860351562\n",
      "        - 0.048828125\n",
      "        - -0.6777706146240234\n",
      "        - 0.03134918212890625\n",
      "        - -0.45409393310546875\n",
      "        - 1.3215179443359375\n",
      "        - -0.06290304660797119\n",
      "        - -0.16993510723114014\n",
      "        - -0.13181689381599426\n",
      "        - 1.4346199035644531\n",
      "        - 1.2890377044677734\n",
      "        - -0.43430328369140625\n",
      "        - 1.1008224487304688\n",
      "        - 0.2939453125\n",
      "        - 1.6878890991210938\n",
      "        - 0.9770584106445312\n",
      "        - 1.8563766479492188\n",
      "        - -0.015622831881046295\n",
      "        - 0.5972366333007812\n",
      "        - 1.2241744995117188\n",
      "        - 0.15140151977539062\n",
      "        - 0.26177215576171875\n",
      "        - 0.6324615478515625\n",
      "        - 1.2778472900390625\n",
      "        - 1.1921768188476562\n",
      "        - -0.05225458741188049\n",
      "        - -1.1231918334960938\n",
      "        - 1.00457763671875\n",
      "        - 0.3157958984375\n",
      "        - 0.10272080451250076\n",
      "        - 0.45703125\n",
      "        - -0.03229135274887085\n",
      "        - -0.14652785658836365\n",
      "        - 1.1491432189941406\n",
      "        - 0.6328964233398438\n",
      "        - 2.3914718627929688\n",
      "        - 0.8978271484375\n",
      "        - -0.7543182373046875\n",
      "        - -0.21996307373046875\n",
      "        - 0.26013946533203125\n",
      "        - 0.4668998718261719\n",
      "        - -0.1166514903306961\n",
      "        - 0.008968381211161613\n",
      "        - 1.2608909606933594\n",
      "        - -0.2666893005371094\n",
      "        - 1.3401031494140625\n",
      "        - -0.06830528378486633\n",
      "        - 1.722747802734375\n",
      "        - -0.20407730340957642\n",
      "        - 0.15794330835342407\n",
      "        - -0.5370712280273438\n",
      "        - 2.134185791015625\n",
      "        - -1.3161678314208984\n",
      "        - -0.19876337051391602\n",
      "        - -0.9438667297363281\n",
      "        - 1.4052886962890625\n",
      "        - -0.18741583824157715\n",
      "        - -0.07522360980510712\n",
      "        - 0.8627719879150391\n",
      "        - -0.2128983438014984\n",
      "        - 0.1571502685546875\n",
      "        - 1.1213226318359375\n",
      "        - -0.17044860124588013\n",
      "        - 0.038659192621707916\n",
      "        - -0.13565149903297424\n",
      "        - -1.20245361328125\n",
      "        - 1.1866188049316406\n",
      "        - -0.2780969440937042\n",
      "        - -0.11487095057964325\n",
      "        - -1.1193695068359375\n",
      "        - 0.6131820678710938\n",
      "        - 0.9173431396484375\n",
      "        - 0.255218505859375\n",
      "        - 1.3713836669921875\n",
      "        - 0.42779541015625\n",
      "        - -0.10079455375671387\n",
      "        - -0.43987274169921875\n",
      "        - -0.0078277587890625\n",
      "        - 0.2964630126953125\n",
      "        - -0.0728302001953125\n",
      "        - 0.9019241333007812\n",
      "        - -0.027227764949202538\n",
      "        - 0.6586837768554688\n",
      "        - -0.28214749693870544\n",
      "        - -0.4197196960449219\n",
      "        - 0.13979339599609375\n",
      "        - 0.09124064445495605\n",
      "        - -0.029795603826642036\n",
      "        - -0.1500692367553711\n",
      "        - 1.5997390747070312\n",
      "        - 2.014972686767578\n",
      "        - 1.2377166748046875\n",
      "        - 4.970787048339844\n",
      "        - -0.507232666015625\n",
      "        - -0.11271072924137115\n",
      "        - 0.6722488403320312\n",
      "        - 0.4958648681640625\n",
      "        - 0.059729911386966705\n",
      "        - -0.4157142639160156\n",
      "        - -0.38071441650390625\n",
      "        - 0.760467529296875\n",
      "        - 0.07964324951171875\n",
      "        - 0.21315765380859375\n",
      "        - 1.2003631591796875\n",
      "        - 0.34159183502197266\n",
      "        - -0.8828201293945312\n",
      "        - 0.2213287353515625\n",
      "        - 0.2862892150878906\n",
      "        - -0.2774658203125\n",
      "        - 1.4659423828125\n",
      "        - 0.24802398681640625\n",
      "        - 0.16580963134765625\n",
      "        - 0.3137168884277344\n",
      "        - 0.44747161865234375\n",
      "        - 0.004786260426044464\n",
      "        - 0.19085693359375\n",
      "        - 0.13397979736328125\n",
      "        - -0.7610931396484375\n",
      "        - 0.6707687377929688\n",
      "        - 0.2135009765625\n",
      "        - 0.23297119140625\n",
      "        - -0.9777603149414062\n",
      "        - -0.11012282222509384\n",
      "        - 0.21147918701171875\n",
      "        - -0.13442648947238922\n",
      "        - 1.0462417602539062\n",
      "        - -0.11195552349090576\n",
      "        - -0.9135360717773438\n",
      "        - -0.200592041015625\n",
      "        - -0.46041107177734375\n",
      "        - 0.02974700927734375\n",
      "        - 1.5016326904296875\n",
      "        - -0.08768784254789352\n",
      "        - -0.6444282531738281\n",
      "        - 0.87664794921875\n",
      "        - 0.07814979553222656\n",
      "        - 0.83538818359375\n",
      "        - -0.9235916137695312\n",
      "        - -1.099747896194458\n",
      "        - 0.8099288940429688\n",
      "        - -0.13654237985610962\n",
      "        - 0.8890876770019531\n",
      "        - -0.04590487480163574\n",
      "        - 0.1515653133392334\n",
      "        - 2.0327301025390625\n",
      "        - 0.0195159912109375\n",
      "        - 0.253448486328125\n",
      "        - -0.5844535827636719\n",
      "        - -0.13456624746322632\n",
      "        - 0.8750228881835938\n",
      "        - -0.7917709350585938\n",
      "        - 0.2676849365234375\n",
      "        - 1.5306625366210938\n",
      "        - -0.6210365295410156\n",
      "        - 1.4876632690429688\n",
      "    num_agent_steps_sampled: 14500\n",
      "    num_agent_steps_trained: 1664256\n",
      "    num_steps_sampled: 14500\n",
      "    num_steps_trained: 1664256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 6501\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 7.954166666666667\n",
      "    ram_util_percent: 1.8\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.20239345412289986\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.21725181924829945\n",
      "    mean_inference_ms: 1.496812439358062\n",
      "    mean_raw_obs_processing_ms: 0.5394920447260426\n",
      "  time_since_restore: 231.68567085266113\n",
      "  time_this_iter_s: 16.4470534324646\n",
      "  time_total_s: 231.68567085266113\n",
      "  timers:\n",
      "    learn_throughput: 50897.646\n",
      "    learn_time_ms: 5.03\n",
      "    load_throughput: 638523.92\n",
      "    load_time_ms: 0.401\n",
      "    update_time_ms: 2.986\n",
      "  timestamp: 1647533889\n",
      "  timesteps_since_restore: 3584\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 14500\n",
      "  training_iteration: 14\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:18:12 (running for 00:04:09.36)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         231.686</td><td style=\"text-align: right;\">14500</td><td style=\"text-align: right;\">-976.136</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:18:17 (running for 00:04:14.37)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         231.686</td><td style=\"text-align: right;\">14500</td><td style=\"text-align: right;\">-976.136</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:18:22 (running for 00:04:19.38)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         231.686</td><td style=\"text-align: right;\">14500</td><td style=\"text-align: right;\">-976.136</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 15500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-18-26\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.625332495372558\n",
      "  episode_reward_mean: -934.8804976113106\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 76\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 15500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 1.3295410871505737\n",
      "          mean_q: -54.93117904663086\n",
      "          min_q: -101.98088836669922\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.11853271722793579\n",
      "        - 1.1119308471679688\n",
      "        - -1.55126953125\n",
      "        - -0.37530526518821716\n",
      "        - -0.23855865001678467\n",
      "        - -0.47512054443359375\n",
      "        - -0.14568328857421875\n",
      "        - 0.6137351989746094\n",
      "        - -0.24147507548332214\n",
      "        - -0.19666124880313873\n",
      "        - 1.2597198486328125\n",
      "        - 0.4405555725097656\n",
      "        - -0.33839845657348633\n",
      "        - -0.20722240209579468\n",
      "        - -0.2734832763671875\n",
      "        - 0.12176513671875\n",
      "        - 0.023529052734375\n",
      "        - 0.6542892456054688\n",
      "        - -0.25537943840026855\n",
      "        - -0.3332206606864929\n",
      "        - 0.42877960205078125\n",
      "        - -2.77899169921875\n",
      "        - -0.11315155029296875\n",
      "        - -0.38235947489738464\n",
      "        - -0.639556884765625\n",
      "        - -0.5213165283203125\n",
      "        - -0.2567704916000366\n",
      "        - 0.38568878173828125\n",
      "        - 0.139495849609375\n",
      "        - -0.27240806818008423\n",
      "        - -1.5607452392578125\n",
      "        - -0.3400883674621582\n",
      "        - -0.06230926513671875\n",
      "        - -0.3463171124458313\n",
      "        - -0.28497567772865295\n",
      "        - 0.1973419189453125\n",
      "        - 0.6625747680664062\n",
      "        - 0.5706558227539062\n",
      "        - 0.8394546508789062\n",
      "        - 0.0533599853515625\n",
      "        - 0.6232700347900391\n",
      "        - -0.1304779052734375\n",
      "        - -1.1454267501831055\n",
      "        - -0.7942428588867188\n",
      "        - -0.6547622680664062\n",
      "        - -0.33938729763031006\n",
      "        - 0.902435302734375\n",
      "        - 0.18708038330078125\n",
      "        - 2.975860595703125\n",
      "        - 0.7058372497558594\n",
      "        - -0.8354110717773438\n",
      "        - 0.8116035461425781\n",
      "        - 0.70159912109375\n",
      "        - 1.8132591247558594\n",
      "        - 0.6998176574707031\n",
      "        - 0.436920166015625\n",
      "        - 0.7950210571289062\n",
      "        - -0.10457611083984375\n",
      "        - -0.07134246826171875\n",
      "        - -0.49387359619140625\n",
      "        - 0.00152587890625\n",
      "        - -1.1469402313232422\n",
      "        - -0.32102254033088684\n",
      "        - -0.30176907777786255\n",
      "        - 0.3554229736328125\n",
      "        - -0.0006953217089176178\n",
      "        - 0.21973419189453125\n",
      "        - -1.49102783203125\n",
      "        - 1.8419647216796875\n",
      "        - 0.5615768432617188\n",
      "        - -0.27788835763931274\n",
      "        - -0.9655036926269531\n",
      "        - -0.07152557373046875\n",
      "        - 0.01825714111328125\n",
      "        - 1.8009490966796875\n",
      "        - 1.5961709022521973\n",
      "        - 1.2278366088867188\n",
      "        - 0.7183685302734375\n",
      "        - -0.20337677001953125\n",
      "        - 0.06336212158203125\n",
      "        - -0.3042280972003937\n",
      "        - 0.7612762451171875\n",
      "        - -0.8857765197753906\n",
      "        - -0.036529541015625\n",
      "        - -0.5192947387695312\n",
      "        - -0.31809648871421814\n",
      "        - -0.8949050903320312\n",
      "        - -0.20772552490234375\n",
      "        - 1.7454299926757812\n",
      "        - -0.6862392425537109\n",
      "        - 0.6592483520507812\n",
      "        - 0.4310455322265625\n",
      "        - -0.62335205078125\n",
      "        - 0.13578033447265625\n",
      "        - -0.3404309153556824\n",
      "        - -0.33954373002052307\n",
      "        - -0.5705795288085938\n",
      "        - 0.22671890258789062\n",
      "        - -0.15559981763362885\n",
      "        - 0.24970245361328125\n",
      "        - 0.3671417236328125\n",
      "        - 0.31328582763671875\n",
      "        - -0.3052937686443329\n",
      "        - 0.33843231201171875\n",
      "        - -0.613037109375\n",
      "        - 0.3023223876953125\n",
      "        - -0.33516159653663635\n",
      "        - -0.2875097692012787\n",
      "        - -0.12485504150390625\n",
      "        - 0.25565338134765625\n",
      "        - -0.31843581795692444\n",
      "        - -0.30376794934272766\n",
      "        - 1.8413314819335938\n",
      "        - -0.15380096435546875\n",
      "        - 0.0573272705078125\n",
      "        - 0.690399169921875\n",
      "        - -1.181121826171875\n",
      "        - -0.20899838209152222\n",
      "        - 2.6502227783203125\n",
      "        - -0.38226318359375\n",
      "        - 0.0783538818359375\n",
      "        - -0.32986122369766235\n",
      "        - -0.20284020900726318\n",
      "        - -0.09858143329620361\n",
      "        - -0.2558910548686981\n",
      "        - -0.27684879302978516\n",
      "        - -0.43137285113334656\n",
      "        - 0.611419677734375\n",
      "        - -0.31734538078308105\n",
      "        - 0.41544342041015625\n",
      "        - -0.4157283306121826\n",
      "        - 0.20001220703125\n",
      "        - -0.3463171124458313\n",
      "        - -1.6413421630859375\n",
      "        - -0.2971253991127014\n",
      "        - -0.4712018370628357\n",
      "        - -0.3404946029186249\n",
      "        - -0.602783203125\n",
      "        - -0.18616485595703125\n",
      "        - -0.34807586669921875\n",
      "        - 1.8237686157226562\n",
      "        - 0.0709991455078125\n",
      "        - -1.7987594604492188\n",
      "        - 0.9756317138671875\n",
      "        - -0.38504791259765625\n",
      "        - -0.5107421875\n",
      "        - 1.8760261535644531\n",
      "        - 0.7458877563476562\n",
      "        - -0.5014572143554688\n",
      "        - -2.4911842346191406\n",
      "        - -0.3387451171875\n",
      "        - 1.72406005859375\n",
      "        - 0.6507077217102051\n",
      "        - 0.15006256103515625\n",
      "        - 0.3031005859375\n",
      "        - -0.2408284842967987\n",
      "        - -0.4354133605957031\n",
      "        - -0.35613882541656494\n",
      "        - -1.4927635192871094\n",
      "        - 1.2827644348144531\n",
      "        - 0.06525421142578125\n",
      "        - -1.1071510314941406\n",
      "        - 0.16002655029296875\n",
      "        - 0.6219558715820312\n",
      "        - -1.0999603271484375\n",
      "        - -0.3265346586704254\n",
      "        - 0.16302490234375\n",
      "        - -0.36441558599472046\n",
      "        - 0.18661439418792725\n",
      "        - -0.34927093982696533\n",
      "        - 0.5536346435546875\n",
      "        - -0.29987630248069763\n",
      "        - 0.814422607421875\n",
      "        - -2.239337921142578\n",
      "        - -0.29746291041374207\n",
      "        - 1.018157958984375\n",
      "        - 3.5302047729492188\n",
      "        - -0.31915968656539917\n",
      "        - 3.0377426147460938\n",
      "        - -0.7423248291015625\n",
      "        - -0.6711733937263489\n",
      "        - -0.7674331665039062\n",
      "        - -2.246776580810547\n",
      "        - -0.10617828369140625\n",
      "        - -0.4577178955078125\n",
      "        - 0.7167739868164062\n",
      "        - -1.2397270202636719\n",
      "        - 1.4063720703125\n",
      "        - 0.25322723388671875\n",
      "        - -0.49874114990234375\n",
      "        - -0.2511746287345886\n",
      "        - 0.27704620361328125\n",
      "        - 0.9386978149414062\n",
      "        - 0.290802001953125\n",
      "        - -0.1472882479429245\n",
      "        - -0.3866942822933197\n",
      "        - -0.14444732666015625\n",
      "        - -1.0428085327148438\n",
      "        - -1.4286422729492188\n",
      "        - -0.4764719605445862\n",
      "        - 1.8707695007324219\n",
      "        - 2.4295425415039062\n",
      "        - 1.1177101135253906\n",
      "        - -0.16521453857421875\n",
      "        - -2.2529830932617188\n",
      "        - -0.3029235303401947\n",
      "        - -0.532135009765625\n",
      "        - 0.13442230224609375\n",
      "        - 0.1605987548828125\n",
      "        - 0.2184600830078125\n",
      "        - -0.1202239990234375\n",
      "        - -0.46210479736328125\n",
      "        - -2.0606765747070312\n",
      "        - 0.8094329833984375\n",
      "        - -0.9297103881835938\n",
      "        - 0.6080374717712402\n",
      "        - 0.8740615844726562\n",
      "        - 1.237945556640625\n",
      "        - -0.687530517578125\n",
      "        - -0.07373366504907608\n",
      "        - -0.1998138427734375\n",
      "        - -0.4361114501953125\n",
      "        - -1.0594329833984375\n",
      "        - 0.7445526123046875\n",
      "        - -0.3201938569545746\n",
      "        - 0.3217620849609375\n",
      "        - -0.3169581890106201\n",
      "        - -0.07848358154296875\n",
      "        - -0.4647064208984375\n",
      "        - -1.9043731689453125\n",
      "        - 1.3507766723632812\n",
      "        - -0.38197407126426697\n",
      "        - -0.514870285987854\n",
      "        - -0.29167813062667847\n",
      "        - 0.9217529296875\n",
      "        - -0.06769949197769165\n",
      "        - -0.28071925044059753\n",
      "        - 0.8528594970703125\n",
      "        - -0.30563223361968994\n",
      "        - 0.32981109619140625\n",
      "        - -0.2053530514240265\n",
      "        - 0.566253662109375\n",
      "        - 0.9114456176757812\n",
      "        - 0.16031646728515625\n",
      "        - -0.36576080322265625\n",
      "        - -1.8140640258789062\n",
      "        - -0.31428658962249756\n",
      "        - -0.24297186732292175\n",
      "        - -0.7767562866210938\n",
      "        - -2.2000579833984375\n",
      "        - 1.1135330200195312\n",
      "        - -0.23833465576171875\n",
      "        - 1.8899002075195312\n",
      "        - -0.1996920108795166\n",
      "        - -0.3100564181804657\n",
      "        - 0.012969970703125\n",
      "    num_agent_steps_sampled: 15500\n",
      "    num_agent_steps_trained: 1792256\n",
      "    num_steps_sampled: 15500\n",
      "    num_steps_trained: 1792256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 7001\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 9.639130434782608\n",
      "    ram_util_percent: 1.7999999999999994\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.20197530590117088\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.21655746786046193\n",
      "    mean_inference_ms: 1.4793703162406064\n",
      "    mean_raw_obs_processing_ms: 0.5373671431059396\n",
      "  time_since_restore: 248.33060097694397\n",
      "  time_this_iter_s: 16.644930124282837\n",
      "  time_total_s: 248.33060097694397\n",
      "  timers:\n",
      "    learn_throughput: 51514.468\n",
      "    learn_time_ms: 4.969\n",
      "    load_throughput: 656602.351\n",
      "    load_time_ms: 0.39\n",
      "    update_time_ms: 2.817\n",
      "  timestamp: 1647533906\n",
      "  timesteps_since_restore: 3840\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 15500\n",
      "  training_iteration: 15\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:18:28 (running for 00:04:25.00)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         248.331</td><td style=\"text-align: right;\">15500</td><td style=\"text-align: right;\"> -934.88</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:18:33 (running for 00:04:30.04)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         248.331</td><td style=\"text-align: right;\">15500</td><td style=\"text-align: right;\"> -934.88</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:18:38 (running for 00:04:35.05)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         248.331</td><td style=\"text-align: right;\">15500</td><td style=\"text-align: right;\"> -934.88</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 16500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-18-43\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.625332495372558\n",
      "  episode_reward_mean: -886.8005577472517\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 82\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 16500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 2.2173075675964355\n",
      "          mean_q: -52.52128601074219\n",
      "          min_q: -106.34693908691406\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.774017333984375\n",
      "        - 0.207968607544899\n",
      "        - 0.16248035430908203\n",
      "        - 0.22962811589241028\n",
      "        - -0.2953338623046875\n",
      "        - -1.1737327575683594\n",
      "        - 0.5366134643554688\n",
      "        - 0.8064422607421875\n",
      "        - -0.01428985595703125\n",
      "        - 0.16422227025032043\n",
      "        - 0.20165252685546875\n",
      "        - 0.23884205520153046\n",
      "        - 0.05455678701400757\n",
      "        - -0.6687774658203125\n",
      "        - 0.1537293642759323\n",
      "        - 1.1668243408203125\n",
      "        - 1.7874679565429688\n",
      "        - -0.0024459362030029297\n",
      "        - 1.2858352661132812\n",
      "        - 0.377288818359375\n",
      "        - -0.11590576171875\n",
      "        - 0.32355499267578125\n",
      "        - 0.3545684814453125\n",
      "        - -0.545166015625\n",
      "        - -0.3248558044433594\n",
      "        - -0.9460830688476562\n",
      "        - 0.12277242541313171\n",
      "        - 1.0304040908813477\n",
      "        - -1.2943191528320312\n",
      "        - -0.44797515869140625\n",
      "        - -0.01031494140625\n",
      "        - -0.9605007171630859\n",
      "        - -0.02617645263671875\n",
      "        - -1.3926422595977783\n",
      "        - 0.3172086179256439\n",
      "        - 1.4376487731933594\n",
      "        - 0.8329238891601562\n",
      "        - 0.06869333982467651\n",
      "        - 1.9986114501953125\n",
      "        - 0.0923309326171875\n",
      "        - 0.68646240234375\n",
      "        - 0.21308253705501556\n",
      "        - -0.129547119140625\n",
      "        - 0.838623046875\n",
      "        - 2.581085205078125\n",
      "        - 0.10985662043094635\n",
      "        - -1.1337394714355469\n",
      "        - 0.063812255859375\n",
      "        - -0.14177978038787842\n",
      "        - 0.20147769153118134\n",
      "        - 0.6217671632766724\n",
      "        - 0.9656906127929688\n",
      "        - -0.07298445701599121\n",
      "        - 0.8287429809570312\n",
      "        - -0.6228828430175781\n",
      "        - 0.1420128345489502\n",
      "        - 0.02646654099225998\n",
      "        - 0.17477983236312866\n",
      "        - 0.19719821214675903\n",
      "        - 0.12258486449718475\n",
      "        - 0.5615081787109375\n",
      "        - 0.32794952392578125\n",
      "        - 0.37653350830078125\n",
      "        - -0.041562944650650024\n",
      "        - -1.1354179382324219\n",
      "        - 0.17217117547988892\n",
      "        - 0.1410844326019287\n",
      "        - 0.723541259765625\n",
      "        - 0.7751235961914062\n",
      "        - 0.7202987670898438\n",
      "        - 0.6904983520507812\n",
      "        - 1.854156494140625\n",
      "        - -0.1993255615234375\n",
      "        - -0.9160995483398438\n",
      "        - 0.7286224365234375\n",
      "        - 1.8140029907226562\n",
      "        - 0.25199347734451294\n",
      "        - -0.19576424360275269\n",
      "        - 0.553985595703125\n",
      "        - 0.23682403564453125\n",
      "        - 0.8253402709960938\n",
      "        - 1.4343795776367188\n",
      "        - 1.0461654663085938\n",
      "        - -0.04701995849609375\n",
      "        - 0.7307145595550537\n",
      "        - -1.1703224182128906\n",
      "        - 0.8328475952148438\n",
      "        - 0.12612810730934143\n",
      "        - -0.11847686767578125\n",
      "        - 1.1650581359863281\n",
      "        - 1.1236190795898438\n",
      "        - -0.1993255615234375\n",
      "        - 0.07468423247337341\n",
      "        - 0.15185546875\n",
      "        - 0.2427215576171875\n",
      "        - -1.385000228881836\n",
      "        - -0.35245800018310547\n",
      "        - 1.9162826538085938\n",
      "        - 1.2095794677734375\n",
      "        - -0.29042816162109375\n",
      "        - 0.4960709810256958\n",
      "        - 0.00261688232421875\n",
      "        - 0.8932113647460938\n",
      "        - 1.7357559204101562\n",
      "        - 0.43924713134765625\n",
      "        - -0.06331634521484375\n",
      "        - -0.09777069091796875\n",
      "        - -0.1547088623046875\n",
      "        - -0.6593399047851562\n",
      "        - 0.4548376798629761\n",
      "        - 0.46370697021484375\n",
      "        - 0.5784759521484375\n",
      "        - -0.43274688720703125\n",
      "        - -0.3739280700683594\n",
      "        - 0.8280410766601562\n",
      "        - -0.066436767578125\n",
      "        - 0.121612548828125\n",
      "        - 0.18638858199119568\n",
      "        - 0.3285612463951111\n",
      "        - -0.00133514404296875\n",
      "        - 2.0088729858398438\n",
      "        - 0.017791748046875\n",
      "        - 0.5324478149414062\n",
      "        - 0.8100357055664062\n",
      "        - 0.10698550939559937\n",
      "        - 0.8372650146484375\n",
      "        - 0.862579345703125\n",
      "        - -0.874755859375\n",
      "        - 1.4693145751953125\n",
      "        - 0.20383618772029877\n",
      "        - 0.13875308632850647\n",
      "        - 1.0275650024414062\n",
      "        - 1.8836555480957031\n",
      "        - -1.1017227172851562\n",
      "        - 0.6356887817382812\n",
      "        - 0.20941470563411713\n",
      "        - 0.11693572998046875\n",
      "        - 0.2990625500679016\n",
      "        - 0.5332489013671875\n",
      "        - -0.2597503662109375\n",
      "        - 2.1082763671875\n",
      "        - 0.4844818115234375\n",
      "        - 1.8606109619140625\n",
      "        - 0.4461822509765625\n",
      "        - 0.16274148225784302\n",
      "        - 0.11447043716907501\n",
      "        - 1.2849884033203125\n",
      "        - 0.15505969524383545\n",
      "        - 0.22303742170333862\n",
      "        - 0.10613948106765747\n",
      "        - 0.2511558532714844\n",
      "        - -0.8740329742431641\n",
      "        - 0.8589935302734375\n",
      "        - 0.17657451331615448\n",
      "        - 0.007369399070739746\n",
      "        - 0.39044952392578125\n",
      "        - 1.5632858276367188\n",
      "        - 0.2486419677734375\n",
      "        - -0.7428359985351562\n",
      "        - -0.18054962158203125\n",
      "        - 0.23489496111869812\n",
      "        - -0.03009033203125\n",
      "        - 0.8266983032226562\n",
      "        - 1.5108013153076172\n",
      "        - 0.819427490234375\n",
      "        - 0.07333220541477203\n",
      "        - 0.12457852065563202\n",
      "        - 1.5211410522460938\n",
      "        - -0.774871826171875\n",
      "        - -2.4989166259765625\n",
      "        - 0.20700013637542725\n",
      "        - -0.47971343994140625\n",
      "        - 1.8629646301269531\n",
      "        - -0.29393768310546875\n",
      "        - 0.750091552734375\n",
      "        - 0.2526702880859375\n",
      "        - 0.2597392797470093\n",
      "        - 1.2434768676757812\n",
      "        - 0.08072298765182495\n",
      "        - 0.13512757420539856\n",
      "        - 1.358327865600586\n",
      "        - 0.23327460885047913\n",
      "        - 1.6978645324707031\n",
      "        - -0.5468363761901855\n",
      "        - -0.3635587692260742\n",
      "        - -0.14937591552734375\n",
      "        - 1.69329833984375\n",
      "        - 1.1091537475585938\n",
      "        - 0.33977508544921875\n",
      "        - 1.7230224609375\n",
      "        - 0.14913299679756165\n",
      "        - 2.1750946044921875\n",
      "        - 1.479736328125\n",
      "        - 0.29654067754745483\n",
      "        - -0.09608078002929688\n",
      "        - 0.1601858139038086\n",
      "        - 4.1254425048828125\n",
      "        - 0.8273239135742188\n",
      "        - 0.1106492131948471\n",
      "        - 0.13808059692382812\n",
      "        - 0.16708604991436005\n",
      "        - 0.11105918884277344\n",
      "        - 0.15871146321296692\n",
      "        - 0.062152087688446045\n",
      "        - -0.12377166748046875\n",
      "        - 0.05797198414802551\n",
      "        - 0.6467514038085938\n",
      "        - 0.003400474786758423\n",
      "        - 0.33487701416015625\n",
      "        - -0.3108062744140625\n",
      "        - 1.4189682006835938\n",
      "        - 0.13607531785964966\n",
      "        - 0.14511901140213013\n",
      "        - -0.07807159423828125\n",
      "        - 1.5763587951660156\n",
      "        - 0.25533807277679443\n",
      "        - 0.29686737060546875\n",
      "        - 0.16630737483501434\n",
      "        - 0.2064984142780304\n",
      "        - 0.080535888671875\n",
      "        - 0.6383435726165771\n",
      "        - -0.07562637329101562\n",
      "        - -0.07065534591674805\n",
      "        - 0.3652496337890625\n",
      "        - 0.8033599853515625\n",
      "        - 0.4976806640625\n",
      "        - 0.22199934720993042\n",
      "        - -0.07186126708984375\n",
      "        - 0.25577518343925476\n",
      "        - 0.191619873046875\n",
      "        - 0.38461506366729736\n",
      "        - 0.5350723266601562\n",
      "        - -0.9039382934570312\n",
      "        - 0.5658645629882812\n",
      "        - 0.2812882661819458\n",
      "        - 0.254446417093277\n",
      "        - 0.26903802156448364\n",
      "        - 0.25730133056640625\n",
      "        - 0.5228958129882812\n",
      "        - 1.5841751098632812\n",
      "        - -0.26792144775390625\n",
      "        - 1.473419189453125\n",
      "        - -0.5928497314453125\n",
      "        - -0.4658355712890625\n",
      "        - -1.1490631103515625\n",
      "        - 1.2489395141601562\n",
      "        - -0.09304046630859375\n",
      "        - -0.08182144165039062\n",
      "        - 0.9775772094726562\n",
      "        - 0.39044952392578125\n",
      "        - 0.18717500567436218\n",
      "        - 0.6436080932617188\n",
      "        - 0.24738311767578125\n",
      "        - 0.27730223536491394\n",
      "        - 0.09293735027313232\n",
      "        - 0.5988311767578125\n",
      "    num_agent_steps_sampled: 16500\n",
      "    num_agent_steps_trained: 1920256\n",
      "    num_steps_sampled: 16500\n",
      "    num_steps_trained: 1920256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 7501\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 7.970833333333334\n",
      "    ram_util_percent: 1.8\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.20139398970509884\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.21558588221390604\n",
      "    mean_inference_ms: 1.4556507112201902\n",
      "    mean_raw_obs_processing_ms: 0.5344146748615848\n",
      "  time_since_restore: 265.11452412605286\n",
      "  time_this_iter_s: 16.783923149108887\n",
      "  time_total_s: 265.11452412605286\n",
      "  timers:\n",
      "    learn_throughput: 51383.32\n",
      "    learn_time_ms: 4.982\n",
      "    load_throughput: 652056.734\n",
      "    load_time_ms: 0.393\n",
      "    update_time_ms: 2.879\n",
      "  timestamp: 1647533923\n",
      "  timesteps_since_restore: 4096\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 16500\n",
      "  training_iteration: 16\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:18:44 (running for 00:04:40.87)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         265.115</td><td style=\"text-align: right;\">16500</td><td style=\"text-align: right;\">-886.801</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:18:49 (running for 00:04:45.87)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         265.115</td><td style=\"text-align: right;\">16500</td><td style=\"text-align: right;\">-886.801</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:18:54 (running for 00:04:50.88)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         265.115</td><td style=\"text-align: right;\">16500</td><td style=\"text-align: right;\">-886.801</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:18:59 (running for 00:04:55.89)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         265.115</td><td style=\"text-align: right;\">16500</td><td style=\"text-align: right;\">-886.801</td><td style=\"text-align: right;\">           -0.625332</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 17500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-18-59\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5667682941302677\n",
      "  episode_reward_mean: -850.1482876683848\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 86\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 17500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 0.6603628993034363\n",
      "          mean_q: -55.20359802246094\n",
      "          min_q: -111.78539276123047\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.317535400390625\n",
      "        - -0.683013916015625\n",
      "        - 0.25496673583984375\n",
      "        - -0.3710690140724182\n",
      "        - -0.2989806532859802\n",
      "        - -0.1674041748046875\n",
      "        - -0.4463081359863281\n",
      "        - 0.0675201416015625\n",
      "        - -0.7048263549804688\n",
      "        - -0.51800537109375\n",
      "        - -0.4066975712776184\n",
      "        - -0.38197851181030273\n",
      "        - -0.045501708984375\n",
      "        - 1.1859588623046875\n",
      "        - -0.6833912134170532\n",
      "        - 0.1879425048828125\n",
      "        - -0.3171469569206238\n",
      "        - 0.14226531982421875\n",
      "        - -1.8125457763671875\n",
      "        - 2.1945838928222656\n",
      "        - -0.2764930725097656\n",
      "        - -0.15378570556640625\n",
      "        - 0.9239501953125\n",
      "        - -0.509837806224823\n",
      "        - -0.36203157901763916\n",
      "        - 0.1905975341796875\n",
      "        - 0.00931549072265625\n",
      "        - -0.3543228805065155\n",
      "        - -0.0369720458984375\n",
      "        - -1.1838302612304688\n",
      "        - -1.466552734375\n",
      "        - -0.31873804330825806\n",
      "        - -0.36258170008659363\n",
      "        - 0.7806320190429688\n",
      "        - -0.10133552551269531\n",
      "        - -0.1414337158203125\n",
      "        - -0.15164947509765625\n",
      "        - -0.02579498291015625\n",
      "        - -0.80328369140625\n",
      "        - -0.38518524169921875\n",
      "        - -0.6161069273948669\n",
      "        - -1.585235595703125\n",
      "        - -0.37176513671875\n",
      "        - -0.35428711771965027\n",
      "        - -0.6687850952148438\n",
      "        - 0.22806549072265625\n",
      "        - -1.1966476440429688\n",
      "        - -0.6019577980041504\n",
      "        - -0.24191801249980927\n",
      "        - -0.3633829653263092\n",
      "        - -0.42528092861175537\n",
      "        - -0.5084563493728638\n",
      "        - 0.0924224853515625\n",
      "        - -0.389851838350296\n",
      "        - -0.6994396448135376\n",
      "        - 1.6054306030273438\n",
      "        - -0.3804003596305847\n",
      "        - -0.4719145894050598\n",
      "        - -1.0376954078674316\n",
      "        - -0.29617294669151306\n",
      "        - -1.2263412475585938\n",
      "        - -0.3859860599040985\n",
      "        - -0.6474456787109375\n",
      "        - 0.10390472412109375\n",
      "        - 1.5745849609375\n",
      "        - -1.713775634765625\n",
      "        - -0.07755279541015625\n",
      "        - -0.4347381591796875\n",
      "        - -0.5033673048019409\n",
      "        - 0.780364990234375\n",
      "        - -0.4892258048057556\n",
      "        - 1.2217330932617188\n",
      "        - 1.4833984375\n",
      "        - -0.3145514726638794\n",
      "        - -0.4104253947734833\n",
      "        - 1.2559051513671875\n",
      "        - -83.03716278076172\n",
      "        - 0.7158355712890625\n",
      "        - -0.3231048583984375\n",
      "        - 0.8644943237304688\n",
      "        - 0.228271484375\n",
      "        - -0.4918365478515625\n",
      "        - 1.0081634521484375\n",
      "        - -0.32237619161605835\n",
      "        - 0.93402099609375\n",
      "        - -0.9429179430007935\n",
      "        - -1.018402099609375\n",
      "        - -0.346811980009079\n",
      "        - 0.6071929931640625\n",
      "        - 0.196136474609375\n",
      "        - -0.8301552534103394\n",
      "        - -0.6466903686523438\n",
      "        - -0.37244734168052673\n",
      "        - 0.7845458984375\n",
      "        - 0.6376686096191406\n",
      "        - -0.58343505859375\n",
      "        - -0.6098474860191345\n",
      "        - -0.47643280029296875\n",
      "        - -0.26033782958984375\n",
      "        - -0.2268829345703125\n",
      "        - 1.247894287109375\n",
      "        - 0.45461273193359375\n",
      "        - -1.719757080078125\n",
      "        - 0.07220456004142761\n",
      "        - -0.21929931640625\n",
      "        - -0.17060089111328125\n",
      "        - -0.17601776123046875\n",
      "        - 0.73291015625\n",
      "        - -0.3855860233306885\n",
      "        - 0.6188125610351562\n",
      "        - 0.10630035400390625\n",
      "        - -1.9137191772460938\n",
      "        - -2.0077362060546875\n",
      "        - -0.2679595947265625\n",
      "        - -0.7183303833007812\n",
      "        - -0.27957215905189514\n",
      "        - -0.7547035217285156\n",
      "        - -0.6800460815429688\n",
      "        - -0.423480749130249\n",
      "        - -0.30711865425109863\n",
      "        - -0.5949020385742188\n",
      "        - 0.417694091796875\n",
      "        - -0.3288002014160156\n",
      "        - -0.16627013683319092\n",
      "        - -0.4515838623046875\n",
      "        - 0.490997314453125\n",
      "        - -0.7911758422851562\n",
      "        - -0.44207894802093506\n",
      "        - -0.8257293701171875\n",
      "        - -1.7733688354492188\n",
      "        - 0.3225669860839844\n",
      "        - -0.17979344725608826\n",
      "        - 0.4061431884765625\n",
      "        - 0.6210098266601562\n",
      "        - -0.7522035837173462\n",
      "        - 0.35121917724609375\n",
      "        - -0.7301254272460938\n",
      "        - 1.983917236328125\n",
      "        - -0.0031280517578125\n",
      "        - 0.17055511474609375\n",
      "        - -0.4983479380607605\n",
      "        - 0.7133865356445312\n",
      "        - 1.4650993347167969\n",
      "        - 0.30689239501953125\n",
      "        - -2.386444091796875\n",
      "        - -0.7169094681739807\n",
      "        - -0.4024023115634918\n",
      "        - -0.4961223304271698\n",
      "        - -0.9262771606445312\n",
      "        - -0.43769118189811707\n",
      "        - -0.3383672833442688\n",
      "        - -0.1355133056640625\n",
      "        - -0.1091180145740509\n",
      "        - -0.3159564733505249\n",
      "        - 0.8938941955566406\n",
      "        - -0.3251584470272064\n",
      "        - -0.21997833251953125\n",
      "        - -0.04216766357421875\n",
      "        - -0.40359196066856384\n",
      "        - -0.9499435424804688\n",
      "        - -0.5164413452148438\n",
      "        - -0.6677017211914062\n",
      "        - -0.25571441650390625\n",
      "        - -0.44704729318618774\n",
      "        - -88.1861572265625\n",
      "        - -0.5034694075584412\n",
      "        - -0.4616842269897461\n",
      "        - -0.41150665283203125\n",
      "        - -0.6761436462402344\n",
      "        - -0.32598876953125\n",
      "        - 0.2546844482421875\n",
      "        - -0.4598035216331482\n",
      "        - -0.27433013916015625\n",
      "        - 0.4735832214355469\n",
      "        - -0.6535110473632812\n",
      "        - -0.585324764251709\n",
      "        - -0.214546799659729\n",
      "        - 1.3067703247070312\n",
      "        - -0.5378156900405884\n",
      "        - -0.5395238399505615\n",
      "        - -0.1265869140625\n",
      "        - -0.3872790038585663\n",
      "        - -0.9180908203125\n",
      "        - 0.6902236938476562\n",
      "        - -0.35858839750289917\n",
      "        - -0.051849365234375\n",
      "        - -0.18695417046546936\n",
      "        - -0.364288330078125\n",
      "        - 0.48743438720703125\n",
      "        - -0.409129798412323\n",
      "        - -0.3061981201171875\n",
      "        - 0.6624908447265625\n",
      "        - -0.4677920341491699\n",
      "        - -0.5665431022644043\n",
      "        - -1.7347640991210938\n",
      "        - -0.4051593244075775\n",
      "        - 0.5056343078613281\n",
      "        - -1.4364852905273438\n",
      "        - -0.112579345703125\n",
      "        - 0.26561737060546875\n",
      "        - -0.7202532887458801\n",
      "        - -0.42022326588630676\n",
      "        - 0.9453506469726562\n",
      "        - -0.3967437744140625\n",
      "        - -0.8405685424804688\n",
      "        - -0.4073857069015503\n",
      "        - -0.18242061138153076\n",
      "        - -0.0656280517578125\n",
      "        - -0.7172317504882812\n",
      "        - -0.28452301025390625\n",
      "        - -0.4341581165790558\n",
      "        - -0.35478082299232483\n",
      "        - 1.1633834838867188\n",
      "        - 0.3805389404296875\n",
      "        - 0.43907928466796875\n",
      "        - -0.1979319453239441\n",
      "        - 1.28167724609375\n",
      "        - -0.6531544327735901\n",
      "        - 0.48819732666015625\n",
      "        - -0.41944095492362976\n",
      "        - -1.1065444946289062\n",
      "        - -0.38489609956741333\n",
      "        - -1.3351669311523438\n",
      "        - -0.008880615234375\n",
      "        - -0.3517650067806244\n",
      "        - 0.6618804931640625\n",
      "        - 0.1446685791015625\n",
      "        - -0.6146609783172607\n",
      "        - -0.5555843114852905\n",
      "        - -0.13260751962661743\n",
      "        - 0.8096542358398438\n",
      "        - -0.48658132553100586\n",
      "        - -0.5230026245117188\n",
      "        - -0.2911834716796875\n",
      "        - -0.4136788845062256\n",
      "        - -0.39106521010398865\n",
      "        - -0.320587158203125\n",
      "        - -0.5632021427154541\n",
      "        - 0.229736328125\n",
      "        - 0.12480926513671875\n",
      "        - 2.1857681274414062\n",
      "        - 0.052536964416503906\n",
      "        - -0.4383023977279663\n",
      "        - -0.561981201171875\n",
      "        - -1.6504745483398438\n",
      "        - -0.00322723388671875\n",
      "        - -0.471876859664917\n",
      "        - 0.1510467529296875\n",
      "        - -0.3305511474609375\n",
      "        - -0.5418181419372559\n",
      "        - -0.6089515686035156\n",
      "        - -0.6255186200141907\n",
      "        - -0.3389129638671875\n",
      "        - -0.58945232629776\n",
      "        - -0.7974090576171875\n",
      "        - -0.6838455200195312\n",
      "    num_agent_steps_sampled: 17500\n",
      "    num_agent_steps_trained: 2048256\n",
      "    num_steps_sampled: 17500\n",
      "    num_steps_trained: 2048256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 8001\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 8.35\n",
      "    ram_util_percent: 1.8\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.2010278847954068\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.21497822019515092\n",
      "    mean_inference_ms: 1.4412094831670776\n",
      "    mean_raw_obs_processing_ms: 0.5325764884540132\n",
      "  time_since_restore: 281.5411081314087\n",
      "  time_this_iter_s: 16.426584005355835\n",
      "  time_total_s: 281.5411081314087\n",
      "  timers:\n",
      "    learn_throughput: 51624.437\n",
      "    learn_time_ms: 4.959\n",
      "    load_throughput: 650555.483\n",
      "    load_time_ms: 0.394\n",
      "    update_time_ms: 2.84\n",
      "  timestamp: 1647533939\n",
      "  timesteps_since_restore: 4352\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 17500\n",
      "  training_iteration: 17\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:19:04 (running for 00:05:01.34)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         281.541</td><td style=\"text-align: right;\">17500</td><td style=\"text-align: right;\">-850.148</td><td style=\"text-align: right;\">           -0.566768</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:19:09 (running for 00:05:06.35)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         281.541</td><td style=\"text-align: right;\">17500</td><td style=\"text-align: right;\">-850.148</td><td style=\"text-align: right;\">           -0.566768</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:19:14 (running for 00:05:11.36)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         281.541</td><td style=\"text-align: right;\">17500</td><td style=\"text-align: right;\">-850.148</td><td style=\"text-align: right;\">           -0.566768</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 18500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-19-16\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.43706980447560756\n",
      "  episode_reward_mean: -804.668451150847\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 92\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 18500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 1.8454539775848389\n",
      "          mean_q: -54.80985641479492\n",
      "          min_q: -116.20391845703125\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.2686978578567505\n",
      "        - -2.5198898315429688\n",
      "        - -0.3087005615234375\n",
      "        - -0.2719154357910156\n",
      "        - -0.5507736206054688\n",
      "        - -0.4014892578125\n",
      "        - -0.1177983283996582\n",
      "        - 0.1696319580078125\n",
      "        - 0.38100457191467285\n",
      "        - -2.6617469787597656\n",
      "        - 0.315592497587204\n",
      "        - 0.18105292320251465\n",
      "        - -1.4783248901367188\n",
      "        - 0.31402587890625\n",
      "        - -2.4106292724609375\n",
      "        - 0.3124277591705322\n",
      "        - -0.00261688232421875\n",
      "        - -0.20798856019973755\n",
      "        - 0.2820572853088379\n",
      "        - 0.3248199224472046\n",
      "        - -0.8769073486328125\n",
      "        - 0.7769088745117188\n",
      "        - -0.6385993957519531\n",
      "        - 0.19806049764156342\n",
      "        - 5.385459899902344\n",
      "        - 0.5920940637588501\n",
      "        - -0.1568145751953125\n",
      "        - -1.1866302490234375\n",
      "        - 0.42749980092048645\n",
      "        - 0.4045493006706238\n",
      "        - 0.6733150482177734\n",
      "        - 0.363128662109375\n",
      "        - -1.1787948608398438\n",
      "        - -0.05342191457748413\n",
      "        - -0.1977616548538208\n",
      "        - 0.213897705078125\n",
      "        - 0.3867029547691345\n",
      "        - -1.35888671875\n",
      "        - 4.0023651123046875\n",
      "        - 0.2830427289009094\n",
      "        - -2.356517791748047\n",
      "        - -0.63677978515625\n",
      "        - 0.3031497001647949\n",
      "        - -0.843048095703125\n",
      "        - 2.3352890014648438\n",
      "        - 0.13009753823280334\n",
      "        - -0.41208648681640625\n",
      "        - 0.03575897216796875\n",
      "        - -1.6312637329101562\n",
      "        - 0.3114689886569977\n",
      "        - -1.9476089477539062\n",
      "        - -0.7814102172851562\n",
      "        - -0.31391143798828125\n",
      "        - -0.1123809814453125\n",
      "        - -0.017974853515625\n",
      "        - 0.13159340620040894\n",
      "        - 0.29929137229919434\n",
      "        - -0.20361828804016113\n",
      "        - 0.379716694355011\n",
      "        - 0.2797572910785675\n",
      "        - -0.18682861328125\n",
      "        - -0.19525909423828125\n",
      "        - -2.5093841552734375\n",
      "        - 0.32891082763671875\n",
      "        - 0.23958328366279602\n",
      "        - 0.22243139147758484\n",
      "        - 0.4468606114387512\n",
      "        - 0.7672500610351562\n",
      "        - 0.1210174560546875\n",
      "        - -2.0852813720703125\n",
      "        - 0.6085472106933594\n",
      "        - 1.7271003723144531\n",
      "        - 0.33869415521621704\n",
      "        - 0.38140869140625\n",
      "        - 0.3037828803062439\n",
      "        - 0.22249743342399597\n",
      "        - 0.15033912658691406\n",
      "        - 0.3602561950683594\n",
      "        - -0.6138992309570312\n",
      "        - -0.7300987243652344\n",
      "        - 0.0609283447265625\n",
      "        - -0.253204345703125\n",
      "        - 0.2732887268066406\n",
      "        - -0.07242584228515625\n",
      "        - -2.4408364295959473\n",
      "        - -0.4156951904296875\n",
      "        - -2.444652557373047\n",
      "        - -1.5785980224609375\n",
      "        - 0.2813114523887634\n",
      "        - 0.4840918779373169\n",
      "        - -0.9429435729980469\n",
      "        - 0.12217958271503448\n",
      "        - -3.07720947265625\n",
      "        - -1.519927978515625\n",
      "        - 0.20736750960350037\n",
      "        - 0.39600372314453125\n",
      "        - 0.11197662353515625\n",
      "        - -2.778167724609375\n",
      "        - 1.1679763793945312\n",
      "        - 0.7728805541992188\n",
      "        - -1.4886703491210938\n",
      "        - 1.2917251586914062\n",
      "        - -1.1861801147460938\n",
      "        - 0.03163909912109375\n",
      "        - 1.7731781005859375\n",
      "        - 0.06528472900390625\n",
      "        - -0.098968505859375\n",
      "        - -0.3350067138671875\n",
      "        - -0.6588058471679688\n",
      "        - 0.6074295043945312\n",
      "        - 0.1451987326145172\n",
      "        - 0.36548733711242676\n",
      "        - 0.25193095207214355\n",
      "        - 0.19791379570960999\n",
      "        - 0.31507110595703125\n",
      "        - -0.15143966674804688\n",
      "        - 0.26017144322395325\n",
      "        - 0.17592459917068481\n",
      "        - -1.2035064697265625\n",
      "        - 1.0568161010742188\n",
      "        - -0.0951690673828125\n",
      "        - 0.2635025978088379\n",
      "        - 0.3256714344024658\n",
      "        - 0.9489364624023438\n",
      "        - -1.3333969116210938\n",
      "        - -0.33545684814453125\n",
      "        - 0.4899909198284149\n",
      "        - -0.7584376335144043\n",
      "        - 0.7544708251953125\n",
      "        - -0.3725738525390625\n",
      "        - -0.26883697509765625\n",
      "        - 0.0992431640625\n",
      "        - 0.9000015258789062\n",
      "        - 0.48122769594192505\n",
      "        - 0.3344985246658325\n",
      "        - 0.5021008253097534\n",
      "        - -2.91168212890625\n",
      "        - -0.47370147705078125\n",
      "        - 1.3353652954101562\n",
      "        - -1.3462982177734375\n",
      "        - -1.4502410888671875\n",
      "        - 0.116424560546875\n",
      "        - 0.26348674297332764\n",
      "        - 0.2811598777770996\n",
      "        - 0.7885894775390625\n",
      "        - 1.7983932495117188\n",
      "        - 0.725799560546875\n",
      "        - -0.28340911865234375\n",
      "        - -0.47405242919921875\n",
      "        - 0.19870181381702423\n",
      "        - 0.1274670958518982\n",
      "        - 0.42571258544921875\n",
      "        - -0.576934814453125\n",
      "        - 0.005270242691040039\n",
      "        - -0.7721023559570312\n",
      "        - -1.8011322021484375\n",
      "        - -0.17185211181640625\n",
      "        - 0.45077037811279297\n",
      "        - -0.31451416015625\n",
      "        - -0.7005691528320312\n",
      "        - 0.18514640629291534\n",
      "        - -0.5789337158203125\n",
      "        - 0.19705358147621155\n",
      "        - 0.6767807006835938\n",
      "        - 0.01451873779296875\n",
      "        - 2.5886764526367188\n",
      "        - 0.3821789026260376\n",
      "        - -0.7892704010009766\n",
      "        - -0.8976211547851562\n",
      "        - 0.26907026767730713\n",
      "        - 0.4481544494628906\n",
      "        - 0.25139397382736206\n",
      "        - -0.35909271240234375\n",
      "        - -0.9720306396484375\n",
      "        - -1.3666863441467285\n",
      "        - -1.3572006225585938\n",
      "        - 0.13753849267959595\n",
      "        - 0.26934030652046204\n",
      "        - 0.27186548709869385\n",
      "        - -0.688507080078125\n",
      "        - 0.31158992648124695\n",
      "        - -0.7639617919921875\n",
      "        - -2.2533721923828125\n",
      "        - 0.17895632982254028\n",
      "        - 1.5997161865234375\n",
      "        - -0.91015625\n",
      "        - 0.4468606114387512\n",
      "        - 0.06242012977600098\n",
      "        - 0.9865341186523438\n",
      "        - 0.27252960205078125\n",
      "        - 0.21864521503448486\n",
      "        - -0.5696868896484375\n",
      "        - -0.26976776123046875\n",
      "        - -0.26132965087890625\n",
      "        - 0.391143798828125\n",
      "        - -1.9889640808105469\n",
      "        - 0.592376708984375\n",
      "        - -0.48165130615234375\n",
      "        - 0.952728271484375\n",
      "        - 0.1919056922197342\n",
      "        - 0.3268055319786072\n",
      "        - -0.0672454833984375\n",
      "        - -0.4648590087890625\n",
      "        - 0.3518643379211426\n",
      "        - 0.1664922833442688\n",
      "        - 0.1788787841796875\n",
      "        - -2.30859375\n",
      "        - 0.154083251953125\n",
      "        - -0.7348556518554688\n",
      "        - -0.0464630126953125\n",
      "        - -0.7148513793945312\n",
      "        - 0.29573094844818115\n",
      "        - -0.7781982421875\n",
      "        - 0.1903764307498932\n",
      "        - 0.18523742258548737\n",
      "        - 0.2745751738548279\n",
      "        - 0.28243255615234375\n",
      "        - -0.15688323974609375\n",
      "        - -0.8795166015625\n",
      "        - 0.2388533353805542\n",
      "        - -0.28972625732421875\n",
      "        - -0.787236213684082\n",
      "        - -1.0235099792480469\n",
      "        - -0.8385848999023438\n",
      "        - 0.4470723569393158\n",
      "        - 0.18904146552085876\n",
      "        - -0.07512664794921875\n",
      "        - 0.34991878271102905\n",
      "        - -0.8486557006835938\n",
      "        - -0.1640625\n",
      "        - -1.0733642578125\n",
      "        - -0.41658782958984375\n",
      "        - 0.1873103678226471\n",
      "        - -0.921661376953125\n",
      "        - 0.9078216552734375\n",
      "        - 0.3330521285533905\n",
      "        - 0.6382293701171875\n",
      "        - -1.5199127197265625\n",
      "        - -0.7157211303710938\n",
      "        - 0.52264404296875\n",
      "        - 0.01568603515625\n",
      "        - 0.0880584716796875\n",
      "        - 0.2302805781364441\n",
      "        - 0.247369647026062\n",
      "        - -0.4978485107421875\n",
      "        - 0.29008835554122925\n",
      "        - -0.16534423828125\n",
      "        - -0.9403762817382812\n",
      "        - 0.2011367827653885\n",
      "        - -0.8450775146484375\n",
      "        - -0.3972930908203125\n",
      "        - 0.20964035391807556\n",
      "        - -0.966583251953125\n",
      "        - 1.444183349609375\n",
      "        - 0.34981590509414673\n",
      "        - 0.21158325672149658\n",
      "    num_agent_steps_sampled: 18500\n",
      "    num_agent_steps_trained: 2176256\n",
      "    num_steps_sampled: 18500\n",
      "    num_steps_trained: 2176256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 8501\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 7.979166666666667\n",
      "    ram_util_percent: 1.8\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.20055675493608038\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.21414717990178148\n",
      "    mean_inference_ms: 1.4214445016429729\n",
      "    mean_raw_obs_processing_ms: 0.530052450728891\n",
      "  time_since_restore: 298.44474959373474\n",
      "  time_this_iter_s: 16.90364146232605\n",
      "  time_total_s: 298.44474959373474\n",
      "  timers:\n",
      "    learn_throughput: 52391.962\n",
      "    learn_time_ms: 4.886\n",
      "    load_throughput: 647612.68\n",
      "    load_time_ms: 0.395\n",
      "    update_time_ms: 2.853\n",
      "  timestamp: 1647533956\n",
      "  timesteps_since_restore: 4608\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 18500\n",
      "  training_iteration: 18\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:19:20 (running for 00:05:17.26)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         298.445</td><td style=\"text-align: right;\">18500</td><td style=\"text-align: right;\">-804.668</td><td style=\"text-align: right;\">            -0.43707</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:19:25 (running for 00:05:22.37)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         298.445</td><td style=\"text-align: right;\">18500</td><td style=\"text-align: right;\">-804.668</td><td style=\"text-align: right;\">            -0.43707</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:19:30 (running for 00:05:27.39)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         298.445</td><td style=\"text-align: right;\">18500</td><td style=\"text-align: right;\">-804.668</td><td style=\"text-align: right;\">            -0.43707</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:19:35 (running for 00:05:32.40)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         298.445</td><td style=\"text-align: right;\">18500</td><td style=\"text-align: right;\">-804.668</td><td style=\"text-align: right;\">            -0.43707</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 19500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-19-38\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.2930634876035956\n",
      "  episode_reward_mean: -778.1750358122025\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 96\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 19500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 1.6136672496795654\n",
      "          mean_q: -52.898109436035156\n",
      "          min_q: -121.43116760253906\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.10690803825855255\n",
      "        - -0.02339935302734375\n",
      "        - -0.45819854736328125\n",
      "        - 0.2679443359375\n",
      "        - 0.27872467041015625\n",
      "        - 1.174163818359375\n",
      "        - -0.09334728121757507\n",
      "        - 0.7675628662109375\n",
      "        - -0.45343017578125\n",
      "        - -0.010928422212600708\n",
      "        - -1.4986724853515625\n",
      "        - -0.1513214111328125\n",
      "        - 0.0002951323986053467\n",
      "        - 1.0055465698242188\n",
      "        - -0.1842423677444458\n",
      "        - 2.2431488037109375\n",
      "        - 1.7907791137695312\n",
      "        - 0.39342498779296875\n",
      "        - -0.03551404923200607\n",
      "        - 0.6243209838867188\n",
      "        - 0.27872467041015625\n",
      "        - 1.3260955810546875\n",
      "        - 0.718292236328125\n",
      "        - -0.13433919847011566\n",
      "        - 0.02963903546333313\n",
      "        - -0.00762176513671875\n",
      "        - 0.9437408447265625\n",
      "        - 0.0106029212474823\n",
      "        - -0.06168356537818909\n",
      "        - -0.0023750215768814087\n",
      "        - -0.40889739990234375\n",
      "        - 0.035728394985198975\n",
      "        - 1.3933792114257812\n",
      "        - 0.01332855224609375\n",
      "        - -0.09283968061208725\n",
      "        - 0.05777859687805176\n",
      "        - 1.9173660278320312\n",
      "        - -0.14152958989143372\n",
      "        - -0.1739044189453125\n",
      "        - 0.24242401123046875\n",
      "        - 0.043554648756980896\n",
      "        - -0.02887357771396637\n",
      "        - -0.0421205535531044\n",
      "        - 2.1773300170898438\n",
      "        - 0.47016143798828125\n",
      "        - 0.6773223876953125\n",
      "        - -0.07155609130859375\n",
      "        - -0.12942121922969818\n",
      "        - 0.6059799194335938\n",
      "        - -0.57891845703125\n",
      "        - 0.5881805419921875\n",
      "        - -0.087509885430336\n",
      "        - 0.43854522705078125\n",
      "        - 0.0562286376953125\n",
      "        - -0.4964447021484375\n",
      "        - 0.02761366218328476\n",
      "        - -0.11950358748435974\n",
      "        - -0.12465667724609375\n",
      "        - 5.196262359619141\n",
      "        - -0.11559295654296875\n",
      "        - 1.4953765869140625\n",
      "        - 0.8978748321533203\n",
      "        - -0.40535783767700195\n",
      "        - 2.0736160278320312\n",
      "        - -0.016872093081474304\n",
      "        - 0.0034351497888565063\n",
      "        - 0.31073296070098877\n",
      "        - 0.1711457073688507\n",
      "        - 0.33957672119140625\n",
      "        - 0.11469510197639465\n",
      "        - -0.6242387294769287\n",
      "        - 0.2379135936498642\n",
      "        - 0.2191450595855713\n",
      "        - -0.35970211029052734\n",
      "        - 0.061929911375045776\n",
      "        - 0.7921676635742188\n",
      "        - 1.5701026916503906\n",
      "        - -0.18447940051555634\n",
      "        - -0.12158580124378204\n",
      "        - 0.9237594604492188\n",
      "        - -0.10509157180786133\n",
      "        - -0.08373324573040009\n",
      "        - -0.8136138916015625\n",
      "        - -0.0033249258995056152\n",
      "        - -0.84539794921875\n",
      "        - 0.6657257080078125\n",
      "        - -0.009477198123931885\n",
      "        - -0.0024871826171875\n",
      "        - 0.3126983642578125\n",
      "        - 0.07892990112304688\n",
      "        - -0.031184494495391846\n",
      "        - -0.058319091796875\n",
      "        - 0.6856689453125\n",
      "        - 0.712860107421875\n",
      "        - -0.0984039455652237\n",
      "        - 0.7179718017578125\n",
      "        - 0.6794052124023438\n",
      "        - -0.03414943814277649\n",
      "        - 1.50811767578125\n",
      "        - 0.5917837619781494\n",
      "        - 1.3693313598632812\n",
      "        - -0.033665239810943604\n",
      "        - 0.003042571246623993\n",
      "        - 0.73016357421875\n",
      "        - 0.2878580093383789\n",
      "        - -0.11877861618995667\n",
      "        - 1.4762039184570312\n",
      "        - 0.019996196031570435\n",
      "        - -0.009898148477077484\n",
      "        - -0.06742994487285614\n",
      "        - 0.7936477661132812\n",
      "        - 1.3002853393554688\n",
      "        - -0.05051995813846588\n",
      "        - 0.13211284577846527\n",
      "        - 0.05395925045013428\n",
      "        - 0.07183666527271271\n",
      "        - -0.017669677734375\n",
      "        - -0.0338749885559082\n",
      "        - 0.08149246126413345\n",
      "        - -0.098313108086586\n",
      "        - 1.2376556396484375\n",
      "        - 0.8357162475585938\n",
      "        - 2.3949737548828125\n",
      "        - -0.029619164764881134\n",
      "        - 0.9413528442382812\n",
      "        - -1.3261301517486572\n",
      "        - 2.2297744750976562\n",
      "        - -0.1285041719675064\n",
      "        - -0.08420272916555405\n",
      "        - 0.898529052734375\n",
      "        - -0.42359161376953125\n",
      "        - -0.35861968994140625\n",
      "        - -0.6597900390625\n",
      "        - 0.0023750364780426025\n",
      "        - 1.230010986328125\n",
      "        - -0.17665910720825195\n",
      "        - -1.534414291381836\n",
      "        - 0.10830375552177429\n",
      "        - -0.0671369880437851\n",
      "        - -0.1337890625\n",
      "        - 0.5258102416992188\n",
      "        - -0.028013154864311218\n",
      "        - -0.20421600341796875\n",
      "        - -0.9261932373046875\n",
      "        - -0.02764613926410675\n",
      "        - -0.7961349487304688\n",
      "        - 3.6042823791503906\n",
      "        - 0.024826183915138245\n",
      "        - -0.10690271854400635\n",
      "        - 3.4777908325195312\n",
      "        - 0.8263778686523438\n",
      "        - 0.1178131103515625\n",
      "        - -0.7706069946289062\n",
      "        - -0.9152374267578125\n",
      "        - 0.2956809997558594\n",
      "        - 0.89801025390625\n",
      "        - -0.07539848238229752\n",
      "        - -0.1126282811164856\n",
      "        - 0.6617507934570312\n",
      "        - -0.130462646484375\n",
      "        - -0.11742626130580902\n",
      "        - 0.640869140625\n",
      "        - -0.12981939315795898\n",
      "        - -0.0710652619600296\n",
      "        - 1.040618896484375\n",
      "        - 0.009980514645576477\n",
      "        - 0.1959550678730011\n",
      "        - -0.010470390319824219\n",
      "        - 0.8371047973632812\n",
      "        - 0.5408554077148438\n",
      "        - 0.2878580093383789\n",
      "        - 2.705648422241211\n",
      "        - 0.17629127204418182\n",
      "        - -0.025663122534751892\n",
      "        - 0.008569777011871338\n",
      "        - 1.57867431640625\n",
      "        - 0.17111068964004517\n",
      "        - -0.65936279296875\n",
      "        - 1.205322265625\n",
      "        - 0.972076416015625\n",
      "        - 1.1923599243164062\n",
      "        - 0.26852181553840637\n",
      "        - 0.33046722412109375\n",
      "        - 0.3481709957122803\n",
      "        - 0.00029981136322021484\n",
      "        - 1.2134246826171875\n",
      "        - 0.06668028235435486\n",
      "        - -1.0532379150390625\n",
      "        - 0.5391845703125\n",
      "        - 0.0025884658098220825\n",
      "        - 0.24045047163963318\n",
      "        - 1.381561279296875\n",
      "        - 2.6149520874023438\n",
      "        - 0.8357162475585938\n",
      "        - 0.9342727661132812\n",
      "        - -0.09531404078006744\n",
      "        - 0.8209762573242188\n",
      "        - 0.06878994405269623\n",
      "        - 1.7398529052734375\n",
      "        - -0.08406619727611542\n",
      "        - -0.20084381103515625\n",
      "        - 1.5608901977539062\n",
      "        - 1.6906814575195312\n",
      "        - -0.06866525113582611\n",
      "        - 0.8625335693359375\n",
      "        - 0.14667510986328125\n",
      "        - 1.0033340454101562\n",
      "        - -0.0007788538932800293\n",
      "        - -0.027453027665615082\n",
      "        - -0.9309310913085938\n",
      "        - 0.885833740234375\n",
      "        - 0.239837646484375\n",
      "        - 0.5354156494140625\n",
      "        - -0.09441258013248444\n",
      "        - 0.010348916053771973\n",
      "        - 0.04841434955596924\n",
      "        - -0.13310794532299042\n",
      "        - -0.4552154541015625\n",
      "        - -0.05738118290901184\n",
      "        - 1.0556907653808594\n",
      "        - 0.824127197265625\n",
      "        - 0.83721923828125\n",
      "        - 0.6855545043945312\n",
      "        - 0.5800628662109375\n",
      "        - -0.27225494384765625\n",
      "        - 0.2769404649734497\n",
      "        - 0.0856170654296875\n",
      "        - 0.8512095808982849\n",
      "        - -1.6158599853515625\n",
      "        - 0.4990386962890625\n",
      "        - 1.2714500427246094\n",
      "        - 0.15908050537109375\n",
      "        - 0.7547988891601562\n",
      "        - -1.9739265441894531\n",
      "        - 0.1229248046875\n",
      "        - 0.3785247802734375\n",
      "        - 0.43761444091796875\n",
      "        - -0.1842423677444458\n",
      "        - 1.0489730834960938\n",
      "        - 0.45558929443359375\n",
      "        - 0.3785247802734375\n",
      "        - 0.8916015625\n",
      "        - 1.2388687133789062\n",
      "        - 0.9749832153320312\n",
      "        - 0.03813232481479645\n",
      "        - -0.03136743605136871\n",
      "        - 1.1448516845703125\n",
      "        - 0.059808243066072464\n",
      "        - 1.7712554931640625\n",
      "        - 0.073333740234375\n",
      "        - 0.4667224884033203\n",
      "        - 0.004384249448776245\n",
      "        - 0.048975154757499695\n",
      "        - -0.07191603630781174\n",
      "        - 2.742034912109375\n",
      "        - -1.4923477172851562\n",
      "    num_agent_steps_sampled: 19500\n",
      "    num_agent_steps_trained: 2304256\n",
      "    num_steps_sampled: 19500\n",
      "    num_steps_trained: 2304256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 9001\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 8.629032258064514\n",
      "    ram_util_percent: 1.7999999999999994\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.200406847114333\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.21372497540621282\n",
      "    mean_inference_ms: 1.4100684000850325\n",
      "    mean_raw_obs_processing_ms: 0.5288721287313787\n",
      "  time_since_restore: 319.9737985134125\n",
      "  time_this_iter_s: 21.529048919677734\n",
      "  time_total_s: 319.9737985134125\n",
      "  timers:\n",
      "    learn_throughput: 51999.197\n",
      "    learn_time_ms: 4.923\n",
      "    load_throughput: 640504.548\n",
      "    load_time_ms: 0.4\n",
      "    update_time_ms: 2.827\n",
      "  timestamp: 1647533978\n",
      "  timesteps_since_restore: 4864\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 19500\n",
      "  training_iteration: 19\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:19:41 (running for 00:05:37.84)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         319.974</td><td style=\"text-align: right;\">19500</td><td style=\"text-align: right;\">-778.175</td><td style=\"text-align: right;\">           -0.293063</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:19:46 (running for 00:05:42.88)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         319.974</td><td style=\"text-align: right;\">19500</td><td style=\"text-align: right;\">-778.175</td><td style=\"text-align: right;\">           -0.293063</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:19:51 (running for 00:05:47.88)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         319.974</td><td style=\"text-align: right;\">19500</td><td style=\"text-align: right;\">-778.175</td><td style=\"text-align: right;\">           -0.293063</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 20500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-19-54\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.2930634876035956\n",
      "  episode_reward_mean: -730.086297713418\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 102\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 20500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 0.8578717112541199\n",
      "          mean_q: -54.87456512451172\n",
      "          min_q: -125.44137573242188\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.04843014478683472\n",
      "        - -0.9819660782814026\n",
      "        - -0.06997393071651459\n",
      "        - -0.20115219056606293\n",
      "        - -0.5487666726112366\n",
      "        - -0.12942270934581757\n",
      "        - 0.1592559814453125\n",
      "        - 0.017578125\n",
      "        - 2.4178543090820312\n",
      "        - -0.5892486572265625\n",
      "        - -0.0053125470876693726\n",
      "        - 0.7863693237304688\n",
      "        - -0.11843156814575195\n",
      "        - 0.3520050048828125\n",
      "        - 0.600921630859375\n",
      "        - 1.6712722778320312\n",
      "        - -0.38201218843460083\n",
      "        - -0.18818137049674988\n",
      "        - -0.08024758100509644\n",
      "        - 0.5139694213867188\n",
      "        - -0.28004080057144165\n",
      "        - 1.1421356201171875\n",
      "        - -0.07689666748046875\n",
      "        - 0.00872039794921875\n",
      "        - 0.9628143310546875\n",
      "        - -0.11086736619472504\n",
      "        - 1.2346267700195312\n",
      "        - 0.30950164794921875\n",
      "        - -0.05053876340389252\n",
      "        - -3.76708984375\n",
      "        - -0.23458921909332275\n",
      "        - 0.0013128817081451416\n",
      "        - -2.1467208862304688\n",
      "        - 1.0662078857421875\n",
      "        - -0.06066131591796875\n",
      "        - -0.08150699734687805\n",
      "        - 0.2021942138671875\n",
      "        - 0.20688629150390625\n",
      "        - 0.36199951171875\n",
      "        - 0.25846099853515625\n",
      "        - 0.15167999267578125\n",
      "        - -0.29195061326026917\n",
      "        - -0.026033759117126465\n",
      "        - -0.10189676284790039\n",
      "        - 0.5009536743164062\n",
      "        - -0.11123651266098022\n",
      "        - -0.05063728243112564\n",
      "        - 1.7168807983398438\n",
      "        - 0.40663909912109375\n",
      "        - 1.772552490234375\n",
      "        - -0.2067345529794693\n",
      "        - 0.09394029527902603\n",
      "        - -0.004503868520259857\n",
      "        - -0.0526123046875\n",
      "        - 0.2924156188964844\n",
      "        - 0.37657928466796875\n",
      "        - -0.8094329833984375\n",
      "        - -0.25896453857421875\n",
      "        - 1.772552490234375\n",
      "        - -0.89666748046875\n",
      "        - -2.7587032318115234\n",
      "        - -0.14087986946105957\n",
      "        - 0.06383848190307617\n",
      "        - 0.44171142578125\n",
      "        - -0.528167724609375\n",
      "        - -0.8005905151367188\n",
      "        - -0.8254547119140625\n",
      "        - -1.3859481811523438\n",
      "        - -0.06335426867008209\n",
      "        - 0.11544036865234375\n",
      "        - -0.805145263671875\n",
      "        - -0.157217338681221\n",
      "        - 0.6931686401367188\n",
      "        - 1.31719970703125\n",
      "        - -3.9258604049682617\n",
      "        - -0.17121991515159607\n",
      "        - 0.35565185546875\n",
      "        - -2.7182235717773438\n",
      "        - 0.38004976511001587\n",
      "        - -0.2383953183889389\n",
      "        - -0.5031356811523438\n",
      "        - -0.12790685892105103\n",
      "        - -0.705322265625\n",
      "        - 3.06280517578125\n",
      "        - 0.024049580097198486\n",
      "        - -0.13324762880802155\n",
      "        - 0.0597381591796875\n",
      "        - -0.09673592448234558\n",
      "        - -0.2202911376953125\n",
      "        - -0.016382500529289246\n",
      "        - -0.18743035197257996\n",
      "        - -0.6429214477539062\n",
      "        - 0.6079559326171875\n",
      "        - -2.2913360595703125\n",
      "        - 1.4315185546875\n",
      "        - -2.599315643310547\n",
      "        - 1.0645980834960938\n",
      "        - -0.9188003540039062\n",
      "        - -0.1660221815109253\n",
      "        - 0.060791015625\n",
      "        - -0.1017291396856308\n",
      "        - 1.4157638549804688\n",
      "        - 0.013298481702804565\n",
      "        - -0.22076416015625\n",
      "        - -0.5918350219726562\n",
      "        - -0.113899827003479\n",
      "        - 0.8503265380859375\n",
      "        - -0.5725669860839844\n",
      "        - 0.2230399250984192\n",
      "        - 0.05477438122034073\n",
      "        - 0.35997772216796875\n",
      "        - -0.15384352207183838\n",
      "        - -0.008653640747070312\n",
      "        - -0.17514801025390625\n",
      "        - 0.0909576416015625\n",
      "        - -0.22576701641082764\n",
      "        - 0.9585647583007812\n",
      "        - -0.025633305311203003\n",
      "        - -0.4794883728027344\n",
      "        - -0.20496246218681335\n",
      "        - 0.6129684448242188\n",
      "        - -0.21734197437763214\n",
      "        - 1.0848236083984375\n",
      "        - -0.1824112981557846\n",
      "        - -1.2512741088867188\n",
      "        - -0.6805038452148438\n",
      "        - -0.01715087890625\n",
      "        - 0.5463333129882812\n",
      "        - -0.6610565185546875\n",
      "        - -0.21953679621219635\n",
      "        - 2.9890823364257812\n",
      "        - 0.0167999267578125\n",
      "        - 0.5715866088867188\n",
      "        - -0.8978424072265625\n",
      "        - -2.3965377807617188\n",
      "        - 0.39669787883758545\n",
      "        - -0.03135274350643158\n",
      "        - -0.23884093761444092\n",
      "        - 1.0848236083984375\n",
      "        - -0.43958282470703125\n",
      "        - -0.12790685892105103\n",
      "        - 0.00244903564453125\n",
      "        - -0.182292178273201\n",
      "        - -0.2602415680885315\n",
      "        - -3.2972640991210938\n",
      "        - -1.1391372680664062\n",
      "        - -0.17239044606685638\n",
      "        - 0.5601272583007812\n",
      "        - -0.7139434814453125\n",
      "        - -2.1568374633789062\n",
      "        - 0.5171051025390625\n",
      "        - 1.2071609497070312\n",
      "        - 0.88922119140625\n",
      "        - 0.09951019287109375\n",
      "        - -0.20439910888671875\n",
      "        - -1.1391372680664062\n",
      "        - 0.7281875610351562\n",
      "        - -0.002461940050125122\n",
      "        - -0.09713028371334076\n",
      "        - 1.68511962890625\n",
      "        - -0.5419008731842041\n",
      "        - -0.1146087646484375\n",
      "        - -0.05797278881072998\n",
      "        - 0.02523954212665558\n",
      "        - -1.209059715270996\n",
      "        - -0.42266845703125\n",
      "        - -1.5339431762695312\n",
      "        - -0.2009887993335724\n",
      "        - 0.006480768322944641\n",
      "        - -0.17545989155769348\n",
      "        - -0.14788062870502472\n",
      "        - -0.4381215572357178\n",
      "        - -0.09310245513916016\n",
      "        - -1.967041015625\n",
      "        - -1.48553466796875\n",
      "        - 0.015081256628036499\n",
      "        - -0.12044771015644073\n",
      "        - -1.810333251953125\n",
      "        - -2.6114234924316406\n",
      "        - -1.283782958984375\n",
      "        - -0.021350659430027008\n",
      "        - -0.11743225157260895\n",
      "        - -0.09642113745212555\n",
      "        - -0.3117218017578125\n",
      "        - -0.022120401263237\n",
      "        - -0.6482009887695312\n",
      "        - 1.5604934692382812\n",
      "        - -0.1042022705078125\n",
      "        - 0.9557418823242188\n",
      "        - -0.19237807393074036\n",
      "        - 0.37010955810546875\n",
      "        - -0.08392991125583649\n",
      "        - 0.20813751220703125\n",
      "        - -1.48553466796875\n",
      "        - -0.14183174073696136\n",
      "        - 0.20407867431640625\n",
      "        - -0.12700007855892181\n",
      "        - -0.20322969555854797\n",
      "        - 0.3783111572265625\n",
      "        - -0.007111169397830963\n",
      "        - -0.15444327890872955\n",
      "        - -0.2230992466211319\n",
      "        - -2.1025619506835938\n",
      "        - 0.8489913940429688\n",
      "        - 0.227783203125\n",
      "        - 0.32479095458984375\n",
      "        - 1.3760528564453125\n",
      "        - 0.229989156126976\n",
      "        - 0.32770538330078125\n",
      "        - 0.8137969970703125\n",
      "        - -1.3087921142578125\n",
      "        - -0.27837371826171875\n",
      "        - 0.18233665823936462\n",
      "        - -0.04939007759094238\n",
      "        - -0.23878657817840576\n",
      "        - 0.44235992431640625\n",
      "        - -0.2547454833984375\n",
      "        - -2.8039627075195312\n",
      "        - 0.116790771484375\n",
      "        - -0.10963888466358185\n",
      "        - -1.6581802368164062\n",
      "        - -1.0116958618164062\n",
      "        - 1.0677413940429688\n",
      "        - -0.06711111962795258\n",
      "        - 0.2542572021484375\n",
      "        - -0.09938190132379532\n",
      "        - -0.9646453857421875\n",
      "        - -0.15273284912109375\n",
      "        - 0.5171051025390625\n",
      "        - 0.6957244873046875\n",
      "        - -0.07737964391708374\n",
      "        - -0.12174893915653229\n",
      "        - -0.28590768575668335\n",
      "        - 1.1594772338867188\n",
      "        - -1.4795150756835938\n",
      "        - 0.3808441162109375\n",
      "        - -0.08110786974430084\n",
      "        - 0.21651458740234375\n",
      "        - -0.09233686327934265\n",
      "        - -1.5269241333007812\n",
      "        - 0.187652587890625\n",
      "        - 1.0085906982421875\n",
      "        - 0.6021575927734375\n",
      "        - -0.11155086755752563\n",
      "        - -1.4317398071289062\n",
      "        - -0.021555468440055847\n",
      "        - 0.24672698974609375\n",
      "        - -0.07666015625\n",
      "        - -0.4063262939453125\n",
      "        - -3.676802635192871\n",
      "        - -0.6429214477539062\n",
      "        - -0.1224580705165863\n",
      "        - -0.018467620015144348\n",
      "        - 1.618011474609375\n",
      "        - 0.9045791625976562\n",
      "        - -0.64190673828125\n",
      "    num_agent_steps_sampled: 20500\n",
      "    num_agent_steps_trained: 2432256\n",
      "    num_steps_sampled: 20500\n",
      "    num_steps_trained: 2432256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 9501\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 8.178260869565216\n",
      "    ram_util_percent: 1.7999999999999994\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.20009849999705687\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.21265642965165132\n",
      "    mean_inference_ms: 1.3709998439222444\n",
      "    mean_raw_obs_processing_ms: 0.5256250420056767\n",
      "  time_since_restore: 336.584388256073\n",
      "  time_this_iter_s: 16.610589742660522\n",
      "  time_total_s: 336.584388256073\n",
      "  timers:\n",
      "    learn_throughput: 51268.5\n",
      "    learn_time_ms: 4.993\n",
      "    load_throughput: 605539.039\n",
      "    load_time_ms: 0.423\n",
      "    update_time_ms: 2.894\n",
      "  timestamp: 1647533994\n",
      "  timesteps_since_restore: 5120\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 20500\n",
      "  training_iteration: 20\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:19:56 (running for 00:05:53.53)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         336.584</td><td style=\"text-align: right;\">20500</td><td style=\"text-align: right;\">-730.086</td><td style=\"text-align: right;\">           -0.293063</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:20:01 (running for 00:05:58.54)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         336.584</td><td style=\"text-align: right;\">20500</td><td style=\"text-align: right;\">-730.086</td><td style=\"text-align: right;\">           -0.293063</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:20:06 (running for 00:06:03.54)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         336.584</td><td style=\"text-align: right;\">20500</td><td style=\"text-align: right;\">-730.086</td><td style=\"text-align: right;\">           -0.293063</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 21500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-20-11\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.2930634876035956\n",
      "  episode_reward_mean: -684.0580118097938\n",
      "  episode_reward_min: -1590.8487312251493\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 106\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 21500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 2.340029716491699\n",
      "          mean_q: -55.59410095214844\n",
      "          min_q: -126.9139175415039\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.20607148110866547\n",
      "        - 0.2677946090698242\n",
      "        - 0.11833953857421875\n",
      "        - -1.33111572265625\n",
      "        - 0.1870388388633728\n",
      "        - 0.31095123291015625\n",
      "        - 0.33753204345703125\n",
      "        - -0.14550018310546875\n",
      "        - 0.3468397855758667\n",
      "        - 0.7058944702148438\n",
      "        - 0.3844882547855377\n",
      "        - -0.5072402954101562\n",
      "        - -0.5692977905273438\n",
      "        - -0.14141082763671875\n",
      "        - -0.40259552001953125\n",
      "        - 0.36760273575782776\n",
      "        - -0.47449493408203125\n",
      "        - 1.7241058349609375\n",
      "        - -0.47566986083984375\n",
      "        - 0.06609344482421875\n",
      "        - -0.4394683837890625\n",
      "        - 0.41746971011161804\n",
      "        - 0.4021081328392029\n",
      "        - -0.01548004150390625\n",
      "        - 0.47353699803352356\n",
      "        - 0.3669741749763489\n",
      "        - -0.9953765869140625\n",
      "        - 0.5437698364257812\n",
      "        - 0.42224547266960144\n",
      "        - -0.08586883544921875\n",
      "        - 0.2368621826171875\n",
      "        - 0.290008544921875\n",
      "        - -0.12351608276367188\n",
      "        - 0.5603467226028442\n",
      "        - 0.7575225830078125\n",
      "        - 0.4116065204143524\n",
      "        - 0.4972497224807739\n",
      "        - 0.35414955019950867\n",
      "        - 0.30172568559646606\n",
      "        - 0.27732887864112854\n",
      "        - 0.5993576049804688\n",
      "        - 0.4708767533302307\n",
      "        - -1.1384048461914062\n",
      "        - -0.5516433715820312\n",
      "        - -0.295867919921875\n",
      "        - 0.17545318603515625\n",
      "        - 0.018829345703125\n",
      "        - -0.4018402099609375\n",
      "        - 0.1537322998046875\n",
      "        - -0.8916091918945312\n",
      "        - 0.3744567334651947\n",
      "        - 0.43262720108032227\n",
      "        - 0.19715118408203125\n",
      "        - -0.9589157104492188\n",
      "        - -0.7287368774414062\n",
      "        - 0.11418145895004272\n",
      "        - 0.23334474861621857\n",
      "        - 0.7600555419921875\n",
      "        - 0.414337158203125\n",
      "        - -0.5185928344726562\n",
      "        - 0.02066802978515625\n",
      "        - -1.9023666381835938\n",
      "        - 0.35662928223609924\n",
      "        - 0.3597288131713867\n",
      "        - 2.3572940826416016\n",
      "        - 1.1839752197265625\n",
      "        - 0.079498291015625\n",
      "        - 8.799657821655273\n",
      "        - 0.38768669962882996\n",
      "        - 1.213104486465454\n",
      "        - 0.8802419900894165\n",
      "        - -1.0546875\n",
      "        - 0.42389288544654846\n",
      "        - 0.023006372153759003\n",
      "        - 0.29351189732551575\n",
      "        - -0.8156814575195312\n",
      "        - -0.48717498779296875\n",
      "        - 0.243896484375\n",
      "        - -0.27149200439453125\n",
      "        - 0.355279803276062\n",
      "        - -0.19378662109375\n",
      "        - 1.5943489074707031\n",
      "        - 0.47620391845703125\n",
      "        - -1.5287857055664062\n",
      "        - -0.31951904296875\n",
      "        - -0.16284942626953125\n",
      "        - 0.7505340576171875\n",
      "        - 0.41823694109916687\n",
      "        - 1.5254287719726562\n",
      "        - 0.2972928583621979\n",
      "        - 0.2828993797302246\n",
      "        - -0.44390869140625\n",
      "        - -0.07286834716796875\n",
      "        - -0.017543792724609375\n",
      "        - 0.41290193796157837\n",
      "        - 0.4116065204143524\n",
      "        - 0.38816598057746887\n",
      "        - 0.4303436279296875\n",
      "        - 0.37759262323379517\n",
      "        - 0.39570873975753784\n",
      "        - 0.4564560651779175\n",
      "        - -0.5331573486328125\n",
      "        - 0.5446704626083374\n",
      "        - 0.350201278924942\n",
      "        - 2.7648162841796875\n",
      "        - 0.32612067461013794\n",
      "        - 0.4441882371902466\n",
      "        - 2.802581787109375\n",
      "        - 0.26964032649993896\n",
      "        - 2.820953369140625\n",
      "        - 0.28972625732421875\n",
      "        - 0.20448163151741028\n",
      "        - 0.0340576171875\n",
      "        - 0.2437659502029419\n",
      "        - 0.3168134391307831\n",
      "        - 0.199859619140625\n",
      "        - 0.059783935546875\n",
      "        - -0.2211456298828125\n",
      "        - -0.0245819091796875\n",
      "        - 0.32798895239830017\n",
      "        - 0.5687179565429688\n",
      "        - 0.23602294921875\n",
      "        - -1.5973739624023438\n",
      "        - 0.17253875732421875\n",
      "        - 1.5082778930664062\n",
      "        - 0.5124014019966125\n",
      "        - -0.0253753662109375\n",
      "        - -0.038909912109375\n",
      "        - 0.07540130615234375\n",
      "        - -0.45613959431648254\n",
      "        - 0.17102675139904022\n",
      "        - -0.22884368896484375\n",
      "        - 0.3741483986377716\n",
      "        - 0.395355224609375\n",
      "        - 0.5392913818359375\n",
      "        - 0.07993316650390625\n",
      "        - 0.3382718861103058\n",
      "        - -0.587860107421875\n",
      "        - 0.45663541555404663\n",
      "        - 1.4905548095703125\n",
      "        - 0.6833744049072266\n",
      "        - -0.3204345703125\n",
      "        - -1.8589286804199219\n",
      "        - 0.42305466532707214\n",
      "        - 0.42826080322265625\n",
      "        - 1.9371185302734375\n",
      "        - 0.286834716796875\n",
      "        - 0.31960123777389526\n",
      "        - 1.0961227416992188\n",
      "        - 0.4890326261520386\n",
      "        - -0.44525909423828125\n",
      "        - 0.0608062744140625\n",
      "        - -0.594482421875\n",
      "        - 0.35640716552734375\n",
      "        - 0.4261402487754822\n",
      "        - 1.4924479722976685\n",
      "        - 0.1666412353515625\n",
      "        - 0.4150678813457489\n",
      "        - 0.6339501738548279\n",
      "        - 0.9195404052734375\n",
      "        - 0.27431488037109375\n",
      "        - 0.578335165977478\n",
      "        - 1.1315536499023438\n",
      "        - -0.0856475830078125\n",
      "        - -0.5140266418457031\n",
      "        - -0.7224502563476562\n",
      "        - 0.3146097660064697\n",
      "        - 0.40531015396118164\n",
      "        - 0.3740829825401306\n",
      "        - 0.5438308715820312\n",
      "        - 0.513129472732544\n",
      "        - 0.36532437801361084\n",
      "        - -0.46739959716796875\n",
      "        - 0.27519461512565613\n",
      "        - 0.33650970458984375\n",
      "        - -0.258575439453125\n",
      "        - -0.15743255615234375\n",
      "        - 1.1844022274017334\n",
      "        - 0.3466937243938446\n",
      "        - 0.6609878540039062\n",
      "        - -2.9365615844726562\n",
      "        - 0.9967193603515625\n",
      "        - -0.7644424438476562\n",
      "        - -0.6681861877441406\n",
      "        - 0.3859708607196808\n",
      "        - 0.3532824218273163\n",
      "        - 0.3540455400943756\n",
      "        - 0.4424285888671875\n",
      "        - 0.3570777475833893\n",
      "        - -0.60205078125\n",
      "        - 0.3691738247871399\n",
      "        - 0.2536378502845764\n",
      "        - 0.3142447769641876\n",
      "        - 0.32906341552734375\n",
      "        - 1.0550384521484375\n",
      "        - -0.59368896484375\n",
      "        - 0.4196929931640625\n",
      "        - 0.8141273856163025\n",
      "        - -0.849853515625\n",
      "        - 0.45843344926834106\n",
      "        - 0.05710601806640625\n",
      "        - -0.0804595947265625\n",
      "        - 0.3962112069129944\n",
      "        - 1.7565383911132812\n",
      "        - -0.183380126953125\n",
      "        - 0.5421829223632812\n",
      "        - 0.27306947112083435\n",
      "        - 0.6993179321289062\n",
      "        - 0.57537841796875\n",
      "        - 0.5330066084861755\n",
      "        - 0.20449066162109375\n",
      "        - -0.7501754760742188\n",
      "        - 0.750640869140625\n",
      "        - 0.36194664239883423\n",
      "        - -0.0802001953125\n",
      "        - 0.3998461067676544\n",
      "        - 0.10379251837730408\n",
      "        - -1.25091552734375\n",
      "        - -0.39527130126953125\n",
      "        - 0.1487705111503601\n",
      "        - -0.09355926513671875\n",
      "        - 0.4184023439884186\n",
      "        - 0.3338889181613922\n",
      "        - 0.290283203125\n",
      "        - 0.48366880416870117\n",
      "        - 0.5612106323242188\n",
      "        - 0.8162765502929688\n",
      "        - 0.12014389038085938\n",
      "        - -0.43671417236328125\n",
      "        - 0.4497582018375397\n",
      "        - 0.1409480720758438\n",
      "        - 0.06105804443359375\n",
      "        - 0.37576740980148315\n",
      "        - 0.16021783649921417\n",
      "        - -2.2509307861328125\n",
      "        - 0.39016208052635193\n",
      "        - 0.38211822509765625\n",
      "        - -0.06803131103515625\n",
      "        - 0.5547870397567749\n",
      "        - 0.3773738443851471\n",
      "        - 0.4923613667488098\n",
      "        - 0.3103525638580322\n",
      "        - 0.30540692806243896\n",
      "        - 0.42321300506591797\n",
      "        - 0.12857818603515625\n",
      "        - 0.5170525312423706\n",
      "        - -0.630279541015625\n",
      "        - 2.3996200561523438\n",
      "        - 0.2095111906528473\n",
      "        - -0.43949127197265625\n",
      "        - 0.48032379150390625\n",
      "        - 0.406563937664032\n",
      "        - 0.4724246859550476\n",
      "        - 0.27346664667129517\n",
      "        - 0.3611205816268921\n",
      "        - -0.00881195068359375\n",
      "    num_agent_steps_sampled: 21500\n",
      "    num_agent_steps_trained: 2560256\n",
      "    num_steps_sampled: 21500\n",
      "    num_steps_trained: 2560256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 10001\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 7.891666666666667\n",
      "    ram_util_percent: 1.8\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.19973215343341977\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.21123568958825514\n",
      "    mean_inference_ms: 1.3143525496702761\n",
      "    mean_raw_obs_processing_ms: 0.5212073963451843\n",
      "  time_since_restore: 353.0694189071655\n",
      "  time_this_iter_s: 16.48503065109253\n",
      "  time_total_s: 353.0694189071655\n",
      "  timers:\n",
      "    learn_throughput: 51305.0\n",
      "    learn_time_ms: 4.99\n",
      "    load_throughput: 655800.296\n",
      "    load_time_ms: 0.39\n",
      "    update_time_ms: 2.893\n",
      "  timestamp: 1647534011\n",
      "  timesteps_since_restore: 5376\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 21500\n",
      "  training_iteration: 21\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:20:12 (running for 00:06:09.03)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         353.069</td><td style=\"text-align: right;\">21500</td><td style=\"text-align: right;\">-684.058</td><td style=\"text-align: right;\">           -0.293063</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:20:17 (running for 00:06:14.07)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         353.069</td><td style=\"text-align: right;\">21500</td><td style=\"text-align: right;\">-684.058</td><td style=\"text-align: right;\">           -0.293063</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:20:22 (running for 00:06:19.07)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         353.069</td><td style=\"text-align: right;\">21500</td><td style=\"text-align: right;\">-684.058</td><td style=\"text-align: right;\">           -0.293063</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:20:27 (running for 00:06:24.08)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         353.069</td><td style=\"text-align: right;\">21500</td><td style=\"text-align: right;\">-684.058</td><td style=\"text-align: right;\">           -0.293063</td><td style=\"text-align: right;\">            -1590.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 22500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-20-27\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.2930634876035956\n",
      "  episode_reward_mean: -617.3331499716521\n",
      "  episode_reward_min: -1530.7984765622975\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 112\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 22500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 2.163687229156494\n",
      "          mean_q: -53.95960235595703\n",
      "          min_q: -130.42530822753906\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 1.463287353515625\n",
      "        - -0.10001564025878906\n",
      "        - 0.24628448486328125\n",
      "        - 0.4196622371673584\n",
      "        - -0.42240142822265625\n",
      "        - 1.3515625\n",
      "        - -0.8400402069091797\n",
      "        - 0.47886425256729126\n",
      "        - 1.2181339263916016\n",
      "        - 0.41449737548828125\n",
      "        - 0.27320027351379395\n",
      "        - 0.26690196990966797\n",
      "        - 0.8059234619140625\n",
      "        - -0.4161376953125\n",
      "        - 3.2126007080078125\n",
      "        - 0.7418972849845886\n",
      "        - 1.6280441284179688\n",
      "        - -0.2483673095703125\n",
      "        - 0.7999228239059448\n",
      "        - 2.7595863342285156\n",
      "        - 0.24146845936775208\n",
      "        - 0.801069974899292\n",
      "        - 0.630401611328125\n",
      "        - 0.4854034185409546\n",
      "        - 0.9303207397460938\n",
      "        - 1.4288177490234375\n",
      "        - 2.4966049194335938\n",
      "        - -1.145355224609375\n",
      "        - 0.6863136291503906\n",
      "        - -0.202850341796875\n",
      "        - 0.22743988037109375\n",
      "        - -0.04112662374973297\n",
      "        - -1.3143348693847656\n",
      "        - 0.45090800523757935\n",
      "        - 0.21504592895507812\n",
      "        - -1.2934722900390625\n",
      "        - 1.7017593383789062\n",
      "        - 0.40847015380859375\n",
      "        - 1.273516058921814\n",
      "        - 1.0813674926757812\n",
      "        - 0.38565200567245483\n",
      "        - 4.12432861328125\n",
      "        - 0.05719757080078125\n",
      "        - 0.8461074829101562\n",
      "        - 1.39874267578125\n",
      "        - -0.33740997314453125\n",
      "        - 1.166595458984375\n",
      "        - 0.4265230894088745\n",
      "        - 0.1187591552734375\n",
      "        - -0.17100422084331512\n",
      "        - 0.51596599817276\n",
      "        - 1.0855218172073364\n",
      "        - 0.2470293641090393\n",
      "        - 0.5431880950927734\n",
      "        - 3.8850173950195312\n",
      "        - 0.9013824462890625\n",
      "        - 0.4644625782966614\n",
      "        - 0.43193119764328003\n",
      "        - 0.4644795060157776\n",
      "        - 0.06317901611328125\n",
      "        - 0.40135419368743896\n",
      "        - 0.7443079948425293\n",
      "        - 0.37779730558395386\n",
      "        - 0.900241494178772\n",
      "        - 0.9989166259765625\n",
      "        - 0.9982452392578125\n",
      "        - -0.8476715087890625\n",
      "        - 0.461517333984375\n",
      "        - 0.5891113877296448\n",
      "        - 0.6537950038909912\n",
      "        - -0.8348007202148438\n",
      "        - 0.03516387939453125\n",
      "        - -0.3892822265625\n",
      "        - 0.26886823773384094\n",
      "        - -1.322021484375\n",
      "        - 2.4046630859375\n",
      "        - -2.4867401123046875\n",
      "        - 0.9445266723632812\n",
      "        - 0.9370880126953125\n",
      "        - 0.6868473291397095\n",
      "        - -1.2367782592773438\n",
      "        - -0.09504595398902893\n",
      "        - 1.047698974609375\n",
      "        - 0.627471923828125\n",
      "        - 0.6519330143928528\n",
      "        - 1.6062545776367188\n",
      "        - 0.4066857397556305\n",
      "        - -0.6371383666992188\n",
      "        - 3.5066909790039062\n",
      "        - 0.2137298583984375\n",
      "        - 1.4524993896484375\n",
      "        - 0.7611494064331055\n",
      "        - 0.0529816597700119\n",
      "        - -0.072357177734375\n",
      "        - 1.4837026596069336\n",
      "        - -0.40502166748046875\n",
      "        - 0.8140422105789185\n",
      "        - 1.9729995727539062\n",
      "        - 0.9540215730667114\n",
      "        - 0.3051099181175232\n",
      "        - -0.28348541259765625\n",
      "        - 2.4671478271484375\n",
      "        - -0.1919708251953125\n",
      "        - 0.45014938712120056\n",
      "        - -0.107818603515625\n",
      "        - 0.9261703491210938\n",
      "        - 0.026724398136138916\n",
      "        - 0.5758533477783203\n",
      "        - 0.40122777223587036\n",
      "        - 1.64776611328125\n",
      "        - 0.845346212387085\n",
      "        - -0.4068117141723633\n",
      "        - 0.9228439331054688\n",
      "        - 1.1371688842773438\n",
      "        - 0.5073484778404236\n",
      "        - 1.1393661499023438\n",
      "        - 2.9173431396484375\n",
      "        - 1.2603302001953125\n",
      "        - 0.37969672679901123\n",
      "        - 0.3729501962661743\n",
      "        - 0.237274169921875\n",
      "        - 0.5213793516159058\n",
      "        - 0.5090309977531433\n",
      "        - -0.32884979248046875\n",
      "        - 0.4207916259765625\n",
      "        - 1.3574371337890625\n",
      "        - -0.4031829833984375\n",
      "        - 0.7000910043716431\n",
      "        - 0.02739715576171875\n",
      "        - -0.1693878173828125\n",
      "        - 2.4350204467773438\n",
      "        - 2.3966064453125\n",
      "        - 0.4907256066799164\n",
      "        - 0.792938232421875\n",
      "        - 0.38802656531333923\n",
      "        - 0.33707427978515625\n",
      "        - 3.7400131225585938\n",
      "        - 0.4040234386920929\n",
      "        - -0.9129791259765625\n",
      "        - -0.01667744666337967\n",
      "        - 0.5762362480163574\n",
      "        - 0.8624693155288696\n",
      "        - 0.9929012060165405\n",
      "        - 0.4754791259765625\n",
      "        - 0.03314647078514099\n",
      "        - 0.6986083984375\n",
      "        - 1.251251220703125\n",
      "        - -1.8849906921386719\n",
      "        - 0.7463922500610352\n",
      "        - 1.5223541259765625\n",
      "        - -1.1576309204101562\n",
      "        - 0.8440920114517212\n",
      "        - 0.6687040328979492\n",
      "        - 0.28742122650146484\n",
      "        - -0.07698549330234528\n",
      "        - 0.4605255126953125\n",
      "        - 0.4921838939189911\n",
      "        - -0.9223785400390625\n",
      "        - 0.27051040530204773\n",
      "        - -0.9217453002929688\n",
      "        - 0.8981286287307739\n",
      "        - 1.3094635009765625\n",
      "        - 2.3187408447265625\n",
      "        - 0.21410983800888062\n",
      "        - 0.04843902587890625\n",
      "        - -1.7991943359375\n",
      "        - 0.37804150581359863\n",
      "        - -0.9748764038085938\n",
      "        - 0.6596641540527344\n",
      "        - -0.11894822120666504\n",
      "        - 0.28159627318382263\n",
      "        - 1.3095550537109375\n",
      "        - 0.0012656599283218384\n",
      "        - 0.9845123291015625\n",
      "        - 0.5371217727661133\n",
      "        - 0.4484684467315674\n",
      "        - 1.1259536743164062\n",
      "        - 0.9926646947860718\n",
      "        - 2.1133804321289062\n",
      "        - -0.1667346954345703\n",
      "        - 1.184295654296875\n",
      "        - 0.5307731628417969\n",
      "        - 0.5086817741394043\n",
      "        - 0.6596641540527344\n",
      "        - 1.95758056640625\n",
      "        - 0.49933546781539917\n",
      "        - 0.37100034952163696\n",
      "        - 0.03462982177734375\n",
      "        - 0.5519203543663025\n",
      "        - -0.0462799072265625\n",
      "        - 1.4753799438476562\n",
      "        - 2.1586380004882812\n",
      "        - -0.36038970947265625\n",
      "        - 0.8156967163085938\n",
      "        - 0.16078948974609375\n",
      "        - 1.9561882019042969\n",
      "        - 1.1682205200195312\n",
      "        - -0.7572021484375\n",
      "        - -0.141632080078125\n",
      "        - 0.21136224269866943\n",
      "        - 0.5513477325439453\n",
      "        - 0.6781212091445923\n",
      "        - -0.19989776611328125\n",
      "        - -0.27749109268188477\n",
      "        - 0.9923629760742188\n",
      "        - 0.4996933043003082\n",
      "        - 0.7674663662910461\n",
      "        - 0.6172555685043335\n",
      "        - 0.03845977783203125\n",
      "        - 0.41990363597869873\n",
      "        - -0.223602294921875\n",
      "        - 0.028167724609375\n",
      "        - -0.42099761962890625\n",
      "        - 0.38184356689453125\n",
      "        - -0.27132415771484375\n",
      "        - 0.9599953889846802\n",
      "        - 0.495574951171875\n",
      "        - 0.48942697048187256\n",
      "        - 0.17135941982269287\n",
      "        - 0.4571489691734314\n",
      "        - -1.5670700073242188\n",
      "        - 0.46302586793899536\n",
      "        - 0.55609130859375\n",
      "        - -0.7356414794921875\n",
      "        - 2.9979782104492188\n",
      "        - 1.2392425537109375\n",
      "        - 0.6749258637428284\n",
      "        - 0.8047695159912109\n",
      "        - -0.006766796112060547\n",
      "        - 0.49262264370918274\n",
      "        - 0.33566755056381226\n",
      "        - 1.0393638610839844\n",
      "        - 0.92529296875\n",
      "        - 0.3099976181983948\n",
      "        - 0.5689408779144287\n",
      "        - -1.2426376342773438\n",
      "        - 0.3686654567718506\n",
      "        - 0.5865814089775085\n",
      "        - 0.6254281997680664\n",
      "        - 0.3679046630859375\n",
      "        - -0.4829254150390625\n",
      "        - -0.47418212890625\n",
      "        - 1.1097183227539062\n",
      "        - 0.41488564014434814\n",
      "        - 0.32360243797302246\n",
      "        - 0.5005937218666077\n",
      "        - -0.07497231662273407\n",
      "        - 0.5482025146484375\n",
      "        - 0.6383633613586426\n",
      "        - -0.4726104736328125\n",
      "        - -0.13271331787109375\n",
      "        - -1.5339889526367188\n",
      "        - -0.18825583159923553\n",
      "        - 0.9113845825195312\n",
      "        - -0.6614532470703125\n",
      "        - 0.7537844181060791\n",
      "    num_agent_steps_sampled: 22500\n",
      "    num_agent_steps_trained: 2688256\n",
      "    num_steps_sampled: 22500\n",
      "    num_steps_trained: 2688256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 10501\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 8.182608695652172\n",
      "    ram_util_percent: 1.7999999999999994\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.19796967397303003\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.20845392728605902\n",
      "    mean_inference_ms: 1.258896243549348\n",
      "    mean_raw_obs_processing_ms: 0.5131129920256852\n",
      "  time_since_restore: 369.59992957115173\n",
      "  time_this_iter_s: 16.530510663986206\n",
      "  time_total_s: 369.59992957115173\n",
      "  timers:\n",
      "    learn_throughput: 50488.399\n",
      "    learn_time_ms: 5.07\n",
      "    load_throughput: 637084.267\n",
      "    load_time_ms: 0.402\n",
      "    update_time_ms: 3.016\n",
      "  timestamp: 1647534027\n",
      "  timesteps_since_restore: 5632\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 22500\n",
      "  training_iteration: 22\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:20:32 (running for 00:06:29.61)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">           369.6</td><td style=\"text-align: right;\">22500</td><td style=\"text-align: right;\">-617.333</td><td style=\"text-align: right;\">           -0.293063</td><td style=\"text-align: right;\">             -1530.8</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:20:38 (running for 00:06:34.65)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">           369.6</td><td style=\"text-align: right;\">22500</td><td style=\"text-align: right;\">-617.333</td><td style=\"text-align: right;\">           -0.293063</td><td style=\"text-align: right;\">             -1530.8</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:20:43 (running for 00:06:39.65)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">           369.6</td><td style=\"text-align: right;\">22500</td><td style=\"text-align: right;\">-617.333</td><td style=\"text-align: right;\">           -0.293063</td><td style=\"text-align: right;\">             -1530.8</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_432bf_00000:\n",
      "  agent_timesteps_total: 23500\n",
      "  custom_metrics: {}\n",
      "  date: 2022-03-17_16-20-44\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.2930634876035956\n",
      "  episode_reward_mean: -583.4867948244034\n",
      "  episode_reward_min: -1523.6178108731317\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 116\n",
      "  experiment_id: 20d954a7ba764f52953fb2d5a75c6833\n",
      "  hostname: ip-172-16-6-103\n",
      "  info:\n",
      "    last_target_update_ts: 23500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          max_q: 0.8179748058319092\n",
      "          mean_q: -56.09696960449219\n",
      "          min_q: -135.4779815673828\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.057830810546875\n",
      "        - -0.5764235258102417\n",
      "        - 1.4037551879882812\n",
      "        - -0.9512331485748291\n",
      "        - -0.5241372585296631\n",
      "        - -1.009674072265625\n",
      "        - -0.53973388671875\n",
      "        - -0.4779447913169861\n",
      "        - -1.5383319854736328\n",
      "        - -1.2913742065429688\n",
      "        - -1.333282232284546\n",
      "        - -0.6459548473358154\n",
      "        - -0.342376708984375\n",
      "        - 0.013519287109375\n",
      "        - -0.5707040429115295\n",
      "        - -1.0819473266601562\n",
      "        - -0.43605804443359375\n",
      "        - -0.34112548828125\n",
      "        - -0.30397337675094604\n",
      "        - 0.488861083984375\n",
      "        - -0.4743170738220215\n",
      "        - -0.5768796801567078\n",
      "        - -1.226165771484375\n",
      "        - -0.2998504638671875\n",
      "        - 1.9247512817382812\n",
      "        - 0.39681243896484375\n",
      "        - 1.9014968872070312\n",
      "        - -0.561854362487793\n",
      "        - 3.1656150817871094\n",
      "        - -0.6204652786254883\n",
      "        - -0.002349853515625\n",
      "        - -0.5413532853126526\n",
      "        - 1.3347396850585938\n",
      "        - 0.7889175415039062\n",
      "        - -0.21689605712890625\n",
      "        - -0.9006274342536926\n",
      "        - -0.6670913696289062\n",
      "        - -1.25364089012146\n",
      "        - -0.6088247299194336\n",
      "        - 0.0147552490234375\n",
      "        - 0.87457275390625\n",
      "        - 0.19850921630859375\n",
      "        - -0.45130103826522827\n",
      "        - 0.73101806640625\n",
      "        - 0.86627197265625\n",
      "        - -2.357565402984619\n",
      "        - -1.386155605316162\n",
      "        - 1.336944580078125\n",
      "        - -0.5725244879722595\n",
      "        - -0.4430999755859375\n",
      "        - -0.8105621337890625\n",
      "        - -1.2355519533157349\n",
      "        - -0.7105058431625366\n",
      "        - -0.05791473388671875\n",
      "        - 0.38907623291015625\n",
      "        - -2.268857955932617\n",
      "        - -0.02864837646484375\n",
      "        - -0.6259191036224365\n",
      "        - -0.5652669668197632\n",
      "        - 1.4307098388671875\n",
      "        - -0.5737600326538086\n",
      "        - -1.1468124389648438\n",
      "        - 2.035064697265625\n",
      "        - 2.0883636474609375\n",
      "        - 1.4784927368164062\n",
      "        - -1.4069137573242188\n",
      "        - 1.9608917236328125\n",
      "        - -0.45556640625\n",
      "        - -0.9319534301757812\n",
      "        - 0.1210479736328125\n",
      "        - -0.381744384765625\n",
      "        - -0.419281005859375\n",
      "        - 0.7354660034179688\n",
      "        - -0.5923618078231812\n",
      "        - 0.21562957763671875\n",
      "        - -0.3147656321525574\n",
      "        - 0.17089080810546875\n",
      "        - -3.025949478149414\n",
      "        - -0.6178261637687683\n",
      "        - 2.8293895721435547\n",
      "        - -0.89752197265625\n",
      "        - 0.4437408447265625\n",
      "        - -0.5298124551773071\n",
      "        - 0.9886474609375\n",
      "        - 0.45923614501953125\n",
      "        - 0.6953125\n",
      "        - -0.33125022053718567\n",
      "        - -0.6543897390365601\n",
      "        - -1.8398056030273438\n",
      "        - -3.542703628540039\n",
      "        - 0.5418930053710938\n",
      "        - -0.6485977172851562\n",
      "        - 0.20257568359375\n",
      "        - -0.40139302611351013\n",
      "        - -0.44948577880859375\n",
      "        - -3.001678466796875\n",
      "        - -0.04590606689453125\n",
      "        - -0.5122909545898438\n",
      "        - -0.46861979365348816\n",
      "        - 1.305389404296875\n",
      "        - -0.6424386501312256\n",
      "        - -0.5590364933013916\n",
      "        - -0.48759299516677856\n",
      "        - -0.49201667308807373\n",
      "        - 3.3283233642578125\n",
      "        - 0.647430419921875\n",
      "        - -0.741943359375\n",
      "        - 0.299102783203125\n",
      "        - -0.6728992462158203\n",
      "        - 2.417083740234375\n",
      "        - -0.5937641859054565\n",
      "        - -0.5937095284461975\n",
      "        - -0.5840541124343872\n",
      "        - -3.0345606803894043\n",
      "        - -0.14678192138671875\n",
      "        - -1.1050872802734375\n",
      "        - -0.8374710083007812\n",
      "        - -0.2667788863182068\n",
      "        - -0.5337666273117065\n",
      "        - -0.8547770380973816\n",
      "        - -0.6510326862335205\n",
      "        - 0.502777099609375\n",
      "        - 0.0676116943359375\n",
      "        - 2.9628982543945312\n",
      "        - -0.36760905385017395\n",
      "        - -0.6437525749206543\n",
      "        - 0.09947967529296875\n",
      "        - -111.85852813720703\n",
      "        - -0.6280010938644409\n",
      "        - 0.2693939208984375\n",
      "        - -0.5151967406272888\n",
      "        - -0.6021479964256287\n",
      "        - 0.33591461181640625\n",
      "        - -0.6239384412765503\n",
      "        - -0.7706069946289062\n",
      "        - -0.6126283407211304\n",
      "        - -2.0836901664733887\n",
      "        - 0.96661376953125\n",
      "        - -1.1821823120117188\n",
      "        - 0.2925262451171875\n",
      "        - 2.0608901977539062\n",
      "        - -4.735651016235352\n",
      "        - 1.4805374145507812\n",
      "        - -0.5597434639930725\n",
      "        - -0.4967498779296875\n",
      "        - 0.3314056396484375\n",
      "        - 0.8217010498046875\n",
      "        - -0.496134877204895\n",
      "        - -0.47190120816230774\n",
      "        - -0.6956100463867188\n",
      "        - -1.518320083618164\n",
      "        - -2.8459415435791016\n",
      "        - 2.1988677978515625\n",
      "        - 1.04962158203125\n",
      "        - -0.2673187255859375\n",
      "        - 2.2734451293945312\n",
      "        - -0.1870880126953125\n",
      "        - -0.5794227123260498\n",
      "        - -0.08327484130859375\n",
      "        - -0.5795872807502747\n",
      "        - -1.2381439208984375\n",
      "        - -0.530264139175415\n",
      "        - -0.5648956298828125\n",
      "        - -0.6044865846633911\n",
      "        - -0.38165709376335144\n",
      "        - -0.5789991021156311\n",
      "        - -0.8544719219207764\n",
      "        - 0.115509033203125\n",
      "        - -1.174285888671875\n",
      "        - -1.0048446655273438\n",
      "        - 2.3840789794921875\n",
      "        - 2.7482376098632812\n",
      "        - -0.5985610485076904\n",
      "        - -0.46353548765182495\n",
      "        - -0.32507941126823425\n",
      "        - -0.5093048810958862\n",
      "        - -0.5166279077529907\n",
      "        - -0.7309494018554688\n",
      "        - -0.5805003643035889\n",
      "        - -0.5631648898124695\n",
      "        - -0.6233426332473755\n",
      "        - -1.2880096435546875\n",
      "        - -0.594479501247406\n",
      "        - -0.3863525390625\n",
      "        - 0.38541412353515625\n",
      "        - 0.5507431030273438\n",
      "        - -1.0817530155181885\n",
      "        - -0.5114974975585938\n",
      "        - -0.8921356201171875\n",
      "        - -0.4759346842765808\n",
      "        - -0.4768194556236267\n",
      "        - 0.0870208740234375\n",
      "        - -0.6033521294593811\n",
      "        - -0.6118506193161011\n",
      "        - -0.770842432975769\n",
      "        - -0.5884829759597778\n",
      "        - 0.398773193359375\n",
      "        - 0.0285797119140625\n",
      "        - 2.5385971069335938\n",
      "        - 0.2005615234375\n",
      "        - -0.4270172119140625\n",
      "        - 0.10665130615234375\n",
      "        - 0.940155029296875\n",
      "        - -1.3068618774414062\n",
      "        - -0.5410923957824707\n",
      "        - 0.0547027587890625\n",
      "        - -0.628451943397522\n",
      "        - -0.6933919191360474\n",
      "        - -0.15540313720703125\n",
      "        - -0.5174790620803833\n",
      "        - -0.6038886308670044\n",
      "        - -0.15244293212890625\n",
      "        - -0.6004054546356201\n",
      "        - -0.45347076654434204\n",
      "        - -2.497344970703125\n",
      "        - -0.5868386030197144\n",
      "        - -0.7388080358505249\n",
      "        - 0.5770187377929688\n",
      "        - -0.613025963306427\n",
      "        - -0.550407350063324\n",
      "        - -0.6437910795211792\n",
      "        - 2.0170364379882812\n",
      "        - -0.7665863037109375\n",
      "        - 0.10120391845703125\n",
      "        - 0.6726608276367188\n",
      "        - -0.6751556396484375\n",
      "        - 0.9042205810546875\n",
      "        - -0.5570129752159119\n",
      "        - -0.5711588859558105\n",
      "        - 2.0415267944335938\n",
      "        - 0.22856903076171875\n",
      "        - -0.5494792461395264\n",
      "        - -0.5305835008621216\n",
      "        - -0.7038071155548096\n",
      "        - -0.724043607711792\n",
      "        - 0.1739501953125\n",
      "        - 0.1985931396484375\n",
      "        - -0.6323037147521973\n",
      "        - -1.6586532592773438\n",
      "        - -0.5818181037902832\n",
      "        - -0.7825164794921875\n",
      "        - -0.5405639410018921\n",
      "        - -0.5684689283370972\n",
      "        - -0.6713030338287354\n",
      "        - -0.9267981648445129\n",
      "        - -0.61630779504776\n",
      "        - -0.4889262318611145\n",
      "        - 0.922607421875\n",
      "        - -0.3319511413574219\n",
      "        - 1.2785873413085938\n",
      "        - 0.19366455078125\n",
      "        - -0.579140305519104\n",
      "        - -0.7326006889343262\n",
      "        - -1.2348806858062744\n",
      "        - -0.5860512852668762\n",
      "        - -1.3396682739257812\n",
      "    num_agent_steps_sampled: 23500\n",
      "    num_agent_steps_trained: 2816256\n",
      "    num_steps_sampled: 23500\n",
      "    num_steps_trained: 2816256\n",
      "    num_steps_trained_this_iter: 256\n",
      "    num_target_updates: 11001\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 172.16.6.103\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 7.970833333333334\n",
      "    ram_util_percent: 1.8\n",
      "  pid: 61074\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1970437478620938\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.20706263012201787\n",
      "    mean_inference_ms: 1.23330936597911\n",
      "    mean_raw_obs_processing_ms: 0.509136906708941\n",
      "  time_since_restore: 386.0912730693817\n",
      "  time_this_iter_s: 16.49134349822998\n",
      "  time_total_s: 386.0912730693817\n",
      "  timers:\n",
      "    learn_throughput: 51866.324\n",
      "    learn_time_ms: 4.936\n",
      "    load_throughput: 650358.464\n",
      "    load_time_ms: 0.394\n",
      "    update_time_ms: 2.897\n",
      "  timestamp: 1647534044\n",
      "  timesteps_since_restore: 5888\n",
      "  timesteps_this_iter: 256\n",
      "  timesteps_total: 23500\n",
      "  training_iteration: 23\n",
      "  trial_id: 432bf_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:20:48 (running for 00:06:45.18)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         386.091</td><td style=\"text-align: right;\">23500</td><td style=\"text-align: right;\">-583.487</td><td style=\"text-align: right;\">           -0.293063</td><td style=\"text-align: right;\">            -1523.62</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-17 16:20:53 (running for 00:06:50.19)<br>Memory usage on this node: 8.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0/8 GPUs, 0.0/325.57 GiB heap, 0.0/143.52 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_432bf_00000</td><td>RUNNING </td><td>172.16.6.103:61074</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         386.091</td><td style=\"text-align: right;\">23500</td><td style=\"text-align: right;\">-583.487</td><td style=\"text-align: right;\">           -0.293063</td><td style=\"text-align: right;\">            -1523.62</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alg = 'DDPG'\n",
    "tune.run(alg,\n",
    "    stop={\"training_iteration\": 100},\n",
    "    config={\n",
    "        'env':'Pendulum-v1',\n",
    "        'num_gpus':0,\n",
    "        'num_workers':2,\n",
    "        'lr':tune.grid_search([.001,])     \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m 2021-08-20 13:44:05,796\tINFO trainer.py:706 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m 2021-08-20 13:44:05,796\tINFO trainer.py:718 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m 2021-08-20 13:44:14,857\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 4000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-44-19\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -861.7010709272424\n",
      "  episode_reward_mean: -1247.730572467082\n",
      "  episode_reward_min: -1559.5065434762291\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 20\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3914216756820679\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012996056117117405\n",
      "          model: {}\n",
      "          policy_loss: -0.007822790183126926\n",
      "          total_loss: 145535.796875\n",
      "          vf_explained_var: 0.003884573234245181\n",
      "          vf_loss: 145535.828125\n",
      "    num_agent_steps_sampled: 4000\n",
      "    num_agent_steps_trained: 4000\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.850000000000005\n",
      "    ram_util_percent: 67.83333333333333\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0842969933490286\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1192378854823077\n",
      "    mean_inference_ms: 0.5967783248764107\n",
      "    mean_raw_obs_processing_ms: 0.0583328407207529\n",
      "  time_since_restore: 4.2074809074401855\n",
      "  time_this_iter_s: 4.2074809074401855\n",
      "  time_total_s: 4.2074809074401855\n",
      "  timers:\n",
      "    learn_throughput: 1664.833\n",
      "    learn_time_ms: 2402.643\n",
      "    load_throughput: 90977.306\n",
      "    load_time_ms: 43.967\n",
      "    sample_throughput: 2279.163\n",
      "    sample_time_ms: 1755.03\n",
      "    update_time_ms: 1.749\n",
      "  timestamp: 1629485059\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.20748</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">-1247.73</td><td style=\"text-align: right;\">            -861.701</td><td style=\"text-align: right;\">            -1559.51</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 12000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-44-25\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -861.7010709272424\n",
      "  episode_reward_mean: -1181.6867835564474\n",
      "  episode_reward_min: -1748.4394313483292\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 60\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2951185703277588\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019712885841727257\n",
      "          model: {}\n",
      "          policy_loss: -0.01567647233605385\n",
      "          total_loss: 105931.5\n",
      "          vf_explained_var: 0.03061719797551632\n",
      "          vf_loss: 105931.515625\n",
      "    num_agent_steps_sampled: 12000\n",
      "    num_agent_steps_trained: 12000\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 12000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.8\n",
      "    ram_util_percent: 68.11999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07768856358195843\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11074756140020132\n",
      "    mean_inference_ms: 0.5481736757450373\n",
      "    mean_raw_obs_processing_ms: 0.05306546952751003\n",
      "  time_since_restore: 11.047992944717407\n",
      "  time_this_iter_s: 3.3503990173339844\n",
      "  time_total_s: 11.047992944717407\n",
      "  timers:\n",
      "    learn_throughput: 1851.92\n",
      "    learn_time_ms: 2159.92\n",
      "    load_throughput: 263444.758\n",
      "    load_time_ms: 15.183\n",
      "    sample_throughput: 2662.723\n",
      "    sample_time_ms: 1502.222\n",
      "    update_time_ms: 1.497\n",
      "  timestamp: 1629485065\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 3\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">          11.048</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">-1181.69</td><td style=\"text-align: right;\">            -861.701</td><td style=\"text-align: right;\">            -1748.44</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 20000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-44-32\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -765.0367910823298\n",
      "  episode_reward_mean: -1164.5790178624363\n",
      "  episode_reward_min: -1748.4394313483292\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 100\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3369152545928955\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02118964120745659\n",
      "          model: {}\n",
      "          policy_loss: -0.02064530737698078\n",
      "          total_loss: 89807.0625\n",
      "          vf_explained_var: 0.054389216005802155\n",
      "          vf_loss: 89807.0703125\n",
      "    num_agent_steps_sampled: 20000\n",
      "    num_agent_steps_trained: 20000\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.740000000000002\n",
      "    ram_util_percent: 68.3\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07466436042072662\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10699763373831023\n",
      "    mean_inference_ms: 0.526210017908064\n",
      "    mean_raw_obs_processing_ms: 0.050692280284007706\n",
      "  time_since_restore: 17.641114711761475\n",
      "  time_this_iter_s: 3.0896499156951904\n",
      "  time_total_s: 17.641114711761475\n",
      "  timers:\n",
      "    learn_throughput: 1936.167\n",
      "    learn_time_ms: 2065.937\n",
      "    load_throughput: 424475.289\n",
      "    load_time_ms: 9.423\n",
      "    sample_throughput: 2770.992\n",
      "    sample_time_ms: 1443.526\n",
      "    update_time_ms: 1.388\n",
      "  timestamp: 1629485072\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 5\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         17.6411</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">-1164.58</td><td style=\"text-align: right;\">            -765.037</td><td style=\"text-align: right;\">            -1748.44</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 28000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-44-39\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -765.0367910823298\n",
      "  episode_reward_mean: -1110.8743558113963\n",
      "  episode_reward_min: -1748.4394313483292\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 140\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2820247411727905\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017025019973516464\n",
      "          model: {}\n",
      "          policy_loss: -0.023783231154084206\n",
      "          total_loss: 65443.2109375\n",
      "          vf_explained_var: 0.051222797483205795\n",
      "          vf_loss: 65443.2265625\n",
      "    num_agent_steps_sampled: 28000\n",
      "    num_agent_steps_trained: 28000\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 28000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.440000000000005\n",
      "    ram_util_percent: 67.9\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07032717477039277\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10160676183628946\n",
      "    mean_inference_ms: 0.49424986474626464\n",
      "    mean_raw_obs_processing_ms: 0.04726399834420716\n",
      "  time_since_restore: 24.23247194290161\n",
      "  time_this_iter_s: 3.4286561012268066\n",
      "  time_total_s: 24.23247194290161\n",
      "  timers:\n",
      "    learn_throughput: 2000.049\n",
      "    learn_time_ms: 1999.951\n",
      "    load_throughput: 574065.081\n",
      "    load_time_ms: 6.968\n",
      "    sample_throughput: 2764.994\n",
      "    sample_time_ms: 1446.658\n",
      "    update_time_ms: 1.398\n",
      "  timestamp: 1629485079\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 7\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         24.2325</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">-1110.87</td><td style=\"text-align: right;\">            -765.037</td><td style=\"text-align: right;\">            -1748.44</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 36000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-44-46\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -765.0367910823298\n",
      "  episode_reward_mean: -1054.5513677332435\n",
      "  episode_reward_min: -1730.6306737238613\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 180\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3237019777297974\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022166144102811813\n",
      "          model: {}\n",
      "          policy_loss: -0.0309299323707819\n",
      "          total_loss: 54791.28515625\n",
      "          vf_explained_var: 0.05643095448613167\n",
      "          vf_loss: 54791.30859375\n",
      "    num_agent_steps_sampled: 36000\n",
      "    num_agent_steps_trained: 36000\n",
      "    num_steps_sampled: 36000\n",
      "    num_steps_trained: 36000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.88333333333333\n",
      "    ram_util_percent: 68.0\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0696428184428571\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10076558212970108\n",
      "    mean_inference_ms: 0.4883137542534914\n",
      "    mean_raw_obs_processing_ms: 0.04666718486629506\n",
      "  time_since_restore: 31.672873735427856\n",
      "  time_this_iter_s: 3.9558639526367188\n",
      "  time_total_s: 31.672873735427856\n",
      "  timers:\n",
      "    learn_throughput: 1942.357\n",
      "    learn_time_ms: 2059.353\n",
      "    load_throughput: 712687.412\n",
      "    load_time_ms: 5.613\n",
      "    sample_throughput: 2765.192\n",
      "    sample_time_ms: 1446.554\n",
      "    update_time_ms: 1.405\n",
      "  timestamp: 1629485086\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 9\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         31.6729</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">-1054.55</td><td style=\"text-align: right;\">            -765.037</td><td style=\"text-align: right;\">            -1730.63</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 44000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-44-53\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -652.0579853569814\n",
      "  episode_reward_mean: -1032.9860006834995\n",
      "  episode_reward_min: -1574.1321829834644\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 220\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3283683061599731\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011564229615032673\n",
      "          model: {}\n",
      "          policy_loss: -0.01673576794564724\n",
      "          total_loss: 43464.55078125\n",
      "          vf_explained_var: 0.06871659308671951\n",
      "          vf_loss: 43464.55859375\n",
      "    num_agent_steps_sampled: 44000\n",
      "    num_agent_steps_trained: 44000\n",
      "    num_steps_sampled: 44000\n",
      "    num_steps_trained: 44000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.32000000000001\n",
      "    ram_util_percent: 67.96000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0702798418082635\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10165675718157832\n",
      "    mean_inference_ms: 0.491630249803192\n",
      "    mean_raw_obs_processing_ms: 0.047111553133881455\n",
      "  time_since_restore: 38.84664058685303\n",
      "  time_this_iter_s: 3.6737060546875\n",
      "  time_total_s: 38.84664058685303\n",
      "  timers:\n",
      "    learn_throughput: 1981.249\n",
      "    learn_time_ms: 2018.929\n",
      "    load_throughput: 4768150.969\n",
      "    load_time_ms: 0.839\n",
      "    sample_throughput: 2784.164\n",
      "    sample_time_ms: 1436.697\n",
      "    update_time_ms: 1.373\n",
      "  timestamp: 1629485093\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 44000\n",
      "  training_iteration: 11\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         38.8466</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\">-1032.99</td><td style=\"text-align: right;\">            -652.058</td><td style=\"text-align: right;\">            -1574.13</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 52000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-00\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -652.0579853569814\n",
      "  episode_reward_mean: -1041.4897291979926\n",
      "  episode_reward_min: -1574.1321829834644\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 260\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2789126634597778\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01498641911894083\n",
      "          model: {}\n",
      "          policy_loss: -0.02070006914436817\n",
      "          total_loss: 38337.828125\n",
      "          vf_explained_var: 0.07115664333105087\n",
      "          vf_loss: 38337.83203125\n",
      "    num_agent_steps_sampled: 52000\n",
      "    num_agent_steps_trained: 52000\n",
      "    num_steps_sampled: 52000\n",
      "    num_steps_trained: 52000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.55\n",
      "    ram_util_percent: 67.8\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07055443126283475\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10205939118428078\n",
      "    mean_inference_ms: 0.4929637341624287\n",
      "    mean_raw_obs_processing_ms: 0.047286125612685054\n",
      "  time_since_restore: 45.132662773132324\n",
      "  time_this_iter_s: 3.1521222591400146\n",
      "  time_total_s: 45.132662773132324\n",
      "  timers:\n",
      "    learn_throughput: 2033.988\n",
      "    learn_time_ms: 1966.58\n",
      "    load_throughput: 4817163.202\n",
      "    load_time_ms: 0.83\n",
      "    sample_throughput: 2790.043\n",
      "    sample_time_ms: 1433.669\n",
      "    update_time_ms: 1.345\n",
      "  timestamp: 1629485100\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 52000\n",
      "  training_iteration: 13\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         45.1327</td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\">-1041.49</td><td style=\"text-align: right;\">            -652.058</td><td style=\"text-align: right;\">            -1574.13</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-06\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -652.0579853569814\n",
      "  episode_reward_mean: -1032.3922369698164\n",
      "  episode_reward_min: -1615.047905476564\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 300\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3489347696304321\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017803119495511055\n",
      "          model: {}\n",
      "          policy_loss: -0.026169482618570328\n",
      "          total_loss: 33105.859375\n",
      "          vf_explained_var: 0.07398030161857605\n",
      "          vf_loss: 33105.87890625\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_agent_steps_trained: 60000\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.975\n",
      "    ram_util_percent: 67.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07033671404593772\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1017910330008513\n",
      "    mean_inference_ms: 0.4913401123072137\n",
      "    mean_raw_obs_processing_ms: 0.04709627931693248\n",
      "  time_since_restore: 51.544148683547974\n",
      "  time_this_iter_s: 3.270878791809082\n",
      "  time_total_s: 51.544148683547974\n",
      "  timers:\n",
      "    learn_throughput: 2048.665\n",
      "    learn_time_ms: 1952.491\n",
      "    load_throughput: 4832843.439\n",
      "    load_time_ms: 0.828\n",
      "    sample_throughput: 2793.947\n",
      "    sample_time_ms: 1431.666\n",
      "    update_time_ms: 1.356\n",
      "  timestamp: 1629485106\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 15\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         51.5441</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">-1032.39</td><td style=\"text-align: right;\">            -652.058</td><td style=\"text-align: right;\">            -1615.05</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 68000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-13\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -750.4548601951891\n",
      "  episode_reward_mean: -999.1340143537749\n",
      "  episode_reward_min: -1615.047905476564\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 340\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.147055983543396\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01609395258128643\n",
      "          model: {}\n",
      "          policy_loss: -0.021593304350972176\n",
      "          total_loss: 23533.0625\n",
      "          vf_explained_var: 0.05944361910223961\n",
      "          vf_loss: 23533.07421875\n",
      "    num_agent_steps_sampled: 68000\n",
      "    num_agent_steps_trained: 68000\n",
      "    num_steps_sampled: 68000\n",
      "    num_steps_trained: 68000\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.7\n",
      "    ram_util_percent: 67.67999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06976071597202313\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10099827658508864\n",
      "    mean_inference_ms: 0.4875018175765124\n",
      "    mean_raw_obs_processing_ms: 0.04663429222717221\n",
      "  time_since_restore: 58.097867250442505\n",
      "  time_this_iter_s: 3.3513636589050293\n",
      "  time_total_s: 58.097867250442505\n",
      "  timers:\n",
      "    learn_throughput: 2041.638\n",
      "    learn_time_ms: 1959.211\n",
      "    load_throughput: 4797465.328\n",
      "    load_time_ms: 0.834\n",
      "    sample_throughput: 2814.305\n",
      "    sample_time_ms: 1421.31\n",
      "    update_time_ms: 1.333\n",
      "  timestamp: 1629485113\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 68000\n",
      "  training_iteration: 17\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         58.0979</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">-999.134</td><td style=\"text-align: right;\">            -750.455</td><td style=\"text-align: right;\">            -1615.05</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 76000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-19\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -750.4548601951891\n",
      "  episode_reward_mean: -981.6374921750662\n",
      "  episode_reward_min: -1582.118281778163\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 380\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.138116478919983\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009961972013115883\n",
      "          model: {}\n",
      "          policy_loss: -0.012737400829792023\n",
      "          total_loss: 18793.3125\n",
      "          vf_explained_var: 0.09615538269281387\n",
      "          vf_loss: 18793.31640625\n",
      "    num_agent_steps_sampled: 76000\n",
      "    num_agent_steps_trained: 76000\n",
      "    num_steps_sampled: 76000\n",
      "    num_steps_trained: 76000\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.98\n",
      "    ram_util_percent: 67.2\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06944948673358933\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10052505923617357\n",
      "    mean_inference_ms: 0.485368394873595\n",
      "    mean_raw_obs_processing_ms: 0.04636414153513068\n",
      "  time_since_restore: 64.71084308624268\n",
      "  time_this_iter_s: 3.3802459239959717\n",
      "  time_total_s: 64.71084308624268\n",
      "  timers:\n",
      "    learn_throughput: 2120.96\n",
      "    learn_time_ms: 1885.938\n",
      "    load_throughput: 4924915.165\n",
      "    load_time_ms: 0.812\n",
      "    sample_throughput: 2832.634\n",
      "    sample_time_ms: 1412.113\n",
      "    update_time_ms: 1.296\n",
      "  timestamp: 1629485119\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 76000\n",
      "  training_iteration: 19\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         64.7108</td><td style=\"text-align: right;\">76000</td><td style=\"text-align: right;\">-981.637</td><td style=\"text-align: right;\">            -750.455</td><td style=\"text-align: right;\">            -1582.12</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 84000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-26\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -750.0360247172193\n",
      "  episode_reward_mean: -990.3854969557972\n",
      "  episode_reward_min: -1685.0551173128385\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 420\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.612725019454956\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00928998738527298\n",
      "          model: {}\n",
      "          policy_loss: -0.013718923553824425\n",
      "          total_loss: 26902.974609375\n",
      "          vf_explained_var: 0.1330251693725586\n",
      "          vf_loss: 26902.982421875\n",
      "    num_agent_steps_sampled: 84000\n",
      "    num_agent_steps_trained: 84000\n",
      "    num_steps_sampled: 84000\n",
      "    num_steps_trained: 84000\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.079999999999995\n",
      "    ram_util_percent: 67.02000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06933940684221349\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10034124564863164\n",
      "    mean_inference_ms: 0.48455009022769174\n",
      "    mean_raw_obs_processing_ms: 0.04626970432733685\n",
      "  time_since_restore: 71.304603099823\n",
      "  time_this_iter_s: 3.2620980739593506\n",
      "  time_total_s: 71.304603099823\n",
      "  timers:\n",
      "    learn_throughput: 2153.2\n",
      "    learn_time_ms: 1857.701\n",
      "    load_throughput: 4868040.854\n",
      "    load_time_ms: 0.822\n",
      "    sample_throughput: 2893.81\n",
      "    sample_time_ms: 1382.261\n",
      "    update_time_ms: 1.329\n",
      "  timestamp: 1629485126\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 84000\n",
      "  training_iteration: 21\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         71.3046</td><td style=\"text-align: right;\">84000</td><td style=\"text-align: right;\">-990.385</td><td style=\"text-align: right;\">            -750.036</td><td style=\"text-align: right;\">            -1685.06</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 92000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-33\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -750.0360247172193\n",
      "  episode_reward_mean: -1010.5507575119403\n",
      "  episode_reward_min: -1685.0551173128385\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 460\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3867007493972778\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010622402653098106\n",
      "          model: {}\n",
      "          policy_loss: -0.021630944684147835\n",
      "          total_loss: 18721.6953125\n",
      "          vf_explained_var: 0.1422927975654602\n",
      "          vf_loss: 18721.70703125\n",
      "    num_agent_steps_sampled: 92000\n",
      "    num_agent_steps_trained: 92000\n",
      "    num_steps_sampled: 92000\n",
      "    num_steps_trained: 92000\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.7\n",
      "    ram_util_percent: 67.1\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06925881021040053\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1002380940530098\n",
      "    mean_inference_ms: 0.4840445544294971\n",
      "    mean_raw_obs_processing_ms: 0.04622833752086798\n",
      "  time_since_restore: 77.85871005058289\n",
      "  time_this_iter_s: 3.221095085144043\n",
      "  time_total_s: 77.85871005058289\n",
      "  timers:\n",
      "    learn_throughput: 2137.567\n",
      "    learn_time_ms: 1871.286\n",
      "    load_throughput: 4727041.587\n",
      "    load_time_ms: 0.846\n",
      "    sample_throughput: 2867.065\n",
      "    sample_time_ms: 1395.155\n",
      "    update_time_ms: 1.446\n",
      "  timestamp: 1629485133\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 92000\n",
      "  training_iteration: 23\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         77.8587</td><td style=\"text-align: right;\">92000</td><td style=\"text-align: right;\">-1010.55</td><td style=\"text-align: right;\">            -750.036</td><td style=\"text-align: right;\">            -1685.06</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 100000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-40\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -732.5105983158745\n",
      "  episode_reward_mean: -1031.2249469831443\n",
      "  episode_reward_min: -1685.0551173128385\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 500\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2975060939788818\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01088643167167902\n",
      "          model: {}\n",
      "          policy_loss: -0.02106568031013012\n",
      "          total_loss: 14752.814453125\n",
      "          vf_explained_var: 0.1842322051525116\n",
      "          vf_loss: 14752.82421875\n",
      "    num_agent_steps_sampled: 100000\n",
      "    num_agent_steps_trained: 100000\n",
      "    num_steps_sampled: 100000\n",
      "    num_steps_trained: 100000\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.439999999999998\n",
      "    ram_util_percent: 66.75999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06923763151207224\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10022671411031463\n",
      "    mean_inference_ms: 0.4839165280999277\n",
      "    mean_raw_obs_processing_ms: 0.046252031466706034\n",
      "  time_since_restore: 84.64135599136353\n",
      "  time_this_iter_s: 3.4659950733184814\n",
      "  time_total_s: 84.64135599136353\n",
      "  timers:\n",
      "    learn_throughput: 2120.994\n",
      "    learn_time_ms: 1885.908\n",
      "    load_throughput: 4563118.013\n",
      "    load_time_ms: 0.877\n",
      "    sample_throughput: 2821.737\n",
      "    sample_time_ms: 1417.567\n",
      "    update_time_ms: 1.473\n",
      "  timestamp: 1629485140\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 100000\n",
      "  training_iteration: 25\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         84.6414</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-1031.22</td><td style=\"text-align: right;\">            -732.511</td><td style=\"text-align: right;\">            -1685.06</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 108000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-46\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -630.6912001434713\n",
      "  episode_reward_mean: -1043.7307244439542\n",
      "  episode_reward_min: -1718.9726366638777\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 540\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.879002332687378\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011907962150871754\n",
      "          model: {}\n",
      "          policy_loss: -0.01969742216169834\n",
      "          total_loss: 22054.294921875\n",
      "          vf_explained_var: 0.2851261794567108\n",
      "          vf_loss: 22054.296875\n",
      "    num_agent_steps_sampled: 108000\n",
      "    num_agent_steps_trained: 108000\n",
      "    num_steps_sampled: 108000\n",
      "    num_steps_trained: 108000\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.359999999999996\n",
      "    ram_util_percent: 66.9\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0692460008008586\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10023371245385772\n",
      "    mean_inference_ms: 0.4839306324239418\n",
      "    mean_raw_obs_processing_ms: 0.046274970741536185\n",
      "  time_since_restore: 91.22690677642822\n",
      "  time_this_iter_s: 3.2756669521331787\n",
      "  time_total_s: 91.22690677642822\n",
      "  timers:\n",
      "    learn_throughput: 2117.079\n",
      "    learn_time_ms: 1889.396\n",
      "    load_throughput: 4559397.777\n",
      "    load_time_ms: 0.877\n",
      "    sample_throughput: 2822.363\n",
      "    sample_time_ms: 1417.252\n",
      "    update_time_ms: 1.475\n",
      "  timestamp: 1629485146\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 108000\n",
      "  training_iteration: 27\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         91.2269</td><td style=\"text-align: right;\">108000</td><td style=\"text-align: right;\">-1043.73</td><td style=\"text-align: right;\">            -630.691</td><td style=\"text-align: right;\">            -1718.97</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 116000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-53\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -630.6912001434713\n",
      "  episode_reward_mean: -1010.4580316223162\n",
      "  episode_reward_min: -1718.9726366638777\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 580\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.9193784594535828\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012211025692522526\n",
      "          model: {}\n",
      "          policy_loss: -0.01306854747235775\n",
      "          total_loss: 10650.8046875\n",
      "          vf_explained_var: 0.22014197707176208\n",
      "          vf_loss: 10650.8056640625\n",
      "    num_agent_steps_sampled: 116000\n",
      "    num_agent_steps_trained: 116000\n",
      "    num_steps_sampled: 116000\n",
      "    num_steps_trained: 116000\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.76\n",
      "    ram_util_percent: 67.22\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06926912630493835\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10024508440909674\n",
      "    mean_inference_ms: 0.4840069089488381\n",
      "    mean_raw_obs_processing_ms: 0.04628308664669233\n",
      "  time_since_restore: 97.86976313591003\n",
      "  time_this_iter_s: 3.338068962097168\n",
      "  time_total_s: 97.86976313591003\n",
      "  timers:\n",
      "    learn_throughput: 2122.152\n",
      "    learn_time_ms: 1884.879\n",
      "    load_throughput: 4494057.645\n",
      "    load_time_ms: 0.89\n",
      "    sample_throughput: 2807.646\n",
      "    sample_time_ms: 1424.681\n",
      "    update_time_ms: 1.482\n",
      "  timestamp: 1629485153\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 116000\n",
      "  training_iteration: 29\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         97.8698</td><td style=\"text-align: right;\">116000</td><td style=\"text-align: right;\">-1010.46</td><td style=\"text-align: right;\">            -630.691</td><td style=\"text-align: right;\">            -1718.97</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 124000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-59\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -730.3838476494092\n",
      "  episode_reward_mean: -1042.9413741065052\n",
      "  episode_reward_min: -1759.947757152376\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 620\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.8066339492797852\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011592076160013676\n",
      "          model: {}\n",
      "          policy_loss: -0.01907852478325367\n",
      "          total_loss: 19893.439453125\n",
      "          vf_explained_var: 0.28621706366539\n",
      "          vf_loss: 19893.4453125\n",
      "    num_agent_steps_sampled: 124000\n",
      "    num_agent_steps_trained: 124000\n",
      "    num_steps_sampled: 124000\n",
      "    num_steps_trained: 124000\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.26\n",
      "    ram_util_percent: 67.3\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06921627230224234\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10014045635978676\n",
      "    mean_inference_ms: 0.4835945767563029\n",
      "    mean_raw_obs_processing_ms: 0.046212873008717244\n",
      "  time_since_restore: 104.42366433143616\n",
      "  time_this_iter_s: 3.2862768173217773\n",
      "  time_total_s: 104.42366433143616\n",
      "  timers:\n",
      "    learn_throughput: 2121.331\n",
      "    learn_time_ms: 1885.609\n",
      "    load_throughput: 4698315.831\n",
      "    load_time_ms: 0.851\n",
      "    sample_throughput: 2816.372\n",
      "    sample_time_ms: 1420.267\n",
      "    update_time_ms: 1.414\n",
      "  timestamp: 1629485159\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 124000\n",
      "  training_iteration: 31\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         104.424</td><td style=\"text-align: right;\">124000</td><td style=\"text-align: right;\">-1042.94</td><td style=\"text-align: right;\">            -730.384</td><td style=\"text-align: right;\">            -1759.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 132000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-07\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -741.7314728915361\n",
      "  episode_reward_mean: -1022.2670066389339\n",
      "  episode_reward_min: -1759.947757152376\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 660\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.618180274963379\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012345453724265099\n",
      "          model: {}\n",
      "          policy_loss: -0.02471439354121685\n",
      "          total_loss: 12137.2490234375\n",
      "          vf_explained_var: 0.4350372850894928\n",
      "          vf_loss: 12137.26171875\n",
      "    num_agent_steps_sampled: 132000\n",
      "    num_agent_steps_trained: 132000\n",
      "    num_steps_sampled: 132000\n",
      "    num_steps_trained: 132000\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.26\n",
      "    ram_util_percent: 67.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06939415081572509\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10033982736246085\n",
      "    mean_inference_ms: 0.4847611188645716\n",
      "    mean_raw_obs_processing_ms: 0.04633235574072572\n",
      "  time_since_restore: 112.10044813156128\n",
      "  time_this_iter_s: 3.815706968307495\n",
      "  time_total_s: 112.10044813156128\n",
      "  timers:\n",
      "    learn_throughput: 2037.899\n",
      "    learn_time_ms: 1962.805\n",
      "    load_throughput: 4670977.226\n",
      "    load_time_ms: 0.856\n",
      "    sample_throughput: 2748.301\n",
      "    sample_time_ms: 1455.445\n",
      "    update_time_ms: 1.364\n",
      "  timestamp: 1629485167\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 132000\n",
      "  training_iteration: 33\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">           112.1</td><td style=\"text-align: right;\">132000</td><td style=\"text-align: right;\">-1022.27</td><td style=\"text-align: right;\">            -741.731</td><td style=\"text-align: right;\">            -1759.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 140000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-15\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -575.7102946698726\n",
      "  episode_reward_mean: -1022.6872157866918\n",
      "  episode_reward_min: -1759.947757152376\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 700\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.5862019062042236\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01306239329278469\n",
      "          model: {}\n",
      "          policy_loss: -0.016106856986880302\n",
      "          total_loss: 12868.044921875\n",
      "          vf_explained_var: 0.4221709072589874\n",
      "          vf_loss: 12868.0498046875\n",
      "    num_agent_steps_sampled: 140000\n",
      "    num_agent_steps_trained: 140000\n",
      "    num_steps_sampled: 140000\n",
      "    num_steps_trained: 140000\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 35.68333333333333\n",
      "    ram_util_percent: 67.81666666666668\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06974985423573397\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10077678393328\n",
      "    mean_inference_ms: 0.4870930358827632\n",
      "    mean_raw_obs_processing_ms: 0.04661513466359936\n",
      "  time_since_restore: 120.36115598678589\n",
      "  time_this_iter_s: 3.76053786277771\n",
      "  time_total_s: 120.36115598678589\n",
      "  timers:\n",
      "    learn_throughput: 1921.502\n",
      "    learn_time_ms: 2081.705\n",
      "    load_throughput: 4392516.298\n",
      "    load_time_ms: 0.911\n",
      "    sample_throughput: 2694.954\n",
      "    sample_time_ms: 1484.255\n",
      "    update_time_ms: 1.344\n",
      "  timestamp: 1629485175\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 140000\n",
      "  training_iteration: 35\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         120.361</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">-1022.69</td><td style=\"text-align: right;\">             -575.71</td><td style=\"text-align: right;\">            -1759.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 148000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-22\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -575.7102946698726\n",
      "  episode_reward_mean: -1027.404432289974\n",
      "  episode_reward_min: -1711.9996755025059\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 740\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.8227649927139282\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011758917011320591\n",
      "          model: {}\n",
      "          policy_loss: -0.014279463328421116\n",
      "          total_loss: 13531.529296875\n",
      "          vf_explained_var: 0.4432796537876129\n",
      "          vf_loss: 13531.5302734375\n",
      "    num_agent_steps_sampled: 148000\n",
      "    num_agent_steps_trained: 148000\n",
      "    num_steps_sampled: 148000\n",
      "    num_steps_trained: 148000\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.8\n",
      "    ram_util_percent: 67.72\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07003658400623307\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10112393515719789\n",
      "    mean_inference_ms: 0.48905513122413213\n",
      "    mean_raw_obs_processing_ms: 0.046833094423540444\n",
      "  time_since_restore: 126.778559923172\n",
      "  time_this_iter_s: 3.1659018993377686\n",
      "  time_total_s: 126.778559923172\n",
      "  timers:\n",
      "    learn_throughput: 1934.676\n",
      "    learn_time_ms: 2067.529\n",
      "    load_throughput: 4399311.936\n",
      "    load_time_ms: 0.909\n",
      "    sample_throughput: 2699.673\n",
      "    sample_time_ms: 1481.661\n",
      "    update_time_ms: 1.321\n",
      "  timestamp: 1629485182\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 148000\n",
      "  training_iteration: 37\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         126.779</td><td style=\"text-align: right;\">148000</td><td style=\"text-align: right;\"> -1027.4</td><td style=\"text-align: right;\">             -575.71</td><td style=\"text-align: right;\">               -1712</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 156000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-28\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -575.7102946698726\n",
      "  episode_reward_mean: -1044.0525233657056\n",
      "  episode_reward_min: -1691.1267287366854\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 780\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7034541368484497\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011067953892052174\n",
      "          model: {}\n",
      "          policy_loss: -0.019947124645113945\n",
      "          total_loss: 14097.197265625\n",
      "          vf_explained_var: 0.4234596788883209\n",
      "          vf_loss: 14097.205078125\n",
      "    num_agent_steps_sampled: 156000\n",
      "    num_agent_steps_trained: 156000\n",
      "    num_steps_sampled: 156000\n",
      "    num_steps_trained: 156000\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.225\n",
      "    ram_util_percent: 66.64999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07005527241666362\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10112035874997645\n",
      "    mean_inference_ms: 0.489371150061653\n",
      "    mean_raw_obs_processing_ms: 0.04682510598178764\n",
      "  time_since_restore: 133.2816517353058\n",
      "  time_this_iter_s: 3.3030357360839844\n",
      "  time_total_s: 133.2816517353058\n",
      "  timers:\n",
      "    learn_throughput: 1945.525\n",
      "    learn_time_ms: 2056.001\n",
      "    load_throughput: 4362817.839\n",
      "    load_time_ms: 0.917\n",
      "    sample_throughput: 2704.074\n",
      "    sample_time_ms: 1479.25\n",
      "    update_time_ms: 1.327\n",
      "  timestamp: 1629485188\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 156000\n",
      "  training_iteration: 39\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         133.282</td><td style=\"text-align: right;\">156000</td><td style=\"text-align: right;\">-1044.05</td><td style=\"text-align: right;\">             -575.71</td><td style=\"text-align: right;\">            -1691.13</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 164000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-35\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -743.9866797461497\n",
      "  episode_reward_mean: -1025.4424514173543\n",
      "  episode_reward_min: -1696.5970621478803\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 820\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1105883121490479\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011235026642680168\n",
      "          model: {}\n",
      "          policy_loss: -0.014406774193048477\n",
      "          total_loss: 10807.919921875\n",
      "          vf_explained_var: 0.3834441006183624\n",
      "          vf_loss: 10807.9248046875\n",
      "    num_agent_steps_sampled: 164000\n",
      "    num_agent_steps_trained: 164000\n",
      "    num_steps_sampled: 164000\n",
      "    num_steps_trained: 164000\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.26\n",
      "    ram_util_percent: 66.12\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0699824370573309\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10100809494156347\n",
      "    mean_inference_ms: 0.48901406371793243\n",
      "    mean_raw_obs_processing_ms: 0.046747511128504324\n",
      "  time_since_restore: 140.13890624046326\n",
      "  time_this_iter_s: 3.4345781803131104\n",
      "  time_total_s: 140.13890624046326\n",
      "  timers:\n",
      "    learn_throughput: 1926.233\n",
      "    learn_time_ms: 2076.592\n",
      "    load_throughput: 4314239.868\n",
      "    load_time_ms: 0.927\n",
      "    sample_throughput: 2686.513\n",
      "    sample_time_ms: 1488.919\n",
      "    update_time_ms: 1.346\n",
      "  timestamp: 1629485195\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 164000\n",
      "  training_iteration: 41\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         140.139</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\">-1025.44</td><td style=\"text-align: right;\">            -743.987</td><td style=\"text-align: right;\">             -1696.6</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 172000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-43\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -733.0212221234876\n",
      "  episode_reward_mean: -996.9560604038786\n",
      "  episode_reward_min: -1791.823133566769\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 860\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.634163498878479\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011408006772398949\n",
      "          model: {}\n",
      "          policy_loss: -0.008866180665791035\n",
      "          total_loss: 12902.4375\n",
      "          vf_explained_var: 0.46788448095321655\n",
      "          vf_loss: 12902.43359375\n",
      "    num_agent_steps_sampled: 172000\n",
      "    num_agent_steps_trained: 172000\n",
      "    num_steps_sampled: 172000\n",
      "    num_steps_trained: 172000\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.26\n",
      "    ram_util_percent: 66.86\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07005423824583205\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10110173679919619\n",
      "    mean_inference_ms: 0.48947964503497376\n",
      "    mean_raw_obs_processing_ms: 0.04680482236050082\n",
      "  time_since_restore: 148.09751510620117\n",
      "  time_this_iter_s: 3.9446558952331543\n",
      "  time_total_s: 148.09751510620117\n",
      "  timers:\n",
      "    learn_throughput: 1889.576\n",
      "    learn_time_ms: 2116.877\n",
      "    load_throughput: 4334189.982\n",
      "    load_time_ms: 0.923\n",
      "    sample_throughput: 2708.347\n",
      "    sample_time_ms: 1476.916\n",
      "    update_time_ms: 1.299\n",
      "  timestamp: 1629485203\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 172000\n",
      "  training_iteration: 43\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         148.098</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\">-996.956</td><td style=\"text-align: right;\">            -733.021</td><td style=\"text-align: right;\">            -1791.82</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 180000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-50\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -631.2426580852854\n",
      "  episode_reward_mean: -981.8323547548162\n",
      "  episode_reward_min: -1791.823133566769\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 900\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3244298696517944\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011415433138608932\n",
      "          model: {}\n",
      "          policy_loss: -0.014314445666968822\n",
      "          total_loss: 9988.47265625\n",
      "          vf_explained_var: 0.4630546569824219\n",
      "          vf_loss: 9988.4755859375\n",
      "    num_agent_steps_sampled: 180000\n",
      "    num_agent_steps_trained: 180000\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.179999999999996\n",
      "    ram_util_percent: 66.88\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0701608781688785\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10124517329020427\n",
      "    mean_inference_ms: 0.4901354175626764\n",
      "    mean_raw_obs_processing_ms: 0.046898943997748466\n",
      "  time_since_restore: 154.7887568473816\n",
      "  time_this_iter_s: 3.273242950439453\n",
      "  time_total_s: 154.7887568473816\n",
      "  timers:\n",
      "    learn_throughput: 2009.004\n",
      "    learn_time_ms: 1991.037\n",
      "    load_throughput: 4773034.424\n",
      "    load_time_ms: 0.838\n",
      "    sample_throughput: 2766.124\n",
      "    sample_time_ms: 1446.067\n",
      "    update_time_ms: 1.281\n",
      "  timestamp: 1629485210\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 45\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         154.789</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\">-981.832</td><td style=\"text-align: right;\">            -631.243</td><td style=\"text-align: right;\">            -1791.82</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 188000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-57\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -629.3977337988962\n",
      "  episode_reward_mean: -995.1829215012846\n",
      "  episode_reward_min: -1791.823133566769\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 940\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3577574491500854\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01083450112491846\n",
      "          model: {}\n",
      "          policy_loss: -0.017753321677446365\n",
      "          total_loss: 10265.3515625\n",
      "          vf_explained_var: 0.43747782707214355\n",
      "          vf_loss: 10265.3583984375\n",
      "    num_agent_steps_sampled: 188000\n",
      "    num_agent_steps_trained: 188000\n",
      "    num_steps_sampled: 188000\n",
      "    num_steps_trained: 188000\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.46\n",
      "    ram_util_percent: 66.58\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07030874167853325\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10142886089302744\n",
      "    mean_inference_ms: 0.4910965497528423\n",
      "    mean_raw_obs_processing_ms: 0.047020579397031845\n",
      "  time_since_restore: 161.68916583061218\n",
      "  time_this_iter_s: 3.257439136505127\n",
      "  time_total_s: 161.68916583061218\n",
      "  timers:\n",
      "    learn_throughput: 1988.771\n",
      "    learn_time_ms: 2011.292\n",
      "    load_throughput: 4775751.779\n",
      "    load_time_ms: 0.838\n",
      "    sample_throughput: 2713.497\n",
      "    sample_time_ms: 1474.112\n",
      "    update_time_ms: 1.28\n",
      "  timestamp: 1629485217\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 188000\n",
      "  training_iteration: 47\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         161.689</td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\">-995.183</td><td style=\"text-align: right;\">            -629.398</td><td style=\"text-align: right;\">            -1791.82</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 196000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-04\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -629.3977337988962\n",
      "  episode_reward_mean: -1013.9992745932628\n",
      "  episode_reward_min: -1750.0167036690998\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 980\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.1757988929748535\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00922983605414629\n",
      "          model: {}\n",
      "          policy_loss: -0.017294740304350853\n",
      "          total_loss: 15539.4736328125\n",
      "          vf_explained_var: 0.47723841667175293\n",
      "          vf_loss: 15539.4814453125\n",
      "    num_agent_steps_sampled: 196000\n",
      "    num_agent_steps_trained: 196000\n",
      "    num_steps_sampled: 196000\n",
      "    num_steps_trained: 196000\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.480000000000008\n",
      "    ram_util_percent: 66.67999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07034065040373394\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10146054257639044\n",
      "    mean_inference_ms: 0.49133356633912517\n",
      "    mean_raw_obs_processing_ms: 0.04704089013029943\n",
      "  time_since_restore: 168.66379690170288\n",
      "  time_this_iter_s: 3.57236385345459\n",
      "  time_total_s: 168.66379690170288\n",
      "  timers:\n",
      "    learn_throughput: 1947.261\n",
      "    learn_time_ms: 2054.167\n",
      "    load_throughput: 4824088.792\n",
      "    load_time_ms: 0.829\n",
      "    sample_throughput: 2705.764\n",
      "    sample_time_ms: 1478.325\n",
      "    update_time_ms: 1.288\n",
      "  timestamp: 1629485224\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 196000\n",
      "  training_iteration: 49\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         168.664</td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">   -1014</td><td style=\"text-align: right;\">            -629.398</td><td style=\"text-align: right;\">            -1750.02</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 204000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-11\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -744.1916957844479\n",
      "  episode_reward_mean: -1009.8282911532389\n",
      "  episode_reward_min: -1750.0167036690998\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1020\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.761823058128357\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010485198348760605\n",
      "          model: {}\n",
      "          policy_loss: -0.016281604766845703\n",
      "          total_loss: 13348.2763671875\n",
      "          vf_explained_var: 0.46484696865081787\n",
      "          vf_loss: 13348.2822265625\n",
      "    num_agent_steps_sampled: 204000\n",
      "    num_agent_steps_trained: 204000\n",
      "    num_steps_sampled: 204000\n",
      "    num_steps_trained: 204000\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.775\n",
      "    ram_util_percent: 66.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07035379269210179\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10148633812653543\n",
      "    mean_inference_ms: 0.4914357248804698\n",
      "    mean_raw_obs_processing_ms: 0.04705728286355459\n",
      "  time_since_restore: 175.23236775398254\n",
      "  time_this_iter_s: 3.269742727279663\n",
      "  time_total_s: 175.23236775398254\n",
      "  timers:\n",
      "    learn_throughput: 1971.514\n",
      "    learn_time_ms: 2028.898\n",
      "    load_throughput: 4892600.391\n",
      "    load_time_ms: 0.818\n",
      "    sample_throughput: 2712.373\n",
      "    sample_time_ms: 1474.724\n",
      "    update_time_ms: 1.288\n",
      "  timestamp: 1629485231\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 204000\n",
      "  training_iteration: 51\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         175.232</td><td style=\"text-align: right;\">204000</td><td style=\"text-align: right;\">-1009.83</td><td style=\"text-align: right;\">            -744.192</td><td style=\"text-align: right;\">            -1750.02</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 212000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-20\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -501.4707088320807\n",
      "  episode_reward_mean: -1007.5657462256714\n",
      "  episode_reward_min: -1726.3964042171408\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1060\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.632434368133545\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01130130235105753\n",
      "          model: {}\n",
      "          policy_loss: -0.021617727354168892\n",
      "          total_loss: 11467.7705078125\n",
      "          vf_explained_var: 0.5169113874435425\n",
      "          vf_loss: 11467.7822265625\n",
      "    num_agent_steps_sampled: 212000\n",
      "    num_agent_steps_trained: 212000\n",
      "    num_steps_sampled: 212000\n",
      "    num_steps_trained: 212000\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.371428571428574\n",
      "    ram_util_percent: 68.02857142857144\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07047764806484225\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10163669726211948\n",
      "    mean_inference_ms: 0.4922212955555696\n",
      "    mean_raw_obs_processing_ms: 0.047148375720967334\n",
      "  time_since_restore: 184.5059425830841\n",
      "  time_this_iter_s: 5.37188982963562\n",
      "  time_total_s: 184.5059425830841\n",
      "  timers:\n",
      "    learn_throughput: 1894.906\n",
      "    learn_time_ms: 2110.922\n",
      "    load_throughput: 4872423.547\n",
      "    load_time_ms: 0.821\n",
      "    sample_throughput: 2624.993\n",
      "    sample_time_ms: 1523.814\n",
      "    update_time_ms: 1.361\n",
      "  timestamp: 1629485240\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 212000\n",
      "  training_iteration: 53\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         184.506</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\">-1007.57</td><td style=\"text-align: right;\">            -501.471</td><td style=\"text-align: right;\">             -1726.4</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 220000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-28\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -501.4707088320807\n",
      "  episode_reward_mean: -988.871039232908\n",
      "  episode_reward_min: -1726.3964042171408\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1100\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3439828157424927\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010741790756583214\n",
      "          model: {}\n",
      "          policy_loss: -0.015692995861172676\n",
      "          total_loss: 9464.666015625\n",
      "          vf_explained_var: 0.49364280700683594\n",
      "          vf_loss: 9464.669921875\n",
      "    num_agent_steps_sampled: 220000\n",
      "    num_agent_steps_trained: 220000\n",
      "    num_steps_sampled: 220000\n",
      "    num_steps_trained: 220000\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.339999999999996\n",
      "    ram_util_percent: 68.53999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07109118993730708\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10230354631492868\n",
      "    mean_inference_ms: 0.4962358192875573\n",
      "    mean_raw_obs_processing_ms: 0.04757647502903626\n",
      "  time_since_restore: 192.56479573249817\n",
      "  time_this_iter_s: 3.2761390209198\n",
      "  time_total_s: 192.56479573249817\n",
      "  timers:\n",
      "    learn_throughput: 1858.724\n",
      "    learn_time_ms: 2152.014\n",
      "    load_throughput: 4634718.086\n",
      "    load_time_ms: 0.863\n",
      "    sample_throughput: 2470.096\n",
      "    sample_time_ms: 1619.37\n",
      "    update_time_ms: 1.361\n",
      "  timestamp: 1629485248\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 220000\n",
      "  training_iteration: 55\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         192.565</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\">-988.871</td><td style=\"text-align: right;\">            -501.471</td><td style=\"text-align: right;\">             -1726.4</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 228000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-34\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -411.36966133382225\n",
      "  episode_reward_mean: -953.1972024145348\n",
      "  episode_reward_min: -1698.2448619264273\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1140\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.9809526205062866\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01407674327492714\n",
      "          model: {}\n",
      "          policy_loss: -0.012463761493563652\n",
      "          total_loss: 8902.99609375\n",
      "          vf_explained_var: 0.28797224164009094\n",
      "          vf_loss: 8902.994140625\n",
      "    num_agent_steps_sampled: 228000\n",
      "    num_agent_steps_trained: 228000\n",
      "    num_steps_sampled: 228000\n",
      "    num_steps_trained: 228000\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.799999999999997\n",
      "    ram_util_percent: 67.05000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07166367150565657\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1029198637035071\n",
      "    mean_inference_ms: 0.4999740656953733\n",
      "    mean_raw_obs_processing_ms: 0.047973187625595416\n",
      "  time_since_restore: 199.05036783218384\n",
      "  time_this_iter_s: 3.2255349159240723\n",
      "  time_total_s: 199.05036783218384\n",
      "  timers:\n",
      "    learn_throughput: 1868.44\n",
      "    learn_time_ms: 2140.823\n",
      "    load_throughput: 4725310.801\n",
      "    load_time_ms: 0.847\n",
      "    sample_throughput: 2517.226\n",
      "    sample_time_ms: 1589.051\n",
      "    update_time_ms: 1.373\n",
      "  timestamp: 1629485254\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 228000\n",
      "  training_iteration: 57\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">          199.05</td><td style=\"text-align: right;\">228000</td><td style=\"text-align: right;\">-953.197</td><td style=\"text-align: right;\">             -411.37</td><td style=\"text-align: right;\">            -1698.24</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 236000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-43\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -411.36966133382225\n",
      "  episode_reward_mean: -923.5028760815865\n",
      "  episode_reward_min: -1698.2448619264273\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1180\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.5522300004959106\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011608139611780643\n",
      "          model: {}\n",
      "          policy_loss: -0.009791683405637741\n",
      "          total_loss: 13132.0341796875\n",
      "          vf_explained_var: 0.4275711178779602\n",
      "          vf_loss: 13132.03125\n",
      "    num_agent_steps_sampled: 236000\n",
      "    num_agent_steps_trained: 236000\n",
      "    num_steps_sampled: 236000\n",
      "    num_steps_trained: 236000\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.41428571428572\n",
      "    ram_util_percent: 68.64285714285714\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07186028938125313\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10311551202615077\n",
      "    mean_inference_ms: 0.5013012491915823\n",
      "    mean_raw_obs_processing_ms: 0.04810173879713577\n",
      "  time_since_restore: 207.85307955741882\n",
      "  time_this_iter_s: 4.803573846817017\n",
      "  time_total_s: 207.85307955741882\n",
      "  timers:\n",
      "    learn_throughput: 1768.7\n",
      "    learn_time_ms: 2261.549\n",
      "    load_throughput: 4209035.625\n",
      "    load_time_ms: 0.95\n",
      "    sample_throughput: 2423.556\n",
      "    sample_time_ms: 1650.467\n",
      "    update_time_ms: 1.571\n",
      "  timestamp: 1629485263\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 236000\n",
      "  training_iteration: 59\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         207.853</td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\">-923.503</td><td style=\"text-align: right;\">             -411.37</td><td style=\"text-align: right;\">            -1698.24</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 244000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-50\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -644.1001234234999\n",
      "  episode_reward_mean: -954.8672878838067\n",
      "  episode_reward_min: -1815.2885135142992\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1220\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7281264066696167\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01056593470275402\n",
      "          model: {}\n",
      "          policy_loss: -0.01810789294540882\n",
      "          total_loss: 12390.83203125\n",
      "          vf_explained_var: 0.5107462406158447\n",
      "          vf_loss: 12390.8388671875\n",
      "    num_agent_steps_sampled: 244000\n",
      "    num_agent_steps_trained: 244000\n",
      "    num_steps_sampled: 244000\n",
      "    num_steps_trained: 244000\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.700000000000003\n",
      "    ram_util_percent: 66.95\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07204413822637887\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10331978012680391\n",
      "    mean_inference_ms: 0.5025678053272779\n",
      "    mean_raw_obs_processing_ms: 0.0482230512756005\n",
      "  time_since_restore: 214.5980944633484\n",
      "  time_this_iter_s: 3.204292058944702\n",
      "  time_total_s: 214.5980944633484\n",
      "  timers:\n",
      "    learn_throughput: 1771.24\n",
      "    learn_time_ms: 2258.305\n",
      "    load_throughput: 4220895.643\n",
      "    load_time_ms: 0.948\n",
      "    sample_throughput: 2393.167\n",
      "    sample_time_ms: 1671.426\n",
      "    update_time_ms: 1.554\n",
      "  timestamp: 1629485270\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 244000\n",
      "  training_iteration: 61\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         214.598</td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\">-954.867</td><td style=\"text-align: right;\">              -644.1</td><td style=\"text-align: right;\">            -1815.29</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 252000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-57\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -644.1001234234999\n",
      "  episode_reward_mean: -990.1667539342235\n",
      "  episode_reward_min: -1815.2885135142992\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1260\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.5871754884719849\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013256299309432507\n",
      "          model: {}\n",
      "          policy_loss: -0.010848736390471458\n",
      "          total_loss: 12965.8037109375\n",
      "          vf_explained_var: 0.4771033227443695\n",
      "          vf_loss: 12965.80078125\n",
      "    num_agent_steps_sampled: 252000\n",
      "    num_agent_steps_trained: 252000\n",
      "    num_steps_sampled: 252000\n",
      "    num_steps_trained: 252000\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.199999999999996\n",
      "    ram_util_percent: 66.45\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07226419851116896\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10357162121364873\n",
      "    mean_inference_ms: 0.5040461058226015\n",
      "    mean_raw_obs_processing_ms: 0.04837140009202111\n",
      "  time_since_restore: 221.48597860336304\n",
      "  time_this_iter_s: 3.188655138015747\n",
      "  time_total_s: 221.48597860336304\n",
      "  timers:\n",
      "    learn_throughput: 1918.906\n",
      "    learn_time_ms: 2084.521\n",
      "    load_throughput: 4242348.598\n",
      "    load_time_ms: 0.943\n",
      "    sample_throughput: 2488.997\n",
      "    sample_time_ms: 1607.073\n",
      "    update_time_ms: 1.462\n",
      "  timestamp: 1629485277\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 252000\n",
      "  training_iteration: 63\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         221.486</td><td style=\"text-align: right;\">252000</td><td style=\"text-align: right;\">-990.167</td><td style=\"text-align: right;\">              -644.1</td><td style=\"text-align: right;\">            -1815.29</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 260000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-03\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -644.1001234234999\n",
      "  episode_reward_mean: -973.8727877567844\n",
      "  episode_reward_min: -1815.2885135142992\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1300\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.197723150253296\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009940294548869133\n",
      "          model: {}\n",
      "          policy_loss: -0.008407527580857277\n",
      "          total_loss: 9240.6494140625\n",
      "          vf_explained_var: 0.44488388299942017\n",
      "          vf_loss: 9240.6484375\n",
      "    num_agent_steps_sampled: 260000\n",
      "    num_agent_steps_trained: 260000\n",
      "    num_steps_sampled: 260000\n",
      "    num_steps_trained: 260000\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.82\n",
      "    ram_util_percent: 66.23999999999998\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0721766507915604\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10347095862302087\n",
      "    mean_inference_ms: 0.5035057579202338\n",
      "    mean_raw_obs_processing_ms: 0.048310544718018225\n",
      "  time_since_restore: 227.92214226722717\n",
      "  time_this_iter_s: 3.258575677871704\n",
      "  time_total_s: 227.92214226722717\n",
      "  timers:\n",
      "    learn_throughput: 1966.606\n",
      "    learn_time_ms: 2033.961\n",
      "    load_throughput: 4415173.031\n",
      "    load_time_ms: 0.906\n",
      "    sample_throughput: 2674.738\n",
      "    sample_time_ms: 1495.474\n",
      "    update_time_ms: 1.467\n",
      "  timestamp: 1629485283\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 260000\n",
      "  training_iteration: 65\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         227.922</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\">-973.873</td><td style=\"text-align: right;\">              -644.1</td><td style=\"text-align: right;\">            -1815.29</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 268000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-10\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -500.3891987307547\n",
      "  episode_reward_mean: -919.4078348580683\n",
      "  episode_reward_min: -1804.578475378275\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1340\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.877570629119873\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01697554998099804\n",
      "          model: {}\n",
      "          policy_loss: -0.007996234111487865\n",
      "          total_loss: 8950.8564453125\n",
      "          vf_explained_var: 0.31427842378616333\n",
      "          vf_loss: 8950.8466796875\n",
      "    num_agent_steps_sampled: 268000\n",
      "    num_agent_steps_trained: 268000\n",
      "    num_steps_sampled: 268000\n",
      "    num_steps_trained: 268000\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.659999999999997\n",
      "    ram_util_percent: 65.86\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07202082686264268\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1032828893052961\n",
      "    mean_inference_ms: 0.5025291956996009\n",
      "    mean_raw_obs_processing_ms: 0.04820132326426412\n",
      "  time_since_restore: 234.37717509269714\n",
      "  time_this_iter_s: 3.212095022201538\n",
      "  time_total_s: 234.37717509269714\n",
      "  timers:\n",
      "    learn_throughput: 1969.709\n",
      "    learn_time_ms: 2030.757\n",
      "    load_throughput: 4324247.642\n",
      "    load_time_ms: 0.925\n",
      "    sample_throughput: 2674.651\n",
      "    sample_time_ms: 1495.522\n",
      "    update_time_ms: 1.475\n",
      "  timestamp: 1629485290\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 268000\n",
      "  training_iteration: 67\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         234.377</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\">-919.408</td><td style=\"text-align: right;\">            -500.389</td><td style=\"text-align: right;\">            -1804.58</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 276000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-16\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -375.240588422337\n",
      "  episode_reward_mean: -859.6136573132488\n",
      "  episode_reward_min: -1787.4435496163799\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1380\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.0888336896896362\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014043658971786499\n",
      "          model: {}\n",
      "          policy_loss: -0.01441219076514244\n",
      "          total_loss: 8052.61083984375\n",
      "          vf_explained_var: 0.4832903742790222\n",
      "          vf_loss: 8052.611328125\n",
      "    num_agent_steps_sampled: 276000\n",
      "    num_agent_steps_trained: 276000\n",
      "    num_steps_sampled: 276000\n",
      "    num_steps_trained: 276000\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.880000000000003\n",
      "    ram_util_percent: 65.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07185988501579528\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10308743250921891\n",
      "    mean_inference_ms: 0.5015173290981678\n",
      "    mean_raw_obs_processing_ms: 0.048082198881463964\n",
      "  time_since_restore: 240.84571886062622\n",
      "  time_this_iter_s: 3.2382888793945312\n",
      "  time_total_s: 240.84571886062622\n",
      "  timers:\n",
      "    learn_throughput: 2135.888\n",
      "    learn_time_ms: 1872.757\n",
      "    load_throughput: 4919139.154\n",
      "    load_time_ms: 0.813\n",
      "    sample_throughput: 2815.648\n",
      "    sample_time_ms: 1420.632\n",
      "    update_time_ms: 1.345\n",
      "  timestamp: 1629485296\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 276000\n",
      "  training_iteration: 69\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         240.846</td><td style=\"text-align: right;\">276000</td><td style=\"text-align: right;\">-859.614</td><td style=\"text-align: right;\">            -375.241</td><td style=\"text-align: right;\">            -1787.44</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 284000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-23\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -375.240588422337\n",
      "  episode_reward_mean: -883.0650201359236\n",
      "  episode_reward_min: -1570.1519081428155\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1420\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1058136224746704\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01135489996522665\n",
      "          model: {}\n",
      "          policy_loss: -0.02085150219500065\n",
      "          total_loss: 8800.94921875\n",
      "          vf_explained_var: 0.4533478617668152\n",
      "          vf_loss: 8800.9599609375\n",
      "    num_agent_steps_sampled: 284000\n",
      "    num_agent_steps_trained: 284000\n",
      "    num_steps_sampled: 284000\n",
      "    num_steps_trained: 284000\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.775\n",
      "    ram_util_percent: 65.80000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07171372425279346\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10290519736995403\n",
      "    mean_inference_ms: 0.5005962534093122\n",
      "    mean_raw_obs_processing_ms: 0.04797227470999254\n",
      "  time_since_restore: 247.3451406955719\n",
      "  time_this_iter_s: 3.2295868396759033\n",
      "  time_total_s: 247.3451406955719\n",
      "  timers:\n",
      "    learn_throughput: 2135.609\n",
      "    learn_time_ms: 1873.002\n",
      "    load_throughput: 4797876.916\n",
      "    load_time_ms: 0.834\n",
      "    sample_throughput: 2865.72\n",
      "    sample_time_ms: 1395.81\n",
      "    update_time_ms: 1.346\n",
      "  timestamp: 1629485303\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 284000\n",
      "  training_iteration: 71\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         247.345</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\">-883.065</td><td style=\"text-align: right;\">            -375.241</td><td style=\"text-align: right;\">            -1570.15</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 292000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-30\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -489.833076166596\n",
      "  episode_reward_mean: -903.2199600083534\n",
      "  episode_reward_min: -1655.732895147801\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1460\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.6261107921600342\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010865563526749611\n",
      "          model: {}\n",
      "          policy_loss: -0.021891038864850998\n",
      "          total_loss: 8553.205078125\n",
      "          vf_explained_var: 0.6509803533554077\n",
      "          vf_loss: 8553.21484375\n",
      "    num_agent_steps_sampled: 292000\n",
      "    num_agent_steps_trained: 292000\n",
      "    num_steps_sampled: 292000\n",
      "    num_steps_trained: 292000\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.52\n",
      "    ram_util_percent: 65.75999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07157436611146525\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10273516656981638\n",
      "    mean_inference_ms: 0.49974343399074683\n",
      "    mean_raw_obs_processing_ms: 0.04786883389762122\n",
      "  time_since_restore: 253.85786700248718\n",
      "  time_this_iter_s: 3.221330165863037\n",
      "  time_total_s: 253.85786700248718\n",
      "  timers:\n",
      "    learn_throughput: 2156.745\n",
      "    learn_time_ms: 1854.647\n",
      "    load_throughput: 4798563.052\n",
      "    load_time_ms: 0.834\n",
      "    sample_throughput: 2905.41\n",
      "    sample_time_ms: 1376.742\n",
      "    update_time_ms: 1.346\n",
      "  timestamp: 1629485310\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 292000\n",
      "  training_iteration: 73\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         253.858</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\"> -903.22</td><td style=\"text-align: right;\">            -489.833</td><td style=\"text-align: right;\">            -1655.73</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 300000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-36\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -492.6382714003566\n",
      "  episode_reward_mean: -884.8873054150646\n",
      "  episode_reward_min: -1655.732895147801\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1500\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3087481260299683\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012823345139622688\n",
      "          model: {}\n",
      "          policy_loss: -0.0180087611079216\n",
      "          total_loss: 8927.509765625\n",
      "          vf_explained_var: 0.4935537278652191\n",
      "          vf_loss: 8927.5146484375\n",
      "    num_agent_steps_sampled: 300000\n",
      "    num_agent_steps_trained: 300000\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.48\n",
      "    ram_util_percent: 65.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0714458502147049\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1025766704039696\n",
      "    mean_inference_ms: 0.49896513927600067\n",
      "    mean_raw_obs_processing_ms: 0.047770738223852326\n",
      "  time_since_restore: 260.3394031524658\n",
      "  time_this_iter_s: 3.2420310974121094\n",
      "  time_total_s: 260.3394031524658\n",
      "  timers:\n",
      "    learn_throughput: 2157.662\n",
      "    learn_time_ms: 1853.858\n",
      "    load_throughput: 4779288.97\n",
      "    load_time_ms: 0.837\n",
      "    sample_throughput: 2894.876\n",
      "    sample_time_ms: 1381.752\n",
      "    update_time_ms: 1.431\n",
      "  timestamp: 1629485316\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 75\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         260.339</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">-884.887</td><td style=\"text-align: right;\">            -492.638</td><td style=\"text-align: right;\">            -1655.73</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 308000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-43\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -500.2011254067121\n",
      "  episode_reward_mean: -884.805798401424\n",
      "  episode_reward_min: -1703.524210961871\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1540\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.107470154762268\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012602739967405796\n",
      "          model: {}\n",
      "          policy_loss: -0.016861626878380775\n",
      "          total_loss: 9049.8876953125\n",
      "          vf_explained_var: 0.4470648169517517\n",
      "          vf_loss: 9049.8935546875\n",
      "    num_agent_steps_sampled: 308000\n",
      "    num_agent_steps_trained: 308000\n",
      "    num_steps_sampled: 308000\n",
      "    num_steps_trained: 308000\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.925000000000004\n",
      "    ram_util_percent: 65.55\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07132285897396151\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10242644914354358\n",
      "    mean_inference_ms: 0.4981971070040043\n",
      "    mean_raw_obs_processing_ms: 0.047674162899101855\n",
      "  time_since_restore: 266.8091173171997\n",
      "  time_this_iter_s: 3.2402291297912598\n",
      "  time_total_s: 266.8091173171997\n",
      "  timers:\n",
      "    learn_throughput: 2157.831\n",
      "    learn_time_ms: 1853.713\n",
      "    load_throughput: 4713760.396\n",
      "    load_time_ms: 0.849\n",
      "    sample_throughput: 2891.293\n",
      "    sample_time_ms: 1383.464\n",
      "    update_time_ms: 1.425\n",
      "  timestamp: 1629485323\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 308000\n",
      "  training_iteration: 77\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         266.809</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">-884.806</td><td style=\"text-align: right;\">            -500.201</td><td style=\"text-align: right;\">            -1703.52</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 316000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-49\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -500.5530806236494\n",
      "  episode_reward_mean: -845.3488103274074\n",
      "  episode_reward_min: -1787.8314336222272\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1580\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3047748804092407\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012788317166268826\n",
      "          model: {}\n",
      "          policy_loss: -0.021438302472233772\n",
      "          total_loss: 7424.08251953125\n",
      "          vf_explained_var: 0.5574263334274292\n",
      "          vf_loss: 7424.0908203125\n",
      "    num_agent_steps_sampled: 316000\n",
      "    num_agent_steps_trained: 316000\n",
      "    num_steps_sampled: 316000\n",
      "    num_steps_trained: 316000\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.175\n",
      "    ram_util_percent: 65.5\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07121494026963095\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10229074692884961\n",
      "    mean_inference_ms: 0.4975350050618481\n",
      "    mean_raw_obs_processing_ms: 0.04758711825493961\n",
      "  time_since_restore: 273.29408740997314\n",
      "  time_this_iter_s: 3.2561700344085693\n",
      "  time_total_s: 273.29408740997314\n",
      "  timers:\n",
      "    learn_throughput: 2158.52\n",
      "    learn_time_ms: 1853.121\n",
      "    load_throughput: 4704112.155\n",
      "    load_time_ms: 0.85\n",
      "    sample_throughput: 2886.144\n",
      "    sample_time_ms: 1385.932\n",
      "    update_time_ms: 1.326\n",
      "  timestamp: 1629485329\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 316000\n",
      "  training_iteration: 79\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         273.294</td><td style=\"text-align: right;\">316000</td><td style=\"text-align: right;\">-845.349</td><td style=\"text-align: right;\">            -500.553</td><td style=\"text-align: right;\">            -1787.83</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 324000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-56\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -494.20018185794504\n",
      "  episode_reward_mean: -808.263663329181\n",
      "  episode_reward_min: -1787.8314336222272\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1620\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1429001092910767\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013791458681225777\n",
      "          model: {}\n",
      "          policy_loss: -0.0159845482558012\n",
      "          total_loss: 7514.08984375\n",
      "          vf_explained_var: 0.5541303157806396\n",
      "          vf_loss: 7514.0908203125\n",
      "    num_agent_steps_sampled: 324000\n",
      "    num_agent_steps_trained: 324000\n",
      "    num_steps_sampled: 324000\n",
      "    num_steps_trained: 324000\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.839999999999996\n",
      "    ram_util_percent: 65.6\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07111037744927293\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10216389128855025\n",
      "    mean_inference_ms: 0.4969166362427934\n",
      "    mean_raw_obs_processing_ms: 0.04750806594925312\n",
      "  time_since_restore: 279.86789202690125\n",
      "  time_this_iter_s: 3.3440709114074707\n",
      "  time_total_s: 279.86789202690125\n",
      "  timers:\n",
      "    learn_throughput: 2148.856\n",
      "    learn_time_ms: 1861.456\n",
      "    load_throughput: 4702925.38\n",
      "    load_time_ms: 0.851\n",
      "    sample_throughput: 2887.956\n",
      "    sample_time_ms: 1385.063\n",
      "    update_time_ms: 1.308\n",
      "  timestamp: 1629485336\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 324000\n",
      "  training_iteration: 81\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         279.868</td><td style=\"text-align: right;\">324000</td><td style=\"text-align: right;\">-808.264</td><td style=\"text-align: right;\">              -494.2</td><td style=\"text-align: right;\">            -1787.83</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 332000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-02\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -494.20018185794504\n",
      "  episode_reward_mean: -775.3160524743602\n",
      "  episode_reward_min: -1772.5397490771331\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1660\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2818514108657837\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010063674300909042\n",
      "          model: {}\n",
      "          policy_loss: -0.015131683088839054\n",
      "          total_loss: 7614.55859375\n",
      "          vf_explained_var: 0.5766569375991821\n",
      "          vf_loss: 7614.56298828125\n",
      "    num_agent_steps_sampled: 332000\n",
      "    num_agent_steps_trained: 332000\n",
      "    num_steps_sampled: 332000\n",
      "    num_steps_trained: 332000\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.900000000000002\n",
      "    ram_util_percent: 66.125\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07102026323059256\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10206055054537871\n",
      "    mean_inference_ms: 0.49638265304655604\n",
      "    mean_raw_obs_processing_ms: 0.04744298520001368\n",
      "  time_since_restore: 286.479868888855\n",
      "  time_this_iter_s: 3.2146849632263184\n",
      "  time_total_s: 286.479868888855\n",
      "  timers:\n",
      "    learn_throughput: 2145.103\n",
      "    learn_time_ms: 1864.713\n",
      "    load_throughput: 4673839.982\n",
      "    load_time_ms: 0.856\n",
      "    sample_throughput: 2874.433\n",
      "    sample_time_ms: 1391.579\n",
      "    update_time_ms: 1.34\n",
      "  timestamp: 1629485342\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 332000\n",
      "  training_iteration: 83\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">          286.48</td><td style=\"text-align: right;\">332000</td><td style=\"text-align: right;\">-775.316</td><td style=\"text-align: right;\">              -494.2</td><td style=\"text-align: right;\">            -1772.54</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 340000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-11\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -496.28796498523644\n",
      "  episode_reward_mean: -744.5336173739156\n",
      "  episode_reward_min: -1772.5397490771331\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1700\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2769513130187988\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011985479854047298\n",
      "          model: {}\n",
      "          policy_loss: -0.01813066378235817\n",
      "          total_loss: 6506.54443359375\n",
      "          vf_explained_var: 0.6198861002922058\n",
      "          vf_loss: 6506.54931640625\n",
      "    num_agent_steps_sampled: 340000\n",
      "    num_agent_steps_trained: 340000\n",
      "    num_steps_sampled: 340000\n",
      "    num_steps_trained: 340000\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.34\n",
      "    ram_util_percent: 66.66\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07107693402743594\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10213469367565997\n",
      "    mean_inference_ms: 0.4967895383578538\n",
      "    mean_raw_obs_processing_ms: 0.047491092866331436\n",
      "  time_since_restore: 294.66577887535095\n",
      "  time_this_iter_s: 3.527911901473999\n",
      "  time_total_s: 294.66577887535095\n",
      "  timers:\n",
      "    learn_throughput: 2027.806\n",
      "    learn_time_ms: 1972.576\n",
      "    load_throughput: 4228448.723\n",
      "    load_time_ms: 0.946\n",
      "    sample_throughput: 2750.886\n",
      "    sample_time_ms: 1454.077\n",
      "    update_time_ms: 1.329\n",
      "  timestamp: 1629485351\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 340000\n",
      "  training_iteration: 85\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         294.666</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\">-744.534</td><td style=\"text-align: right;\">            -496.288</td><td style=\"text-align: right;\">            -1772.54</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 348000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-17\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -366.6225700801443\n",
      "  episode_reward_mean: -702.2920121904233\n",
      "  episode_reward_min: -1772.5397490771331\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1740\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.894886314868927\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013597758486866951\n",
      "          model: {}\n",
      "          policy_loss: -0.015195478685200214\n",
      "          total_loss: 6608.53759765625\n",
      "          vf_explained_var: 0.40700361132621765\n",
      "          vf_loss: 6608.5380859375\n",
      "    num_agent_steps_sampled: 348000\n",
      "    num_agent_steps_trained: 348000\n",
      "    num_steps_sampled: 348000\n",
      "    num_steps_trained: 348000\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.6\n",
      "    ram_util_percent: 66.76000000000002\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07113086827987597\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10220784952155208\n",
      "    mean_inference_ms: 0.4971753666050644\n",
      "    mean_raw_obs_processing_ms: 0.047539097789175866\n",
      "  time_since_restore: 301.3475377559662\n",
      "  time_this_iter_s: 3.363055944442749\n",
      "  time_total_s: 301.3475377559662\n",
      "  timers:\n",
      "    learn_throughput: 2004.126\n",
      "    learn_time_ms: 1995.882\n",
      "    load_throughput: 4348231.391\n",
      "    load_time_ms: 0.92\n",
      "    sample_throughput: 2755.34\n",
      "    sample_time_ms: 1451.726\n",
      "    update_time_ms: 1.381\n",
      "  timestamp: 1629485357\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 348000\n",
      "  training_iteration: 87\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         301.348</td><td style=\"text-align: right;\">348000</td><td style=\"text-align: right;\">-702.292</td><td style=\"text-align: right;\">            -366.623</td><td style=\"text-align: right;\">            -1772.54</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 356000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-24\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -366.6225700801443\n",
      "  episode_reward_mean: -698.5064725357158\n",
      "  episode_reward_min: -1804.07088610893\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1780\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1532264947891235\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011898976750671864\n",
      "          model: {}\n",
      "          policy_loss: -0.02045481838285923\n",
      "          total_loss: 8572.810546875\n",
      "          vf_explained_var: 0.6153269410133362\n",
      "          vf_loss: 8572.818359375\n",
      "    num_agent_steps_sampled: 356000\n",
      "    num_agent_steps_trained: 356000\n",
      "    num_steps_sampled: 356000\n",
      "    num_steps_trained: 356000\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.7\n",
      "    ram_util_percent: 66.36\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07114389955694676\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10223559482875047\n",
      "    mean_inference_ms: 0.4972642109839326\n",
      "    mean_raw_obs_processing_ms: 0.04755801658577164\n",
      "  time_since_restore: 308.2827994823456\n",
      "  time_this_iter_s: 3.588160991668701\n",
      "  time_total_s: 308.2827994823456\n",
      "  timers:\n",
      "    learn_throughput: 1976.964\n",
      "    learn_time_ms: 2023.304\n",
      "    load_throughput: 4213157.882\n",
      "    load_time_ms: 0.949\n",
      "    sample_throughput: 2723.063\n",
      "    sample_time_ms: 1468.934\n",
      "    update_time_ms: 1.457\n",
      "  timestamp: 1629485364\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 356000\n",
      "  training_iteration: 89\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         308.283</td><td style=\"text-align: right;\">356000</td><td style=\"text-align: right;\">-698.506</td><td style=\"text-align: right;\">            -366.623</td><td style=\"text-align: right;\">            -1804.07</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 364000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-31\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -251.45630504880916\n",
      "  episode_reward_mean: -663.4683699076355\n",
      "  episode_reward_min: -1804.07088610893\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1820\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.9531769156455994\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017534207552671432\n",
      "          model: {}\n",
      "          policy_loss: -0.021498924121260643\n",
      "          total_loss: 4533.3076171875\n",
      "          vf_explained_var: 0.7286509275436401\n",
      "          vf_loss: 4533.31103515625\n",
      "    num_agent_steps_sampled: 364000\n",
      "    num_agent_steps_trained: 364000\n",
      "    num_steps_sampled: 364000\n",
      "    num_steps_trained: 364000\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.660000000000004\n",
      "    ram_util_percent: 68.46000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0711659853679825\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10227415291792653\n",
      "    mean_inference_ms: 0.4973905519966965\n",
      "    mean_raw_obs_processing_ms: 0.04757872478588376\n",
      "  time_since_restore: 315.3147404193878\n",
      "  time_this_iter_s: 3.4044840335845947\n",
      "  time_total_s: 315.3147404193878\n",
      "  timers:\n",
      "    learn_throughput: 1971.012\n",
      "    learn_time_ms: 2029.414\n",
      "    load_throughput: 4088314.448\n",
      "    load_time_ms: 0.978\n",
      "    sample_throughput: 2651.807\n",
      "    sample_time_ms: 1508.405\n",
      "    update_time_ms: 1.516\n",
      "  timestamp: 1629485371\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 364000\n",
      "  training_iteration: 91\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         315.315</td><td style=\"text-align: right;\">364000</td><td style=\"text-align: right;\">-663.468</td><td style=\"text-align: right;\">            -251.456</td><td style=\"text-align: right;\">            -1804.07</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 372000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-38\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -251.45630504880916\n",
      "  episode_reward_mean: -645.9403975517781\n",
      "  episode_reward_min: -1728.8776258204562\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1860\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.8381274342536926\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013584040105342865\n",
      "          model: {}\n",
      "          policy_loss: -0.016646770760416985\n",
      "          total_loss: 2890.692138671875\n",
      "          vf_explained_var: 0.768486738204956\n",
      "          vf_loss: 2890.695068359375\n",
      "    num_agent_steps_sampled: 372000\n",
      "    num_agent_steps_trained: 372000\n",
      "    num_steps_sampled: 372000\n",
      "    num_steps_trained: 372000\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.160000000000004\n",
      "    ram_util_percent: 67.46000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07123988526361312\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10237865058823419\n",
      "    mean_inference_ms: 0.49786936735401527\n",
      "    mean_raw_obs_processing_ms: 0.04764452451010939\n",
      "  time_since_restore: 322.02294063568115\n",
      "  time_this_iter_s: 3.2619330883026123\n",
      "  time_total_s: 322.02294063568115\n",
      "  timers:\n",
      "    learn_throughput: 1974.427\n",
      "    learn_time_ms: 2025.904\n",
      "    load_throughput: 4154215.817\n",
      "    load_time_ms: 0.963\n",
      "    sample_throughput: 2628.883\n",
      "    sample_time_ms: 1521.559\n",
      "    update_time_ms: 1.52\n",
      "  timestamp: 1629485378\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 372000\n",
      "  training_iteration: 93\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         322.023</td><td style=\"text-align: right;\">372000</td><td style=\"text-align: right;\"> -645.94</td><td style=\"text-align: right;\">            -251.456</td><td style=\"text-align: right;\">            -1728.88</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 380000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-45\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -128.49092281635353\n",
      "  episode_reward_mean: -601.8772232079974\n",
      "  episode_reward_min: -1769.3963747194175\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1900\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1069345474243164\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009890632703900337\n",
      "          model: {}\n",
      "          policy_loss: -0.015983613207936287\n",
      "          total_loss: 5715.34716796875\n",
      "          vf_explained_var: 0.7970908880233765\n",
      "          vf_loss: 5715.353515625\n",
      "    num_agent_steps_sampled: 380000\n",
      "    num_agent_steps_trained: 380000\n",
      "    num_steps_sampled: 380000\n",
      "    num_steps_trained: 380000\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.24\n",
      "    ram_util_percent: 66.38\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07129270349677118\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10245220457196456\n",
      "    mean_inference_ms: 0.498219186700686\n",
      "    mean_raw_obs_processing_ms: 0.04769194037377519\n",
      "  time_since_restore: 328.98945689201355\n",
      "  time_this_iter_s: 3.2396399974823\n",
      "  time_total_s: 328.98945689201355\n",
      "  timers:\n",
      "    learn_throughput: 2051.549\n",
      "    learn_time_ms: 1949.746\n",
      "    load_throughput: 4461550.899\n",
      "    load_time_ms: 0.897\n",
      "    sample_throughput: 2709.885\n",
      "    sample_time_ms: 1476.077\n",
      "    update_time_ms: 1.45\n",
      "  timestamp: 1629485385\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 380000\n",
      "  training_iteration: 95\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         328.989</td><td style=\"text-align: right;\">380000</td><td style=\"text-align: right;\">-601.877</td><td style=\"text-align: right;\">            -128.491</td><td style=\"text-align: right;\">             -1769.4</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 388000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-53\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -122.16343090166565\n",
      "  episode_reward_mean: -523.9962195018411\n",
      "  episode_reward_min: -1769.3963747194175\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1940\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.625196635723114\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0127638578414917\n",
      "          model: {}\n",
      "          policy_loss: -0.018134335055947304\n",
      "          total_loss: 1832.400146484375\n",
      "          vf_explained_var: 0.8256890177726746\n",
      "          vf_loss: 1832.4053955078125\n",
      "    num_agent_steps_sampled: 388000\n",
      "    num_agent_steps_trained: 388000\n",
      "    num_steps_sampled: 388000\n",
      "    num_steps_trained: 388000\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 36.38333333333333\n",
      "    ram_util_percent: 67.23333333333333\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07133576160599375\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10250606085501084\n",
      "    mean_inference_ms: 0.498530637139076\n",
      "    mean_raw_obs_processing_ms: 0.04772011311049724\n",
      "  time_since_restore: 336.38775515556335\n",
      "  time_this_iter_s: 4.117885112762451\n",
      "  time_total_s: 336.38775515556335\n",
      "  timers:\n",
      "    learn_throughput: 2049.895\n",
      "    learn_time_ms: 1951.32\n",
      "    load_throughput: 4394011.838\n",
      "    load_time_ms: 0.91\n",
      "    sample_throughput: 2586.731\n",
      "    sample_time_ms: 1546.353\n",
      "    update_time_ms: 1.424\n",
      "  timestamp: 1629485393\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 388000\n",
      "  training_iteration: 97\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         336.388</td><td style=\"text-align: right;\">388000</td><td style=\"text-align: right;\">-523.996</td><td style=\"text-align: right;\">            -122.163</td><td style=\"text-align: right;\">             -1769.4</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 396000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-59\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2.52912217531191\n",
      "  episode_reward_mean: -548.826271675337\n",
      "  episode_reward_min: -1769.3963747194175\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1980\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1419079303741455\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0139545239508152\n",
      "          model: {}\n",
      "          policy_loss: -0.022646300494670868\n",
      "          total_loss: 3520.194091796875\n",
      "          vf_explained_var: 0.852955162525177\n",
      "          vf_loss: 3520.202392578125\n",
      "    num_agent_steps_sampled: 396000\n",
      "    num_agent_steps_trained: 396000\n",
      "    num_steps_sampled: 396000\n",
      "    num_steps_trained: 396000\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.18\n",
      "    ram_util_percent: 67.66\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07141419623342332\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10260007973192513\n",
      "    mean_inference_ms: 0.4991049651972073\n",
      "    mean_raw_obs_processing_ms: 0.047767174253463454\n",
      "  time_since_restore: 342.8990173339844\n",
      "  time_this_iter_s: 3.1951842308044434\n",
      "  time_total_s: 342.8990173339844\n",
      "  timers:\n",
      "    learn_throughput: 2077.828\n",
      "    learn_time_ms: 1925.087\n",
      "    load_throughput: 4516439.013\n",
      "    load_time_ms: 0.886\n",
      "    sample_throughput: 2613.36\n",
      "    sample_time_ms: 1530.596\n",
      "    update_time_ms: 1.356\n",
      "  timestamp: 1629485399\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 396000\n",
      "  training_iteration: 99\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         342.899</td><td style=\"text-align: right;\">396000</td><td style=\"text-align: right;\">-548.826</td><td style=\"text-align: right;\">            -2.52912</td><td style=\"text-align: right;\">             -1769.4</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 404000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-50-07\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2.52912217531191\n",
      "  episode_reward_mean: -500.4693218801559\n",
      "  episode_reward_min: -1749.7129137520612\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2020\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5574398040771484\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01063667144626379\n",
      "          model: {}\n",
      "          policy_loss: -0.01845693774521351\n",
      "          total_loss: 1235.53076171875\n",
      "          vf_explained_var: 0.9049233198165894\n",
      "          vf_loss: 1235.53857421875\n",
      "    num_agent_steps_sampled: 404000\n",
      "    num_agent_steps_trained: 404000\n",
      "    num_steps_sampled: 404000\n",
      "    num_steps_trained: 404000\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.050000000000004\n",
      "    ram_util_percent: 67.3\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07150256651353731\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10270838415636707\n",
      "    mean_inference_ms: 0.4997482598134415\n",
      "    mean_raw_obs_processing_ms: 0.047823995791188685\n",
      "  time_since_restore: 350.6344995498657\n",
      "  time_this_iter_s: 4.221503019332886\n",
      "  time_total_s: 350.6344995498657\n",
      "  timers:\n",
      "    learn_throughput: 1996.55\n",
      "    learn_time_ms: 2003.456\n",
      "    load_throughput: 4493094.804\n",
      "    load_time_ms: 0.89\n",
      "    sample_throughput: 2626.937\n",
      "    sample_time_ms: 1522.686\n",
      "    update_time_ms: 1.328\n",
      "  timestamp: 1629485407\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 404000\n",
      "  training_iteration: 101\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         350.634</td><td style=\"text-align: right;\">404000</td><td style=\"text-align: right;\">-500.469</td><td style=\"text-align: right;\">            -2.52912</td><td style=\"text-align: right;\">            -1749.71</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 412000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-50-14\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2.52912217531191\n",
      "  episode_reward_mean: -498.5790289645226\n",
      "  episode_reward_min: -1723.2982295313748\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2060\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1897404193878174\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011463725008070469\n",
      "          model: {}\n",
      "          policy_loss: -0.02069832570850849\n",
      "          total_loss: 4132.2431640625\n",
      "          vf_explained_var: 0.8964266777038574\n",
      "          vf_loss: 4132.251953125\n",
      "    num_agent_steps_sampled: 412000\n",
      "    num_agent_steps_trained: 412000\n",
      "    num_steps_sampled: 412000\n",
      "    num_steps_trained: 412000\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.78\n",
      "    ram_util_percent: 67.92\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07150915014736205\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10272277597198491\n",
      "    mean_inference_ms: 0.4998119716017322\n",
      "    mean_raw_obs_processing_ms: 0.04783184786129704\n",
      "  time_since_restore: 357.66578435897827\n",
      "  time_this_iter_s: 3.2793262004852295\n",
      "  time_total_s: 357.66578435897827\n",
      "  timers:\n",
      "    learn_throughput: 1961.163\n",
      "    learn_time_ms: 2039.606\n",
      "    load_throughput: 4278592.268\n",
      "    load_time_ms: 0.935\n",
      "    sample_throughput: 2633.64\n",
      "    sample_time_ms: 1518.811\n",
      "    update_time_ms: 1.321\n",
      "  timestamp: 1629485414\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 412000\n",
      "  training_iteration: 103\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         357.666</td><td style=\"text-align: right;\">412000</td><td style=\"text-align: right;\">-498.579</td><td style=\"text-align: right;\">            -2.52912</td><td style=\"text-align: right;\">             -1723.3</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 420000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-50-21\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -57.19103100704712\n",
      "  episode_reward_mean: -452.34100220458976\n",
      "  episode_reward_min: -1812.9580340260018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2100\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5983957648277283\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0060006300918757915\n",
      "          model: {}\n",
      "          policy_loss: -0.015968676656484604\n",
      "          total_loss: 2936.256591796875\n",
      "          vf_explained_var: 0.8553943037986755\n",
      "          vf_loss: 2936.26611328125\n",
      "    num_agent_steps_sampled: 420000\n",
      "    num_agent_steps_trained: 420000\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.060000000000002\n",
      "    ram_util_percent: 67.86\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07150506111925554\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10272457320504731\n",
      "    mean_inference_ms: 0.49978697866408694\n",
      "    mean_raw_obs_processing_ms: 0.04783251797798834\n",
      "  time_since_restore: 364.7674992084503\n",
      "  time_this_iter_s: 3.3286688327789307\n",
      "  time_total_s: 364.7674992084503\n",
      "  timers:\n",
      "    learn_throughput: 1925.071\n",
      "    learn_time_ms: 2077.846\n",
      "    load_throughput: 4390332.339\n",
      "    load_time_ms: 0.911\n",
      "    sample_throughput: 2677.499\n",
      "    sample_time_ms: 1493.932\n",
      "    update_time_ms: 1.37\n",
      "  timestamp: 1629485421\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 105\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         364.767</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\">-452.341</td><td style=\"text-align: right;\">             -57.191</td><td style=\"text-align: right;\">            -1812.96</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 428000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-50-29\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.48676704192136266\n",
      "  episode_reward_mean: -401.76998478100387\n",
      "  episode_reward_min: -1812.9580340260018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2140\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.2205180823802948\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014357643201947212\n",
      "          model: {}\n",
      "          policy_loss: -0.023579377681016922\n",
      "          total_loss: 412.3289489746094\n",
      "          vf_explained_var: 0.9397326111793518\n",
      "          vf_loss: 412.3380126953125\n",
      "    num_agent_steps_sampled: 428000\n",
      "    num_agent_steps_trained: 428000\n",
      "    num_steps_sampled: 428000\n",
      "    num_steps_trained: 428000\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.5\n",
      "    ram_util_percent: 67.55999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07147920891603145\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10270619878059038\n",
      "    mean_inference_ms: 0.4995969257245962\n",
      "    mean_raw_obs_processing_ms: 0.04782276369776338\n",
      "  time_since_restore: 372.3628628253937\n",
      "  time_this_iter_s: 3.810384750366211\n",
      "  time_total_s: 372.3628628253937\n",
      "  timers:\n",
      "    learn_throughput: 1880.42\n",
      "    learn_time_ms: 2127.184\n",
      "    load_throughput: 4324359.1\n",
      "    load_time_ms: 0.925\n",
      "    sample_throughput: 2731.951\n",
      "    sample_time_ms: 1464.155\n",
      "    update_time_ms: 1.382\n",
      "  timestamp: 1629485429\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 428000\n",
      "  training_iteration: 107\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         372.363</td><td style=\"text-align: right;\">428000</td><td style=\"text-align: right;\"> -401.77</td><td style=\"text-align: right;\">           -0.486767</td><td style=\"text-align: right;\">            -1812.96</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 436000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-50-37\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.48676704192136266\n",
      "  episode_reward_mean: -337.1318420514648\n",
      "  episode_reward_min: -1812.9580340260018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2180\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.48317816853523254\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006145931314677\n",
      "          model: {}\n",
      "          policy_loss: -0.018793759867548943\n",
      "          total_loss: 799.5115356445312\n",
      "          vf_explained_var: 0.958051860332489\n",
      "          vf_loss: 799.5240478515625\n",
      "    num_agent_steps_sampled: 436000\n",
      "    num_agent_steps_trained: 436000\n",
      "    num_steps_sampled: 436000\n",
      "    num_steps_trained: 436000\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.55\n",
      "    ram_util_percent: 66.83333333333333\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07154089561664662\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10280385453038918\n",
      "    mean_inference_ms: 0.4999949833867061\n",
      "    mean_raw_obs_processing_ms: 0.04788822587355227\n",
      "  time_since_restore: 380.3910298347473\n",
      "  time_this_iter_s: 4.112171173095703\n",
      "  time_total_s: 380.3910298347473\n",
      "  timers:\n",
      "    learn_throughput: 1804.459\n",
      "    learn_time_ms: 2216.731\n",
      "    load_throughput: 3901405.948\n",
      "    load_time_ms: 1.025\n",
      "    sample_throughput: 2622.421\n",
      "    sample_time_ms: 1525.308\n",
      "    update_time_ms: 1.678\n",
      "  timestamp: 1629485437\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 436000\n",
      "  training_iteration: 109\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         380.391</td><td style=\"text-align: right;\">436000</td><td style=\"text-align: right;\">-337.132</td><td style=\"text-align: right;\">           -0.486767</td><td style=\"text-align: right;\">            -1812.96</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 444000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-50-45\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -117.53094002136906\n",
      "  episode_reward_mean: -336.4494431396527\n",
      "  episode_reward_min: -1563.2426621589486\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2220\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.25610220432281494\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011380063369870186\n",
      "          model: {}\n",
      "          policy_loss: -0.02934354916214943\n",
      "          total_loss: 503.468505859375\n",
      "          vf_explained_var: 0.93242347240448\n",
      "          vf_loss: 503.486328125\n",
      "    num_agent_steps_sampled: 444000\n",
      "    num_agent_steps_trained: 444000\n",
      "    num_steps_sampled: 444000\n",
      "    num_steps_trained: 444000\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.516666666666666\n",
      "    ram_util_percent: 66.71666666666665\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07169788738723208\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10302191928598325\n",
      "    mean_inference_ms: 0.5010213370709548\n",
      "    mean_raw_obs_processing_ms: 0.04803363301760986\n",
      "  time_since_restore: 388.1591069698334\n",
      "  time_this_iter_s: 3.6948800086975098\n",
      "  time_total_s: 388.1591069698334\n",
      "  timers:\n",
      "    learn_throughput: 1814.176\n",
      "    learn_time_ms: 2204.857\n",
      "    load_throughput: 3908131.1\n",
      "    load_time_ms: 1.024\n",
      "    sample_throughput: 2596.859\n",
      "    sample_time_ms: 1540.323\n",
      "    update_time_ms: 1.716\n",
      "  timestamp: 1629485445\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 444000\n",
      "  training_iteration: 111\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         388.159</td><td style=\"text-align: right;\">444000</td><td style=\"text-align: right;\">-336.449</td><td style=\"text-align: right;\">            -117.531</td><td style=\"text-align: right;\">            -1563.24</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 452000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-50-52\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5891529305080412\n",
      "  episode_reward_mean: -342.4467095204089\n",
      "  episode_reward_min: -1563.2426621589486\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2260\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.2805686295032501\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005570209119468927\n",
      "          model: {}\n",
      "          policy_loss: -0.01515578106045723\n",
      "          total_loss: 360.9591369628906\n",
      "          vf_explained_var: 0.9663246870040894\n",
      "          vf_loss: 360.96868896484375\n",
      "    num_agent_steps_sampled: 452000\n",
      "    num_agent_steps_trained: 452000\n",
      "    num_steps_sampled: 452000\n",
      "    num_steps_trained: 452000\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.14\n",
      "    ram_util_percent: 66.64\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0718317467492672\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10321129736563811\n",
      "    mean_inference_ms: 0.5019123403898706\n",
      "    mean_raw_obs_processing_ms: 0.04815823521356673\n",
      "  time_since_restore: 395.7259588241577\n",
      "  time_this_iter_s: 3.7492380142211914\n",
      "  time_total_s: 395.7259588241577\n",
      "  timers:\n",
      "    learn_throughput: 1784.757\n",
      "    learn_time_ms: 2241.201\n",
      "    load_throughput: 4034148.312\n",
      "    load_time_ms: 0.992\n",
      "    sample_throughput: 2568.664\n",
      "    sample_time_ms: 1557.23\n",
      "    update_time_ms: 1.846\n",
      "  timestamp: 1629485452\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 452000\n",
      "  training_iteration: 113\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         395.726</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\">-342.447</td><td style=\"text-align: right;\">           -0.589153</td><td style=\"text-align: right;\">            -1563.24</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 460000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-00\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5526071383355003\n",
      "  episode_reward_mean: -305.7929809558207\n",
      "  episode_reward_min: -1781.3687062041015\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2300\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4043802320957184\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010161465033888817\n",
      "          model: {}\n",
      "          policy_loss: -0.0224758293479681\n",
      "          total_loss: 2612.506591796875\n",
      "          vf_explained_var: 0.8593878149986267\n",
      "          vf_loss: 2612.518798828125\n",
      "    num_agent_steps_sampled: 460000\n",
      "    num_agent_steps_trained: 460000\n",
      "    num_steps_sampled: 460000\n",
      "    num_steps_trained: 460000\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.45\n",
      "    ram_util_percent: 66.6\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0719134761175315\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10333990722982599\n",
      "    mean_inference_ms: 0.5024626146281533\n",
      "    mean_raw_obs_processing_ms: 0.04824178293044451\n",
      "  time_since_restore: 403.4932019710541\n",
      "  time_this_iter_s: 3.776362180709839\n",
      "  time_total_s: 403.4932019710541\n",
      "  timers:\n",
      "    learn_throughput: 1769.816\n",
      "    learn_time_ms: 2260.122\n",
      "    load_throughput: 3793776.089\n",
      "    load_time_ms: 1.054\n",
      "    sample_throughput: 2492.44\n",
      "    sample_time_ms: 1604.853\n",
      "    update_time_ms: 1.83\n",
      "  timestamp: 1629485460\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 460000\n",
      "  training_iteration: 115\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         403.493</td><td style=\"text-align: right;\">460000</td><td style=\"text-align: right;\">-305.793</td><td style=\"text-align: right;\">           -0.552607</td><td style=\"text-align: right;\">            -1781.37</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 468000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-09\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3543045935595232\n",
      "  episode_reward_mean: -316.2949826529386\n",
      "  episode_reward_min: -1781.3687062041015\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2340\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.16523562371730804\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015823109075427055\n",
      "          model: {}\n",
      "          policy_loss: -0.04339559003710747\n",
      "          total_loss: 444.0305480957031\n",
      "          vf_explained_var: 0.9395307302474976\n",
      "          vf_loss: 444.05792236328125\n",
      "    num_agent_steps_sampled: 468000\n",
      "    num_agent_steps_trained: 468000\n",
      "    num_steps_sampled: 468000\n",
      "    num_steps_trained: 468000\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.97142857142857\n",
      "    ram_util_percent: 66.78571428571429\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07205558918702007\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10353299068617677\n",
      "    mean_inference_ms: 0.5034134818749023\n",
      "    mean_raw_obs_processing_ms: 0.04836424922618834\n",
      "  time_since_restore: 411.9967019557953\n",
      "  time_this_iter_s: 4.340620994567871\n",
      "  time_total_s: 411.9967019557953\n",
      "  timers:\n",
      "    learn_throughput: 1738.26\n",
      "    learn_time_ms: 2301.152\n",
      "    load_throughput: 3812137.242\n",
      "    load_time_ms: 1.049\n",
      "    sample_throughput: 2417.443\n",
      "    sample_time_ms: 1654.641\n",
      "    update_time_ms: 1.828\n",
      "  timestamp: 1629485469\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 468000\n",
      "  training_iteration: 117\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         411.997</td><td style=\"text-align: right;\">468000</td><td style=\"text-align: right;\">-316.295</td><td style=\"text-align: right;\">           -0.354305</td><td style=\"text-align: right;\">            -1781.37</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 476000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-17\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3543045935595232\n",
      "  episode_reward_mean: -291.90122473155486\n",
      "  episode_reward_min: -1781.3687062041015\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2380\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.037978071719408035\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011732571758329868\n",
      "          model: {}\n",
      "          policy_loss: -0.033087000250816345\n",
      "          total_loss: 340.1856689453125\n",
      "          vf_explained_var: 0.9230901002883911\n",
      "          vf_loss: 340.2068786621094\n",
      "    num_agent_steps_sampled: 476000\n",
      "    num_agent_steps_trained: 476000\n",
      "    num_steps_sampled: 476000\n",
      "    num_steps_trained: 476000\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.5\n",
      "    ram_util_percent: 66.68333333333332\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07225920232127352\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10379154835367554\n",
      "    mean_inference_ms: 0.5047654488570877\n",
      "    mean_raw_obs_processing_ms: 0.048528928081228884\n",
      "  time_since_restore: 420.248069524765\n",
      "  time_this_iter_s: 4.208183765411377\n",
      "  time_total_s: 420.248069524765\n",
      "  timers:\n",
      "    learn_throughput: 1731.345\n",
      "    learn_time_ms: 2310.343\n",
      "    load_throughput: 3742408.209\n",
      "    load_time_ms: 1.069\n",
      "    sample_throughput: 2397.564\n",
      "    sample_time_ms: 1668.36\n",
      "    update_time_ms: 1.565\n",
      "  timestamp: 1629485477\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 476000\n",
      "  training_iteration: 119\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         420.248</td><td style=\"text-align: right;\">476000</td><td style=\"text-align: right;\">-291.901</td><td style=\"text-align: right;\">           -0.354305</td><td style=\"text-align: right;\">            -1781.37</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 484000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-24\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3543045935595232\n",
      "  episode_reward_mean: -258.676650922016\n",
      "  episode_reward_min: -819.0398331419522\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2420\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.2664121389389038\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009483801200985909\n",
      "          model: {}\n",
      "          policy_loss: -0.025507623329758644\n",
      "          total_loss: 247.2438201904297\n",
      "          vf_explained_var: 0.9749913215637207\n",
      "          vf_loss: 247.25970458984375\n",
      "    num_agent_steps_sampled: 484000\n",
      "    num_agent_steps_trained: 484000\n",
      "    num_steps_sampled: 484000\n",
      "    num_steps_trained: 484000\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.17999999999999\n",
      "    ram_util_percent: 66.75999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07245439977339448\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10403454275400362\n",
      "    mean_inference_ms: 0.5060700558187721\n",
      "    mean_raw_obs_processing_ms: 0.04868365640117877\n",
      "  time_since_restore: 427.5588493347168\n",
      "  time_this_iter_s: 3.6645748615264893\n",
      "  time_total_s: 427.5588493347168\n",
      "  timers:\n",
      "    learn_throughput: 1750.36\n",
      "    learn_time_ms: 2285.244\n",
      "    load_throughput: 3789577.159\n",
      "    load_time_ms: 1.056\n",
      "    sample_throughput: 2427.494\n",
      "    sample_time_ms: 1647.79\n",
      "    update_time_ms: 1.542\n",
      "  timestamp: 1629485484\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 484000\n",
      "  training_iteration: 121\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         427.559</td><td style=\"text-align: right;\">484000</td><td style=\"text-align: right;\">-258.677</td><td style=\"text-align: right;\">           -0.354305</td><td style=\"text-align: right;\">             -819.04</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 492000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-31\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3892086905210388\n",
      "  episode_reward_mean: -279.81531181167816\n",
      "  episode_reward_min: -1421.3665305702038\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2460\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.19299499690532684\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0075228032656013966\n",
      "          model: {}\n",
      "          policy_loss: -0.021675994619727135\n",
      "          total_loss: 236.41053771972656\n",
      "          vf_explained_var: 0.9634706974029541\n",
      "          vf_loss: 236.42459106445312\n",
      "    num_agent_steps_sampled: 492000\n",
      "    num_agent_steps_trained: 492000\n",
      "    num_steps_sampled: 492000\n",
      "    num_steps_trained: 492000\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.160000000000004\n",
      "    ram_util_percent: 66.85999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07256525797868413\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10418334389741485\n",
      "    mean_inference_ms: 0.506842118037096\n",
      "    mean_raw_obs_processing_ms: 0.048779996613454994\n",
      "  time_since_restore: 434.7763867378235\n",
      "  time_this_iter_s: 3.4730024337768555\n",
      "  time_total_s: 434.7763867378235\n",
      "  timers:\n",
      "    learn_throughput: 1783.335\n",
      "    learn_time_ms: 2242.988\n",
      "    load_throughput: 3771177.846\n",
      "    load_time_ms: 1.061\n",
      "    sample_throughput: 2416.382\n",
      "    sample_time_ms: 1655.368\n",
      "    update_time_ms: 1.429\n",
      "  timestamp: 1629485491\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 492000\n",
      "  training_iteration: 123\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         434.776</td><td style=\"text-align: right;\">492000</td><td style=\"text-align: right;\">-279.815</td><td style=\"text-align: right;\">           -0.389209</td><td style=\"text-align: right;\">            -1421.37</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 500000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-39\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4502226348995147\n",
      "  episode_reward_mean: -301.03637124972965\n",
      "  episode_reward_min: -1486.1523582495013\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2500\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3781278431415558\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008015221916139126\n",
      "          model: {}\n",
      "          policy_loss: -0.023257767781615257\n",
      "          total_loss: 964.3396606445312\n",
      "          vf_explained_var: 0.9221048951148987\n",
      "          vf_loss: 964.3547973632812\n",
      "    num_agent_steps_sampled: 500000\n",
      "    num_agent_steps_trained: 500000\n",
      "    num_steps_sampled: 500000\n",
      "    num_steps_trained: 500000\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.880000000000003\n",
      "    ram_util_percent: 66.84\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07263999760819063\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10429256565748304\n",
      "    mean_inference_ms: 0.5073679193247229\n",
      "    mean_raw_obs_processing_ms: 0.048848008597570346\n",
      "  time_since_restore: 442.3886466026306\n",
      "  time_this_iter_s: 3.8506479263305664\n",
      "  time_total_s: 442.3886466026306\n",
      "  timers:\n",
      "    learn_throughput: 1812.351\n",
      "    learn_time_ms: 2207.077\n",
      "    load_throughput: 3931023.688\n",
      "    load_time_ms: 1.018\n",
      "    sample_throughput: 2386.949\n",
      "    sample_time_ms: 1675.779\n",
      "    update_time_ms: 1.451\n",
      "  timestamp: 1629485499\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 500000\n",
      "  training_iteration: 125\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         442.389</td><td style=\"text-align: right;\">500000</td><td style=\"text-align: right;\">-301.036</td><td style=\"text-align: right;\">           -0.450223</td><td style=\"text-align: right;\">            -1486.15</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 508000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-46\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4502226348995147\n",
      "  episode_reward_mean: -284.6694578185045\n",
      "  episode_reward_min: -1486.1523582495013\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2540\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.19965896010398865\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008224894292652607\n",
      "          model: {}\n",
      "          policy_loss: -0.03243985027074814\n",
      "          total_loss: 179.39529418945312\n",
      "          vf_explained_var: 0.9792578816413879\n",
      "          vf_loss: 179.41940307617188\n",
      "    num_agent_steps_sampled: 508000\n",
      "    num_agent_steps_trained: 508000\n",
      "    num_steps_sampled: 508000\n",
      "    num_steps_trained: 508000\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.93333333333333\n",
      "    ram_util_percent: 67.3\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07272730955329568\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10441824589321062\n",
      "    mean_inference_ms: 0.507943246297182\n",
      "    mean_raw_obs_processing_ms: 0.04892562429602572\n",
      "  time_since_restore: 449.74478936195374\n",
      "  time_this_iter_s: 3.615648031234741\n",
      "  time_total_s: 449.74478936195374\n",
      "  timers:\n",
      "    learn_throughput: 1858.356\n",
      "    learn_time_ms: 2152.44\n",
      "    load_throughput: 3913418.395\n",
      "    load_time_ms: 1.022\n",
      "    sample_throughput: 2475.745\n",
      "    sample_time_ms: 1615.676\n",
      "    update_time_ms: 1.47\n",
      "  timestamp: 1629485506\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 508000\n",
      "  training_iteration: 127\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         449.745</td><td style=\"text-align: right;\">508000</td><td style=\"text-align: right;\">-284.669</td><td style=\"text-align: right;\">           -0.450223</td><td style=\"text-align: right;\">            -1486.15</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 516000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-54\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6102728606037484\n",
      "  episode_reward_mean: -276.9959468303167\n",
      "  episode_reward_min: -1193.0202706133637\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2580\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.19972991943359375\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008281835354864597\n",
      "          model: {}\n",
      "          policy_loss: -0.02852977067232132\n",
      "          total_loss: 620.09814453125\n",
      "          vf_explained_var: 0.9336275458335876\n",
      "          vf_loss: 620.1182861328125\n",
      "    num_agent_steps_sampled: 516000\n",
      "    num_agent_steps_trained: 516000\n",
      "    num_steps_sampled: 516000\n",
      "    num_steps_trained: 516000\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.48\n",
      "    ram_util_percent: 66.9\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07278759378487847\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10451969265099485\n",
      "    mean_inference_ms: 0.5083513085358657\n",
      "    mean_raw_obs_processing_ms: 0.04898902265084766\n",
      "  time_since_restore: 456.99661135673523\n",
      "  time_this_iter_s: 3.6144089698791504\n",
      "  time_total_s: 456.99661135673523\n",
      "  timers:\n",
      "    learn_throughput: 1901.308\n",
      "    learn_time_ms: 2103.814\n",
      "    load_throughput: 4346541.62\n",
      "    load_time_ms: 0.92\n",
      "    sample_throughput: 2556.704\n",
      "    sample_time_ms: 1564.514\n",
      "    update_time_ms: 1.489\n",
      "  timestamp: 1629485514\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 516000\n",
      "  training_iteration: 129\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         456.997</td><td style=\"text-align: right;\">516000</td><td style=\"text-align: right;\">-276.996</td><td style=\"text-align: right;\">           -0.610273</td><td style=\"text-align: right;\">            -1193.02</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 524000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-01\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.39380693428998004\n",
      "  episode_reward_mean: -281.0545093286302\n",
      "  episode_reward_min: -1176.139190041442\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2620\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5193880796432495\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007803010288625956\n",
      "          model: {}\n",
      "          policy_loss: -0.024038735777139664\n",
      "          total_loss: 554.5653076171875\n",
      "          vf_explained_var: 0.9597111940383911\n",
      "          vf_loss: 554.5814819335938\n",
      "    num_agent_steps_sampled: 524000\n",
      "    num_agent_steps_trained: 524000\n",
      "    num_steps_sampled: 524000\n",
      "    num_steps_trained: 524000\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.42\n",
      "    ram_util_percent: 66.75999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07279309123829952\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10455605592717636\n",
      "    mean_inference_ms: 0.5084121585919184\n",
      "    mean_raw_obs_processing_ms: 0.04901467790120392\n",
      "  time_since_restore: 464.19348406791687\n",
      "  time_this_iter_s: 3.5898478031158447\n",
      "  time_total_s: 464.19348406791687\n",
      "  timers:\n",
      "    learn_throughput: 1907.192\n",
      "    learn_time_ms: 2097.324\n",
      "    load_throughput: 4410878.115\n",
      "    load_time_ms: 0.907\n",
      "    sample_throughput: 2564.727\n",
      "    sample_time_ms: 1559.62\n",
      "    update_time_ms: 1.489\n",
      "  timestamp: 1629485521\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 524000\n",
      "  training_iteration: 131\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         464.193</td><td style=\"text-align: right;\">524000</td><td style=\"text-align: right;\">-281.055</td><td style=\"text-align: right;\">           -0.393807</td><td style=\"text-align: right;\">            -1176.14</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 532000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-08\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.39380693428998004\n",
      "  episode_reward_mean: -296.840730943534\n",
      "  episode_reward_min: -1176.139190041442\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2660\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.2033504992723465\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008650118485093117\n",
      "          model: {}\n",
      "          policy_loss: -0.029817823320627213\n",
      "          total_loss: 403.174072265625\n",
      "          vf_explained_var: 0.9510040283203125\n",
      "          vf_loss: 403.1951599121094\n",
      "    num_agent_steps_sampled: 532000\n",
      "    num_agent_steps_trained: 532000\n",
      "    num_steps_sampled: 532000\n",
      "    num_steps_trained: 532000\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.220000000000006\n",
      "    ram_util_percent: 66.5\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07279396913117465\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10458253004215931\n",
      "    mean_inference_ms: 0.5084559797296451\n",
      "    mean_raw_obs_processing_ms: 0.04903355210784727\n",
      "  time_since_restore: 471.40856099128723\n",
      "  time_this_iter_s: 3.564866065979004\n",
      "  time_total_s: 471.40856099128723\n",
      "  timers:\n",
      "    learn_throughput: 1896.245\n",
      "    learn_time_ms: 2109.432\n",
      "    load_throughput: 4374534.835\n",
      "    load_time_ms: 0.914\n",
      "    sample_throughput: 2585.169\n",
      "    sample_time_ms: 1547.288\n",
      "    update_time_ms: 1.481\n",
      "  timestamp: 1629485528\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 532000\n",
      "  training_iteration: 133\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         471.409</td><td style=\"text-align: right;\">532000</td><td style=\"text-align: right;\">-296.841</td><td style=\"text-align: right;\">           -0.393807</td><td style=\"text-align: right;\">            -1176.14</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 540000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-16\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.39380693428998004\n",
      "  episode_reward_mean: -318.26481263609895\n",
      "  episode_reward_min: -1504.5983444590192\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2700\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5692239999771118\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009801557287573814\n",
      "          model: {}\n",
      "          policy_loss: -0.0314130000770092\n",
      "          total_loss: 1017.3955688476562\n",
      "          vf_explained_var: 0.9445459246635437\n",
      "          vf_loss: 1017.4171142578125\n",
      "    num_agent_steps_sampled: 540000\n",
      "    num_agent_steps_trained: 540000\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 540000\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.5\n",
      "    ram_util_percent: 66.3\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07279063054978803\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10460251519130104\n",
      "    mean_inference_ms: 0.5084964245770944\n",
      "    mean_raw_obs_processing_ms: 0.049049082272841764\n",
      "  time_since_restore: 478.66780161857605\n",
      "  time_this_iter_s: 3.574605703353882\n",
      "  time_total_s: 478.66780161857605\n",
      "  timers:\n",
      "    learn_throughput: 1895.713\n",
      "    learn_time_ms: 2110.024\n",
      "    load_throughput: 4403122.064\n",
      "    load_time_ms: 0.908\n",
      "    sample_throughput: 2646.453\n",
      "    sample_time_ms: 1511.457\n",
      "    update_time_ms: 1.473\n",
      "  timestamp: 1629485536\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 135\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         478.668</td><td style=\"text-align: right;\">540000</td><td style=\"text-align: right;\">-318.265</td><td style=\"text-align: right;\">           -0.393807</td><td style=\"text-align: right;\">             -1504.6</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 548000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-23\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.40520516610916996\n",
      "  episode_reward_mean: -312.06382093179354\n",
      "  episode_reward_min: -1504.5983444590192\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2740\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.45203524827957153\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008877117186784744\n",
      "          model: {}\n",
      "          policy_loss: -0.03033849410712719\n",
      "          total_loss: 294.1210021972656\n",
      "          vf_explained_var: 0.9758987426757812\n",
      "          vf_loss: 294.14239501953125\n",
      "    num_agent_steps_sampled: 548000\n",
      "    num_agent_steps_trained: 548000\n",
      "    num_steps_sampled: 548000\n",
      "    num_steps_trained: 548000\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 36.74\n",
      "    ram_util_percent: 66.42\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07278617338578906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10461829938315961\n",
      "    mean_inference_ms: 0.5085403406895759\n",
      "    mean_raw_obs_processing_ms: 0.04906231739173077\n",
      "  time_since_restore: 485.88396072387695\n",
      "  time_this_iter_s: 3.603649139404297\n",
      "  time_total_s: 485.88396072387695\n",
      "  timers:\n",
      "    learn_throughput: 1904.402\n",
      "    learn_time_ms: 2100.397\n",
      "    load_throughput: 4451134.458\n",
      "    load_time_ms: 0.899\n",
      "    sample_throughput: 2654.039\n",
      "    sample_time_ms: 1507.137\n",
      "    update_time_ms: 1.444\n",
      "  timestamp: 1629485543\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 548000\n",
      "  training_iteration: 137\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         485.884</td><td style=\"text-align: right;\">548000</td><td style=\"text-align: right;\">-312.064</td><td style=\"text-align: right;\">           -0.405205</td><td style=\"text-align: right;\">             -1504.6</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 556000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-30\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.40520516610916996\n",
      "  episode_reward_mean: -303.5888129574334\n",
      "  episode_reward_min: -1504.5983444590192\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2780\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187499523162842\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.48138099908828735\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008577428758144379\n",
      "          model: {}\n",
      "          policy_loss: -0.03574135899543762\n",
      "          total_loss: 722.7014770507812\n",
      "          vf_explained_var: 0.9397444725036621\n",
      "          vf_loss: 722.7242431640625\n",
      "    num_agent_steps_sampled: 556000\n",
      "    num_agent_steps_trained: 556000\n",
      "    num_steps_sampled: 556000\n",
      "    num_steps_trained: 556000\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.339999999999996\n",
      "    ram_util_percent: 66.44000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0727790576460785\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1046285124630037\n",
      "    mean_inference_ms: 0.508571036114671\n",
      "    mean_raw_obs_processing_ms: 0.049072424212526417\n",
      "  time_since_restore: 493.0647189617157\n",
      "  time_this_iter_s: 3.56392502784729\n",
      "  time_total_s: 493.0647189617157\n",
      "  timers:\n",
      "    learn_throughput: 1906.705\n",
      "    learn_time_ms: 2097.86\n",
      "    load_throughput: 4440649.003\n",
      "    load_time_ms: 0.901\n",
      "    sample_throughput: 2662.023\n",
      "    sample_time_ms: 1502.617\n",
      "    update_time_ms: 1.426\n",
      "  timestamp: 1629485550\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 556000\n",
      "  training_iteration: 139\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         493.065</td><td style=\"text-align: right;\">556000</td><td style=\"text-align: right;\">-303.589</td><td style=\"text-align: right;\">           -0.405205</td><td style=\"text-align: right;\">             -1504.6</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 564000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-37\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3327938712640481\n",
      "  episode_reward_mean: -313.3842654206427\n",
      "  episode_reward_min: -1692.2088352137093\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2820\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187499523162842\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.29253995418548584\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.004903966560959816\n",
      "          model: {}\n",
      "          policy_loss: -0.018704885616898537\n",
      "          total_loss: 760.8428955078125\n",
      "          vf_explained_var: 0.9154450297355652\n",
      "          vf_loss: 760.85400390625\n",
      "    num_agent_steps_sampled: 564000\n",
      "    num_agent_steps_trained: 564000\n",
      "    num_steps_sampled: 564000\n",
      "    num_steps_trained: 564000\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.48\n",
      "    ram_util_percent: 66.5\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07277295439928347\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10464098195934099\n",
      "    mean_inference_ms: 0.508630286754224\n",
      "    mean_raw_obs_processing_ms: 0.049082888535255643\n",
      "  time_since_restore: 500.28911209106445\n",
      "  time_this_iter_s: 3.569317102432251\n",
      "  time_total_s: 500.28911209106445\n",
      "  timers:\n",
      "    learn_throughput: 1908.941\n",
      "    learn_time_ms: 2095.403\n",
      "    load_throughput: 4463568.787\n",
      "    load_time_ms: 0.896\n",
      "    sample_throughput: 2652.876\n",
      "    sample_time_ms: 1507.798\n",
      "    update_time_ms: 1.436\n",
      "  timestamp: 1629485557\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 564000\n",
      "  training_iteration: 141\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         500.289</td><td style=\"text-align: right;\">564000</td><td style=\"text-align: right;\">-313.384</td><td style=\"text-align: right;\">           -0.332794</td><td style=\"text-align: right;\">            -1692.21</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 572000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-44\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3327938712640481\n",
      "  episode_reward_mean: -354.3118059174976\n",
      "  episode_reward_min: -1793.878684087295\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2860\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.8941616415977478\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01656072400510311\n",
      "          model: {}\n",
      "          policy_loss: -0.04381180182099342\n",
      "          total_loss: 2666.342041015625\n",
      "          vf_explained_var: 0.8898111581802368\n",
      "          vf_loss: 2666.37353515625\n",
      "    num_agent_steps_sampled: 572000\n",
      "    num_agent_steps_trained: 572000\n",
      "    num_steps_sampled: 572000\n",
      "    num_steps_trained: 572000\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.26\n",
      "    ram_util_percent: 66.06\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07276642234144709\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10464996908184322\n",
      "    mean_inference_ms: 0.5086920346703695\n",
      "    mean_raw_obs_processing_ms: 0.0490910009973277\n",
      "  time_since_restore: 507.51253724098206\n",
      "  time_this_iter_s: 3.6069321632385254\n",
      "  time_total_s: 507.51253724098206\n",
      "  timers:\n",
      "    learn_throughput: 1909.089\n",
      "    learn_time_ms: 2095.241\n",
      "    load_throughput: 4434545.503\n",
      "    load_time_ms: 0.902\n",
      "    sample_throughput: 2651.161\n",
      "    sample_time_ms: 1508.773\n",
      "    update_time_ms: 1.438\n",
      "  timestamp: 1629485564\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 572000\n",
      "  training_iteration: 143\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         507.513</td><td style=\"text-align: right;\">572000</td><td style=\"text-align: right;\">-354.312</td><td style=\"text-align: right;\">           -0.332794</td><td style=\"text-align: right;\">            -1793.88</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 580000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-52\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.42100826121374185\n",
      "  episode_reward_mean: -339.9227554667377\n",
      "  episode_reward_min: -1793.878684087295\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2900\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.0447617769241333\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011814366094768047\n",
      "          model: {}\n",
      "          policy_loss: -0.030121181160211563\n",
      "          total_loss: 3339.402587890625\n",
      "          vf_explained_var: 0.8627030849456787\n",
      "          vf_loss: 3339.423583984375\n",
      "    num_agent_steps_sampled: 580000\n",
      "    num_agent_steps_trained: 580000\n",
      "    num_steps_sampled: 580000\n",
      "    num_steps_trained: 580000\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.68333333333334\n",
      "    ram_util_percent: 66.2\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07275855841605498\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10465508109858405\n",
      "    mean_inference_ms: 0.5087546775065159\n",
      "    mean_raw_obs_processing_ms: 0.04909786131812982\n",
      "  time_since_restore: 514.7796320915222\n",
      "  time_this_iter_s: 3.653256893157959\n",
      "  time_total_s: 514.7796320915222\n",
      "  timers:\n",
      "    learn_throughput: 1905.006\n",
      "    learn_time_ms: 2099.73\n",
      "    load_throughput: 4442295.125\n",
      "    load_time_ms: 0.9\n",
      "    sample_throughput: 2657.738\n",
      "    sample_time_ms: 1505.039\n",
      "    update_time_ms: 1.438\n",
      "  timestamp: 1629485572\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 580000\n",
      "  training_iteration: 145\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">          514.78</td><td style=\"text-align: right;\">580000</td><td style=\"text-align: right;\">-339.923</td><td style=\"text-align: right;\">           -0.421008</td><td style=\"text-align: right;\">            -1793.88</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 588000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-59\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4537255436550378\n",
      "  episode_reward_mean: -384.63813574392356\n",
      "  episode_reward_min: -1737.5808648440143\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2940\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.720223069190979\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011728649027645588\n",
      "          model: {}\n",
      "          policy_loss: -0.03086782619357109\n",
      "          total_loss: 1062.4534912109375\n",
      "          vf_explained_var: 0.929296612739563\n",
      "          vf_loss: 1062.4755859375\n",
      "    num_agent_steps_sampled: 588000\n",
      "    num_agent_steps_trained: 588000\n",
      "    num_steps_sampled: 588000\n",
      "    num_steps_trained: 588000\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.760000000000005\n",
      "    ram_util_percent: 69.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07277767125255971\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10469097595183124\n",
      "    mean_inference_ms: 0.5089783539338393\n",
      "    mean_raw_obs_processing_ms: 0.04912342479254967\n",
      "  time_since_restore: 522.202892780304\n",
      "  time_this_iter_s: 3.587932825088501\n",
      "  time_total_s: 522.202892780304\n",
      "  timers:\n",
      "    learn_throughput: 1903.243\n",
      "    learn_time_ms: 2101.675\n",
      "    load_throughput: 4434897.172\n",
      "    load_time_ms: 0.902\n",
      "    sample_throughput: 2625.046\n",
      "    sample_time_ms: 1523.783\n",
      "    update_time_ms: 1.446\n",
      "  timestamp: 1629485579\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 588000\n",
      "  training_iteration: 147\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         522.203</td><td style=\"text-align: right;\">588000</td><td style=\"text-align: right;\">-384.638</td><td style=\"text-align: right;\">           -0.453726</td><td style=\"text-align: right;\">            -1737.58</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 596000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-53-07\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5525094892197626\n",
      "  episode_reward_mean: -414.9459997182291\n",
      "  episode_reward_min: -1739.8457719918763\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2980\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.8421304225921631\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02318800985813141\n",
      "          model: {}\n",
      "          policy_loss: -0.05193726718425751\n",
      "          total_loss: 1533.60986328125\n",
      "          vf_explained_var: 0.8925516605377197\n",
      "          vf_loss: 1533.644287109375\n",
      "    num_agent_steps_sampled: 596000\n",
      "    num_agent_steps_trained: 596000\n",
      "    num_steps_sampled: 596000\n",
      "    num_steps_trained: 596000\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.459999999999994\n",
      "    ram_util_percent: 69.5\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07279555400169026\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10472834433522432\n",
      "    mean_inference_ms: 0.5091856080238566\n",
      "    mean_raw_obs_processing_ms: 0.049146701803909315\n",
      "  time_since_restore: 529.4337220191956\n",
      "  time_this_iter_s: 3.5822761058807373\n",
      "  time_total_s: 529.4337220191956\n",
      "  timers:\n",
      "    learn_throughput: 1901.643\n",
      "    learn_time_ms: 2103.444\n",
      "    load_throughput: 4503225.252\n",
      "    load_time_ms: 0.888\n",
      "    sample_throughput: 2619.525\n",
      "    sample_time_ms: 1526.995\n",
      "    update_time_ms: 1.447\n",
      "  timestamp: 1629485587\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 596000\n",
      "  training_iteration: 149\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         529.434</td><td style=\"text-align: right;\">596000</td><td style=\"text-align: right;\">-414.946</td><td style=\"text-align: right;\">           -0.552509</td><td style=\"text-align: right;\">            -1739.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 604000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-53-14\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.49285387966709054\n",
      "  episode_reward_mean: -357.1288808927116\n",
      "  episode_reward_min: -1739.8457719918763\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3020\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.7602370977401733\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011911097913980484\n",
      "          model: {}\n",
      "          policy_loss: -0.03858986124396324\n",
      "          total_loss: 993.3609008789062\n",
      "          vf_explained_var: 0.9422360062599182\n",
      "          vf_loss: 993.3859252929688\n",
      "    num_agent_steps_sampled: 604000\n",
      "    num_agent_steps_trained: 604000\n",
      "    num_steps_sampled: 604000\n",
      "    num_steps_trained: 604000\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.56\n",
      "    ram_util_percent: 68.50000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07280731831368682\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10475948302899342\n",
      "    mean_inference_ms: 0.5093479450064488\n",
      "    mean_raw_obs_processing_ms: 0.049165250996469234\n",
      "  time_since_restore: 536.7079949378967\n",
      "  time_this_iter_s: 3.5994350910186768\n",
      "  time_total_s: 536.7079949378967\n",
      "  timers:\n",
      "    learn_throughput: 1899.295\n",
      "    learn_time_ms: 2106.044\n",
      "    load_throughput: 4535240.721\n",
      "    load_time_ms: 0.882\n",
      "    sample_throughput: 2615.373\n",
      "    sample_time_ms: 1529.419\n",
      "    update_time_ms: 1.456\n",
      "  timestamp: 1629485594\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 604000\n",
      "  training_iteration: 151\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">         536.708</td><td style=\"text-align: right;\">604000</td><td style=\"text-align: right;\">-357.129</td><td style=\"text-align: right;\">           -0.492854</td><td style=\"text-align: right;\">            -1739.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 612000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-53-21\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.49285387966709054\n",
      "  episode_reward_mean: -358.1539546575087\n",
      "  episode_reward_min: -1646.6416084363216\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3060\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.7804085612297058\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012718611396849155\n",
      "          model: {}\n",
      "          policy_loss: -0.03613091632723808\n",
      "          total_loss: 2217.675048828125\n",
      "          vf_explained_var: 0.8766252994537354\n",
      "          vf_loss: 2217.69677734375\n",
      "    num_agent_steps_sampled: 612000\n",
      "    num_agent_steps_trained: 612000\n",
      "    num_steps_sampled: 612000\n",
      "    num_steps_trained: 612000\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.5\n",
      "    ram_util_percent: 68.24\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07280331720426371\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10476983637599294\n",
      "    mean_inference_ms: 0.5094475430990206\n",
      "    mean_raw_obs_processing_ms: 0.049171652113732985\n",
      "  time_since_restore: 543.9048309326172\n",
      "  time_this_iter_s: 3.57279896736145\n",
      "  time_total_s: 543.9048309326172\n",
      "  timers:\n",
      "    learn_throughput: 1900.381\n",
      "    learn_time_ms: 2104.841\n",
      "    load_throughput: 4616608.239\n",
      "    load_time_ms: 0.866\n",
      "    sample_throughput: 2617.86\n",
      "    sample_time_ms: 1527.966\n",
      "    update_time_ms: 1.468\n",
      "  timestamp: 1629485601\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 612000\n",
      "  training_iteration: 153\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   153</td><td style=\"text-align: right;\">         543.905</td><td style=\"text-align: right;\">612000</td><td style=\"text-align: right;\">-358.154</td><td style=\"text-align: right;\">           -0.492854</td><td style=\"text-align: right;\">            -1646.64</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 620000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-53-29\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3929215808827661\n",
      "  episode_reward_mean: -341.45148899579\n",
      "  episode_reward_min: -1646.6416084363216\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3100\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.7811005115509033\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01602937839925289\n",
      "          model: {}\n",
      "          policy_loss: -0.036535944789648056\n",
      "          total_loss: 454.30609130859375\n",
      "          vf_explained_var: 0.9727401733398438\n",
      "          vf_loss: 454.3243103027344\n",
      "    num_agent_steps_sampled: 620000\n",
      "    num_agent_steps_trained: 620000\n",
      "    num_steps_sampled: 620000\n",
      "    num_steps_trained: 620000\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.28\n",
      "    ram_util_percent: 67.0\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07280149794207845\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10477966825170054\n",
      "    mean_inference_ms: 0.5095515047588328\n",
      "    mean_raw_obs_processing_ms: 0.04917582994819819\n",
      "  time_since_restore: 551.42698097229\n",
      "  time_this_iter_s: 3.572986125946045\n",
      "  time_total_s: 551.42698097229\n",
      "  timers:\n",
      "    learn_throughput: 1884.239\n",
      "    learn_time_ms: 2122.873\n",
      "    load_throughput: 4520454.815\n",
      "    load_time_ms: 0.885\n",
      "    sample_throughput: 2605.215\n",
      "    sample_time_ms: 1535.382\n",
      "    update_time_ms: 1.466\n",
      "  timestamp: 1629485609\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 620000\n",
      "  training_iteration: 155\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">         551.427</td><td style=\"text-align: right;\">620000</td><td style=\"text-align: right;\">-341.451</td><td style=\"text-align: right;\">           -0.392922</td><td style=\"text-align: right;\">            -1646.64</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 628000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-53-36\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3929215808827661\n",
      "  episode_reward_mean: -331.4956964976131\n",
      "  episode_reward_min: -1646.6416084363216\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3140\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.886764407157898\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009473496116697788\n",
      "          model: {}\n",
      "          policy_loss: -0.03199653699994087\n",
      "          total_loss: 1159.69189453125\n",
      "          vf_explained_var: 0.9453511238098145\n",
      "          vf_loss: 1159.7132568359375\n",
      "    num_agent_steps_sampled: 628000\n",
      "    num_agent_steps_trained: 628000\n",
      "    num_steps_sampled: 628000\n",
      "    num_steps_trained: 628000\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.1\n",
      "    ram_util_percent: 66.6\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07280399189721949\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10478427634713995\n",
      "    mean_inference_ms: 0.5097321315756548\n",
      "    mean_raw_obs_processing_ms: 0.0491702995330798\n",
      "  time_since_restore: 558.6485590934753\n",
      "  time_this_iter_s: 3.5673270225524902\n",
      "  time_total_s: 558.6485590934753\n",
      "  timers:\n",
      "    learn_throughput: 1894.172\n",
      "    learn_time_ms: 2111.74\n",
      "    load_throughput: 4488046.653\n",
      "    load_time_ms: 0.891\n",
      "    sample_throughput: 2620.6\n",
      "    sample_time_ms: 1526.368\n",
      "    update_time_ms: 1.445\n",
      "  timestamp: 1629485616\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 628000\n",
      "  training_iteration: 157\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   157</td><td style=\"text-align: right;\">         558.649</td><td style=\"text-align: right;\">628000</td><td style=\"text-align: right;\">-331.496</td><td style=\"text-align: right;\">           -0.392922</td><td style=\"text-align: right;\">            -1646.64</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 636000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-53-43\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4187134709649353\n",
      "  episode_reward_mean: -357.10603405324497\n",
      "  episode_reward_min: -1792.607871692411\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3180\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.0731686353683472\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008291160687804222\n",
      "          model: {}\n",
      "          policy_loss: -0.024618029594421387\n",
      "          total_loss: 3013.588623046875\n",
      "          vf_explained_var: 0.863718569278717\n",
      "          vf_loss: 3013.603271484375\n",
      "    num_agent_steps_sampled: 636000\n",
      "    num_agent_steps_trained: 636000\n",
      "    num_steps_sampled: 636000\n",
      "    num_steps_trained: 636000\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.72\n",
      "    ram_util_percent: 66.74\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0728136492810861\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10479329349003041\n",
      "    mean_inference_ms: 0.5099965510763255\n",
      "    mean_raw_obs_processing_ms: 0.04916420997875104\n",
      "  time_since_restore: 565.9788999557495\n",
      "  time_this_iter_s: 3.6996827125549316\n",
      "  time_total_s: 565.9788999557495\n",
      "  timers:\n",
      "    learn_throughput: 1892.9\n",
      "    learn_time_ms: 2113.16\n",
      "    load_throughput: 4497310.28\n",
      "    load_time_ms: 0.889\n",
      "    sample_throughput: 2605.978\n",
      "    sample_time_ms: 1534.932\n",
      "    update_time_ms: 1.431\n",
      "  timestamp: 1629485623\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 636000\n",
      "  training_iteration: 159\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   159</td><td style=\"text-align: right;\">         565.979</td><td style=\"text-align: right;\">636000</td><td style=\"text-align: right;\">-357.106</td><td style=\"text-align: right;\">           -0.418713</td><td style=\"text-align: right;\">            -1792.61</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 644000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-53-50\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.9900678890726173\n",
      "  episode_reward_mean: -328.7900097143391\n",
      "  episode_reward_min: -1792.607871692411\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3220\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.24960826337337494\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012781028635799885\n",
      "          model: {}\n",
      "          policy_loss: -0.027991702780127525\n",
      "          total_loss: 150.3510284423828\n",
      "          vf_explained_var: 0.9556770324707031\n",
      "          vf_loss: 150.36447143554688\n",
      "    num_agent_steps_sampled: 644000\n",
      "    num_agent_steps_trained: 644000\n",
      "    num_steps_sampled: 644000\n",
      "    num_steps_trained: 644000\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.36\n",
      "    ram_util_percent: 67.1\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07282626377052628\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10480334039855788\n",
      "    mean_inference_ms: 0.5102944876545279\n",
      "    mean_raw_obs_processing_ms: 0.04915802751052633\n",
      "  time_since_restore: 573.1698980331421\n",
      "  time_this_iter_s: 3.563778877258301\n",
      "  time_total_s: 573.1698980331421\n",
      "  timers:\n",
      "    learn_throughput: 1902.507\n",
      "    learn_time_ms: 2102.489\n",
      "    load_throughput: 4484807.399\n",
      "    load_time_ms: 0.892\n",
      "    sample_throughput: 2602.058\n",
      "    sample_time_ms: 1537.245\n",
      "    update_time_ms: 1.439\n",
      "  timestamp: 1629485630\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 644000\n",
      "  training_iteration: 161\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   161</td><td style=\"text-align: right;\">          573.17</td><td style=\"text-align: right;\">644000</td><td style=\"text-align: right;\"> -328.79</td><td style=\"text-align: right;\">           -0.990068</td><td style=\"text-align: right;\">            -1792.61</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 652000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-00\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5035122220619553\n",
      "  episode_reward_mean: -306.5198369490692\n",
      "  episode_reward_min: -1792.607871692411\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3260\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.6601067185401917\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009990016929805279\n",
      "          model: {}\n",
      "          policy_loss: -0.03877044841647148\n",
      "          total_loss: 480.9149475097656\n",
      "          vf_explained_var: 0.9612283110618591\n",
      "          vf_loss: 480.94232177734375\n",
      "    num_agent_steps_sampled: 652000\n",
      "    num_agent_steps_trained: 652000\n",
      "    num_steps_sampled: 652000\n",
      "    num_steps_trained: 652000\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.42857142857143\n",
      "    ram_util_percent: 70.04285714285713\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07288229892645198\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1048673323670944\n",
      "    mean_inference_ms: 0.5108171439789037\n",
      "    mean_raw_obs_processing_ms: 0.04919402984976992\n",
      "  time_since_restore: 582.5932188034058\n",
      "  time_this_iter_s: 4.640837907791138\n",
      "  time_total_s: 582.5932188034058\n",
      "  timers:\n",
      "    learn_throughput: 1760.619\n",
      "    learn_time_ms: 2271.928\n",
      "    load_throughput: 3634815.088\n",
      "    load_time_ms: 1.1\n",
      "    sample_throughput: 2517.344\n",
      "    sample_time_ms: 1588.977\n",
      "    update_time_ms: 1.474\n",
      "  timestamp: 1629485640\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 652000\n",
      "  training_iteration: 163\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   163</td><td style=\"text-align: right;\">         582.593</td><td style=\"text-align: right;\">652000</td><td style=\"text-align: right;\"> -306.52</td><td style=\"text-align: right;\">           -0.503512</td><td style=\"text-align: right;\">            -1792.61</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 660000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-08\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5035122220619553\n",
      "  episode_reward_mean: -388.0944310101997\n",
      "  episode_reward_min: -1742.7633872754936\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3300\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7437785863876343\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018082601949572563\n",
      "          model: {}\n",
      "          policy_loss: -0.036602262407541275\n",
      "          total_loss: 5048.36767578125\n",
      "          vf_explained_var: 0.8782656788825989\n",
      "          vf_loss: 5048.38330078125\n",
      "    num_agent_steps_sampled: 660000\n",
      "    num_agent_steps_trained: 660000\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 660000\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.6\n",
      "    ram_util_percent: 68.53999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07304177500893362\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10506465202075774\n",
      "    mean_inference_ms: 0.5119732848568769\n",
      "    mean_raw_obs_processing_ms: 0.049307600466327386\n",
      "  time_since_restore: 590.8231298923492\n",
      "  time_this_iter_s: 3.6938669681549072\n",
      "  time_total_s: 590.8231298923492\n",
      "  timers:\n",
      "    learn_throughput: 1766.983\n",
      "    learn_time_ms: 2263.746\n",
      "    load_throughput: 3606297.236\n",
      "    load_time_ms: 1.109\n",
      "    sample_throughput: 2398.104\n",
      "    sample_time_ms: 1667.984\n",
      "    update_time_ms: 1.465\n",
      "  timestamp: 1629485648\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 165\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   165</td><td style=\"text-align: right;\">         590.823</td><td style=\"text-align: right;\">660000</td><td style=\"text-align: right;\">-388.094</td><td style=\"text-align: right;\">           -0.503512</td><td style=\"text-align: right;\">            -1742.76</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 668000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-16\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5035122220619553\n",
      "  episode_reward_mean: -411.03829777938313\n",
      "  episode_reward_min: -1805.386641214468\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3340\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.7736090421676636\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008705724962055683\n",
      "          model: {}\n",
      "          policy_loss: -0.026969248428940773\n",
      "          total_loss: 2617.94384765625\n",
      "          vf_explained_var: 0.8607774972915649\n",
      "          vf_loss: 2617.960693359375\n",
      "    num_agent_steps_sampled: 668000\n",
      "    num_agent_steps_trained: 668000\n",
      "    num_steps_sampled: 668000\n",
      "    num_steps_trained: 668000\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.659999999999997\n",
      "    ram_util_percent: 67.38\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07320057495078025\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10526770509668375\n",
      "    mean_inference_ms: 0.513105788631345\n",
      "    mean_raw_obs_processing_ms: 0.04942228836195013\n",
      "  time_since_restore: 598.2238249778748\n",
      "  time_this_iter_s: 3.76971697807312\n",
      "  time_total_s: 598.2238249778748\n",
      "  timers:\n",
      "    learn_throughput: 1759.552\n",
      "    learn_time_ms: 2273.306\n",
      "    load_throughput: 3563857.592\n",
      "    load_time_ms: 1.122\n",
      "    sample_throughput: 2386.233\n",
      "    sample_time_ms: 1676.282\n",
      "    update_time_ms: 1.478\n",
      "  timestamp: 1629485656\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 668000\n",
      "  training_iteration: 167\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   167</td><td style=\"text-align: right;\">         598.224</td><td style=\"text-align: right;\">668000</td><td style=\"text-align: right;\">-411.038</td><td style=\"text-align: right;\">           -0.503512</td><td style=\"text-align: right;\">            -1805.39</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 676000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-23\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3894724863774517\n",
      "  episode_reward_mean: -364.46238876444676\n",
      "  episode_reward_min: -1805.386641214468\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3380\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.654144823551178\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01701219007372856\n",
      "          model: {}\n",
      "          policy_loss: -0.04695107415318489\n",
      "          total_loss: 763.7318115234375\n",
      "          vf_explained_var: 0.9163076281547546\n",
      "          vf_loss: 763.7593383789062\n",
      "    num_agent_steps_sampled: 676000\n",
      "    num_agent_steps_trained: 676000\n",
      "    num_steps_sampled: 676000\n",
      "    num_steps_trained: 676000\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.800000000000004\n",
      "    ram_util_percent: 68.18333333333334\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07329035554562066\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10538730582838475\n",
      "    mean_inference_ms: 0.5137869297248054\n",
      "    mean_raw_obs_processing_ms: 0.049484003808229655\n",
      "  time_since_restore: 605.5950253009796\n",
      "  time_this_iter_s: 3.634733200073242\n",
      "  time_total_s: 605.5950253009796\n",
      "  timers:\n",
      "    learn_throughput: 1761.883\n",
      "    learn_time_ms: 2270.298\n",
      "    load_throughput: 3534501.022\n",
      "    load_time_ms: 1.132\n",
      "    sample_throughput: 2376.139\n",
      "    sample_time_ms: 1683.403\n",
      "    update_time_ms: 1.483\n",
      "  timestamp: 1629485663\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 676000\n",
      "  training_iteration: 169\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   169</td><td style=\"text-align: right;\">         605.595</td><td style=\"text-align: right;\">676000</td><td style=\"text-align: right;\">-364.462</td><td style=\"text-align: right;\">           -0.389472</td><td style=\"text-align: right;\">            -1805.39</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 684000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-30\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3894724863774517\n",
      "  episode_reward_mean: -344.9317746860801\n",
      "  episode_reward_min: -1805.386641214468\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3420\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.7882096767425537\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013849077746272087\n",
      "          model: {}\n",
      "          policy_loss: -0.04154260829091072\n",
      "          total_loss: 863.0398559570312\n",
      "          vf_explained_var: 0.9423192739486694\n",
      "          vf_loss: 863.0656127929688\n",
      "    num_agent_steps_sampled: 684000\n",
      "    num_agent_steps_trained: 684000\n",
      "    num_steps_sampled: 684000\n",
      "    num_steps_trained: 684000\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.4\n",
      "    ram_util_percent: 67.92\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07331904049503177\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10542403965023789\n",
      "    mean_inference_ms: 0.5141095366967913\n",
      "    mean_raw_obs_processing_ms: 0.04949778590540582\n",
      "  time_since_restore: 612.8721354007721\n",
      "  time_this_iter_s: 3.682375907897949\n",
      "  time_total_s: 612.8721354007721\n",
      "  timers:\n",
      "    learn_throughput: 1754.885\n",
      "    learn_time_ms: 2279.352\n",
      "    load_throughput: 3501088.481\n",
      "    load_time_ms: 1.143\n",
      "    sample_throughput: 2376.972\n",
      "    sample_time_ms: 1682.813\n",
      "    update_time_ms: 1.465\n",
      "  timestamp: 1629485670\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 684000\n",
      "  training_iteration: 171\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   171</td><td style=\"text-align: right;\">         612.872</td><td style=\"text-align: right;\">684000</td><td style=\"text-align: right;\">-344.932</td><td style=\"text-align: right;\">           -0.389472</td><td style=\"text-align: right;\">            -1805.39</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 692000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-39\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5713932184144711\n",
      "  episode_reward_mean: -419.7507131007166\n",
      "  episode_reward_min: -1840.460248550385\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3460\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.9425163269042969\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015205838717520237\n",
      "          model: {}\n",
      "          policy_loss: -0.03855326771736145\n",
      "          total_loss: 3742.342529296875\n",
      "          vf_explained_var: 0.910480797290802\n",
      "          vf_loss: 3742.364013671875\n",
      "    num_agent_steps_sampled: 692000\n",
      "    num_agent_steps_trained: 692000\n",
      "    num_steps_sampled: 692000\n",
      "    num_steps_trained: 692000\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.82857142857143\n",
      "    ram_util_percent: 68.14285714285714\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07335425238163223\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10546838210469577\n",
      "    mean_inference_ms: 0.5144668781587887\n",
      "    mean_raw_obs_processing_ms: 0.04951874861251533\n",
      "  time_since_restore: 621.0832033157349\n",
      "  time_this_iter_s: 4.467513799667358\n",
      "  time_total_s: 621.0832033157349\n",
      "  timers:\n",
      "    learn_throughput: 1840.145\n",
      "    learn_time_ms: 2173.742\n",
      "    load_throughput: 4163597.469\n",
      "    load_time_ms: 0.961\n",
      "    sample_throughput: 2397.677\n",
      "    sample_time_ms: 1668.281\n",
      "    update_time_ms: 1.494\n",
      "  timestamp: 1629485679\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 692000\n",
      "  training_iteration: 173\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   173</td><td style=\"text-align: right;\">         621.083</td><td style=\"text-align: right;\">692000</td><td style=\"text-align: right;\">-419.751</td><td style=\"text-align: right;\">           -0.571393</td><td style=\"text-align: right;\">            -1840.46</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 700000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-46\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5713932184144711\n",
      "  episode_reward_mean: -424.4553669477875\n",
      "  episode_reward_min: -1840.460248550385\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3500\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.0744554996490479\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01430294569581747\n",
      "          model: {}\n",
      "          policy_loss: -0.04624783992767334\n",
      "          total_loss: 1670.20458984375\n",
      "          vf_explained_var: 0.9181616306304932\n",
      "          vf_loss: 1670.23486328125\n",
      "    num_agent_steps_sampled: 700000\n",
      "    num_agent_steps_trained: 700000\n",
      "    num_steps_sampled: 700000\n",
      "    num_steps_trained: 700000\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.4\n",
      "    ram_util_percent: 66.5\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07341210388764305\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10553995120015496\n",
      "    mean_inference_ms: 0.5149440762426939\n",
      "    mean_raw_obs_processing_ms: 0.049558548535979234\n",
      "  time_since_restore: 628.5681490898132\n",
      "  time_this_iter_s: 3.7753689289093018\n",
      "  time_total_s: 628.5681490898132\n",
      "  timers:\n",
      "    learn_throughput: 1853.626\n",
      "    learn_time_ms: 2157.933\n",
      "    load_throughput: 4258500.901\n",
      "    load_time_ms: 0.939\n",
      "    sample_throughput: 2485.074\n",
      "    sample_time_ms: 1609.61\n",
      "    update_time_ms: 1.504\n",
      "  timestamp: 1629485686\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 700000\n",
      "  training_iteration: 175\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   175</td><td style=\"text-align: right;\">         628.568</td><td style=\"text-align: right;\">700000</td><td style=\"text-align: right;\">-424.455</td><td style=\"text-align: right;\">           -0.571393</td><td style=\"text-align: right;\">            -1840.46</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 708000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-54\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1.024236947236682\n",
      "  episode_reward_mean: -442.42742380671297\n",
      "  episode_reward_min: -1771.0964883529466\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3540\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3762307167053223\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018532076850533485\n",
      "          model: {}\n",
      "          policy_loss: -0.04545290023088455\n",
      "          total_loss: 3635.40869140625\n",
      "          vf_explained_var: 0.8810557126998901\n",
      "          vf_loss: 3635.432861328125\n",
      "    num_agent_steps_sampled: 708000\n",
      "    num_agent_steps_trained: 708000\n",
      "    num_steps_sampled: 708000\n",
      "    num_steps_trained: 708000\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.060000000000002\n",
      "    ram_util_percent: 66.32\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07348942027980676\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1056403282720083\n",
      "    mean_inference_ms: 0.5154955098216657\n",
      "    mean_raw_obs_processing_ms: 0.04961585748457137\n",
      "  time_since_restore: 636.2481849193573\n",
      "  time_this_iter_s: 3.835089921951294\n",
      "  time_total_s: 636.2481849193573\n",
      "  timers:\n",
      "    learn_throughput: 1835.484\n",
      "    learn_time_ms: 2179.261\n",
      "    load_throughput: 4311800.565\n",
      "    load_time_ms: 0.928\n",
      "    sample_throughput: 2474.945\n",
      "    sample_time_ms: 1616.198\n",
      "    update_time_ms: 1.536\n",
      "  timestamp: 1629485694\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 708000\n",
      "  training_iteration: 177\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   177</td><td style=\"text-align: right;\">         636.248</td><td style=\"text-align: right;\">708000</td><td style=\"text-align: right;\">-442.427</td><td style=\"text-align: right;\">            -1.02424</td><td style=\"text-align: right;\">             -1771.1</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 716000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-01\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1.024236947236682\n",
      "  episode_reward_mean: -419.394836732181\n",
      "  episode_reward_min: -1752.7268506724101\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3580\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.8663357496261597\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01728653535246849\n",
      "          model: {}\n",
      "          policy_loss: -0.03381729871034622\n",
      "          total_loss: 3777.382080078125\n",
      "          vf_explained_var: 0.8947741389274597\n",
      "          vf_loss: 3777.396484375\n",
      "    num_agent_steps_sampled: 716000\n",
      "    num_agent_steps_trained: 716000\n",
      "    num_steps_sampled: 716000\n",
      "    num_steps_trained: 716000\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.339999999999996\n",
      "    ram_util_percent: 66.6\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07354031446112595\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10570853327456355\n",
      "    mean_inference_ms: 0.5158907712114847\n",
      "    mean_raw_obs_processing_ms: 0.04965174287584226\n",
      "  time_since_restore: 643.5089039802551\n",
      "  time_this_iter_s: 3.577075958251953\n",
      "  time_total_s: 643.5089039802551\n",
      "  timers:\n",
      "    learn_throughput: 1837.988\n",
      "    learn_time_ms: 2176.292\n",
      "    load_throughput: 4322576.456\n",
      "    load_time_ms: 0.925\n",
      "    sample_throughput: 2487.401\n",
      "    sample_time_ms: 1608.104\n",
      "    update_time_ms: 1.531\n",
      "  timestamp: 1629485701\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 716000\n",
      "  training_iteration: 179\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   179</td><td style=\"text-align: right;\">         643.509</td><td style=\"text-align: right;\">716000</td><td style=\"text-align: right;\">-419.395</td><td style=\"text-align: right;\">            -1.02424</td><td style=\"text-align: right;\">            -1752.73</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 724000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-09\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4980938105568903\n",
      "  episode_reward_mean: -405.3809569848612\n",
      "  episode_reward_min: -1752.7268506724101\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3620\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1243155002593994\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01688745990395546\n",
      "          model: {}\n",
      "          policy_loss: -0.04621937870979309\n",
      "          total_loss: 779.7901000976562\n",
      "          vf_explained_var: 0.9538249969482422\n",
      "          vf_loss: 779.8170166015625\n",
      "    num_agent_steps_sampled: 724000\n",
      "    num_agent_steps_trained: 724000\n",
      "    num_steps_sampled: 724000\n",
      "    num_steps_trained: 724000\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.449999999999996\n",
      "    ram_util_percent: 66.85000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07357007900754732\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10574987953328599\n",
      "    mean_inference_ms: 0.51615965305305\n",
      "    mean_raw_obs_processing_ms: 0.04967229511823116\n",
      "  time_since_restore: 651.2662155628204\n",
      "  time_this_iter_s: 3.973223924636841\n",
      "  time_total_s: 651.2662155628204\n",
      "  timers:\n",
      "    learn_throughput: 1807.89\n",
      "    learn_time_ms: 2212.524\n",
      "    load_throughput: 4402890.959\n",
      "    load_time_ms: 0.908\n",
      "    sample_throughput: 2469.393\n",
      "    sample_time_ms: 1619.831\n",
      "    update_time_ms: 1.607\n",
      "  timestamp: 1629485709\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 724000\n",
      "  training_iteration: 181\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   181</td><td style=\"text-align: right;\">         651.266</td><td style=\"text-align: right;\">724000</td><td style=\"text-align: right;\">-405.381</td><td style=\"text-align: right;\">           -0.498094</td><td style=\"text-align: right;\">            -1752.73</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 732000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-17\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4980938105568903\n",
      "  episode_reward_mean: -402.81989696980304\n",
      "  episode_reward_min: -1742.7077997978438\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3660\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.4922083616256714\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016712432727217674\n",
      "          model: {}\n",
      "          policy_loss: -0.039079971611499786\n",
      "          total_loss: 3917.011474609375\n",
      "          vf_explained_var: 0.8304048180580139\n",
      "          vf_loss: 3917.03173828125\n",
      "    num_agent_steps_sampled: 732000\n",
      "    num_agent_steps_trained: 732000\n",
      "    num_steps_sampled: 732000\n",
      "    num_steps_trained: 732000\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.61666666666667\n",
      "    ram_util_percent: 67.58333333333333\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07365875243581926\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10584955599181796\n",
      "    mean_inference_ms: 0.5168029598379507\n",
      "    mean_raw_obs_processing_ms: 0.049729789251298194\n",
      "  time_since_restore: 659.740784406662\n",
      "  time_this_iter_s: 4.117811918258667\n",
      "  time_total_s: 659.740784406662\n",
      "  timers:\n",
      "    learn_throughput: 1816.296\n",
      "    learn_time_ms: 2202.284\n",
      "    load_throughput: 4076295.252\n",
      "    load_time_ms: 0.981\n",
      "    sample_throughput: 2414.491\n",
      "    sample_time_ms: 1656.664\n",
      "    update_time_ms: 1.56\n",
      "  timestamp: 1629485717\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 732000\n",
      "  training_iteration: 183\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   183</td><td style=\"text-align: right;\">         659.741</td><td style=\"text-align: right;\">732000</td><td style=\"text-align: right;\"> -402.82</td><td style=\"text-align: right;\">           -0.498094</td><td style=\"text-align: right;\">            -1742.71</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 740000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-25\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6264160574374094\n",
      "  episode_reward_mean: -346.2275642612471\n",
      "  episode_reward_min: -1734.8318153402058\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3700\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.6092731356620789\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014912248589098454\n",
      "          model: {}\n",
      "          policy_loss: -0.03315157815814018\n",
      "          total_loss: 596.8392333984375\n",
      "          vf_explained_var: 0.8841275572776794\n",
      "          vf_loss: 596.8554077148438\n",
      "    num_agent_steps_sampled: 740000\n",
      "    num_agent_steps_trained: 740000\n",
      "    num_steps_sampled: 740000\n",
      "    num_steps_trained: 740000\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.48\n",
      "    ram_util_percent: 67.22\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07376206414201078\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10596652561217715\n",
      "    mean_inference_ms: 0.5174769868851439\n",
      "    mean_raw_obs_processing_ms: 0.04979681529229849\n",
      "  time_since_restore: 666.8033351898193\n",
      "  time_this_iter_s: 3.3522839546203613\n",
      "  time_total_s: 666.8033351898193\n",
      "  timers:\n",
      "    learn_throughput: 1831.168\n",
      "    learn_time_ms: 2184.398\n",
      "    load_throughput: 3584645.429\n",
      "    load_time_ms: 1.116\n",
      "    sample_throughput: 2450.935\n",
      "    sample_time_ms: 1632.03\n",
      "    update_time_ms: 1.593\n",
      "  timestamp: 1629485725\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 740000\n",
      "  training_iteration: 185\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   185</td><td style=\"text-align: right;\">         666.803</td><td style=\"text-align: right;\">740000</td><td style=\"text-align: right;\">-346.228</td><td style=\"text-align: right;\">           -0.626416</td><td style=\"text-align: right;\">            -1734.83</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 748000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-31\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6264160574374094\n",
      "  episode_reward_mean: -356.2098147036081\n",
      "  episode_reward_min: -1734.8318153402058\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3740\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.48390495777130127\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018819371238350868\n",
      "          model: {}\n",
      "          policy_loss: -0.04262881726026535\n",
      "          total_loss: 324.3163146972656\n",
      "          vf_explained_var: 0.932930052280426\n",
      "          vf_loss: 324.3375549316406\n",
      "    num_agent_steps_sampled: 748000\n",
      "    num_agent_steps_trained: 748000\n",
      "    num_steps_sampled: 748000\n",
      "    num_steps_trained: 748000\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.25\n",
      "    ram_util_percent: 67.325\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07378412652858235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10598693039274845\n",
      "    mean_inference_ms: 0.5175802620600575\n",
      "    mean_raw_obs_processing_ms: 0.049807315527613534\n",
      "  time_since_restore: 673.1313240528107\n",
      "  time_this_iter_s: 3.169794797897339\n",
      "  time_total_s: 673.1313240528107\n",
      "  timers:\n",
      "    learn_throughput: 1899.361\n",
      "    learn_time_ms: 2105.971\n",
      "    load_throughput: 3650633.418\n",
      "    load_time_ms: 1.096\n",
      "    sample_throughput: 2538.92\n",
      "    sample_time_ms: 1575.473\n",
      "    update_time_ms: 1.526\n",
      "  timestamp: 1629485731\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 748000\n",
      "  training_iteration: 187\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   187</td><td style=\"text-align: right;\">         673.131</td><td style=\"text-align: right;\">748000</td><td style=\"text-align: right;\"> -356.21</td><td style=\"text-align: right;\">           -0.626416</td><td style=\"text-align: right;\">            -1734.83</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 756000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-37\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.9512539474326712\n",
      "  episode_reward_mean: -413.49796869150833\n",
      "  episode_reward_min: -1725.818419001295\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3780\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3007590770721436\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015845274552702904\n",
      "          model: {}\n",
      "          policy_loss: -0.037518151104450226\n",
      "          total_loss: 2880.631103515625\n",
      "          vf_explained_var: 0.8675475120544434\n",
      "          vf_loss: 2880.650390625\n",
      "    num_agent_steps_sampled: 756000\n",
      "    num_agent_steps_trained: 756000\n",
      "    num_steps_sampled: 756000\n",
      "    num_steps_trained: 756000\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.924999999999997\n",
      "    ram_util_percent: 66.725\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07371505468269046\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10589561729905995\n",
      "    mean_inference_ms: 0.5170893330102853\n",
      "    mean_raw_obs_processing_ms: 0.04975119142927513\n",
      "  time_since_restore: 679.4645462036133\n",
      "  time_this_iter_s: 3.1936681270599365\n",
      "  time_total_s: 679.4645462036133\n",
      "  timers:\n",
      "    learn_throughput: 1950.752\n",
      "    learn_time_ms: 2050.491\n",
      "    load_throughput: 3683980.589\n",
      "    load_time_ms: 1.086\n",
      "    sample_throughput: 2600.125\n",
      "    sample_time_ms: 1538.388\n",
      "    update_time_ms: 1.49\n",
      "  timestamp: 1629485737\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 756000\n",
      "  training_iteration: 189\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   189</td><td style=\"text-align: right;\">         679.465</td><td style=\"text-align: right;\">756000</td><td style=\"text-align: right;\">-413.498</td><td style=\"text-align: right;\">           -0.951254</td><td style=\"text-align: right;\">            -1725.82</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 764000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-44\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6663595071827352\n",
      "  episode_reward_mean: -460.2685521715134\n",
      "  episode_reward_min: -1701.7328996429676\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3820\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.575251817703247\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013168114237487316\n",
      "          model: {}\n",
      "          policy_loss: -0.03643466532230377\n",
      "          total_loss: 3753.357666015625\n",
      "          vf_explained_var: 0.8669828772544861\n",
      "          vf_loss: 3753.378662109375\n",
      "    num_agent_steps_sampled: 764000\n",
      "    num_agent_steps_trained: 764000\n",
      "    num_steps_sampled: 764000\n",
      "    num_steps_trained: 764000\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.339999999999996\n",
      "    ram_util_percent: 65.82000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07363361131967527\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10578754691206584\n",
      "    mean_inference_ms: 0.5165305046369384\n",
      "    mean_raw_obs_processing_ms: 0.04968498094552183\n",
      "  time_since_restore: 686.3214800357819\n",
      "  time_this_iter_s: 3.4503870010375977\n",
      "  time_total_s: 686.3214800357819\n",
      "  timers:\n",
      "    learn_throughput: 2001.7\n",
      "    learn_time_ms: 1998.301\n",
      "    load_throughput: 3670520.697\n",
      "    load_time_ms: 1.09\n",
      "    sample_throughput: 2665.105\n",
      "    sample_time_ms: 1500.879\n",
      "    update_time_ms: 1.387\n",
      "  timestamp: 1629485744\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 764000\n",
      "  training_iteration: 191\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   191</td><td style=\"text-align: right;\">         686.321</td><td style=\"text-align: right;\">764000</td><td style=\"text-align: right;\">-460.269</td><td style=\"text-align: right;\">            -0.66636</td><td style=\"text-align: right;\">            -1701.73</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 772000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-51\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5932351993647459\n",
      "  episode_reward_mean: -428.9028202610844\n",
      "  episode_reward_min: -1725.2972101013158\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3860\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7862921953201294\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01735580898821354\n",
      "          model: {}\n",
      "          policy_loss: -0.04445483535528183\n",
      "          total_loss: 2173.98291015625\n",
      "          vf_explained_var: 0.9282838106155396\n",
      "          vf_loss: 2174.007568359375\n",
      "    num_agent_steps_sampled: 772000\n",
      "    num_agent_steps_trained: 772000\n",
      "    num_steps_sampled: 772000\n",
      "    num_steps_trained: 772000\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.1\n",
      "    ram_util_percent: 66.58\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0735796581540143\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10571890824663008\n",
      "    mean_inference_ms: 0.5161619939578729\n",
      "    mean_raw_obs_processing_ms: 0.04963979206169382\n",
      "  time_since_restore: 693.303943157196\n",
      "  time_this_iter_s: 3.628121852874756\n",
      "  time_total_s: 693.303943157196\n",
      "  timers:\n",
      "    learn_throughput: 2081.018\n",
      "    learn_time_ms: 1922.137\n",
      "    load_throughput: 4098801.915\n",
      "    load_time_ms: 0.976\n",
      "    sample_throughput: 2801.018\n",
      "    sample_time_ms: 1428.052\n",
      "    update_time_ms: 1.357\n",
      "  timestamp: 1629485751\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 772000\n",
      "  training_iteration: 193\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   193</td><td style=\"text-align: right;\">         693.304</td><td style=\"text-align: right;\">772000</td><td style=\"text-align: right;\">-428.903</td><td style=\"text-align: right;\">           -0.593235</td><td style=\"text-align: right;\">             -1725.3</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 780000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-58\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5932351993647459\n",
      "  episode_reward_mean: -415.2219456274296\n",
      "  episode_reward_min: -1725.2972101013158\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3900\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7569597959518433\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018201418220996857\n",
      "          model: {}\n",
      "          policy_loss: -0.041970767080783844\n",
      "          total_loss: 4297.71240234375\n",
      "          vf_explained_var: 0.8654174208641052\n",
      "          vf_loss: 4297.73291015625\n",
      "    num_agent_steps_sampled: 780000\n",
      "    num_agent_steps_trained: 780000\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 780000\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.54\n",
      "    ram_util_percent: 67.11999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07355889557013065\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10569760833019272\n",
      "    mean_inference_ms: 0.516011003298461\n",
      "    mean_raw_obs_processing_ms: 0.04962170026507764\n",
      "  time_since_restore: 700.4853012561798\n",
      "  time_this_iter_s: 3.874582052230835\n",
      "  time_total_s: 700.4853012561798\n",
      "  timers:\n",
      "    learn_throughput: 2064.91\n",
      "    learn_time_ms: 1937.131\n",
      "    load_throughput: 4625135.359\n",
      "    load_time_ms: 0.865\n",
      "    sample_throughput: 2806.434\n",
      "    sample_time_ms: 1425.296\n",
      "    update_time_ms: 1.285\n",
      "  timestamp: 1629485758\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 195\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   195</td><td style=\"text-align: right;\">         700.485</td><td style=\"text-align: right;\">780000</td><td style=\"text-align: right;\">-415.222</td><td style=\"text-align: right;\">           -0.593235</td><td style=\"text-align: right;\">             -1725.3</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 788000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-56-06\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.7387078663495701\n",
      "  episode_reward_mean: -396.37532088043884\n",
      "  episode_reward_min: -1725.2972101013158\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3940\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2612919807434082\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010852253995835781\n",
      "          model: {}\n",
      "          policy_loss: -0.037197984755039215\n",
      "          total_loss: 2075.14306640625\n",
      "          vf_explained_var: 0.8912317156791687\n",
      "          vf_loss: 2075.16796875\n",
      "    num_agent_steps_sampled: 788000\n",
      "    num_agent_steps_trained: 788000\n",
      "    num_steps_sampled: 788000\n",
      "    num_steps_trained: 788000\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.239999999999995\n",
      "    ram_util_percent: 67.1\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0735788652388084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10572786424876587\n",
      "    mean_inference_ms: 0.5161113668296405\n",
      "    mean_raw_obs_processing_ms: 0.04963742772143963\n",
      "  time_since_restore: 708.0835802555084\n",
      "  time_this_iter_s: 3.9144999980926514\n",
      "  time_total_s: 708.0835802555084\n",
      "  timers:\n",
      "    learn_throughput: 1998.432\n",
      "    learn_time_ms: 2001.57\n",
      "    load_throughput: 4559893.458\n",
      "    load_time_ms: 0.877\n",
      "    sample_throughput: 2688.743\n",
      "    sample_time_ms: 1487.684\n",
      "    update_time_ms: 1.34\n",
      "  timestamp: 1629485766\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 788000\n",
      "  training_iteration: 197\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   197</td><td style=\"text-align: right;\">         708.084</td><td style=\"text-align: right;\">788000</td><td style=\"text-align: right;\">-396.375</td><td style=\"text-align: right;\">           -0.738708</td><td style=\"text-align: right;\">             -1725.3</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 796000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-56-13\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.7387078663495701\n",
      "  episode_reward_mean: -335.3502902095717\n",
      "  episode_reward_min: -1717.1613038534406\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3980\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1089630126953125\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016304779797792435\n",
      "          model: {}\n",
      "          policy_loss: -0.04409853741526604\n",
      "          total_loss: 3114.7099609375\n",
      "          vf_explained_var: 0.789918839931488\n",
      "          vf_loss: 3114.735595703125\n",
      "    num_agent_steps_sampled: 796000\n",
      "    num_agent_steps_trained: 796000\n",
      "    num_steps_sampled: 796000\n",
      "    num_steps_trained: 796000\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.516666666666666\n",
      "    ram_util_percent: 66.56666666666666\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07360681310515012\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10576839922144814\n",
      "    mean_inference_ms: 0.516251280681646\n",
      "    mean_raw_obs_processing_ms: 0.04966218507280912\n",
      "  time_since_restore: 715.3529920578003\n",
      "  time_this_iter_s: 3.600825786590576\n",
      "  time_total_s: 715.3529920578003\n",
      "  timers:\n",
      "    learn_throughput: 1934.134\n",
      "    learn_time_ms: 2068.11\n",
      "    load_throughput: 4432553.765\n",
      "    load_time_ms: 0.902\n",
      "    sample_throughput: 2641.098\n",
      "    sample_time_ms: 1514.521\n",
      "    update_time_ms: 1.384\n",
      "  timestamp: 1629485773\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 796000\n",
      "  training_iteration: 199\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   199</td><td style=\"text-align: right;\">         715.353</td><td style=\"text-align: right;\">796000</td><td style=\"text-align: right;\"> -335.35</td><td style=\"text-align: right;\">           -0.738708</td><td style=\"text-align: right;\">            -1717.16</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 804000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-56-22\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1.4675639786346126\n",
      "  episode_reward_mean: -337.91408777699564\n",
      "  episode_reward_min: -1707.6165098933404\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4020\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.9313493967056274\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01894044689834118\n",
      "          model: {}\n",
      "          policy_loss: -0.04346625134348869\n",
      "          total_loss: 908.5494384765625\n",
      "          vf_explained_var: 0.8422393202781677\n",
      "          vf_loss: 908.5714111328125\n",
      "    num_agent_steps_sampled: 804000\n",
      "    num_agent_steps_trained: 804000\n",
      "    num_steps_sampled: 804000\n",
      "    num_steps_trained: 804000\n",
      "  iterations_since_restore: 201\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.785714285714285\n",
      "    ram_util_percent: 68.04285714285713\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07364359168586958\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10582049039268483\n",
      "    mean_inference_ms: 0.5164418085198084\n",
      "    mean_raw_obs_processing_ms: 0.04969723968553254\n",
      "  time_since_restore: 723.8820788860321\n",
      "  time_this_iter_s: 4.351891994476318\n",
      "  time_total_s: 723.8820788860321\n",
      "  timers:\n",
      "    learn_throughput: 1823.381\n",
      "    learn_time_ms: 2193.727\n",
      "    load_throughput: 4166803.1\n",
      "    load_time_ms: 0.96\n",
      "    sample_throughput: 2571.101\n",
      "    sample_time_ms: 1555.754\n",
      "    update_time_ms: 1.465\n",
      "  timestamp: 1629485782\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 804000\n",
      "  training_iteration: 201\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         723.882</td><td style=\"text-align: right;\">804000</td><td style=\"text-align: right;\">-337.914</td><td style=\"text-align: right;\">            -1.46756</td><td style=\"text-align: right;\">            -1707.62</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 808000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-56-28\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.998525084136713\n",
      "  episode_reward_mean: -330.5384884550906\n",
      "  episode_reward_min: -1640.8732397589874\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4040\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.9319899082183838\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010221939533948898\n",
      "          model: {}\n",
      "          policy_loss: -0.04612654820084572\n",
      "          total_loss: 520.7274780273438\n",
      "          vf_explained_var: 0.9480147361755371\n",
      "          vf_loss: 520.761962890625\n",
      "    num_agent_steps_sampled: 808000\n",
      "    num_agent_steps_trained: 808000\n",
      "    num_steps_sampled: 808000\n",
      "    num_steps_trained: 808000\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.150000000000006\n",
      "    ram_util_percent: 68.80000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07368444385085406\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10587321453932694\n",
      "    mean_inference_ms: 0.5166950908041191\n",
      "    mean_raw_obs_processing_ms: 0.04973103257247814\n",
      "  time_since_restore: 729.7095687389374\n",
      "  time_this_iter_s: 5.827489852905273\n",
      "  time_total_s: 729.7095687389374\n",
      "  timers:\n",
      "    learn_throughput: 1692.697\n",
      "    learn_time_ms: 2363.093\n",
      "    load_throughput: 3964370.51\n",
      "    load_time_ms: 1.009\n",
      "    sample_throughput: 2448.625\n",
      "    sample_time_ms: 1633.57\n",
      "    update_time_ms: 1.477\n",
      "  timestamp: 1629485788\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 808000\n",
      "  training_iteration: 202\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   202</td><td style=\"text-align: right;\">          729.71</td><td style=\"text-align: right;\">808000</td><td style=\"text-align: right;\">-330.538</td><td style=\"text-align: right;\">           -0.998525</td><td style=\"text-align: right;\">            -1640.87</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 816000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-56-38\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.643711586059994\n",
      "  episode_reward_mean: -393.4574893702662\n",
      "  episode_reward_min: -1782.4562019484815\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4080\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.5021989345550537\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012273138388991356\n",
      "          model: {}\n",
      "          policy_loss: -0.03584987670183182\n",
      "          total_loss: 8533.474609375\n",
      "          vf_explained_var: 0.8117124438285828\n",
      "          vf_loss: 8533.4892578125\n",
      "    num_agent_steps_sampled: 816000\n",
      "    num_agent_steps_trained: 816000\n",
      "    num_steps_sampled: 816000\n",
      "    num_steps_trained: 816000\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.82857142857143\n",
      "    ram_util_percent: 68.12857142857145\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07387473536198437\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10610892697575507\n",
      "    mean_inference_ms: 0.5179712992214185\n",
      "    mean_raw_obs_processing_ms: 0.049872165793683594\n",
      "  time_since_restore: 739.7876527309418\n",
      "  time_this_iter_s: 5.212205171585083\n",
      "  time_total_s: 739.7876527309418\n",
      "  timers:\n",
      "    learn_throughput: 1574.264\n",
      "    learn_time_ms: 2540.869\n",
      "    load_throughput: 3754720.14\n",
      "    load_time_ms: 1.065\n",
      "    sample_throughput: 2260.375\n",
      "    sample_time_ms: 1769.618\n",
      "    update_time_ms: 1.565\n",
      "  timestamp: 1629485798\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 816000\n",
      "  training_iteration: 204\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   204</td><td style=\"text-align: right;\">         739.788</td><td style=\"text-align: right;\">816000</td><td style=\"text-align: right;\">-393.457</td><td style=\"text-align: right;\">           -0.643712</td><td style=\"text-align: right;\">            -1782.46</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 824000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-56-47\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.643711586059994\n",
      "  episode_reward_mean: -414.2209251545864\n",
      "  episode_reward_min: -1782.4562019484815\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4120\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.5817409753799438\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013129107654094696\n",
      "          model: {}\n",
      "          policy_loss: -0.045049477368593216\n",
      "          total_loss: 3556.67724609375\n",
      "          vf_explained_var: 0.8627921342849731\n",
      "          vf_loss: 3556.700439453125\n",
      "    num_agent_steps_sampled: 824000\n",
      "    num_agent_steps_trained: 824000\n",
      "    num_steps_sampled: 824000\n",
      "    num_steps_trained: 824000\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.48333333333333\n",
      "    ram_util_percent: 67.71666666666668\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07416013495863005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10645886622771035\n",
      "    mean_inference_ms: 0.5199128815912907\n",
      "    mean_raw_obs_processing_ms: 0.05007766967446686\n",
      "  time_since_restore: 748.4746417999268\n",
      "  time_this_iter_s: 4.120248079299927\n",
      "  time_total_s: 748.4746417999268\n",
      "  timers:\n",
      "    learn_throughput: 1553.968\n",
      "    learn_time_ms: 2574.056\n",
      "    load_throughput: 3648648.602\n",
      "    load_time_ms: 1.096\n",
      "    sample_throughput: 2163.135\n",
      "    sample_time_ms: 1849.168\n",
      "    update_time_ms: 1.608\n",
      "  timestamp: 1629485807\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 824000\n",
      "  training_iteration: 206\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   206</td><td style=\"text-align: right;\">         748.475</td><td style=\"text-align: right;\">824000</td><td style=\"text-align: right;\">-414.221</td><td style=\"text-align: right;\">           -0.643712</td><td style=\"text-align: right;\">            -1782.46</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 832000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-56-54\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4851645941156901\n",
      "  episode_reward_mean: -461.3456050805496\n",
      "  episode_reward_min: -1782.4562019484815\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4160\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 3.1205251216888428\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012720542028546333\n",
      "          model: {}\n",
      "          policy_loss: -0.03862043470144272\n",
      "          total_loss: 7830.126953125\n",
      "          vf_explained_var: 0.851412296295166\n",
      "          vf_loss: 7830.14404296875\n",
      "    num_agent_steps_sampled: 832000\n",
      "    num_agent_steps_trained: 832000\n",
      "    num_steps_sampled: 832000\n",
      "    num_steps_trained: 832000\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.93333333333333\n",
      "    ram_util_percent: 67.41666666666667\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0743371172489385\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10668383521562745\n",
      "    mean_inference_ms: 0.5210971890528422\n",
      "    mean_raw_obs_processing_ms: 0.050209370152718764\n",
      "  time_since_restore: 756.1354508399963\n",
      "  time_this_iter_s: 4.023824214935303\n",
      "  time_total_s: 756.1354508399963\n",
      "  timers:\n",
      "    learn_throughput: 1536.868\n",
      "    learn_time_ms: 2602.696\n",
      "    load_throughput: 3659392.327\n",
      "    load_time_ms: 1.093\n",
      "    sample_throughput: 2188.204\n",
      "    sample_time_ms: 1827.983\n",
      "    update_time_ms: 1.721\n",
      "  timestamp: 1629485814\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 832000\n",
      "  training_iteration: 208\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   208</td><td style=\"text-align: right;\">         756.135</td><td style=\"text-align: right;\">832000</td><td style=\"text-align: right;\">-461.346</td><td style=\"text-align: right;\">           -0.485165</td><td style=\"text-align: right;\">            -1782.46</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 836000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-00\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4851645941156901\n",
      "  episode_reward_mean: -446.5404035816671\n",
      "  episode_reward_min: -1721.891140777082\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4180\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.8882673978805542\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01157415471971035\n",
      "          model: {}\n",
      "          policy_loss: -0.04678485915064812\n",
      "          total_loss: 4106.4462890625\n",
      "          vf_explained_var: 0.8765762448310852\n",
      "          vf_loss: 4106.47314453125\n",
      "    num_agent_steps_sampled: 836000\n",
      "    num_agent_steps_trained: 836000\n",
      "    num_steps_sampled: 836000\n",
      "    num_steps_trained: 836000\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.2625\n",
      "    ram_util_percent: 68.3375\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07444243530733698\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10681779256788781\n",
      "    mean_inference_ms: 0.5218232010606009\n",
      "    mean_raw_obs_processing_ms: 0.050287668759580136\n",
      "  time_since_restore: 762.0941278934479\n",
      "  time_this_iter_s: 5.958677053451538\n",
      "  time_total_s: 762.0941278934479\n",
      "  timers:\n",
      "    learn_throughput: 1484.377\n",
      "    learn_time_ms: 2694.732\n",
      "    load_throughput: 3629782.134\n",
      "    load_time_ms: 1.102\n",
      "    sample_throughput: 2028.864\n",
      "    sample_time_ms: 1971.547\n",
      "    update_time_ms: 1.772\n",
      "  timestamp: 1629485820\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 836000\n",
      "  training_iteration: 209\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   209</td><td style=\"text-align: right;\">         762.094</td><td style=\"text-align: right;\">836000</td><td style=\"text-align: right;\"> -446.54</td><td style=\"text-align: right;\">           -0.485165</td><td style=\"text-align: right;\">            -1721.89</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 840000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-06\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4851645941156901\n",
      "  episode_reward_mean: -423.6737503005936\n",
      "  episode_reward_min: -1721.891140777082\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4200\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.148950457572937\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009861799888312817\n",
      "          model: {}\n",
      "          policy_loss: -0.04267974942922592\n",
      "          total_loss: 2002.67822265625\n",
      "          vf_explained_var: 0.8684428334236145\n",
      "          vf_loss: 2002.703857421875\n",
      "    num_agent_steps_sampled: 840000\n",
      "    num_agent_steps_trained: 840000\n",
      "    num_steps_sampled: 840000\n",
      "    num_steps_trained: 840000\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.388888888888886\n",
      "    ram_util_percent: 68.46666666666665\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07455281732612153\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10695742066691315\n",
      "    mean_inference_ms: 0.5225808524655513\n",
      "    mean_raw_obs_processing_ms: 0.050369587167212855\n",
      "  time_since_restore: 767.9268867969513\n",
      "  time_this_iter_s: 5.832758903503418\n",
      "  time_total_s: 767.9268867969513\n",
      "  timers:\n",
      "    learn_throughput: 1441.1\n",
      "    learn_time_ms: 2775.658\n",
      "    load_throughput: 3566660.856\n",
      "    load_time_ms: 1.121\n",
      "    sample_throughput: 1945.762\n",
      "    sample_time_ms: 2055.75\n",
      "    update_time_ms: 1.891\n",
      "  timestamp: 1629485826\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 840000\n",
      "  training_iteration: 210\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   210</td><td style=\"text-align: right;\">         767.927</td><td style=\"text-align: right;\">840000</td><td style=\"text-align: right;\">-423.674</td><td style=\"text-align: right;\">           -0.485165</td><td style=\"text-align: right;\">            -1721.89</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 848000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-14\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.40470208769798016\n",
      "  episode_reward_mean: -485.5370130202897\n",
      "  episode_reward_min: -1723.1772305951688\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4240\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.17799973487854\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01395661011338234\n",
      "          model: {}\n",
      "          policy_loss: -0.04726429283618927\n",
      "          total_loss: 3654.28369140625\n",
      "          vf_explained_var: 0.8893581032752991\n",
      "          vf_loss: 3654.306884765625\n",
      "    num_agent_steps_sampled: 848000\n",
      "    num_agent_steps_trained: 848000\n",
      "    num_steps_sampled: 848000\n",
      "    num_steps_trained: 848000\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.9\n",
      "    ram_util_percent: 68.28\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07478280541630117\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10724571409769716\n",
      "    mean_inference_ms: 0.5241619251332271\n",
      "    mean_raw_obs_processing_ms: 0.05053869539486544\n",
      "  time_since_restore: 776.1009728908539\n",
      "  time_this_iter_s: 4.005574941635132\n",
      "  time_total_s: 776.1009728908539\n",
      "  timers:\n",
      "    learn_throughput: 1520.524\n",
      "    learn_time_ms: 2630.672\n",
      "    load_throughput: 3830064.834\n",
      "    load_time_ms: 1.044\n",
      "    sample_throughput: 1999.36\n",
      "    sample_time_ms: 2000.64\n",
      "    update_time_ms: 1.797\n",
      "  timestamp: 1629485834\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 848000\n",
      "  training_iteration: 212\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   212</td><td style=\"text-align: right;\">         776.101</td><td style=\"text-align: right;\">848000</td><td style=\"text-align: right;\">-485.537</td><td style=\"text-align: right;\">           -0.404702</td><td style=\"text-align: right;\">            -1723.18</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 856000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-22\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.40470208769798016\n",
      "  episode_reward_mean: -434.8148018625667\n",
      "  episode_reward_min: -1723.1772305951688\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4280\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.8777879476547241\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011590884067118168\n",
      "          model: {}\n",
      "          policy_loss: -0.04852188006043434\n",
      "          total_loss: 3369.28466796875\n",
      "          vf_explained_var: 0.8882917761802673\n",
      "          vf_loss: 3369.3134765625\n",
      "    num_agent_steps_sampled: 856000\n",
      "    num_agent_steps_trained: 856000\n",
      "    num_steps_sampled: 856000\n",
      "    num_steps_trained: 856000\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.08\n",
      "    ram_util_percent: 68.0\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07495822289788318\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1074662176063287\n",
      "    mean_inference_ms: 0.5253426840147525\n",
      "    mean_raw_obs_processing_ms: 0.05067028059690318\n",
      "  time_since_restore: 783.7933688163757\n",
      "  time_this_iter_s: 3.713252067565918\n",
      "  time_total_s: 783.7933688163757\n",
      "  timers:\n",
      "    learn_throughput: 1586.276\n",
      "    learn_time_ms: 2521.629\n",
      "    load_throughput: 4079566.201\n",
      "    load_time_ms: 0.98\n",
      "    sample_throughput: 2137.515\n",
      "    sample_time_ms: 1871.332\n",
      "    update_time_ms: 1.777\n",
      "  timestamp: 1629485842\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 856000\n",
      "  training_iteration: 214\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   214</td><td style=\"text-align: right;\">         783.793</td><td style=\"text-align: right;\">856000</td><td style=\"text-align: right;\">-434.815</td><td style=\"text-align: right;\">           -0.404702</td><td style=\"text-align: right;\">            -1723.18</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 864000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-30\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5607349408894178\n",
      "  episode_reward_mean: -429.7895049622719\n",
      "  episode_reward_min: -1723.1772305951688\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4320\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.6779365539550781\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013717212714254856\n",
      "          model: {}\n",
      "          policy_loss: -0.03797063231468201\n",
      "          total_loss: 4189.23046875\n",
      "          vf_explained_var: 0.8640437722206116\n",
      "          vf_loss: 4189.2451171875\n",
      "    num_agent_steps_sampled: 864000\n",
      "    num_agent_steps_trained: 864000\n",
      "    num_steps_sampled: 864000\n",
      "    num_steps_trained: 864000\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.42\n",
      "    ram_util_percent: 66.9\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07498636428880485\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10750978919869696\n",
      "    mean_inference_ms: 0.5254878286317508\n",
      "    mean_raw_obs_processing_ms: 0.05070192447902335\n",
      "  time_since_restore: 791.2349407672882\n",
      "  time_this_iter_s: 3.679172992706299\n",
      "  time_total_s: 791.2349407672882\n",
      "  timers:\n",
      "    learn_throughput: 1615.723\n",
      "    learn_time_ms: 2475.671\n",
      "    load_throughput: 4196612.137\n",
      "    load_time_ms: 0.953\n",
      "    sample_throughput: 2231.023\n",
      "    sample_time_ms: 1792.9\n",
      "    update_time_ms: 1.719\n",
      "  timestamp: 1629485850\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 864000\n",
      "  training_iteration: 216\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   216</td><td style=\"text-align: right;\">         791.235</td><td style=\"text-align: right;\">864000</td><td style=\"text-align: right;\"> -429.79</td><td style=\"text-align: right;\">           -0.560735</td><td style=\"text-align: right;\">            -1723.18</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 872000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-37\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5833403377885203\n",
      "  episode_reward_mean: -372.35874356085355\n",
      "  episode_reward_min: -1696.0342621879606\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4360\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.9977622032165527\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012432415969669819\n",
      "          model: {}\n",
      "          policy_loss: -0.05395560711622238\n",
      "          total_loss: 763.6900634765625\n",
      "          vf_explained_var: 0.9160614013671875\n",
      "          vf_loss: 763.7227172851562\n",
      "    num_agent_steps_sampled: 872000\n",
      "    num_agent_steps_trained: 872000\n",
      "    num_steps_sampled: 872000\n",
      "    num_steps_trained: 872000\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.52\n",
      "    ram_util_percent: 66.9\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07498249812333144\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10751548828964377\n",
      "    mean_inference_ms: 0.5254493409275647\n",
      "    mean_raw_obs_processing_ms: 0.05071069059586697\n",
      "  time_since_restore: 798.5300986766815\n",
      "  time_this_iter_s: 3.698718786239624\n",
      "  time_total_s: 798.5300986766815\n",
      "  timers:\n",
      "    learn_throughput: 1633.868\n",
      "    learn_time_ms: 2448.179\n",
      "    load_throughput: 4267274.392\n",
      "    load_time_ms: 0.937\n",
      "    sample_throughput: 2241.932\n",
      "    sample_time_ms: 1784.175\n",
      "    update_time_ms: 1.605\n",
      "  timestamp: 1629485857\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 872000\n",
      "  training_iteration: 218\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   218</td><td style=\"text-align: right;\">          798.53</td><td style=\"text-align: right;\">872000</td><td style=\"text-align: right;\">-372.359</td><td style=\"text-align: right;\">            -0.58334</td><td style=\"text-align: right;\">            -1696.03</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 880000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-46\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.491115817303045\n",
      "  episode_reward_mean: -420.82084569625215\n",
      "  episode_reward_min: -1742.680569741619\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4400\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.19242787361145\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011983662843704224\n",
      "          model: {}\n",
      "          policy_loss: -0.043575890362262726\n",
      "          total_loss: 3021.216796875\n",
      "          vf_explained_var: 0.9123699069023132\n",
      "          vf_loss: 3021.239990234375\n",
      "    num_agent_steps_sampled: 880000\n",
      "    num_agent_steps_trained: 880000\n",
      "    num_steps_sampled: 880000\n",
      "    num_steps_trained: 880000\n",
      "  iterations_since_restore: 220\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 43.88333333333333\n",
      "    ram_util_percent: 67.93333333333332\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07498531405140291\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10752790826893728\n",
      "    mean_inference_ms: 0.5254647183746998\n",
      "    mean_raw_obs_processing_ms: 0.05072260658779644\n",
      "  time_since_restore: 807.1213445663452\n",
      "  time_this_iter_s: 4.184781074523926\n",
      "  time_total_s: 807.1213445663452\n",
      "  timers:\n",
      "    learn_throughput: 1729.675\n",
      "    learn_time_ms: 2312.573\n",
      "    load_throughput: 4308589.332\n",
      "    load_time_ms: 0.928\n",
      "    sample_throughput: 2499.518\n",
      "    sample_time_ms: 1600.308\n",
      "    update_time_ms: 1.457\n",
      "  timestamp: 1629485866\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 880000\n",
      "  training_iteration: 220\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   220</td><td style=\"text-align: right;\">         807.121</td><td style=\"text-align: right;\">880000</td><td style=\"text-align: right;\">-420.821</td><td style=\"text-align: right;\">           -0.491116</td><td style=\"text-align: right;\">            -1742.68</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 888000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-53\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.38235600621524346\n",
      "  episode_reward_mean: -420.4279492497215\n",
      "  episode_reward_min: -1742.680569741619\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4440\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7697092294692993\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011625428684055805\n",
      "          model: {}\n",
      "          policy_loss: -0.04216347634792328\n",
      "          total_loss: 1492.9573974609375\n",
      "          vf_explained_var: 0.9502371549606323\n",
      "          vf_loss: 1492.9796142578125\n",
      "    num_agent_steps_sampled: 888000\n",
      "    num_agent_steps_trained: 888000\n",
      "    num_steps_sampled: 888000\n",
      "    num_steps_trained: 888000\n",
      "  iterations_since_restore: 222\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.68000000000001\n",
      "    ram_util_percent: 68.0\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07500110730406567\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10755612300526338\n",
      "    mean_inference_ms: 0.5255648733577666\n",
      "    mean_raw_obs_processing_ms: 0.05074176315957743\n",
      "  time_since_restore: 814.3302655220032\n",
      "  time_this_iter_s: 3.575655937194824\n",
      "  time_total_s: 814.3302655220032\n",
      "  timers:\n",
      "    learn_throughput: 1778.339\n",
      "    learn_time_ms: 2249.29\n",
      "    load_throughput: 4284054.951\n",
      "    load_time_ms: 0.934\n",
      "    sample_throughput: 2552.657\n",
      "    sample_time_ms: 1566.995\n",
      "    update_time_ms: 1.461\n",
      "  timestamp: 1629485873\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 888000\n",
      "  training_iteration: 222\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   222</td><td style=\"text-align: right;\">          814.33</td><td style=\"text-align: right;\">888000</td><td style=\"text-align: right;\">-420.428</td><td style=\"text-align: right;\">           -0.382356</td><td style=\"text-align: right;\">            -1742.68</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 896000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-01\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.37098508912918443\n",
      "  episode_reward_mean: -482.9566561446739\n",
      "  episode_reward_min: -1781.7745158731016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4480\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.4478700160980225\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010555516928434372\n",
      "          model: {}\n",
      "          policy_loss: -0.03495396301150322\n",
      "          total_loss: 6123.31787109375\n",
      "          vf_explained_var: 0.8578919172286987\n",
      "          vf_loss: 6123.33349609375\n",
      "    num_agent_steps_sampled: 896000\n",
      "    num_agent_steps_trained: 896000\n",
      "    num_steps_sampled: 896000\n",
      "    num_steps_trained: 896000\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 43.61666666666667\n",
      "    ram_util_percent: 67.75\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07504286518608107\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10761427858125026\n",
      "    mean_inference_ms: 0.5258255814505646\n",
      "    mean_raw_obs_processing_ms: 0.05077803763767432\n",
      "  time_since_restore: 822.3467071056366\n",
      "  time_this_iter_s: 4.184549808502197\n",
      "  time_total_s: 822.3467071056366\n",
      "  timers:\n",
      "    learn_throughput: 1778.804\n",
      "    learn_time_ms: 2248.702\n",
      "    load_throughput: 4350599.279\n",
      "    load_time_ms: 0.919\n",
      "    sample_throughput: 2499.977\n",
      "    sample_time_ms: 1600.015\n",
      "    update_time_ms: 1.449\n",
      "  timestamp: 1629485881\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 896000\n",
      "  training_iteration: 224\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   224</td><td style=\"text-align: right;\">         822.347</td><td style=\"text-align: right;\">896000</td><td style=\"text-align: right;\">-482.957</td><td style=\"text-align: right;\">           -0.370985</td><td style=\"text-align: right;\">            -1781.77</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 904000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-09\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.37098508912918443\n",
      "  episode_reward_mean: -510.0263501976933\n",
      "  episode_reward_min: -1781.7745158731016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4520\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.9314513206481934\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012401551939547062\n",
      "          model: {}\n",
      "          policy_loss: -0.04108237102627754\n",
      "          total_loss: 2733.919921875\n",
      "          vf_explained_var: 0.9001261591911316\n",
      "          vf_loss: 2733.93994140625\n",
      "    num_agent_steps_sampled: 904000\n",
      "    num_agent_steps_trained: 904000\n",
      "    num_steps_sampled: 904000\n",
      "    num_steps_trained: 904000\n",
      "  iterations_since_restore: 226\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.766666666666666\n",
      "    ram_util_percent: 67.31666666666668\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07509077621994625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10767516279446507\n",
      "    mean_inference_ms: 0.5261214250687875\n",
      "    mean_raw_obs_processing_ms: 0.050817371292445575\n",
      "  time_since_restore: 830.2454853057861\n",
      "  time_this_iter_s: 3.8559272289276123\n",
      "  time_total_s: 830.2454853057861\n",
      "  timers:\n",
      "    learn_throughput: 1762.979\n",
      "    learn_time_ms: 2268.887\n",
      "    load_throughput: 4318126.271\n",
      "    load_time_ms: 0.926\n",
      "    sample_throughput: 2460.747\n",
      "    sample_time_ms: 1625.523\n",
      "    update_time_ms: 1.44\n",
      "  timestamp: 1629485889\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 904000\n",
      "  training_iteration: 226\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   226</td><td style=\"text-align: right;\">         830.245</td><td style=\"text-align: right;\">904000</td><td style=\"text-align: right;\">-510.026</td><td style=\"text-align: right;\">           -0.370985</td><td style=\"text-align: right;\">            -1781.77</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 912000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-16\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.37098508912918443\n",
      "  episode_reward_mean: -482.7885712644875\n",
      "  episode_reward_min: -1772.7420557672751\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4560\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.058946132659912\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011392088606953621\n",
      "          model: {}\n",
      "          policy_loss: -0.04266643524169922\n",
      "          total_loss: 3766.876953125\n",
      "          vf_explained_var: 0.8861501812934875\n",
      "          vf_loss: 3766.89990234375\n",
      "    num_agent_steps_sampled: 912000\n",
      "    num_agent_steps_trained: 912000\n",
      "    num_steps_sampled: 912000\n",
      "    num_steps_trained: 912000\n",
      "  iterations_since_restore: 228\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.080000000000002\n",
      "    ram_util_percent: 67.4\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07515080822698733\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10774880907834478\n",
      "    mean_inference_ms: 0.5264984083799326\n",
      "    mean_raw_obs_processing_ms: 0.05086323155815691\n",
      "  time_since_restore: 837.6712353229523\n",
      "  time_this_iter_s: 3.7020230293273926\n",
      "  time_total_s: 837.6712353229523\n",
      "  timers:\n",
      "    learn_throughput: 1759.521\n",
      "    learn_time_ms: 2273.346\n",
      "    load_throughput: 4260555.64\n",
      "    load_time_ms: 0.939\n",
      "    sample_throughput: 2447.792\n",
      "    sample_time_ms: 1634.125\n",
      "    update_time_ms: 1.433\n",
      "  timestamp: 1629485896\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 912000\n",
      "  training_iteration: 228\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   228</td><td style=\"text-align: right;\">         837.671</td><td style=\"text-align: right;\">912000</td><td style=\"text-align: right;\">-482.789</td><td style=\"text-align: right;\">           -0.370985</td><td style=\"text-align: right;\">            -1772.74</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 920000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-24\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2.7204435411331382\n",
      "  episode_reward_mean: -444.84818752235793\n",
      "  episode_reward_min: -1742.3465338695794\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4600\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.7210471630096436\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018152691423892975\n",
      "          model: {}\n",
      "          policy_loss: -0.05257149413228035\n",
      "          total_loss: 5376.673828125\n",
      "          vf_explained_var: 0.8682278394699097\n",
      "          vf_loss: 5376.69580078125\n",
      "    num_agent_steps_sampled: 920000\n",
      "    num_agent_steps_trained: 920000\n",
      "    num_steps_sampled: 920000\n",
      "    num_steps_trained: 920000\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.7\n",
      "    ram_util_percent: 67.25999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07516464264613942\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10777105056416342\n",
      "    mean_inference_ms: 0.5266055136863685\n",
      "    mean_raw_obs_processing_ms: 0.05087658789547854\n",
      "  time_since_restore: 845.3861594200134\n",
      "  time_this_iter_s: 3.8328001499176025\n",
      "  time_total_s: 845.3861594200134\n",
      "  timers:\n",
      "    learn_throughput: 1803.706\n",
      "    learn_time_ms: 2217.656\n",
      "    load_throughput: 4316348.761\n",
      "    load_time_ms: 0.927\n",
      "    sample_throughput: 2496.485\n",
      "    sample_time_ms: 1602.253\n",
      "    update_time_ms: 1.413\n",
      "  timestamp: 1629485904\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 920000\n",
      "  training_iteration: 230\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   230</td><td style=\"text-align: right;\">         845.386</td><td style=\"text-align: right;\">920000</td><td style=\"text-align: right;\">-444.848</td><td style=\"text-align: right;\">            -2.72044</td><td style=\"text-align: right;\">            -1742.35</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 928000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-31\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.524659172960005\n",
      "  episode_reward_mean: -442.16642688144617\n",
      "  episode_reward_min: -1708.6523850329477\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4640\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.8590129613876343\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013450021855533123\n",
      "          model: {}\n",
      "          policy_loss: -0.03631405159831047\n",
      "          total_loss: 3411.929443359375\n",
      "          vf_explained_var: 0.8695670366287231\n",
      "          vf_loss: 3411.943359375\n",
      "    num_agent_steps_sampled: 928000\n",
      "    num_agent_steps_trained: 928000\n",
      "    num_steps_sampled: 928000\n",
      "    num_steps_trained: 928000\n",
      "  iterations_since_restore: 232\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.279999999999994\n",
      "    ram_util_percent: 67.3\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07515582098616573\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10776773831322012\n",
      "    mean_inference_ms: 0.5265767369985661\n",
      "    mean_raw_obs_processing_ms: 0.050873557044482876\n",
      "  time_since_restore: 852.5952613353729\n",
      "  time_this_iter_s: 3.597775936126709\n",
      "  time_total_s: 852.5952613353729\n",
      "  timers:\n",
      "    learn_throughput: 1808.87\n",
      "    learn_time_ms: 2211.325\n",
      "    load_throughput: 4362250.65\n",
      "    load_time_ms: 0.917\n",
      "    sample_throughput: 2486.508\n",
      "    sample_time_ms: 1608.682\n",
      "    update_time_ms: 1.414\n",
      "  timestamp: 1629485911\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 928000\n",
      "  training_iteration: 232\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   232</td><td style=\"text-align: right;\">         852.595</td><td style=\"text-align: right;\">928000</td><td style=\"text-align: right;\">-442.166</td><td style=\"text-align: right;\">           -0.524659</td><td style=\"text-align: right;\">            -1708.65</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 936000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-39\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.524659172960005\n",
      "  episode_reward_mean: -492.53260817734065\n",
      "  episode_reward_min: -1701.6773206832497\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4680\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.9117308855056763\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011648512445390224\n",
      "          model: {}\n",
      "          policy_loss: -0.04716913402080536\n",
      "          total_loss: 3653.754150390625\n",
      "          vf_explained_var: 0.8790267705917358\n",
      "          vf_loss: 3653.78125\n",
      "    num_agent_steps_sampled: 936000\n",
      "    num_agent_steps_trained: 936000\n",
      "    num_steps_sampled: 936000\n",
      "    num_steps_trained: 936000\n",
      "  iterations_since_restore: 234\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.540000000000006\n",
      "    ram_util_percent: 66.75999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07514473732085189\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10775988734470365\n",
      "    mean_inference_ms: 0.5265492266512933\n",
      "    mean_raw_obs_processing_ms: 0.050867931278879654\n",
      "  time_since_restore: 859.9015703201294\n",
      "  time_this_iter_s: 3.691873073577881\n",
      "  time_total_s: 859.9015703201294\n",
      "  timers:\n",
      "    learn_throughput: 1827.838\n",
      "    learn_time_ms: 2188.378\n",
      "    load_throughput: 4375219.319\n",
      "    load_time_ms: 0.914\n",
      "    sample_throughput: 2562.983\n",
      "    sample_time_ms: 1560.681\n",
      "    update_time_ms: 1.416\n",
      "  timestamp: 1629485919\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 936000\n",
      "  training_iteration: 234\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   234</td><td style=\"text-align: right;\">         859.902</td><td style=\"text-align: right;\">936000</td><td style=\"text-align: right;\">-492.533</td><td style=\"text-align: right;\">           -0.524659</td><td style=\"text-align: right;\">            -1701.68</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 944000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-46\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5096034328184365\n",
      "  episode_reward_mean: -434.06124234777434\n",
      "  episode_reward_min: -1688.304994277736\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4720\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.3112857341766357\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012361150234937668\n",
      "          model: {}\n",
      "          policy_loss: -0.04596623033285141\n",
      "          total_loss: 6604.7685546875\n",
      "          vf_explained_var: 0.8238652944564819\n",
      "          vf_loss: 6604.79345703125\n",
      "    num_agent_steps_sampled: 944000\n",
      "    num_agent_steps_trained: 944000\n",
      "    num_steps_sampled: 944000\n",
      "    num_steps_trained: 944000\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.64\n",
      "    ram_util_percent: 67.92\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07514099680074043\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1077613516666329\n",
      "    mean_inference_ms: 0.5265570309514586\n",
      "    mean_raw_obs_processing_ms: 0.05086735103181961\n",
      "  time_since_restore: 867.5496203899384\n",
      "  time_this_iter_s: 3.6351561546325684\n",
      "  time_total_s: 867.5496203899384\n",
      "  timers:\n",
      "    learn_throughput: 1836.891\n",
      "    learn_time_ms: 2177.593\n",
      "    load_throughput: 4542116.577\n",
      "    load_time_ms: 0.881\n",
      "    sample_throughput: 2586.605\n",
      "    sample_time_ms: 1546.429\n",
      "    update_time_ms: 1.424\n",
      "  timestamp: 1629485926\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 944000\n",
      "  training_iteration: 236\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   236</td><td style=\"text-align: right;\">          867.55</td><td style=\"text-align: right;\">944000</td><td style=\"text-align: right;\">-434.061</td><td style=\"text-align: right;\">           -0.509603</td><td style=\"text-align: right;\">             -1688.3</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 952000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-54\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5096034328184365\n",
      "  episode_reward_mean: -432.3432689327599\n",
      "  episode_reward_min: -1703.6412852961519\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4760\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.9917908906936646\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018740421161055565\n",
      "          model: {}\n",
      "          policy_loss: -0.05492956563830376\n",
      "          total_loss: 3218.538330078125\n",
      "          vf_explained_var: 0.9154919385910034\n",
      "          vf_loss: 3218.561279296875\n",
      "    num_agent_steps_sampled: 952000\n",
      "    num_agent_steps_trained: 952000\n",
      "    num_steps_sampled: 952000\n",
      "    num_steps_trained: 952000\n",
      "  iterations_since_restore: 238\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.050000000000004\n",
      "    ram_util_percent: 68.03333333333333\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.075137370066784\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10776293435912869\n",
      "    mean_inference_ms: 0.526560788043966\n",
      "    mean_raw_obs_processing_ms: 0.050867014843420454\n",
      "  time_since_restore: 875.0438809394836\n",
      "  time_this_iter_s: 3.84354567527771\n",
      "  time_total_s: 875.0438809394836\n",
      "  timers:\n",
      "    learn_throughput: 1829.335\n",
      "    learn_time_ms: 2186.587\n",
      "    load_throughput: 4633694.037\n",
      "    load_time_ms: 0.863\n",
      "    sample_throughput: 2590.145\n",
      "    sample_time_ms: 1544.315\n",
      "    update_time_ms: 1.438\n",
      "  timestamp: 1629485934\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 952000\n",
      "  training_iteration: 238\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   238</td><td style=\"text-align: right;\">         875.044</td><td style=\"text-align: right;\">952000</td><td style=\"text-align: right;\">-432.343</td><td style=\"text-align: right;\">           -0.509603</td><td style=\"text-align: right;\">            -1703.64</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 960000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-01\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5096034328184365\n",
      "  episode_reward_mean: -515.9531829189144\n",
      "  episode_reward_min: -1762.3615926464388\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4800\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 3.0786020755767822\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012069487944245338\n",
      "          model: {}\n",
      "          policy_loss: -0.038057632744312286\n",
      "          total_loss: 6750.1220703125\n",
      "          vf_explained_var: 0.8567359447479248\n",
      "          vf_loss: 6750.138671875\n",
      "    num_agent_steps_sampled: 960000\n",
      "    num_agent_steps_trained: 960000\n",
      "    num_steps_sampled: 960000\n",
      "    num_steps_trained: 960000\n",
      "  iterations_since_restore: 240\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.339999999999996\n",
      "    ram_util_percent: 67.75999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07513501581623185\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10776851722715179\n",
      "    mean_inference_ms: 0.5265681278553648\n",
      "    mean_raw_obs_processing_ms: 0.05086960347899618\n",
      "  time_since_restore: 882.4591779708862\n",
      "  time_this_iter_s: 3.653186082839966\n",
      "  time_total_s: 882.4591779708862\n",
      "  timers:\n",
      "    learn_throughput: 1855.555\n",
      "    learn_time_ms: 2155.689\n",
      "    load_throughput: 4731841.155\n",
      "    load_time_ms: 0.845\n",
      "    sample_throughput: 2588.766\n",
      "    sample_time_ms: 1545.138\n",
      "    update_time_ms: 1.47\n",
      "  timestamp: 1629485941\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 960000\n",
      "  training_iteration: 240\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   240</td><td style=\"text-align: right;\">         882.459</td><td style=\"text-align: right;\">960000</td><td style=\"text-align: right;\">-515.953</td><td style=\"text-align: right;\">           -0.509603</td><td style=\"text-align: right;\">            -1762.36</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 968000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-09\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4859573968954919\n",
      "  episode_reward_mean: -501.6959145207246\n",
      "  episode_reward_min: -1787.3999017444694\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4840\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.5437878370285034\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011585949920117855\n",
      "          model: {}\n",
      "          policy_loss: -0.04287157952785492\n",
      "          total_loss: 2043.4444580078125\n",
      "          vf_explained_var: 0.9004544019699097\n",
      "          vf_loss: 2043.467529296875\n",
      "    num_agent_steps_sampled: 968000\n",
      "    num_agent_steps_trained: 968000\n",
      "    num_steps_sampled: 968000\n",
      "    num_steps_trained: 968000\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.38\n",
      "    ram_util_percent: 67.74000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0751273499220401\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10776554507142495\n",
      "    mean_inference_ms: 0.5265598528816514\n",
      "    mean_raw_obs_processing_ms: 0.05086794332483929\n",
      "  time_since_restore: 889.7342500686646\n",
      "  time_this_iter_s: 3.5736660957336426\n",
      "  time_total_s: 889.7342500686646\n",
      "  timers:\n",
      "    learn_throughput: 1850.933\n",
      "    learn_time_ms: 2161.073\n",
      "    load_throughput: 4776567.589\n",
      "    load_time_ms: 0.837\n",
      "    sample_throughput: 2586.744\n",
      "    sample_time_ms: 1546.345\n",
      "    update_time_ms: 1.474\n",
      "  timestamp: 1629485949\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 968000\n",
      "  training_iteration: 242\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   242</td><td style=\"text-align: right;\">         889.734</td><td style=\"text-align: right;\">968000</td><td style=\"text-align: right;\">-501.696</td><td style=\"text-align: right;\">           -0.485957</td><td style=\"text-align: right;\">             -1787.4</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 976000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-16\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4859573968954919\n",
      "  episode_reward_mean: -524.0239088111454\n",
      "  episode_reward_min: -1787.3999017444694\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4880\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.698204278945923\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014877956360578537\n",
      "          model: {}\n",
      "          policy_loss: -0.04541883245110512\n",
      "          total_loss: 6345.044921875\n",
      "          vf_explained_var: 0.8227539658546448\n",
      "          vf_loss: 6345.06494140625\n",
      "    num_agent_steps_sampled: 976000\n",
      "    num_agent_steps_trained: 976000\n",
      "    num_steps_sampled: 976000\n",
      "    num_steps_trained: 976000\n",
      "  iterations_since_restore: 244\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.2\n",
      "    ram_util_percent: 67.8\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07511785259350388\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10775910140224243\n",
      "    mean_inference_ms: 0.5265370535172909\n",
      "    mean_raw_obs_processing_ms: 0.05086423255829826\n",
      "  time_since_restore: 897.0053458213806\n",
      "  time_this_iter_s: 3.580742835998535\n",
      "  time_total_s: 897.0053458213806\n",
      "  timers:\n",
      "    learn_throughput: 1854.452\n",
      "    learn_time_ms: 2156.971\n",
      "    load_throughput: 4717471.6\n",
      "    load_time_ms: 0.848\n",
      "    sample_throughput: 2585.755\n",
      "    sample_time_ms: 1546.937\n",
      "    update_time_ms: 1.49\n",
      "  timestamp: 1629485956\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 976000\n",
      "  training_iteration: 244\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   244</td><td style=\"text-align: right;\">         897.005</td><td style=\"text-align: right;\">976000</td><td style=\"text-align: right;\">-524.024</td><td style=\"text-align: right;\">           -0.485957</td><td style=\"text-align: right;\">             -1787.4</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 984000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-23\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.7765879538673393\n",
      "  episode_reward_mean: -450.4156897296482\n",
      "  episode_reward_min: -1768.1226138890452\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4920\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7089354991912842\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010718145407736301\n",
      "          model: {}\n",
      "          policy_loss: -0.04870002344250679\n",
      "          total_loss: 2852.10888671875\n",
      "          vf_explained_var: 0.859673023223877\n",
      "          vf_loss: 2852.139404296875\n",
      "    num_agent_steps_sampled: 984000\n",
      "    num_agent_steps_trained: 984000\n",
      "    num_steps_sampled: 984000\n",
      "    num_steps_trained: 984000\n",
      "  iterations_since_restore: 246\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.1\n",
      "    ram_util_percent: 67.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07509239649339192\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10773271816846922\n",
      "    mean_inference_ms: 0.5264346940025011\n",
      "    mean_raw_obs_processing_ms: 0.05084850686521069\n",
      "  time_since_restore: 904.1703455448151\n",
      "  time_this_iter_s: 3.5497288703918457\n",
      "  time_total_s: 904.1703455448151\n",
      "  timers:\n",
      "    learn_throughput: 1874.958\n",
      "    learn_time_ms: 2133.381\n",
      "    load_throughput: 4600152.45\n",
      "    load_time_ms: 0.87\n",
      "    sample_throughput: 2627.7\n",
      "    sample_time_ms: 1522.244\n",
      "    update_time_ms: 1.502\n",
      "  timestamp: 1629485963\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 984000\n",
      "  training_iteration: 246\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   246</td><td style=\"text-align: right;\">          904.17</td><td style=\"text-align: right;\">984000</td><td style=\"text-align: right;\">-450.416</td><td style=\"text-align: right;\">           -0.776588</td><td style=\"text-align: right;\">            -1768.12</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 992000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-30\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.7765879538673393\n",
      "  episode_reward_mean: -430.0051474475684\n",
      "  episode_reward_min: -1768.1226138890452\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4960\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.603823184967041\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0142340874299407\n",
      "          model: {}\n",
      "          policy_loss: -0.036697667092084885\n",
      "          total_loss: 5219.11474609375\n",
      "          vf_explained_var: 0.8730764985084534\n",
      "          vf_loss: 5219.1279296875\n",
      "    num_agent_steps_sampled: 992000\n",
      "    num_agent_steps_trained: 992000\n",
      "    num_steps_sampled: 992000\n",
      "    num_steps_trained: 992000\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.44\n",
      "    ram_util_percent: 67.38000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0750632933545619\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10770286419671227\n",
      "    mean_inference_ms: 0.5263058762150784\n",
      "    mean_raw_obs_processing_ms: 0.05083243712697413\n",
      "  time_since_restore: 911.3735752105713\n",
      "  time_this_iter_s: 3.594831705093384\n",
      "  time_total_s: 911.3735752105713\n",
      "  timers:\n",
      "    learn_throughput: 1899.807\n",
      "    learn_time_ms: 2105.477\n",
      "    load_throughput: 4414940.659\n",
      "    load_time_ms: 0.906\n",
      "    sample_throughput: 2629.853\n",
      "    sample_time_ms: 1520.997\n",
      "    update_time_ms: 1.481\n",
      "  timestamp: 1629485970\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 992000\n",
      "  training_iteration: 248\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   248</td><td style=\"text-align: right;\">         911.374</td><td style=\"text-align: right;\">992000</td><td style=\"text-align: right;\">-430.005</td><td style=\"text-align: right;\">           -0.776588</td><td style=\"text-align: right;\">            -1768.12</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1000000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-38\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1.092416319749448\n",
      "  episode_reward_mean: -396.68472084803636\n",
      "  episode_reward_min: -1706.1045476478896\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5000\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7113450765609741\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012752948328852654\n",
      "          model: {}\n",
      "          policy_loss: -0.0448153093457222\n",
      "          total_loss: 2837.4404296875\n",
      "          vf_explained_var: 0.8846222162246704\n",
      "          vf_loss: 2837.46337890625\n",
      "    num_agent_steps_sampled: 1000000\n",
      "    num_agent_steps_trained: 1000000\n",
      "    num_steps_sampled: 1000000\n",
      "    num_steps_trained: 1000000\n",
      "  iterations_since_restore: 250\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.98333333333333\n",
      "    ram_util_percent: 67.43333333333334\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0750558009113478\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10770014851078409\n",
      "    mean_inference_ms: 0.5263101733720836\n",
      "    mean_raw_obs_processing_ms: 0.05083429310174261\n",
      "  time_since_restore: 918.9597401618958\n",
      "  time_this_iter_s: 3.77091383934021\n",
      "  time_total_s: 918.9597401618958\n",
      "  timers:\n",
      "    learn_throughput: 1900.876\n",
      "    learn_time_ms: 2104.293\n",
      "    load_throughput: 4393896.76\n",
      "    load_time_ms: 0.91\n",
      "    sample_throughput: 2598.414\n",
      "    sample_time_ms: 1539.401\n",
      "    update_time_ms: 1.451\n",
      "  timestamp: 1629485978\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1000000\n",
      "  training_iteration: 250\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">          918.96</td><td style=\"text-align: right;\">1000000</td><td style=\"text-align: right;\">-396.685</td><td style=\"text-align: right;\">            -1.09242</td><td style=\"text-align: right;\">             -1706.1</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1008000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-45\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5779007219262546\n",
      "  episode_reward_mean: -466.3055574845304\n",
      "  episode_reward_min: -1723.9865976156811\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5040\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 3.512138605117798\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012688427232205868\n",
      "          model: {}\n",
      "          policy_loss: -0.040724992752075195\n",
      "          total_loss: 10429.962890625\n",
      "          vf_explained_var: 0.8005675077438354\n",
      "          vf_loss: 10429.98046875\n",
      "    num_agent_steps_sampled: 1008000\n",
      "    num_agent_steps_trained: 1008000\n",
      "    num_steps_sampled: 1008000\n",
      "    num_steps_trained: 1008000\n",
      "  iterations_since_restore: 252\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.839999999999996\n",
      "    ram_util_percent: 67.42\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0750627366537666\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10771259404660133\n",
      "    mean_inference_ms: 0.5263956410148044\n",
      "    mean_raw_obs_processing_ms: 0.050844161256603716\n",
      "  time_since_restore: 926.2322890758514\n",
      "  time_this_iter_s: 3.667091131210327\n",
      "  time_total_s: 926.2322890758514\n",
      "  timers:\n",
      "    learn_throughput: 1902.682\n",
      "    learn_time_ms: 2102.296\n",
      "    load_throughput: 4409023.442\n",
      "    load_time_ms: 0.907\n",
      "    sample_throughput: 2595.447\n",
      "    sample_time_ms: 1541.16\n",
      "    update_time_ms: 1.451\n",
      "  timestamp: 1629485985\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1008000\n",
      "  training_iteration: 252\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   252</td><td style=\"text-align: right;\">         926.232</td><td style=\"text-align: right;\">1008000</td><td style=\"text-align: right;\">-466.306</td><td style=\"text-align: right;\">           -0.577901</td><td style=\"text-align: right;\">            -1723.99</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1016000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-52\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5779007219262546\n",
      "  episode_reward_mean: -393.8844554679835\n",
      "  episode_reward_min: -1809.4552244633817\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5080\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.0873383283615112\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01715308614075184\n",
      "          model: {}\n",
      "          policy_loss: -0.047008391469717026\n",
      "          total_loss: 846.0406494140625\n",
      "          vf_explained_var: 0.890026330947876\n",
      "          vf_loss: 846.0584716796875\n",
      "    num_agent_steps_sampled: 1016000\n",
      "    num_agent_steps_trained: 1016000\n",
      "    num_steps_sampled: 1016000\n",
      "    num_steps_trained: 1016000\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.739999999999995\n",
      "    ram_util_percent: 67.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07506269491284401\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10771635834032853\n",
      "    mean_inference_ms: 0.5264461417090909\n",
      "    mean_raw_obs_processing_ms: 0.05084672528400458\n",
      "  time_since_restore: 933.4089510440826\n",
      "  time_this_iter_s: 3.57391095161438\n",
      "  time_total_s: 933.4089510440826\n",
      "  timers:\n",
      "    learn_throughput: 1908.394\n",
      "    learn_time_ms: 2096.003\n",
      "    load_throughput: 4431031.878\n",
      "    load_time_ms: 0.903\n",
      "    sample_throughput: 2601.038\n",
      "    sample_time_ms: 1537.848\n",
      "    update_time_ms: 1.495\n",
      "  timestamp: 1629485992\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1016000\n",
      "  training_iteration: 254\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   254</td><td style=\"text-align: right;\">         933.409</td><td style=\"text-align: right;\">1016000</td><td style=\"text-align: right;\">-393.884</td><td style=\"text-align: right;\">           -0.577901</td><td style=\"text-align: right;\">            -1809.46</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1024000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-00\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.61433177417204\n",
      "  episode_reward_mean: -466.3821209909292\n",
      "  episode_reward_min: -1809.4552244633817\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5120\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 3.335404872894287\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013441285118460655\n",
      "          model: {}\n",
      "          policy_loss: -0.04106750711798668\n",
      "          total_loss: 8219.513671875\n",
      "          vf_explained_var: 0.8317705392837524\n",
      "          vf_loss: 8219.5302734375\n",
      "    num_agent_steps_sampled: 1024000\n",
      "    num_agent_steps_trained: 1024000\n",
      "    num_steps_sampled: 1024000\n",
      "    num_steps_trained: 1024000\n",
      "  iterations_since_restore: 256\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.160000000000004\n",
      "    ram_util_percent: 67.96000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07504224258727954\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10769539111706429\n",
      "    mean_inference_ms: 0.5263742113259754\n",
      "    mean_raw_obs_processing_ms: 0.05083409257896209\n",
      "  time_since_restore: 940.7449221611023\n",
      "  time_this_iter_s: 3.624652147293091\n",
      "  time_total_s: 940.7449221611023\n",
      "  timers:\n",
      "    learn_throughput: 1896.622\n",
      "    learn_time_ms: 2109.013\n",
      "    load_throughput: 4331728.073\n",
      "    load_time_ms: 0.923\n",
      "    sample_throughput: 2594.228\n",
      "    sample_time_ms: 1541.885\n",
      "    update_time_ms: 1.483\n",
      "  timestamp: 1629486000\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1024000\n",
      "  training_iteration: 256\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   256</td><td style=\"text-align: right;\">         940.745</td><td style=\"text-align: right;\">1024000</td><td style=\"text-align: right;\">-466.382</td><td style=\"text-align: right;\">           -0.614332</td><td style=\"text-align: right;\">            -1809.46</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1032000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-07\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6232579943524839\n",
      "  episode_reward_mean: -407.82636247461824\n",
      "  episode_reward_min: -1686.5901611801767\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5160\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2298680543899536\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01479250006377697\n",
      "          model: {}\n",
      "          policy_loss: -0.05663120001554489\n",
      "          total_loss: 975.8499145507812\n",
      "          vf_explained_var: 0.9187660813331604\n",
      "          vf_loss: 975.881103515625\n",
      "    num_agent_steps_sampled: 1032000\n",
      "    num_agent_steps_trained: 1032000\n",
      "    num_steps_sampled: 1032000\n",
      "    num_steps_trained: 1032000\n",
      "  iterations_since_restore: 258\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.4\n",
      "    ram_util_percent: 67.8\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07501606530148314\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10766749605424743\n",
      "    mean_inference_ms: 0.5262621143725265\n",
      "    mean_raw_obs_processing_ms: 0.05081788488844202\n",
      "  time_since_restore: 947.9334650039673\n",
      "  time_this_iter_s: 3.570841073989868\n",
      "  time_total_s: 947.9334650039673\n",
      "  timers:\n",
      "    learn_throughput: 1896.816\n",
      "    learn_time_ms: 2108.797\n",
      "    load_throughput: 4479179.838\n",
      "    load_time_ms: 0.893\n",
      "    sample_throughput: 2596.293\n",
      "    sample_time_ms: 1540.658\n",
      "    update_time_ms: 1.513\n",
      "  timestamp: 1629486007\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1032000\n",
      "  training_iteration: 258\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   258</td><td style=\"text-align: right;\">         947.933</td><td style=\"text-align: right;\">1032000</td><td style=\"text-align: right;\">-407.826</td><td style=\"text-align: right;\">           -0.623258</td><td style=\"text-align: right;\">            -1686.59</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1040000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-14\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6232579943524839\n",
      "  episode_reward_mean: -464.01890505078796\n",
      "  episode_reward_min: -1702.6667837847099\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5200\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.133274555206299\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01258645486086607\n",
      "          model: {}\n",
      "          policy_loss: -0.05053875222802162\n",
      "          total_loss: 3443.409423828125\n",
      "          vf_explained_var: 0.8844317197799683\n",
      "          vf_loss: 3443.438720703125\n",
      "    num_agent_steps_sampled: 1040000\n",
      "    num_agent_steps_trained: 1040000\n",
      "    num_steps_sampled: 1040000\n",
      "    num_steps_trained: 1040000\n",
      "  iterations_since_restore: 260\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.379999999999995\n",
      "    ram_util_percent: 67.58\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07499226774233915\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10764098424609234\n",
      "    mean_inference_ms: 0.5261639199375167\n",
      "    mean_raw_obs_processing_ms: 0.050802474261997015\n",
      "  time_since_restore: 955.1431007385254\n",
      "  time_this_iter_s: 3.587496042251587\n",
      "  time_total_s: 955.1431007385254\n",
      "  timers:\n",
      "    learn_throughput: 1902.389\n",
      "    learn_time_ms: 2102.619\n",
      "    load_throughput: 4404856.123\n",
      "    load_time_ms: 0.908\n",
      "    sample_throughput: 2650.49\n",
      "    sample_time_ms: 1509.155\n",
      "    update_time_ms: 1.512\n",
      "  timestamp: 1629486014\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1040000\n",
      "  training_iteration: 260\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   260</td><td style=\"text-align: right;\">         955.143</td><td style=\"text-align: right;\">1040000</td><td style=\"text-align: right;\">-464.019</td><td style=\"text-align: right;\">           -0.623258</td><td style=\"text-align: right;\">            -1702.67</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1048000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-22\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6232579943524839\n",
      "  episode_reward_mean: -498.35048864562646\n",
      "  episode_reward_min: -1755.306085904107\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5240\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 3.6932573318481445\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010512660257518291\n",
      "          model: {}\n",
      "          policy_loss: -0.03120679222047329\n",
      "          total_loss: 8192.8134765625\n",
      "          vf_explained_var: 0.844706654548645\n",
      "          vf_loss: 8192.8271484375\n",
      "    num_agent_steps_sampled: 1048000\n",
      "    num_agent_steps_trained: 1048000\n",
      "    num_steps_sampled: 1048000\n",
      "    num_steps_trained: 1048000\n",
      "  iterations_since_restore: 262\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.220000000000006\n",
      "    ram_util_percent: 67.64000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07496849162925798\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10761425209762518\n",
      "    mean_inference_ms: 0.5260680798736609\n",
      "    mean_raw_obs_processing_ms: 0.050787846409628426\n",
      "  time_since_restore: 962.3164956569672\n",
      "  time_this_iter_s: 3.567342758178711\n",
      "  time_total_s: 962.3164956569672\n",
      "  timers:\n",
      "    learn_throughput: 1904.866\n",
      "    learn_time_ms: 2099.885\n",
      "    load_throughput: 4399773.419\n",
      "    load_time_ms: 0.909\n",
      "    sample_throughput: 2663.119\n",
      "    sample_time_ms: 1501.998\n",
      "    update_time_ms: 1.513\n",
      "  timestamp: 1629486022\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1048000\n",
      "  training_iteration: 262\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   262</td><td style=\"text-align: right;\">         962.316</td><td style=\"text-align: right;\">1048000</td><td style=\"text-align: right;\"> -498.35</td><td style=\"text-align: right;\">           -0.623258</td><td style=\"text-align: right;\">            -1755.31</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1056000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-29\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.9537147784149033\n",
      "  episode_reward_mean: -493.63796579181917\n",
      "  episode_reward_min: -1755.306085904107\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5280\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.612837314605713\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012716633267700672\n",
      "          model: {}\n",
      "          policy_loss: -0.050649166107177734\n",
      "          total_loss: 1520.16259765625\n",
      "          vf_explained_var: 0.9075784087181091\n",
      "          vf_loss: 1520.19140625\n",
      "    num_agent_steps_sampled: 1056000\n",
      "    num_agent_steps_trained: 1056000\n",
      "    num_steps_sampled: 1056000\n",
      "    num_steps_trained: 1056000\n",
      "  iterations_since_restore: 264\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.94\n",
      "    ram_util_percent: 67.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07494685900597932\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10759360150069806\n",
      "    mean_inference_ms: 0.5259706772581663\n",
      "    mean_raw_obs_processing_ms: 0.05077733971758883\n",
      "  time_since_restore: 969.6620454788208\n",
      "  time_this_iter_s: 3.6351449489593506\n",
      "  time_total_s: 969.6620454788208\n",
      "  timers:\n",
      "    learn_throughput: 1893.989\n",
      "    learn_time_ms: 2111.944\n",
      "    load_throughput: 4274232.141\n",
      "    load_time_ms: 0.936\n",
      "    sample_throughput: 2654.385\n",
      "    sample_time_ms: 1506.94\n",
      "    update_time_ms: 1.471\n",
      "  timestamp: 1629486029\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1056000\n",
      "  training_iteration: 264\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   264</td><td style=\"text-align: right;\">         969.662</td><td style=\"text-align: right;\">1056000</td><td style=\"text-align: right;\">-493.638</td><td style=\"text-align: right;\">           -0.953715</td><td style=\"text-align: right;\">            -1755.31</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1064000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-36\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.9537147784149033\n",
      "  episode_reward_mean: -506.02697679994066\n",
      "  episode_reward_min: -1755.306085904107\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5320\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.7848691940307617\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014444910921156406\n",
      "          model: {}\n",
      "          policy_loss: -0.05225640907883644\n",
      "          total_loss: 5243.88232421875\n",
      "          vf_explained_var: 0.8463694453239441\n",
      "          vf_loss: 5243.90966796875\n",
      "    num_agent_steps_sampled: 1064000\n",
      "    num_agent_steps_trained: 1064000\n",
      "    num_steps_sampled: 1064000\n",
      "    num_steps_trained: 1064000\n",
      "  iterations_since_restore: 266\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.78\n",
      "    ram_util_percent: 67.5\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07492615889032031\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10757553309810385\n",
      "    mean_inference_ms: 0.5258678275318036\n",
      "    mean_raw_obs_processing_ms: 0.0507683871692136\n",
      "  time_since_restore: 976.9050805568695\n",
      "  time_this_iter_s: 3.57395601272583\n",
      "  time_total_s: 976.9050805568695\n",
      "  timers:\n",
      "    learn_throughput: 1901.377\n",
      "    learn_time_ms: 2103.739\n",
      "    load_throughput: 4406475.81\n",
      "    load_time_ms: 0.908\n",
      "    sample_throughput: 2656.063\n",
      "    sample_time_ms: 1505.989\n",
      "    update_time_ms: 1.484\n",
      "  timestamp: 1629486036\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1064000\n",
      "  training_iteration: 266\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   266</td><td style=\"text-align: right;\">         976.905</td><td style=\"text-align: right;\">1064000</td><td style=\"text-align: right;\">-506.027</td><td style=\"text-align: right;\">           -0.953715</td><td style=\"text-align: right;\">            -1755.31</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1072000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-43\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1.0629856956420398\n",
      "  episode_reward_mean: -483.6264358865987\n",
      "  episode_reward_min: -1752.2636166669397\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5360\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.802149772644043\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014132510870695114\n",
      "          model: {}\n",
      "          policy_loss: -0.050237905234098434\n",
      "          total_loss: 3773.263671875\n",
      "          vf_explained_var: 0.8956251740455627\n",
      "          vf_loss: 3773.289794921875\n",
      "    num_agent_steps_sampled: 1072000\n",
      "    num_agent_steps_trained: 1072000\n",
      "    num_steps_sampled: 1072000\n",
      "    num_steps_trained: 1072000\n",
      "  iterations_since_restore: 268\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.840000000000003\n",
      "    ram_util_percent: 67.72\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0749046273171237\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10755687083657012\n",
      "    mean_inference_ms: 0.5257678304961175\n",
      "    mean_raw_obs_processing_ms: 0.050758775498413594\n",
      "  time_since_restore: 984.0970394611359\n",
      "  time_this_iter_s: 3.5646541118621826\n",
      "  time_total_s: 984.0970394611359\n",
      "  timers:\n",
      "    learn_throughput: 1900.418\n",
      "    learn_time_ms: 2104.8\n",
      "    load_throughput: 4391021.776\n",
      "    load_time_ms: 0.911\n",
      "    sample_throughput: 2657.109\n",
      "    sample_time_ms: 1505.395\n",
      "    update_time_ms: 1.456\n",
      "  timestamp: 1629486043\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1072000\n",
      "  training_iteration: 268\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   268</td><td style=\"text-align: right;\">         984.097</td><td style=\"text-align: right;\">1072000</td><td style=\"text-align: right;\">-483.626</td><td style=\"text-align: right;\">            -1.06299</td><td style=\"text-align: right;\">            -1752.26</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1080000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-51\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6094119017273052\n",
      "  episode_reward_mean: -537.0676206809925\n",
      "  episode_reward_min: -1752.2636166669397\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5400\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.9378278255462646\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016696639358997345\n",
      "          model: {}\n",
      "          policy_loss: -0.052778713405132294\n",
      "          total_loss: 5848.787109375\n",
      "          vf_explained_var: 0.862409234046936\n",
      "          vf_loss: 5848.81201171875\n",
      "    num_agent_steps_sampled: 1080000\n",
      "    num_agent_steps_trained: 1080000\n",
      "    num_steps_sampled: 1080000\n",
      "    num_steps_trained: 1080000\n",
      "  iterations_since_restore: 270\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.739999999999995\n",
      "    ram_util_percent: 67.6\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07487945947118685\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10753224223318966\n",
      "    mean_inference_ms: 0.5256486050202964\n",
      "    mean_raw_obs_processing_ms: 0.050744744708771765\n",
      "  time_since_restore: 991.3526384830475\n",
      "  time_this_iter_s: 3.666236162185669\n",
      "  time_total_s: 991.3526384830475\n",
      "  timers:\n",
      "    learn_throughput: 1893.454\n",
      "    learn_time_ms: 2112.542\n",
      "    load_throughput: 4527530.225\n",
      "    load_time_ms: 0.883\n",
      "    sample_throughput: 2662.421\n",
      "    sample_time_ms: 1502.392\n",
      "    update_time_ms: 1.442\n",
      "  timestamp: 1629486051\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1080000\n",
      "  training_iteration: 270\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   270</td><td style=\"text-align: right;\">         991.353</td><td style=\"text-align: right;\">1080000</td><td style=\"text-align: right;\">-537.068</td><td style=\"text-align: right;\">           -0.609412</td><td style=\"text-align: right;\">            -1752.26</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1088000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-59\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6094119017273052\n",
      "  episode_reward_mean: -522.4562899511418\n",
      "  episode_reward_min: -1752.2636166669397\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5440\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7577109336853027\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01734042726457119\n",
      "          model: {}\n",
      "          policy_loss: -0.0588061697781086\n",
      "          total_loss: 802.9971923828125\n",
      "          vf_explained_var: 0.9539178609848022\n",
      "          vf_loss: 803.0264282226562\n",
      "    num_agent_steps_sampled: 1088000\n",
      "    num_agent_steps_trained: 1088000\n",
      "    num_steps_sampled: 1088000\n",
      "    num_steps_trained: 1088000\n",
      "  iterations_since_restore: 272\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.43333333333334\n",
      "    ram_util_percent: 67.71666666666667\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07487785146935268\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1075366359631122\n",
      "    mean_inference_ms: 0.525666562135165\n",
      "    mean_raw_obs_processing_ms: 0.050750407922755654\n",
      "  time_since_restore: 999.4016525745392\n",
      "  time_this_iter_s: 3.85932993888855\n",
      "  time_total_s: 999.4016525745392\n",
      "  timers:\n",
      "    learn_throughput: 1847.999\n",
      "    learn_time_ms: 2164.504\n",
      "    load_throughput: 4276411.093\n",
      "    load_time_ms: 0.935\n",
      "    sample_throughput: 2600.903\n",
      "    sample_time_ms: 1537.927\n",
      "    update_time_ms: 1.435\n",
      "  timestamp: 1629486059\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1088000\n",
      "  training_iteration: 272\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   272</td><td style=\"text-align: right;\">         999.402</td><td style=\"text-align: right;\">1088000</td><td style=\"text-align: right;\">-522.456</td><td style=\"text-align: right;\">           -0.609412</td><td style=\"text-align: right;\">            -1752.26</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 14:01:01,770\tWARNING tune.py:507 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   273</td><td style=\"text-align: right;\">         1003.27</td><td style=\"text-align: right;\">1092000</td><td style=\"text-align: right;\"> -527.75</td><td style=\"text-align: right;\">           -0.609412</td><td style=\"text-align: right;\">            -1742.39</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m 2021-08-20 14:01:03,210\tERROR worker.py:421 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 632, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 486, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 523, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 530, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/_private/function_manager.py\", line 563, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     return next(self.local_it)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 338, in gen_rollouts\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     yield self.sample()\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 739, in sample\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     batches = [self.input_reader.next()]\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 101, in next\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     batches = [self.get_data()]\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 231, in get_data\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     item = next(self.rollout_provider)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 624, in _env_runner\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     eval_results = _do_policy_eval(\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 1031, in _do_policy_eval\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     policy.compute_actions_from_input_dict(\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/policy/tf_policy.py\", line 387, in compute_actions_from_input_dict\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     fetched = builder.get(to_fetch)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/utils/tf_run_builder.py\", line 42, in get\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     self._executed = run_timeline(\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/utils/tf_run_builder.py\", line 89, in run_timeline\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1175, in _run\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     fetch_handler = _FetchHandler(\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 487, in __init__\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     self._fetch_mapper = _FetchMapper.for_fetch(fetches)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/contextlib.py\", line 124, in __exit__\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     next(self.gen)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 5619, in get_controller\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     yield g\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/contextlib.py\", line 124, in __exit__\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     next(self.gen)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 5427, in get_controller\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     if self._enforce_nesting:\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/worker.py\", line 418, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m 2021-08-20 14:01:03,208\tERROR worker.py:421 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"python/ray/_raylet.pyx\", line 632, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"python/ray/_raylet.pyx\", line 486, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"python/ray/_raylet.pyx\", line 523, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"python/ray/_raylet.pyx\", line 530, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/_private/function_manager.py\", line 563, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     return next(self.local_it)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 338, in gen_rollouts\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     yield self.sample()\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 739, in sample\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     batches = [self.input_reader.next()]\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 101, in next\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     batches = [self.get_data()]\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 231, in get_data\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     item = next(self.rollout_provider)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 624, in _env_runner\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     eval_results = _do_policy_eval(\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 1031, in _do_policy_eval\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     policy.compute_actions_from_input_dict(\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/policy/tf_policy.py\", line 387, in compute_actions_from_input_dict\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     fetched = builder.get(to_fetch)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/utils/tf_run_builder.py\", line 42, in get\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     self._executed = run_timeline(\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/utils/tf_run_builder.py\", line 89, in run_timeline\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1130, in _run\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     subfeed_t = self.graph.as_graph_element(\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3755, in as_graph_element\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3775, in _as_graph_element_locked\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     temp_obj = _as_graph_element(obj)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 206, in _as_graph_element\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     conv_fn = getattr(obj, \"_as_graph_element\", None)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 392, in __getattr__\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     def __getattr__(self, name):\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/worker.py\", line 418, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m 2021-08-20 14:01:03,271\tERROR worker.py:421 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 632, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 486, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 523, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 530, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/_private/function_manager.py\", line 563, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/tune/trainable.py\", line 178, in train_buffered\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     result = self.train()\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/agents/trainer.py\", line 629, in train\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     result = Trainable.train(self)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/tune/trainable.py\", line 237, in train\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     result = self.step()\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/agents/trainer_template.py\", line 170, in step\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     res = next(self.train_exec_impl)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 756, in __next__\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     return next(self.built_iterator)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   [Previous line repeated 1 more time]\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 876, in apply_flatten\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 828, in add_wait_hooks\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     item = next(it)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   [Previous line repeated 1 more time]\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 471, in base_iterator\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     yield ray.get(futures, timeout=timeout)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 82, in wrapper\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/worker.py\", line 1557, in get\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     values, debugger_breakpoint = worker.get_objects(\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/worker.py\", line 340, in get_objects\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     data_metadata_pairs = self.core_worker.get_objects(\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/worker.py\", line 418, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m SystemExit: 1\n",
      "2021-08-20 14:01:03,404\tERROR tune.py:546 -- Trials did not complete: [PPO_Pendulum-v0_94afa_00000]\n",
      "2021-08-20 14:01:03,405\tINFO tune.py:550 -- Total run time: 1024.38 seconds (1024.07 seconds for the tuning loop).\n",
      "2021-08-20 14:01:03,405\tWARNING tune.py:554 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7fec26194550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg = 'PPO'\n",
    "tune.run(alg,\n",
    "    stop={\"training_iteration\": 300},\n",
    "    config={\n",
    "        'env':'Pendulum-v0',\n",
    "        'num_gpus':0,\n",
    "        'num_workers':2,\n",
    "        'lr':tune.grid_search([.001,])     \n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
