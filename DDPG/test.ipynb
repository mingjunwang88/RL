{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d5f6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_state:  3\n",
      "dim_action:  1\n",
      "action sample:  [0.2193762]\n",
      "step 500 reward:  -9.83197097927896 action:  [0.48437101]\n",
      "step 1000 reward:  -3.761233609693416 action:  [1.69653385]\n",
      "step 1500 reward:  -12.839314044489388 action:  [0.45119514]\n",
      "step 2000 reward:  -5.44311230572722 action:  [-0.85544479]\n",
      "step 2500 reward:  -0.7708158651749298 action:  [0.32500047]\n",
      "step 3000 reward:  -10.533757191985913 action:  [-1.99928891]\n",
      "step 3500 reward:  -10.147108974493845 action:  [-1.98534412]\n",
      "step 4000 reward:  -8.697110751432296 action:  [-1.99372206]\n",
      "step 4500 reward:  -7.209470761450091 action:  [-0.55796581]\n",
      "step 5000 reward:  -3.2861050982196516 action:  [-0.53108406]\n",
      "step 5500 reward:  -1.687450878441334 action:  [0.05792956]\n",
      "step 6000 reward:  -7.232711067852787 action:  [-0.64697274]\n",
      "step 6500 reward:  -0.3570140197714703 action:  [-2.01309588]\n",
      "step 7000 reward:  -0.4919171194196242 action:  [-1.9832042]\n",
      "step 7500 reward:  -0.3057840041021866 action:  [1.70611971]\n",
      "step 8000 reward:  -3.0901052041538533 action:  [-1.21216264]\n",
      "step 8500 reward:  -6.528248890262533 action:  [-0.80620989]\n",
      "step 9000 reward:  -3.023105757359134 action:  [0.35190362]\n",
      "step 9500 reward:  -2.111304529511259 action:  [0.86231651]\n",
      "step 10000 reward:  -6.529002002434817 action:  [1.0171327]\n",
      "step 10500 reward:  -11.626989629917036 action:  [-1.9771265]\n",
      "step 11000 reward:  -7.689348079367388 action:  [-1.98349235]\n",
      "step 11500 reward:  -10.220646318586583 action:  [-2.00656834]\n",
      "step 12000 reward:  -8.321319699925946 action:  [-2.00365981]\n",
      "step 12500 reward:  -14.444206105639228 action:  [-1.98955833]\n",
      "step 13000 reward:  -7.21808821242503 action:  [-2.00453914]\n",
      "step 13500 reward:  -6.7748583174002075 action:  [-1.99822719]\n",
      "step 14000 reward:  -5.034582285892553 action:  [-2.00501388]\n",
      "step 14500 reward:  -10.668727229661433 action:  [-1.99114801]\n",
      "step 15000 reward:  -13.298433787167768 action:  [-2.00224513]\n",
      "step 15500 reward:  -8.434107802491612 action:  [-2.00049894]\n",
      "step 16000 reward:  -14.135228617249632 action:  [-2.00438396]\n",
      "step 16500 reward:  -8.9489675551915 action:  [-2.00156398]\n",
      "step 17000 reward:  -4.815950318267818 action:  [-1.97354349]\n",
      "step 17500 reward:  -5.871083257860878 action:  [-2.02009312]\n",
      "step 18000 reward:  -3.8083125949723446 action:  [1.99328513]\n",
      "step 18500 reward:  -0.0880315756532609 action:  [1.31932598]\n",
      "step 19000 reward:  -1.172150104171504 action:  [-2.00549821]\n",
      "step 19500 reward:  -0.05258834992029224 action:  [1.5097995]\n",
      "step 20000 reward:  -0.059360639464779666 action:  [1.09098829]\n",
      "...saving check point...\n",
      "...save checkout...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as f\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "#import gym_cartpole_swingup  #pip install gym_cartpole_swingup\n",
    "\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "###################################################\n",
    "# Deep Deterministic Policy Gradient\n",
    "###################################################\n",
    "\n",
    "class Noise():\n",
    "    def __init__(self,mu,sigma=0.15,theta=0.2,dt=1e-2,x0=None):\n",
    "        self.theta = theta\n",
    "        self.mu=mu\n",
    "        self.sigma = sigma\n",
    "        self.dt=dt\n",
    "        self.x0=x0\n",
    "        self.reset()\n",
    "    \n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
    "        self.sigma * np.sqrt(self.dt)*np.random.normal(size=self.mu.shape)\n",
    "        self.prev = x\n",
    "        return x\n",
    "    \n",
    "    def reset(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\n",
    "        \n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, dim_state, dim_action, fc1, fc2, alpha, min_action, max_action, checkpoint='actor_ddpg_v2' ):\n",
    "        super(Actor, self).__init__()\n",
    "        self.dim_state = dim_state\n",
    "        self.dim_action = dim_action\n",
    "        self.min_action = min_action\n",
    "        self.max_action = max_action\n",
    "        \n",
    "        self.linear1 = nn.Linear(dim_state, fc1)\n",
    "        self.linear2 = nn.Linear(fc1, fc2)\n",
    "        self.linear3 = nn.Linear(fc2, dim_action)\n",
    "        \n",
    "        self.device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha, weight_decay=1e-4)\n",
    "        self.to(self.device)\n",
    "        self.path = checkpoint\n",
    "        \n",
    "    def forward(self, state):\n",
    "        output = state.to(self.device)\n",
    "        \n",
    "        output = f.relu(self.linear1(output))\n",
    "        output = f.relu(self.linear2(output))\n",
    "        #output = t.tanh(self.linear3(output)) * self.max_action\n",
    "        output = t.clamp(self.linear3(output), self.min_action, self.max_action)\n",
    "        return output\n",
    "    \n",
    "    def saveCheckpoint(self):\n",
    "        print ('...saving check point...')\n",
    "        t.save(self.state_dict(), self.path)\n",
    "    \n",
    "    def loadCheckpoint(self):\n",
    "        print('...loading check point')\n",
    "        self.load_state_dict(t.load(self.path))\n",
    "    \n",
    "class Critic(nn.Module):   \n",
    "    def __init__(self, dim_state, dim_action, fc1, fc2, alpha,checkpoint='critic_ddpg_v2'):\n",
    "        super(Critic, self).__init__()\n",
    "        self.dim_state = dim_state\n",
    "        self.dim_action = dim_action\n",
    "        self.path = checkpoint\n",
    "        \n",
    "        self.linear1 = nn.Linear(dim_state+ dim_action, fc1)\n",
    "        self.linear2 = nn.Linear(fc1, fc2)\n",
    "        self.linear3 = nn.Linear(fc2, 1)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr = alpha, weight_decay=1e-4)\n",
    "        self.device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        state = state.to(self.device)\n",
    "        action = action.to(self.device)\n",
    "        \n",
    "        output = t.relu(self.linear1(t.cat((state, action), dim=1)))\n",
    "        output = t.relu(self.linear2(output))\n",
    "        output = self.linear3(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def saveCheckpoint(self):\n",
    "        print('...save checkout...')\n",
    "        t.save(self.state_dict(), self.path)\n",
    "    \n",
    "    def loadCheckpoint(self):\n",
    "        print ('...load checj point...')\n",
    "        self.load_state_dict(t.load(self.path))\n",
    "        \n",
    "        \n",
    "class replayBuffer():\n",
    "    def __init__(self, maxm_size, dim_state, dim_action):\n",
    "        self.counter = 0\n",
    "        self.state_mem = np.zeros((maxm_size, dim_state))\n",
    "        self.action_mem = np.zeros((maxm_size, dim_action))\n",
    "        self.reward_mem = np.zeros(maxm_size)\n",
    "        self.state_new_mem = np.zeros((maxm_size, dim_state))\n",
    "        self.done_mem = np.zeros(maxm_size)\n",
    "        self.maxm_size = maxm_size\n",
    "        \n",
    "    def store_Transaction(self, state, action, reward, state_new, done):\n",
    "        index = self.counter % self.maxm_size\n",
    "        \n",
    "        self.state_mem[index] = state\n",
    "        self.action_mem[index] = action\n",
    "        self.reward_mem[index] = reward\n",
    "        self.state_new_mem[index] =state_new\n",
    "        self.done_mem[index] = 1.0 - done\n",
    "        \n",
    "        self.counter+=1\n",
    "    \n",
    "    def sample_batch(self, batch_size=64):\n",
    "        maxm_size = min(self.counter, self.maxm_size)\n",
    "        batch = np.random.choice(maxm_size, batch_size)\n",
    "        \n",
    "        state_batch = self.state_mem[batch]\n",
    "        action_batch = self.action_mem[batch]\n",
    "        reward_batch = self.reward_mem[batch]\n",
    "        state_new_batch = self.state_new_mem[batch]\n",
    "        done_batch = self.done_mem[batch]\n",
    "        \n",
    "        return state_batch, action_batch,reward_batch,state_new_batch,done_batch\n",
    "        \n",
    "    \n",
    "class Agent():\n",
    "    def __init__(self, env, dim_state, dim_action, fc1, fc2, alpha, gamma,min_action, max_action, maxm_size, maxm_iters=50, batch_size=64):\n",
    "        self.dim_state = dim_state\n",
    "        self.dim_action = dim_action\n",
    "        self.maxm_iters = maxm_iters\n",
    "        self.device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.actor=Actor(dim_state, dim_action, fc1, fc2, alpha, min_action, max_action, checkpoint='actor').to(self.device)\n",
    "        self.critic=Critic(dim_state, dim_action, fc1, fc2, alpha,checkpoint='critic').to(self.device)\n",
    "        self.tau = 0.005\n",
    "\n",
    "        #Initilize the target networks           \n",
    "        self.actor_t = Actor(dim_state, dim_action, fc1, fc2, alpha, min_action, max_action, checkpoint='actor').to(self.device)\n",
    "        self.actor_t.load_state_dict(self.actor.state_dict())\n",
    "        \n",
    "        self.critic_t = Critic(dim_state, dim_action, fc1, fc2, alpha,checkpoint='critic').to(self.device)\n",
    "        self.critic_t.load_state_dict(self.critic.state_dict())\n",
    "        \n",
    "        self.buffer = replayBuffer(maxm_size, dim_state, dim_action) # maxm_size, dim_state, dim_action):\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size   \n",
    "        self.noise = Noise(mu=np.zeros(dim_action))\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.env = env\n",
    "        \n",
    "        \n",
    "    def plot_learning_curve(self,x, scores, figure_file='test'):\n",
    "        running_avg = np.zeros(len(scores))\n",
    "        for i in range(len(running_avg)):\n",
    "            running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
    "        plt.plot(x, running_avg)\n",
    "        #plt.title('Running average of previous 100 scores')\n",
    "        plt.savefig('ddpg_v2.png')\n",
    "        \n",
    "    def update_parms(self):\n",
    "        \n",
    "        critic_dict = dict(self.critic_t.named_parameters())\n",
    "        critic_t_dict = dict(self.critic.named_parameters())\n",
    "        \n",
    "        actor_t_dict = dict(self.actor_t.named_parameters())\n",
    "        actor_dict = dict(self.actor.named_parameters())\n",
    "        \n",
    "        #Update the critic\n",
    "        for i in critic_dict:\n",
    "            critic_dict[i] = self.tau*critic_dict[i].clone() + (1-self.tau)*critic_t_dict[i].clone()\n",
    "        self.critic_t.load_state_dict(critic_dict)\n",
    "        \n",
    "        #Update the actor\n",
    "        for j in actor_dict:\n",
    "            actor_dict[j] = self.tau*actor_dict[j].clone() + (1-self.tau)*actor_t_dict[j].clone()\n",
    "        self.actor_t.load_state_dict(actor_dict)\n",
    "           \n",
    "    def learn(self):\n",
    "\n",
    "        reward_list = []  \n",
    "        reward_list_n= []\n",
    "        n=0\n",
    "           \n",
    "        for i in range(self.maxm_iters):\n",
    "            self.noise.reset()\n",
    "            \n",
    "            done= False\n",
    "            state = self.env.reset()       \n",
    "            total_reward= 0\n",
    "            \n",
    "            while not done:   \n",
    "                n+=1\n",
    "                self.critic.train()\n",
    "                self.actor.train()\n",
    "                \n",
    "                self.critic.optimizer.zero_grad()\n",
    "                self.actor.optimizer.zero_grad()\n",
    "                \n",
    "                action = self.actor(t.tensor(state).float().to(self.device)).cpu().detach().numpy() + self.noise()\n",
    "\n",
    "                state_new, reward, done, _ = self.env.step(action)\n",
    "                reward_list_n.append(reward)\n",
    "                total_reward+=reward\n",
    "        \n",
    "                self.buffer.store_Transaction(state, action, reward, state_new, done)\n",
    "\n",
    "                if self.buffer.counter >= self.batch_size:\n",
    "                    state_batch, action_batch, reward_batch, state_new_batch, done_batch = self.buffer.sample_batch()\n",
    "                    \n",
    "                    state_batch = t.tensor(state_batch, dtype=t.float).to(self.actor.device)\n",
    "                    action_batch = t.tensor(action_batch, dtype=t.float).to(self.actor.device)\n",
    "                    reward_batch = t.tensor(reward_batch, dtype=t.float).to(self.actor.device).view(-1,1)\n",
    "                    state_new_batch = t.tensor(state_new_batch, dtype=t.float).to(self.actor.device)\n",
    "                    done_batch = t.tensor(done_batch, dtype=t.float).to(self.actor.device).view(-1,1)                    \n",
    "                        \n",
    "                    ##Update the critic\n",
    "                    with t.no_grad():\n",
    "                        #target = t.tensor(reward_batch)  \n",
    "                        target = reward_batch.clone().detach()\n",
    "                        target += self.gamma*self.critic_t(state_new_batch,self.actor_t(state_new_batch))*done_batch\n",
    "                    preds = self.critic(state_batch, action_batch)\n",
    "\n",
    "                    loss_critic = self.loss(target, preds)\n",
    "                    loss_critic.backward()\n",
    "                    self.critic.optimizer.step()\n",
    "        \n",
    "                    ##Update the actor\n",
    "                    loss_actor = -self.critic(state_batch, self.actor(state_batch))\n",
    "                    loss_actor = loss_actor.mean()\n",
    "                    loss_actor.backward()                    \n",
    "                    self.actor.optimizer.step()                    \n",
    "                    \n",
    "                    self.update_parms()\n",
    "        \n",
    "                state = state_new\n",
    "                if n % 500 ==0:\n",
    "                    print(f'step {n} reward: ', reward, f'action: ', action)\n",
    "                    pass\n",
    "            reward_list.append(total_reward)\n",
    "        \n",
    "        x = [i+1 for i in range(self.maxm_iters)]\n",
    "        self.plot_learning_curve(x, reward_list)\n",
    "        #x = [i+1 for i in range(n)]\n",
    "        #self.plot_learning_curve(x, reward_list_n)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    env = gym.make('Pendulum-v1')\n",
    "    \n",
    "    dim_state = env.observation_space.shape[0]\n",
    "    dim_action = env.action_space.shape[0]\n",
    "    max_action = float(env.action_space.high[0])\n",
    "    min_action = float(env.action_space.low[0])\n",
    "    print('dim_state: ', dim_state)\n",
    "    print ('dim_action: ', dim_action)\n",
    "    print('action sample: ', env.action_space.sample())\n",
    "    agent = Agent(env,dim_state,dim_action, 200, 100, 2.5e-3, 0.99,min_action, max_action, 1000000, maxm_iters=100)\n",
    "    agent.learn()\n",
    "    agent.actor.saveCheckpoint()\n",
    "    agent.critic.saveCheckpoint()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add684cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
