{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.rllib.agents import ppo, ddpg\n",
    "from ray import tune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 15:55:24,243\tINFO services.py:1376 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.16.14.36',\n",
       " 'raylet_ip_address': '172.16.14.36',\n",
       " 'redis_address': '172.16.14.36:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2022-03-08_15-55-21_459234_7112/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-03-08_15-55-21_459234_7112/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2022-03-08_15-55-21_459234_7112',\n",
       " 'metrics_export_port': 57943,\n",
       " 'gcs_address': '172.16.14.36:34329',\n",
       " 'node_id': '9cdb1cd1a85d4815f2c60c8b9f99b57bb7a1c04f0135864ce6a00b88'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-08 16:07:08 (running for 00:00:00.11)<br>Memory usage on this node: 12.7/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/32 CPUs, 0/8 GPUs, 0.0/322.15 GiB heap, 0.0/142.05 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_ce5f3_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m 2022-03-08 16:07:12,637\tINFO trainer.py:2055 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m 2022-03-08 16:07:12,638\tINFO simple_q.py:154 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m 2022-03-08 16:07:12,638\tINFO trainer.py:792 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7414)\u001b[0m 2022-03-08 16:07:17,534\tWARNING deprecation.py:46 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=7398)\u001b[0m 2022-03-08 16:07:17,657\tWARNING deprecation.py:46 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-08 16:07:17 (running for 00:00:08.96)<br>Memory usage on this node: 13.4/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/32 CPUs, 0.2/8 GPUs, 0.0/322.15 GiB heap, 0.0/142.05 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_ce5f3_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 16:07:17,769\tERROR trial_runner.py:927 -- Trial DDPG_Pendulum-v1_ce5f3_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 893, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 707, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/worker.py\", line 1735, in get\n",
      "    raise value\n",
      "  File \"python/ray/_raylet.pyx\", line 770, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 591, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 733, in ray._raylet.execute_task\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::DDPGTrainer.__init__()\u001b[39m (pid=7413, ip=172.16.14.36)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 923, in _init\n",
      "    raise NotImplementedError\n",
      "NotImplementedError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::DDPGTrainer.__init__()\u001b[39m (pid=7413, ip=172.16.14.36)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 729, in __init__\n",
      "    sync_function_tpl)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 122, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 831, in setup\n",
      "    num_workers=self.config[\"num_workers\"])\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 1932, in _make_workers\n",
      "    logdir=self.logdir,\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py\", line 131, in __init__\n",
      "    spaces=spaces,\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py\", line 537, in _make_worker\n",
      "    spaces=spaces,\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 576, in __init__\n",
      "    HOWTO_CHANGE_CONFIG)\n",
      "RuntimeError: Found 0 GPUs on your machine (GPU devices found: [])! If your machine\n",
      "    does not have any GPUs, you should set the config keys `num_gpus` and\n",
      "    `num_gpus_per_worker` to 0 (they may be set to 1 by default for your\n",
      "    particular RL algorithm).\n",
      "To change the config for the `rllib train|rollout` command, use\n",
      "  `--config={'[key]': '[value]'}` on the command line.\n",
      "To change the config for `tune.run()` in a script: Modify the python dict\n",
      "  passed to `tune.run(config=[...])`.\n",
      "To change the config for an RLlib Trainer instance: Modify the python dict\n",
      "  passed to the Trainer's constructor, e.g. `PPOTrainer(config=[...])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v1_ce5f3_00000:\n",
      "  trial_id: ce5f3_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-08 16:07:17 (running for 00:00:08.97)<br>Memory usage on this node: 13.1/480.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/32 CPUs, 0/8 GPUs, 0.0/322.15 GiB heap, 0.0/142.05 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/ec2-user/ray_results/DDPG<br>Number of trials: 1/1 (1 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_ce5f3_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                           </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v1_ce5f3_00000</td><td style=\"text-align: right;\">           1</td><td>/home/ec2-user/ray_results/DDPG/DDPG_Pendulum-v1_ce5f3_00000_0_lr=0.001_2022-03-08_16-07-08/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m 2022-03-08 16:07:17,758\tERROR worker.py:432 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::DDPGTrainer.__init__()\u001b[39m (pid=7413, ip=172.16.14.36)\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 923, in _init\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m     raise NotImplementedError\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m NotImplementedError\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m \u001b[36mray::DDPGTrainer.__init__()\u001b[39m (pid=7413, ip=172.16.14.36)\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 729, in __init__\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m     sync_function_tpl)\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 122, in __init__\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 831, in setup\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m     num_workers=self.config[\"num_workers\"])\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 1932, in _make_workers\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m     logdir=self.logdir,\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py\", line 131, in __init__\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m     spaces=spaces,\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py\", line 537, in _make_worker\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m     spaces=spaces,\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m   File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 576, in __init__\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m     HOWTO_CHANGE_CONFIG)\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m RuntimeError: Found 0 GPUs on your machine (GPU devices found: [])! If your machine\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m     does not have any GPUs, you should set the config keys `num_gpus` and\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m     `num_gpus_per_worker` to 0 (they may be set to 1 by default for your\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m     particular RL algorithm).\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m To change the config for the `rllib train|rollout` command, use\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m   `--config={'[key]': '[value]'}` on the command line.\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m To change the config for `tune.run()` in a script: Modify the python dict\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m   passed to `tune.run(config=[...])`.\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m To change the config for an RLlib Trainer instance: Modify the python dict\n",
      "\u001b[2m\u001b[36m(DDPGTrainer pid=7413)\u001b[0m   passed to the Trainer's constructor, e.g. `PPOTrainer(config=[...])`.\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [DDPG_Pendulum-v1_ce5f3_00000])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-adcc64c555e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m'num_gpus'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m'num_workers'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     }\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, queue_trials, loggers, _remote)\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [DDPG_Pendulum-v1_ce5f3_00000])"
     ]
    }
   ],
   "source": [
    "alg = 'DDPG'\n",
    "tune.run(alg,\n",
    "    stop={\"training_iteration\": 100},\n",
    "    config={\n",
    "        'env':'Pendulum-v1',\n",
    "        'num_gpus':0.2,\n",
    "        'num_workers':2,\n",
    "        'lr':tune.grid_search([.001,])     \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m 2021-08-20 13:44:05,796\tINFO trainer.py:706 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m 2021-08-20 13:44:05,796\tINFO trainer.py:718 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m 2021-08-20 13:44:14,857\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 4000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-44-19\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -861.7010709272424\n",
      "  episode_reward_mean: -1247.730572467082\n",
      "  episode_reward_min: -1559.5065434762291\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 20\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3914216756820679\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012996056117117405\n",
      "          model: {}\n",
      "          policy_loss: -0.007822790183126926\n",
      "          total_loss: 145535.796875\n",
      "          vf_explained_var: 0.003884573234245181\n",
      "          vf_loss: 145535.828125\n",
      "    num_agent_steps_sampled: 4000\n",
      "    num_agent_steps_trained: 4000\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.850000000000005\n",
      "    ram_util_percent: 67.83333333333333\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0842969933490286\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1192378854823077\n",
      "    mean_inference_ms: 0.5967783248764107\n",
      "    mean_raw_obs_processing_ms: 0.0583328407207529\n",
      "  time_since_restore: 4.2074809074401855\n",
      "  time_this_iter_s: 4.2074809074401855\n",
      "  time_total_s: 4.2074809074401855\n",
      "  timers:\n",
      "    learn_throughput: 1664.833\n",
      "    learn_time_ms: 2402.643\n",
      "    load_throughput: 90977.306\n",
      "    load_time_ms: 43.967\n",
      "    sample_throughput: 2279.163\n",
      "    sample_time_ms: 1755.03\n",
      "    update_time_ms: 1.749\n",
      "  timestamp: 1629485059\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.20748</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">-1247.73</td><td style=\"text-align: right;\">            -861.701</td><td style=\"text-align: right;\">            -1559.51</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 12000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-44-25\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -861.7010709272424\n",
      "  episode_reward_mean: -1181.6867835564474\n",
      "  episode_reward_min: -1748.4394313483292\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 60\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2951185703277588\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019712885841727257\n",
      "          model: {}\n",
      "          policy_loss: -0.01567647233605385\n",
      "          total_loss: 105931.5\n",
      "          vf_explained_var: 0.03061719797551632\n",
      "          vf_loss: 105931.515625\n",
      "    num_agent_steps_sampled: 12000\n",
      "    num_agent_steps_trained: 12000\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 12000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.8\n",
      "    ram_util_percent: 68.11999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07768856358195843\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11074756140020132\n",
      "    mean_inference_ms: 0.5481736757450373\n",
      "    mean_raw_obs_processing_ms: 0.05306546952751003\n",
      "  time_since_restore: 11.047992944717407\n",
      "  time_this_iter_s: 3.3503990173339844\n",
      "  time_total_s: 11.047992944717407\n",
      "  timers:\n",
      "    learn_throughput: 1851.92\n",
      "    learn_time_ms: 2159.92\n",
      "    load_throughput: 263444.758\n",
      "    load_time_ms: 15.183\n",
      "    sample_throughput: 2662.723\n",
      "    sample_time_ms: 1502.222\n",
      "    update_time_ms: 1.497\n",
      "  timestamp: 1629485065\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 3\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">          11.048</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">-1181.69</td><td style=\"text-align: right;\">            -861.701</td><td style=\"text-align: right;\">            -1748.44</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 20000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-44-32\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -765.0367910823298\n",
      "  episode_reward_mean: -1164.5790178624363\n",
      "  episode_reward_min: -1748.4394313483292\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 100\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3369152545928955\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02118964120745659\n",
      "          model: {}\n",
      "          policy_loss: -0.02064530737698078\n",
      "          total_loss: 89807.0625\n",
      "          vf_explained_var: 0.054389216005802155\n",
      "          vf_loss: 89807.0703125\n",
      "    num_agent_steps_sampled: 20000\n",
      "    num_agent_steps_trained: 20000\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.740000000000002\n",
      "    ram_util_percent: 68.3\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07466436042072662\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10699763373831023\n",
      "    mean_inference_ms: 0.526210017908064\n",
      "    mean_raw_obs_processing_ms: 0.050692280284007706\n",
      "  time_since_restore: 17.641114711761475\n",
      "  time_this_iter_s: 3.0896499156951904\n",
      "  time_total_s: 17.641114711761475\n",
      "  timers:\n",
      "    learn_throughput: 1936.167\n",
      "    learn_time_ms: 2065.937\n",
      "    load_throughput: 424475.289\n",
      "    load_time_ms: 9.423\n",
      "    sample_throughput: 2770.992\n",
      "    sample_time_ms: 1443.526\n",
      "    update_time_ms: 1.388\n",
      "  timestamp: 1629485072\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 5\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         17.6411</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">-1164.58</td><td style=\"text-align: right;\">            -765.037</td><td style=\"text-align: right;\">            -1748.44</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 28000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-44-39\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -765.0367910823298\n",
      "  episode_reward_mean: -1110.8743558113963\n",
      "  episode_reward_min: -1748.4394313483292\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 140\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2820247411727905\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017025019973516464\n",
      "          model: {}\n",
      "          policy_loss: -0.023783231154084206\n",
      "          total_loss: 65443.2109375\n",
      "          vf_explained_var: 0.051222797483205795\n",
      "          vf_loss: 65443.2265625\n",
      "    num_agent_steps_sampled: 28000\n",
      "    num_agent_steps_trained: 28000\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 28000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.440000000000005\n",
      "    ram_util_percent: 67.9\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07032717477039277\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10160676183628946\n",
      "    mean_inference_ms: 0.49424986474626464\n",
      "    mean_raw_obs_processing_ms: 0.04726399834420716\n",
      "  time_since_restore: 24.23247194290161\n",
      "  time_this_iter_s: 3.4286561012268066\n",
      "  time_total_s: 24.23247194290161\n",
      "  timers:\n",
      "    learn_throughput: 2000.049\n",
      "    learn_time_ms: 1999.951\n",
      "    load_throughput: 574065.081\n",
      "    load_time_ms: 6.968\n",
      "    sample_throughput: 2764.994\n",
      "    sample_time_ms: 1446.658\n",
      "    update_time_ms: 1.398\n",
      "  timestamp: 1629485079\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 7\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         24.2325</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">-1110.87</td><td style=\"text-align: right;\">            -765.037</td><td style=\"text-align: right;\">            -1748.44</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 36000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-44-46\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -765.0367910823298\n",
      "  episode_reward_mean: -1054.5513677332435\n",
      "  episode_reward_min: -1730.6306737238613\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 180\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3237019777297974\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022166144102811813\n",
      "          model: {}\n",
      "          policy_loss: -0.0309299323707819\n",
      "          total_loss: 54791.28515625\n",
      "          vf_explained_var: 0.05643095448613167\n",
      "          vf_loss: 54791.30859375\n",
      "    num_agent_steps_sampled: 36000\n",
      "    num_agent_steps_trained: 36000\n",
      "    num_steps_sampled: 36000\n",
      "    num_steps_trained: 36000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.88333333333333\n",
      "    ram_util_percent: 68.0\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0696428184428571\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10076558212970108\n",
      "    mean_inference_ms: 0.4883137542534914\n",
      "    mean_raw_obs_processing_ms: 0.04666718486629506\n",
      "  time_since_restore: 31.672873735427856\n",
      "  time_this_iter_s: 3.9558639526367188\n",
      "  time_total_s: 31.672873735427856\n",
      "  timers:\n",
      "    learn_throughput: 1942.357\n",
      "    learn_time_ms: 2059.353\n",
      "    load_throughput: 712687.412\n",
      "    load_time_ms: 5.613\n",
      "    sample_throughput: 2765.192\n",
      "    sample_time_ms: 1446.554\n",
      "    update_time_ms: 1.405\n",
      "  timestamp: 1629485086\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 9\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         31.6729</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">-1054.55</td><td style=\"text-align: right;\">            -765.037</td><td style=\"text-align: right;\">            -1730.63</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 44000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-44-53\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -652.0579853569814\n",
      "  episode_reward_mean: -1032.9860006834995\n",
      "  episode_reward_min: -1574.1321829834644\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 220\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3283683061599731\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011564229615032673\n",
      "          model: {}\n",
      "          policy_loss: -0.01673576794564724\n",
      "          total_loss: 43464.55078125\n",
      "          vf_explained_var: 0.06871659308671951\n",
      "          vf_loss: 43464.55859375\n",
      "    num_agent_steps_sampled: 44000\n",
      "    num_agent_steps_trained: 44000\n",
      "    num_steps_sampled: 44000\n",
      "    num_steps_trained: 44000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.32000000000001\n",
      "    ram_util_percent: 67.96000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0702798418082635\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10165675718157832\n",
      "    mean_inference_ms: 0.491630249803192\n",
      "    mean_raw_obs_processing_ms: 0.047111553133881455\n",
      "  time_since_restore: 38.84664058685303\n",
      "  time_this_iter_s: 3.6737060546875\n",
      "  time_total_s: 38.84664058685303\n",
      "  timers:\n",
      "    learn_throughput: 1981.249\n",
      "    learn_time_ms: 2018.929\n",
      "    load_throughput: 4768150.969\n",
      "    load_time_ms: 0.839\n",
      "    sample_throughput: 2784.164\n",
      "    sample_time_ms: 1436.697\n",
      "    update_time_ms: 1.373\n",
      "  timestamp: 1629485093\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 44000\n",
      "  training_iteration: 11\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         38.8466</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\">-1032.99</td><td style=\"text-align: right;\">            -652.058</td><td style=\"text-align: right;\">            -1574.13</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 52000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-00\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -652.0579853569814\n",
      "  episode_reward_mean: -1041.4897291979926\n",
      "  episode_reward_min: -1574.1321829834644\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 260\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2789126634597778\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01498641911894083\n",
      "          model: {}\n",
      "          policy_loss: -0.02070006914436817\n",
      "          total_loss: 38337.828125\n",
      "          vf_explained_var: 0.07115664333105087\n",
      "          vf_loss: 38337.83203125\n",
      "    num_agent_steps_sampled: 52000\n",
      "    num_agent_steps_trained: 52000\n",
      "    num_steps_sampled: 52000\n",
      "    num_steps_trained: 52000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.55\n",
      "    ram_util_percent: 67.8\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07055443126283475\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10205939118428078\n",
      "    mean_inference_ms: 0.4929637341624287\n",
      "    mean_raw_obs_processing_ms: 0.047286125612685054\n",
      "  time_since_restore: 45.132662773132324\n",
      "  time_this_iter_s: 3.1521222591400146\n",
      "  time_total_s: 45.132662773132324\n",
      "  timers:\n",
      "    learn_throughput: 2033.988\n",
      "    learn_time_ms: 1966.58\n",
      "    load_throughput: 4817163.202\n",
      "    load_time_ms: 0.83\n",
      "    sample_throughput: 2790.043\n",
      "    sample_time_ms: 1433.669\n",
      "    update_time_ms: 1.345\n",
      "  timestamp: 1629485100\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 52000\n",
      "  training_iteration: 13\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         45.1327</td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\">-1041.49</td><td style=\"text-align: right;\">            -652.058</td><td style=\"text-align: right;\">            -1574.13</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-06\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -652.0579853569814\n",
      "  episode_reward_mean: -1032.3922369698164\n",
      "  episode_reward_min: -1615.047905476564\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 300\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3489347696304321\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017803119495511055\n",
      "          model: {}\n",
      "          policy_loss: -0.026169482618570328\n",
      "          total_loss: 33105.859375\n",
      "          vf_explained_var: 0.07398030161857605\n",
      "          vf_loss: 33105.87890625\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_agent_steps_trained: 60000\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.975\n",
      "    ram_util_percent: 67.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07033671404593772\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1017910330008513\n",
      "    mean_inference_ms: 0.4913401123072137\n",
      "    mean_raw_obs_processing_ms: 0.04709627931693248\n",
      "  time_since_restore: 51.544148683547974\n",
      "  time_this_iter_s: 3.270878791809082\n",
      "  time_total_s: 51.544148683547974\n",
      "  timers:\n",
      "    learn_throughput: 2048.665\n",
      "    learn_time_ms: 1952.491\n",
      "    load_throughput: 4832843.439\n",
      "    load_time_ms: 0.828\n",
      "    sample_throughput: 2793.947\n",
      "    sample_time_ms: 1431.666\n",
      "    update_time_ms: 1.356\n",
      "  timestamp: 1629485106\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 15\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         51.5441</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">-1032.39</td><td style=\"text-align: right;\">            -652.058</td><td style=\"text-align: right;\">            -1615.05</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 68000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-13\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -750.4548601951891\n",
      "  episode_reward_mean: -999.1340143537749\n",
      "  episode_reward_min: -1615.047905476564\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 340\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.147055983543396\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01609395258128643\n",
      "          model: {}\n",
      "          policy_loss: -0.021593304350972176\n",
      "          total_loss: 23533.0625\n",
      "          vf_explained_var: 0.05944361910223961\n",
      "          vf_loss: 23533.07421875\n",
      "    num_agent_steps_sampled: 68000\n",
      "    num_agent_steps_trained: 68000\n",
      "    num_steps_sampled: 68000\n",
      "    num_steps_trained: 68000\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.7\n",
      "    ram_util_percent: 67.67999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06976071597202313\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10099827658508864\n",
      "    mean_inference_ms: 0.4875018175765124\n",
      "    mean_raw_obs_processing_ms: 0.04663429222717221\n",
      "  time_since_restore: 58.097867250442505\n",
      "  time_this_iter_s: 3.3513636589050293\n",
      "  time_total_s: 58.097867250442505\n",
      "  timers:\n",
      "    learn_throughput: 2041.638\n",
      "    learn_time_ms: 1959.211\n",
      "    load_throughput: 4797465.328\n",
      "    load_time_ms: 0.834\n",
      "    sample_throughput: 2814.305\n",
      "    sample_time_ms: 1421.31\n",
      "    update_time_ms: 1.333\n",
      "  timestamp: 1629485113\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 68000\n",
      "  training_iteration: 17\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         58.0979</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">-999.134</td><td style=\"text-align: right;\">            -750.455</td><td style=\"text-align: right;\">            -1615.05</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 76000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-19\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -750.4548601951891\n",
      "  episode_reward_mean: -981.6374921750662\n",
      "  episode_reward_min: -1582.118281778163\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 380\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.138116478919983\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009961972013115883\n",
      "          model: {}\n",
      "          policy_loss: -0.012737400829792023\n",
      "          total_loss: 18793.3125\n",
      "          vf_explained_var: 0.09615538269281387\n",
      "          vf_loss: 18793.31640625\n",
      "    num_agent_steps_sampled: 76000\n",
      "    num_agent_steps_trained: 76000\n",
      "    num_steps_sampled: 76000\n",
      "    num_steps_trained: 76000\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.98\n",
      "    ram_util_percent: 67.2\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06944948673358933\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10052505923617357\n",
      "    mean_inference_ms: 0.485368394873595\n",
      "    mean_raw_obs_processing_ms: 0.04636414153513068\n",
      "  time_since_restore: 64.71084308624268\n",
      "  time_this_iter_s: 3.3802459239959717\n",
      "  time_total_s: 64.71084308624268\n",
      "  timers:\n",
      "    learn_throughput: 2120.96\n",
      "    learn_time_ms: 1885.938\n",
      "    load_throughput: 4924915.165\n",
      "    load_time_ms: 0.812\n",
      "    sample_throughput: 2832.634\n",
      "    sample_time_ms: 1412.113\n",
      "    update_time_ms: 1.296\n",
      "  timestamp: 1629485119\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 76000\n",
      "  training_iteration: 19\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         64.7108</td><td style=\"text-align: right;\">76000</td><td style=\"text-align: right;\">-981.637</td><td style=\"text-align: right;\">            -750.455</td><td style=\"text-align: right;\">            -1582.12</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 84000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-26\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -750.0360247172193\n",
      "  episode_reward_mean: -990.3854969557972\n",
      "  episode_reward_min: -1685.0551173128385\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 420\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.612725019454956\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00928998738527298\n",
      "          model: {}\n",
      "          policy_loss: -0.013718923553824425\n",
      "          total_loss: 26902.974609375\n",
      "          vf_explained_var: 0.1330251693725586\n",
      "          vf_loss: 26902.982421875\n",
      "    num_agent_steps_sampled: 84000\n",
      "    num_agent_steps_trained: 84000\n",
      "    num_steps_sampled: 84000\n",
      "    num_steps_trained: 84000\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.079999999999995\n",
      "    ram_util_percent: 67.02000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06933940684221349\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10034124564863164\n",
      "    mean_inference_ms: 0.48455009022769174\n",
      "    mean_raw_obs_processing_ms: 0.04626970432733685\n",
      "  time_since_restore: 71.304603099823\n",
      "  time_this_iter_s: 3.2620980739593506\n",
      "  time_total_s: 71.304603099823\n",
      "  timers:\n",
      "    learn_throughput: 2153.2\n",
      "    learn_time_ms: 1857.701\n",
      "    load_throughput: 4868040.854\n",
      "    load_time_ms: 0.822\n",
      "    sample_throughput: 2893.81\n",
      "    sample_time_ms: 1382.261\n",
      "    update_time_ms: 1.329\n",
      "  timestamp: 1629485126\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 84000\n",
      "  training_iteration: 21\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         71.3046</td><td style=\"text-align: right;\">84000</td><td style=\"text-align: right;\">-990.385</td><td style=\"text-align: right;\">            -750.036</td><td style=\"text-align: right;\">            -1685.06</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 92000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-33\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -750.0360247172193\n",
      "  episode_reward_mean: -1010.5507575119403\n",
      "  episode_reward_min: -1685.0551173128385\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 460\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3867007493972778\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010622402653098106\n",
      "          model: {}\n",
      "          policy_loss: -0.021630944684147835\n",
      "          total_loss: 18721.6953125\n",
      "          vf_explained_var: 0.1422927975654602\n",
      "          vf_loss: 18721.70703125\n",
      "    num_agent_steps_sampled: 92000\n",
      "    num_agent_steps_trained: 92000\n",
      "    num_steps_sampled: 92000\n",
      "    num_steps_trained: 92000\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.7\n",
      "    ram_util_percent: 67.1\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06925881021040053\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1002380940530098\n",
      "    mean_inference_ms: 0.4840445544294971\n",
      "    mean_raw_obs_processing_ms: 0.04622833752086798\n",
      "  time_since_restore: 77.85871005058289\n",
      "  time_this_iter_s: 3.221095085144043\n",
      "  time_total_s: 77.85871005058289\n",
      "  timers:\n",
      "    learn_throughput: 2137.567\n",
      "    learn_time_ms: 1871.286\n",
      "    load_throughput: 4727041.587\n",
      "    load_time_ms: 0.846\n",
      "    sample_throughput: 2867.065\n",
      "    sample_time_ms: 1395.155\n",
      "    update_time_ms: 1.446\n",
      "  timestamp: 1629485133\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 92000\n",
      "  training_iteration: 23\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         77.8587</td><td style=\"text-align: right;\">92000</td><td style=\"text-align: right;\">-1010.55</td><td style=\"text-align: right;\">            -750.036</td><td style=\"text-align: right;\">            -1685.06</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 100000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-40\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -732.5105983158745\n",
      "  episode_reward_mean: -1031.2249469831443\n",
      "  episode_reward_min: -1685.0551173128385\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 500\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2975060939788818\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01088643167167902\n",
      "          model: {}\n",
      "          policy_loss: -0.02106568031013012\n",
      "          total_loss: 14752.814453125\n",
      "          vf_explained_var: 0.1842322051525116\n",
      "          vf_loss: 14752.82421875\n",
      "    num_agent_steps_sampled: 100000\n",
      "    num_agent_steps_trained: 100000\n",
      "    num_steps_sampled: 100000\n",
      "    num_steps_trained: 100000\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.439999999999998\n",
      "    ram_util_percent: 66.75999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06923763151207224\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10022671411031463\n",
      "    mean_inference_ms: 0.4839165280999277\n",
      "    mean_raw_obs_processing_ms: 0.046252031466706034\n",
      "  time_since_restore: 84.64135599136353\n",
      "  time_this_iter_s: 3.4659950733184814\n",
      "  time_total_s: 84.64135599136353\n",
      "  timers:\n",
      "    learn_throughput: 2120.994\n",
      "    learn_time_ms: 1885.908\n",
      "    load_throughput: 4563118.013\n",
      "    load_time_ms: 0.877\n",
      "    sample_throughput: 2821.737\n",
      "    sample_time_ms: 1417.567\n",
      "    update_time_ms: 1.473\n",
      "  timestamp: 1629485140\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 100000\n",
      "  training_iteration: 25\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         84.6414</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-1031.22</td><td style=\"text-align: right;\">            -732.511</td><td style=\"text-align: right;\">            -1685.06</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 108000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-46\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -630.6912001434713\n",
      "  episode_reward_mean: -1043.7307244439542\n",
      "  episode_reward_min: -1718.9726366638777\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 540\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.879002332687378\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011907962150871754\n",
      "          model: {}\n",
      "          policy_loss: -0.01969742216169834\n",
      "          total_loss: 22054.294921875\n",
      "          vf_explained_var: 0.2851261794567108\n",
      "          vf_loss: 22054.296875\n",
      "    num_agent_steps_sampled: 108000\n",
      "    num_agent_steps_trained: 108000\n",
      "    num_steps_sampled: 108000\n",
      "    num_steps_trained: 108000\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.359999999999996\n",
      "    ram_util_percent: 66.9\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0692460008008586\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10023371245385772\n",
      "    mean_inference_ms: 0.4839306324239418\n",
      "    mean_raw_obs_processing_ms: 0.046274970741536185\n",
      "  time_since_restore: 91.22690677642822\n",
      "  time_this_iter_s: 3.2756669521331787\n",
      "  time_total_s: 91.22690677642822\n",
      "  timers:\n",
      "    learn_throughput: 2117.079\n",
      "    learn_time_ms: 1889.396\n",
      "    load_throughput: 4559397.777\n",
      "    load_time_ms: 0.877\n",
      "    sample_throughput: 2822.363\n",
      "    sample_time_ms: 1417.252\n",
      "    update_time_ms: 1.475\n",
      "  timestamp: 1629485146\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 108000\n",
      "  training_iteration: 27\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         91.2269</td><td style=\"text-align: right;\">108000</td><td style=\"text-align: right;\">-1043.73</td><td style=\"text-align: right;\">            -630.691</td><td style=\"text-align: right;\">            -1718.97</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 116000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-53\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -630.6912001434713\n",
      "  episode_reward_mean: -1010.4580316223162\n",
      "  episode_reward_min: -1718.9726366638777\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 580\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.9193784594535828\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012211025692522526\n",
      "          model: {}\n",
      "          policy_loss: -0.01306854747235775\n",
      "          total_loss: 10650.8046875\n",
      "          vf_explained_var: 0.22014197707176208\n",
      "          vf_loss: 10650.8056640625\n",
      "    num_agent_steps_sampled: 116000\n",
      "    num_agent_steps_trained: 116000\n",
      "    num_steps_sampled: 116000\n",
      "    num_steps_trained: 116000\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.76\n",
      "    ram_util_percent: 67.22\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06926912630493835\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10024508440909674\n",
      "    mean_inference_ms: 0.4840069089488381\n",
      "    mean_raw_obs_processing_ms: 0.04628308664669233\n",
      "  time_since_restore: 97.86976313591003\n",
      "  time_this_iter_s: 3.338068962097168\n",
      "  time_total_s: 97.86976313591003\n",
      "  timers:\n",
      "    learn_throughput: 2122.152\n",
      "    learn_time_ms: 1884.879\n",
      "    load_throughput: 4494057.645\n",
      "    load_time_ms: 0.89\n",
      "    sample_throughput: 2807.646\n",
      "    sample_time_ms: 1424.681\n",
      "    update_time_ms: 1.482\n",
      "  timestamp: 1629485153\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 116000\n",
      "  training_iteration: 29\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         97.8698</td><td style=\"text-align: right;\">116000</td><td style=\"text-align: right;\">-1010.46</td><td style=\"text-align: right;\">            -630.691</td><td style=\"text-align: right;\">            -1718.97</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 124000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-45-59\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -730.3838476494092\n",
      "  episode_reward_mean: -1042.9413741065052\n",
      "  episode_reward_min: -1759.947757152376\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 620\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.8066339492797852\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011592076160013676\n",
      "          model: {}\n",
      "          policy_loss: -0.01907852478325367\n",
      "          total_loss: 19893.439453125\n",
      "          vf_explained_var: 0.28621706366539\n",
      "          vf_loss: 19893.4453125\n",
      "    num_agent_steps_sampled: 124000\n",
      "    num_agent_steps_trained: 124000\n",
      "    num_steps_sampled: 124000\n",
      "    num_steps_trained: 124000\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.26\n",
      "    ram_util_percent: 67.3\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06921627230224234\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10014045635978676\n",
      "    mean_inference_ms: 0.4835945767563029\n",
      "    mean_raw_obs_processing_ms: 0.046212873008717244\n",
      "  time_since_restore: 104.42366433143616\n",
      "  time_this_iter_s: 3.2862768173217773\n",
      "  time_total_s: 104.42366433143616\n",
      "  timers:\n",
      "    learn_throughput: 2121.331\n",
      "    learn_time_ms: 1885.609\n",
      "    load_throughput: 4698315.831\n",
      "    load_time_ms: 0.851\n",
      "    sample_throughput: 2816.372\n",
      "    sample_time_ms: 1420.267\n",
      "    update_time_ms: 1.414\n",
      "  timestamp: 1629485159\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 124000\n",
      "  training_iteration: 31\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         104.424</td><td style=\"text-align: right;\">124000</td><td style=\"text-align: right;\">-1042.94</td><td style=\"text-align: right;\">            -730.384</td><td style=\"text-align: right;\">            -1759.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 132000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-07\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -741.7314728915361\n",
      "  episode_reward_mean: -1022.2670066389339\n",
      "  episode_reward_min: -1759.947757152376\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 660\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.618180274963379\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012345453724265099\n",
      "          model: {}\n",
      "          policy_loss: -0.02471439354121685\n",
      "          total_loss: 12137.2490234375\n",
      "          vf_explained_var: 0.4350372850894928\n",
      "          vf_loss: 12137.26171875\n",
      "    num_agent_steps_sampled: 132000\n",
      "    num_agent_steps_trained: 132000\n",
      "    num_steps_sampled: 132000\n",
      "    num_steps_trained: 132000\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.26\n",
      "    ram_util_percent: 67.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06939415081572509\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10033982736246085\n",
      "    mean_inference_ms: 0.4847611188645716\n",
      "    mean_raw_obs_processing_ms: 0.04633235574072572\n",
      "  time_since_restore: 112.10044813156128\n",
      "  time_this_iter_s: 3.815706968307495\n",
      "  time_total_s: 112.10044813156128\n",
      "  timers:\n",
      "    learn_throughput: 2037.899\n",
      "    learn_time_ms: 1962.805\n",
      "    load_throughput: 4670977.226\n",
      "    load_time_ms: 0.856\n",
      "    sample_throughput: 2748.301\n",
      "    sample_time_ms: 1455.445\n",
      "    update_time_ms: 1.364\n",
      "  timestamp: 1629485167\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 132000\n",
      "  training_iteration: 33\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">           112.1</td><td style=\"text-align: right;\">132000</td><td style=\"text-align: right;\">-1022.27</td><td style=\"text-align: right;\">            -741.731</td><td style=\"text-align: right;\">            -1759.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 140000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-15\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -575.7102946698726\n",
      "  episode_reward_mean: -1022.6872157866918\n",
      "  episode_reward_min: -1759.947757152376\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 700\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.5862019062042236\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01306239329278469\n",
      "          model: {}\n",
      "          policy_loss: -0.016106856986880302\n",
      "          total_loss: 12868.044921875\n",
      "          vf_explained_var: 0.4221709072589874\n",
      "          vf_loss: 12868.0498046875\n",
      "    num_agent_steps_sampled: 140000\n",
      "    num_agent_steps_trained: 140000\n",
      "    num_steps_sampled: 140000\n",
      "    num_steps_trained: 140000\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 35.68333333333333\n",
      "    ram_util_percent: 67.81666666666668\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06974985423573397\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10077678393328\n",
      "    mean_inference_ms: 0.4870930358827632\n",
      "    mean_raw_obs_processing_ms: 0.04661513466359936\n",
      "  time_since_restore: 120.36115598678589\n",
      "  time_this_iter_s: 3.76053786277771\n",
      "  time_total_s: 120.36115598678589\n",
      "  timers:\n",
      "    learn_throughput: 1921.502\n",
      "    learn_time_ms: 2081.705\n",
      "    load_throughput: 4392516.298\n",
      "    load_time_ms: 0.911\n",
      "    sample_throughput: 2694.954\n",
      "    sample_time_ms: 1484.255\n",
      "    update_time_ms: 1.344\n",
      "  timestamp: 1629485175\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 140000\n",
      "  training_iteration: 35\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         120.361</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">-1022.69</td><td style=\"text-align: right;\">             -575.71</td><td style=\"text-align: right;\">            -1759.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 148000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-22\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -575.7102946698726\n",
      "  episode_reward_mean: -1027.404432289974\n",
      "  episode_reward_min: -1711.9996755025059\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 740\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.8227649927139282\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011758917011320591\n",
      "          model: {}\n",
      "          policy_loss: -0.014279463328421116\n",
      "          total_loss: 13531.529296875\n",
      "          vf_explained_var: 0.4432796537876129\n",
      "          vf_loss: 13531.5302734375\n",
      "    num_agent_steps_sampled: 148000\n",
      "    num_agent_steps_trained: 148000\n",
      "    num_steps_sampled: 148000\n",
      "    num_steps_trained: 148000\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.8\n",
      "    ram_util_percent: 67.72\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07003658400623307\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10112393515719789\n",
      "    mean_inference_ms: 0.48905513122413213\n",
      "    mean_raw_obs_processing_ms: 0.046833094423540444\n",
      "  time_since_restore: 126.778559923172\n",
      "  time_this_iter_s: 3.1659018993377686\n",
      "  time_total_s: 126.778559923172\n",
      "  timers:\n",
      "    learn_throughput: 1934.676\n",
      "    learn_time_ms: 2067.529\n",
      "    load_throughput: 4399311.936\n",
      "    load_time_ms: 0.909\n",
      "    sample_throughput: 2699.673\n",
      "    sample_time_ms: 1481.661\n",
      "    update_time_ms: 1.321\n",
      "  timestamp: 1629485182\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 148000\n",
      "  training_iteration: 37\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         126.779</td><td style=\"text-align: right;\">148000</td><td style=\"text-align: right;\"> -1027.4</td><td style=\"text-align: right;\">             -575.71</td><td style=\"text-align: right;\">               -1712</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 156000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-28\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -575.7102946698726\n",
      "  episode_reward_mean: -1044.0525233657056\n",
      "  episode_reward_min: -1691.1267287366854\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 780\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7034541368484497\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011067953892052174\n",
      "          model: {}\n",
      "          policy_loss: -0.019947124645113945\n",
      "          total_loss: 14097.197265625\n",
      "          vf_explained_var: 0.4234596788883209\n",
      "          vf_loss: 14097.205078125\n",
      "    num_agent_steps_sampled: 156000\n",
      "    num_agent_steps_trained: 156000\n",
      "    num_steps_sampled: 156000\n",
      "    num_steps_trained: 156000\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.225\n",
      "    ram_util_percent: 66.64999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07005527241666362\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10112035874997645\n",
      "    mean_inference_ms: 0.489371150061653\n",
      "    mean_raw_obs_processing_ms: 0.04682510598178764\n",
      "  time_since_restore: 133.2816517353058\n",
      "  time_this_iter_s: 3.3030357360839844\n",
      "  time_total_s: 133.2816517353058\n",
      "  timers:\n",
      "    learn_throughput: 1945.525\n",
      "    learn_time_ms: 2056.001\n",
      "    load_throughput: 4362817.839\n",
      "    load_time_ms: 0.917\n",
      "    sample_throughput: 2704.074\n",
      "    sample_time_ms: 1479.25\n",
      "    update_time_ms: 1.327\n",
      "  timestamp: 1629485188\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 156000\n",
      "  training_iteration: 39\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         133.282</td><td style=\"text-align: right;\">156000</td><td style=\"text-align: right;\">-1044.05</td><td style=\"text-align: right;\">             -575.71</td><td style=\"text-align: right;\">            -1691.13</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 164000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-35\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -743.9866797461497\n",
      "  episode_reward_mean: -1025.4424514173543\n",
      "  episode_reward_min: -1696.5970621478803\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 820\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1105883121490479\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011235026642680168\n",
      "          model: {}\n",
      "          policy_loss: -0.014406774193048477\n",
      "          total_loss: 10807.919921875\n",
      "          vf_explained_var: 0.3834441006183624\n",
      "          vf_loss: 10807.9248046875\n",
      "    num_agent_steps_sampled: 164000\n",
      "    num_agent_steps_trained: 164000\n",
      "    num_steps_sampled: 164000\n",
      "    num_steps_trained: 164000\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.26\n",
      "    ram_util_percent: 66.12\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0699824370573309\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10100809494156347\n",
      "    mean_inference_ms: 0.48901406371793243\n",
      "    mean_raw_obs_processing_ms: 0.046747511128504324\n",
      "  time_since_restore: 140.13890624046326\n",
      "  time_this_iter_s: 3.4345781803131104\n",
      "  time_total_s: 140.13890624046326\n",
      "  timers:\n",
      "    learn_throughput: 1926.233\n",
      "    learn_time_ms: 2076.592\n",
      "    load_throughput: 4314239.868\n",
      "    load_time_ms: 0.927\n",
      "    sample_throughput: 2686.513\n",
      "    sample_time_ms: 1488.919\n",
      "    update_time_ms: 1.346\n",
      "  timestamp: 1629485195\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 164000\n",
      "  training_iteration: 41\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         140.139</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\">-1025.44</td><td style=\"text-align: right;\">            -743.987</td><td style=\"text-align: right;\">             -1696.6</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 172000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-43\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -733.0212221234876\n",
      "  episode_reward_mean: -996.9560604038786\n",
      "  episode_reward_min: -1791.823133566769\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 860\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.634163498878479\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011408006772398949\n",
      "          model: {}\n",
      "          policy_loss: -0.008866180665791035\n",
      "          total_loss: 12902.4375\n",
      "          vf_explained_var: 0.46788448095321655\n",
      "          vf_loss: 12902.43359375\n",
      "    num_agent_steps_sampled: 172000\n",
      "    num_agent_steps_trained: 172000\n",
      "    num_steps_sampled: 172000\n",
      "    num_steps_trained: 172000\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.26\n",
      "    ram_util_percent: 66.86\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07005423824583205\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10110173679919619\n",
      "    mean_inference_ms: 0.48947964503497376\n",
      "    mean_raw_obs_processing_ms: 0.04680482236050082\n",
      "  time_since_restore: 148.09751510620117\n",
      "  time_this_iter_s: 3.9446558952331543\n",
      "  time_total_s: 148.09751510620117\n",
      "  timers:\n",
      "    learn_throughput: 1889.576\n",
      "    learn_time_ms: 2116.877\n",
      "    load_throughput: 4334189.982\n",
      "    load_time_ms: 0.923\n",
      "    sample_throughput: 2708.347\n",
      "    sample_time_ms: 1476.916\n",
      "    update_time_ms: 1.299\n",
      "  timestamp: 1629485203\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 172000\n",
      "  training_iteration: 43\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         148.098</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\">-996.956</td><td style=\"text-align: right;\">            -733.021</td><td style=\"text-align: right;\">            -1791.82</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 180000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-50\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -631.2426580852854\n",
      "  episode_reward_mean: -981.8323547548162\n",
      "  episode_reward_min: -1791.823133566769\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 900\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3244298696517944\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011415433138608932\n",
      "          model: {}\n",
      "          policy_loss: -0.014314445666968822\n",
      "          total_loss: 9988.47265625\n",
      "          vf_explained_var: 0.4630546569824219\n",
      "          vf_loss: 9988.4755859375\n",
      "    num_agent_steps_sampled: 180000\n",
      "    num_agent_steps_trained: 180000\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.179999999999996\n",
      "    ram_util_percent: 66.88\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0701608781688785\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10124517329020427\n",
      "    mean_inference_ms: 0.4901354175626764\n",
      "    mean_raw_obs_processing_ms: 0.046898943997748466\n",
      "  time_since_restore: 154.7887568473816\n",
      "  time_this_iter_s: 3.273242950439453\n",
      "  time_total_s: 154.7887568473816\n",
      "  timers:\n",
      "    learn_throughput: 2009.004\n",
      "    learn_time_ms: 1991.037\n",
      "    load_throughput: 4773034.424\n",
      "    load_time_ms: 0.838\n",
      "    sample_throughput: 2766.124\n",
      "    sample_time_ms: 1446.067\n",
      "    update_time_ms: 1.281\n",
      "  timestamp: 1629485210\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 45\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         154.789</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\">-981.832</td><td style=\"text-align: right;\">            -631.243</td><td style=\"text-align: right;\">            -1791.82</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 188000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-46-57\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -629.3977337988962\n",
      "  episode_reward_mean: -995.1829215012846\n",
      "  episode_reward_min: -1791.823133566769\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 940\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3577574491500854\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01083450112491846\n",
      "          model: {}\n",
      "          policy_loss: -0.017753321677446365\n",
      "          total_loss: 10265.3515625\n",
      "          vf_explained_var: 0.43747782707214355\n",
      "          vf_loss: 10265.3583984375\n",
      "    num_agent_steps_sampled: 188000\n",
      "    num_agent_steps_trained: 188000\n",
      "    num_steps_sampled: 188000\n",
      "    num_steps_trained: 188000\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.46\n",
      "    ram_util_percent: 66.58\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07030874167853325\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10142886089302744\n",
      "    mean_inference_ms: 0.4910965497528423\n",
      "    mean_raw_obs_processing_ms: 0.047020579397031845\n",
      "  time_since_restore: 161.68916583061218\n",
      "  time_this_iter_s: 3.257439136505127\n",
      "  time_total_s: 161.68916583061218\n",
      "  timers:\n",
      "    learn_throughput: 1988.771\n",
      "    learn_time_ms: 2011.292\n",
      "    load_throughput: 4775751.779\n",
      "    load_time_ms: 0.838\n",
      "    sample_throughput: 2713.497\n",
      "    sample_time_ms: 1474.112\n",
      "    update_time_ms: 1.28\n",
      "  timestamp: 1629485217\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 188000\n",
      "  training_iteration: 47\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         161.689</td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\">-995.183</td><td style=\"text-align: right;\">            -629.398</td><td style=\"text-align: right;\">            -1791.82</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 196000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-04\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -629.3977337988962\n",
      "  episode_reward_mean: -1013.9992745932628\n",
      "  episode_reward_min: -1750.0167036690998\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 980\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.1757988929748535\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00922983605414629\n",
      "          model: {}\n",
      "          policy_loss: -0.017294740304350853\n",
      "          total_loss: 15539.4736328125\n",
      "          vf_explained_var: 0.47723841667175293\n",
      "          vf_loss: 15539.4814453125\n",
      "    num_agent_steps_sampled: 196000\n",
      "    num_agent_steps_trained: 196000\n",
      "    num_steps_sampled: 196000\n",
      "    num_steps_trained: 196000\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.480000000000008\n",
      "    ram_util_percent: 66.67999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07034065040373394\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10146054257639044\n",
      "    mean_inference_ms: 0.49133356633912517\n",
      "    mean_raw_obs_processing_ms: 0.04704089013029943\n",
      "  time_since_restore: 168.66379690170288\n",
      "  time_this_iter_s: 3.57236385345459\n",
      "  time_total_s: 168.66379690170288\n",
      "  timers:\n",
      "    learn_throughput: 1947.261\n",
      "    learn_time_ms: 2054.167\n",
      "    load_throughput: 4824088.792\n",
      "    load_time_ms: 0.829\n",
      "    sample_throughput: 2705.764\n",
      "    sample_time_ms: 1478.325\n",
      "    update_time_ms: 1.288\n",
      "  timestamp: 1629485224\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 196000\n",
      "  training_iteration: 49\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         168.664</td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">   -1014</td><td style=\"text-align: right;\">            -629.398</td><td style=\"text-align: right;\">            -1750.02</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 204000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-11\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -744.1916957844479\n",
      "  episode_reward_mean: -1009.8282911532389\n",
      "  episode_reward_min: -1750.0167036690998\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1020\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.761823058128357\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010485198348760605\n",
      "          model: {}\n",
      "          policy_loss: -0.016281604766845703\n",
      "          total_loss: 13348.2763671875\n",
      "          vf_explained_var: 0.46484696865081787\n",
      "          vf_loss: 13348.2822265625\n",
      "    num_agent_steps_sampled: 204000\n",
      "    num_agent_steps_trained: 204000\n",
      "    num_steps_sampled: 204000\n",
      "    num_steps_trained: 204000\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.775\n",
      "    ram_util_percent: 66.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07035379269210179\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10148633812653543\n",
      "    mean_inference_ms: 0.4914357248804698\n",
      "    mean_raw_obs_processing_ms: 0.04705728286355459\n",
      "  time_since_restore: 175.23236775398254\n",
      "  time_this_iter_s: 3.269742727279663\n",
      "  time_total_s: 175.23236775398254\n",
      "  timers:\n",
      "    learn_throughput: 1971.514\n",
      "    learn_time_ms: 2028.898\n",
      "    load_throughput: 4892600.391\n",
      "    load_time_ms: 0.818\n",
      "    sample_throughput: 2712.373\n",
      "    sample_time_ms: 1474.724\n",
      "    update_time_ms: 1.288\n",
      "  timestamp: 1629485231\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 204000\n",
      "  training_iteration: 51\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         175.232</td><td style=\"text-align: right;\">204000</td><td style=\"text-align: right;\">-1009.83</td><td style=\"text-align: right;\">            -744.192</td><td style=\"text-align: right;\">            -1750.02</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 212000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-20\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -501.4707088320807\n",
      "  episode_reward_mean: -1007.5657462256714\n",
      "  episode_reward_min: -1726.3964042171408\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1060\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.632434368133545\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01130130235105753\n",
      "          model: {}\n",
      "          policy_loss: -0.021617727354168892\n",
      "          total_loss: 11467.7705078125\n",
      "          vf_explained_var: 0.5169113874435425\n",
      "          vf_loss: 11467.7822265625\n",
      "    num_agent_steps_sampled: 212000\n",
      "    num_agent_steps_trained: 212000\n",
      "    num_steps_sampled: 212000\n",
      "    num_steps_trained: 212000\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.371428571428574\n",
      "    ram_util_percent: 68.02857142857144\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07047764806484225\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10163669726211948\n",
      "    mean_inference_ms: 0.4922212955555696\n",
      "    mean_raw_obs_processing_ms: 0.047148375720967334\n",
      "  time_since_restore: 184.5059425830841\n",
      "  time_this_iter_s: 5.37188982963562\n",
      "  time_total_s: 184.5059425830841\n",
      "  timers:\n",
      "    learn_throughput: 1894.906\n",
      "    learn_time_ms: 2110.922\n",
      "    load_throughput: 4872423.547\n",
      "    load_time_ms: 0.821\n",
      "    sample_throughput: 2624.993\n",
      "    sample_time_ms: 1523.814\n",
      "    update_time_ms: 1.361\n",
      "  timestamp: 1629485240\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 212000\n",
      "  training_iteration: 53\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         184.506</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\">-1007.57</td><td style=\"text-align: right;\">            -501.471</td><td style=\"text-align: right;\">             -1726.4</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 220000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-28\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -501.4707088320807\n",
      "  episode_reward_mean: -988.871039232908\n",
      "  episode_reward_min: -1726.3964042171408\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1100\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3439828157424927\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010741790756583214\n",
      "          model: {}\n",
      "          policy_loss: -0.015692995861172676\n",
      "          total_loss: 9464.666015625\n",
      "          vf_explained_var: 0.49364280700683594\n",
      "          vf_loss: 9464.669921875\n",
      "    num_agent_steps_sampled: 220000\n",
      "    num_agent_steps_trained: 220000\n",
      "    num_steps_sampled: 220000\n",
      "    num_steps_trained: 220000\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.339999999999996\n",
      "    ram_util_percent: 68.53999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07109118993730708\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10230354631492868\n",
      "    mean_inference_ms: 0.4962358192875573\n",
      "    mean_raw_obs_processing_ms: 0.04757647502903626\n",
      "  time_since_restore: 192.56479573249817\n",
      "  time_this_iter_s: 3.2761390209198\n",
      "  time_total_s: 192.56479573249817\n",
      "  timers:\n",
      "    learn_throughput: 1858.724\n",
      "    learn_time_ms: 2152.014\n",
      "    load_throughput: 4634718.086\n",
      "    load_time_ms: 0.863\n",
      "    sample_throughput: 2470.096\n",
      "    sample_time_ms: 1619.37\n",
      "    update_time_ms: 1.361\n",
      "  timestamp: 1629485248\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 220000\n",
      "  training_iteration: 55\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         192.565</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\">-988.871</td><td style=\"text-align: right;\">            -501.471</td><td style=\"text-align: right;\">             -1726.4</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 228000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-34\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -411.36966133382225\n",
      "  episode_reward_mean: -953.1972024145348\n",
      "  episode_reward_min: -1698.2448619264273\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1140\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.9809526205062866\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01407674327492714\n",
      "          model: {}\n",
      "          policy_loss: -0.012463761493563652\n",
      "          total_loss: 8902.99609375\n",
      "          vf_explained_var: 0.28797224164009094\n",
      "          vf_loss: 8902.994140625\n",
      "    num_agent_steps_sampled: 228000\n",
      "    num_agent_steps_trained: 228000\n",
      "    num_steps_sampled: 228000\n",
      "    num_steps_trained: 228000\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.799999999999997\n",
      "    ram_util_percent: 67.05000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07166367150565657\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1029198637035071\n",
      "    mean_inference_ms: 0.4999740656953733\n",
      "    mean_raw_obs_processing_ms: 0.047973187625595416\n",
      "  time_since_restore: 199.05036783218384\n",
      "  time_this_iter_s: 3.2255349159240723\n",
      "  time_total_s: 199.05036783218384\n",
      "  timers:\n",
      "    learn_throughput: 1868.44\n",
      "    learn_time_ms: 2140.823\n",
      "    load_throughput: 4725310.801\n",
      "    load_time_ms: 0.847\n",
      "    sample_throughput: 2517.226\n",
      "    sample_time_ms: 1589.051\n",
      "    update_time_ms: 1.373\n",
      "  timestamp: 1629485254\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 228000\n",
      "  training_iteration: 57\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">          199.05</td><td style=\"text-align: right;\">228000</td><td style=\"text-align: right;\">-953.197</td><td style=\"text-align: right;\">             -411.37</td><td style=\"text-align: right;\">            -1698.24</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 236000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-43\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -411.36966133382225\n",
      "  episode_reward_mean: -923.5028760815865\n",
      "  episode_reward_min: -1698.2448619264273\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1180\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.5522300004959106\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011608139611780643\n",
      "          model: {}\n",
      "          policy_loss: -0.009791683405637741\n",
      "          total_loss: 13132.0341796875\n",
      "          vf_explained_var: 0.4275711178779602\n",
      "          vf_loss: 13132.03125\n",
      "    num_agent_steps_sampled: 236000\n",
      "    num_agent_steps_trained: 236000\n",
      "    num_steps_sampled: 236000\n",
      "    num_steps_trained: 236000\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.41428571428572\n",
      "    ram_util_percent: 68.64285714285714\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07186028938125313\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10311551202615077\n",
      "    mean_inference_ms: 0.5013012491915823\n",
      "    mean_raw_obs_processing_ms: 0.04810173879713577\n",
      "  time_since_restore: 207.85307955741882\n",
      "  time_this_iter_s: 4.803573846817017\n",
      "  time_total_s: 207.85307955741882\n",
      "  timers:\n",
      "    learn_throughput: 1768.7\n",
      "    learn_time_ms: 2261.549\n",
      "    load_throughput: 4209035.625\n",
      "    load_time_ms: 0.95\n",
      "    sample_throughput: 2423.556\n",
      "    sample_time_ms: 1650.467\n",
      "    update_time_ms: 1.571\n",
      "  timestamp: 1629485263\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 236000\n",
      "  training_iteration: 59\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         207.853</td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\">-923.503</td><td style=\"text-align: right;\">             -411.37</td><td style=\"text-align: right;\">            -1698.24</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 244000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-50\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -644.1001234234999\n",
      "  episode_reward_mean: -954.8672878838067\n",
      "  episode_reward_min: -1815.2885135142992\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1220\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7281264066696167\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01056593470275402\n",
      "          model: {}\n",
      "          policy_loss: -0.01810789294540882\n",
      "          total_loss: 12390.83203125\n",
      "          vf_explained_var: 0.5107462406158447\n",
      "          vf_loss: 12390.8388671875\n",
      "    num_agent_steps_sampled: 244000\n",
      "    num_agent_steps_trained: 244000\n",
      "    num_steps_sampled: 244000\n",
      "    num_steps_trained: 244000\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.700000000000003\n",
      "    ram_util_percent: 66.95\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07204413822637887\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10331978012680391\n",
      "    mean_inference_ms: 0.5025678053272779\n",
      "    mean_raw_obs_processing_ms: 0.0482230512756005\n",
      "  time_since_restore: 214.5980944633484\n",
      "  time_this_iter_s: 3.204292058944702\n",
      "  time_total_s: 214.5980944633484\n",
      "  timers:\n",
      "    learn_throughput: 1771.24\n",
      "    learn_time_ms: 2258.305\n",
      "    load_throughput: 4220895.643\n",
      "    load_time_ms: 0.948\n",
      "    sample_throughput: 2393.167\n",
      "    sample_time_ms: 1671.426\n",
      "    update_time_ms: 1.554\n",
      "  timestamp: 1629485270\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 244000\n",
      "  training_iteration: 61\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         214.598</td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\">-954.867</td><td style=\"text-align: right;\">              -644.1</td><td style=\"text-align: right;\">            -1815.29</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 252000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-47-57\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -644.1001234234999\n",
      "  episode_reward_mean: -990.1667539342235\n",
      "  episode_reward_min: -1815.2885135142992\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1260\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.5871754884719849\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013256299309432507\n",
      "          model: {}\n",
      "          policy_loss: -0.010848736390471458\n",
      "          total_loss: 12965.8037109375\n",
      "          vf_explained_var: 0.4771033227443695\n",
      "          vf_loss: 12965.80078125\n",
      "    num_agent_steps_sampled: 252000\n",
      "    num_agent_steps_trained: 252000\n",
      "    num_steps_sampled: 252000\n",
      "    num_steps_trained: 252000\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.199999999999996\n",
      "    ram_util_percent: 66.45\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07226419851116896\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10357162121364873\n",
      "    mean_inference_ms: 0.5040461058226015\n",
      "    mean_raw_obs_processing_ms: 0.04837140009202111\n",
      "  time_since_restore: 221.48597860336304\n",
      "  time_this_iter_s: 3.188655138015747\n",
      "  time_total_s: 221.48597860336304\n",
      "  timers:\n",
      "    learn_throughput: 1918.906\n",
      "    learn_time_ms: 2084.521\n",
      "    load_throughput: 4242348.598\n",
      "    load_time_ms: 0.943\n",
      "    sample_throughput: 2488.997\n",
      "    sample_time_ms: 1607.073\n",
      "    update_time_ms: 1.462\n",
      "  timestamp: 1629485277\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 252000\n",
      "  training_iteration: 63\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         221.486</td><td style=\"text-align: right;\">252000</td><td style=\"text-align: right;\">-990.167</td><td style=\"text-align: right;\">              -644.1</td><td style=\"text-align: right;\">            -1815.29</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 260000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-03\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -644.1001234234999\n",
      "  episode_reward_mean: -973.8727877567844\n",
      "  episode_reward_min: -1815.2885135142992\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1300\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.197723150253296\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009940294548869133\n",
      "          model: {}\n",
      "          policy_loss: -0.008407527580857277\n",
      "          total_loss: 9240.6494140625\n",
      "          vf_explained_var: 0.44488388299942017\n",
      "          vf_loss: 9240.6484375\n",
      "    num_agent_steps_sampled: 260000\n",
      "    num_agent_steps_trained: 260000\n",
      "    num_steps_sampled: 260000\n",
      "    num_steps_trained: 260000\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.82\n",
      "    ram_util_percent: 66.23999999999998\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0721766507915604\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10347095862302087\n",
      "    mean_inference_ms: 0.5035057579202338\n",
      "    mean_raw_obs_processing_ms: 0.048310544718018225\n",
      "  time_since_restore: 227.92214226722717\n",
      "  time_this_iter_s: 3.258575677871704\n",
      "  time_total_s: 227.92214226722717\n",
      "  timers:\n",
      "    learn_throughput: 1966.606\n",
      "    learn_time_ms: 2033.961\n",
      "    load_throughput: 4415173.031\n",
      "    load_time_ms: 0.906\n",
      "    sample_throughput: 2674.738\n",
      "    sample_time_ms: 1495.474\n",
      "    update_time_ms: 1.467\n",
      "  timestamp: 1629485283\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 260000\n",
      "  training_iteration: 65\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         227.922</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\">-973.873</td><td style=\"text-align: right;\">              -644.1</td><td style=\"text-align: right;\">            -1815.29</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 268000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-10\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -500.3891987307547\n",
      "  episode_reward_mean: -919.4078348580683\n",
      "  episode_reward_min: -1804.578475378275\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1340\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.877570629119873\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01697554998099804\n",
      "          model: {}\n",
      "          policy_loss: -0.007996234111487865\n",
      "          total_loss: 8950.8564453125\n",
      "          vf_explained_var: 0.31427842378616333\n",
      "          vf_loss: 8950.8466796875\n",
      "    num_agent_steps_sampled: 268000\n",
      "    num_agent_steps_trained: 268000\n",
      "    num_steps_sampled: 268000\n",
      "    num_steps_trained: 268000\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.659999999999997\n",
      "    ram_util_percent: 65.86\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07202082686264268\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1032828893052961\n",
      "    mean_inference_ms: 0.5025291956996009\n",
      "    mean_raw_obs_processing_ms: 0.04820132326426412\n",
      "  time_since_restore: 234.37717509269714\n",
      "  time_this_iter_s: 3.212095022201538\n",
      "  time_total_s: 234.37717509269714\n",
      "  timers:\n",
      "    learn_throughput: 1969.709\n",
      "    learn_time_ms: 2030.757\n",
      "    load_throughput: 4324247.642\n",
      "    load_time_ms: 0.925\n",
      "    sample_throughput: 2674.651\n",
      "    sample_time_ms: 1495.522\n",
      "    update_time_ms: 1.475\n",
      "  timestamp: 1629485290\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 268000\n",
      "  training_iteration: 67\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         234.377</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\">-919.408</td><td style=\"text-align: right;\">            -500.389</td><td style=\"text-align: right;\">            -1804.58</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 276000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-16\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -375.240588422337\n",
      "  episode_reward_mean: -859.6136573132488\n",
      "  episode_reward_min: -1787.4435496163799\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1380\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.0888336896896362\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014043658971786499\n",
      "          model: {}\n",
      "          policy_loss: -0.01441219076514244\n",
      "          total_loss: 8052.61083984375\n",
      "          vf_explained_var: 0.4832903742790222\n",
      "          vf_loss: 8052.611328125\n",
      "    num_agent_steps_sampled: 276000\n",
      "    num_agent_steps_trained: 276000\n",
      "    num_steps_sampled: 276000\n",
      "    num_steps_trained: 276000\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.880000000000003\n",
      "    ram_util_percent: 65.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07185988501579528\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10308743250921891\n",
      "    mean_inference_ms: 0.5015173290981678\n",
      "    mean_raw_obs_processing_ms: 0.048082198881463964\n",
      "  time_since_restore: 240.84571886062622\n",
      "  time_this_iter_s: 3.2382888793945312\n",
      "  time_total_s: 240.84571886062622\n",
      "  timers:\n",
      "    learn_throughput: 2135.888\n",
      "    learn_time_ms: 1872.757\n",
      "    load_throughput: 4919139.154\n",
      "    load_time_ms: 0.813\n",
      "    sample_throughput: 2815.648\n",
      "    sample_time_ms: 1420.632\n",
      "    update_time_ms: 1.345\n",
      "  timestamp: 1629485296\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 276000\n",
      "  training_iteration: 69\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         240.846</td><td style=\"text-align: right;\">276000</td><td style=\"text-align: right;\">-859.614</td><td style=\"text-align: right;\">            -375.241</td><td style=\"text-align: right;\">            -1787.44</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 284000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-23\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -375.240588422337\n",
      "  episode_reward_mean: -883.0650201359236\n",
      "  episode_reward_min: -1570.1519081428155\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1420\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1058136224746704\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01135489996522665\n",
      "          model: {}\n",
      "          policy_loss: -0.02085150219500065\n",
      "          total_loss: 8800.94921875\n",
      "          vf_explained_var: 0.4533478617668152\n",
      "          vf_loss: 8800.9599609375\n",
      "    num_agent_steps_sampled: 284000\n",
      "    num_agent_steps_trained: 284000\n",
      "    num_steps_sampled: 284000\n",
      "    num_steps_trained: 284000\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.775\n",
      "    ram_util_percent: 65.80000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07171372425279346\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10290519736995403\n",
      "    mean_inference_ms: 0.5005962534093122\n",
      "    mean_raw_obs_processing_ms: 0.04797227470999254\n",
      "  time_since_restore: 247.3451406955719\n",
      "  time_this_iter_s: 3.2295868396759033\n",
      "  time_total_s: 247.3451406955719\n",
      "  timers:\n",
      "    learn_throughput: 2135.609\n",
      "    learn_time_ms: 1873.002\n",
      "    load_throughput: 4797876.916\n",
      "    load_time_ms: 0.834\n",
      "    sample_throughput: 2865.72\n",
      "    sample_time_ms: 1395.81\n",
      "    update_time_ms: 1.346\n",
      "  timestamp: 1629485303\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 284000\n",
      "  training_iteration: 71\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         247.345</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\">-883.065</td><td style=\"text-align: right;\">            -375.241</td><td style=\"text-align: right;\">            -1570.15</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 292000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-30\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -489.833076166596\n",
      "  episode_reward_mean: -903.2199600083534\n",
      "  episode_reward_min: -1655.732895147801\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1460\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.6261107921600342\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010865563526749611\n",
      "          model: {}\n",
      "          policy_loss: -0.021891038864850998\n",
      "          total_loss: 8553.205078125\n",
      "          vf_explained_var: 0.6509803533554077\n",
      "          vf_loss: 8553.21484375\n",
      "    num_agent_steps_sampled: 292000\n",
      "    num_agent_steps_trained: 292000\n",
      "    num_steps_sampled: 292000\n",
      "    num_steps_trained: 292000\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.52\n",
      "    ram_util_percent: 65.75999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07157436611146525\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10273516656981638\n",
      "    mean_inference_ms: 0.49974343399074683\n",
      "    mean_raw_obs_processing_ms: 0.04786883389762122\n",
      "  time_since_restore: 253.85786700248718\n",
      "  time_this_iter_s: 3.221330165863037\n",
      "  time_total_s: 253.85786700248718\n",
      "  timers:\n",
      "    learn_throughput: 2156.745\n",
      "    learn_time_ms: 1854.647\n",
      "    load_throughput: 4798563.052\n",
      "    load_time_ms: 0.834\n",
      "    sample_throughput: 2905.41\n",
      "    sample_time_ms: 1376.742\n",
      "    update_time_ms: 1.346\n",
      "  timestamp: 1629485310\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 292000\n",
      "  training_iteration: 73\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         253.858</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\"> -903.22</td><td style=\"text-align: right;\">            -489.833</td><td style=\"text-align: right;\">            -1655.73</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 300000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-36\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -492.6382714003566\n",
      "  episode_reward_mean: -884.8873054150646\n",
      "  episode_reward_min: -1655.732895147801\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1500\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3087481260299683\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012823345139622688\n",
      "          model: {}\n",
      "          policy_loss: -0.0180087611079216\n",
      "          total_loss: 8927.509765625\n",
      "          vf_explained_var: 0.4935537278652191\n",
      "          vf_loss: 8927.5146484375\n",
      "    num_agent_steps_sampled: 300000\n",
      "    num_agent_steps_trained: 300000\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.48\n",
      "    ram_util_percent: 65.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0714458502147049\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1025766704039696\n",
      "    mean_inference_ms: 0.49896513927600067\n",
      "    mean_raw_obs_processing_ms: 0.047770738223852326\n",
      "  time_since_restore: 260.3394031524658\n",
      "  time_this_iter_s: 3.2420310974121094\n",
      "  time_total_s: 260.3394031524658\n",
      "  timers:\n",
      "    learn_throughput: 2157.662\n",
      "    learn_time_ms: 1853.858\n",
      "    load_throughput: 4779288.97\n",
      "    load_time_ms: 0.837\n",
      "    sample_throughput: 2894.876\n",
      "    sample_time_ms: 1381.752\n",
      "    update_time_ms: 1.431\n",
      "  timestamp: 1629485316\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 75\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         260.339</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">-884.887</td><td style=\"text-align: right;\">            -492.638</td><td style=\"text-align: right;\">            -1655.73</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 308000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-43\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -500.2011254067121\n",
      "  episode_reward_mean: -884.805798401424\n",
      "  episode_reward_min: -1703.524210961871\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1540\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.107470154762268\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012602739967405796\n",
      "          model: {}\n",
      "          policy_loss: -0.016861626878380775\n",
      "          total_loss: 9049.8876953125\n",
      "          vf_explained_var: 0.4470648169517517\n",
      "          vf_loss: 9049.8935546875\n",
      "    num_agent_steps_sampled: 308000\n",
      "    num_agent_steps_trained: 308000\n",
      "    num_steps_sampled: 308000\n",
      "    num_steps_trained: 308000\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.925000000000004\n",
      "    ram_util_percent: 65.55\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07132285897396151\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10242644914354358\n",
      "    mean_inference_ms: 0.4981971070040043\n",
      "    mean_raw_obs_processing_ms: 0.047674162899101855\n",
      "  time_since_restore: 266.8091173171997\n",
      "  time_this_iter_s: 3.2402291297912598\n",
      "  time_total_s: 266.8091173171997\n",
      "  timers:\n",
      "    learn_throughput: 2157.831\n",
      "    learn_time_ms: 1853.713\n",
      "    load_throughput: 4713760.396\n",
      "    load_time_ms: 0.849\n",
      "    sample_throughput: 2891.293\n",
      "    sample_time_ms: 1383.464\n",
      "    update_time_ms: 1.425\n",
      "  timestamp: 1629485323\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 308000\n",
      "  training_iteration: 77\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         266.809</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">-884.806</td><td style=\"text-align: right;\">            -500.201</td><td style=\"text-align: right;\">            -1703.52</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 316000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-49\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -500.5530806236494\n",
      "  episode_reward_mean: -845.3488103274074\n",
      "  episode_reward_min: -1787.8314336222272\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1580\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3047748804092407\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012788317166268826\n",
      "          model: {}\n",
      "          policy_loss: -0.021438302472233772\n",
      "          total_loss: 7424.08251953125\n",
      "          vf_explained_var: 0.5574263334274292\n",
      "          vf_loss: 7424.0908203125\n",
      "    num_agent_steps_sampled: 316000\n",
      "    num_agent_steps_trained: 316000\n",
      "    num_steps_sampled: 316000\n",
      "    num_steps_trained: 316000\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.175\n",
      "    ram_util_percent: 65.5\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07121494026963095\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10229074692884961\n",
      "    mean_inference_ms: 0.4975350050618481\n",
      "    mean_raw_obs_processing_ms: 0.04758711825493961\n",
      "  time_since_restore: 273.29408740997314\n",
      "  time_this_iter_s: 3.2561700344085693\n",
      "  time_total_s: 273.29408740997314\n",
      "  timers:\n",
      "    learn_throughput: 2158.52\n",
      "    learn_time_ms: 1853.121\n",
      "    load_throughput: 4704112.155\n",
      "    load_time_ms: 0.85\n",
      "    sample_throughput: 2886.144\n",
      "    sample_time_ms: 1385.932\n",
      "    update_time_ms: 1.326\n",
      "  timestamp: 1629485329\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 316000\n",
      "  training_iteration: 79\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         273.294</td><td style=\"text-align: right;\">316000</td><td style=\"text-align: right;\">-845.349</td><td style=\"text-align: right;\">            -500.553</td><td style=\"text-align: right;\">            -1787.83</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 324000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-48-56\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -494.20018185794504\n",
      "  episode_reward_mean: -808.263663329181\n",
      "  episode_reward_min: -1787.8314336222272\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1620\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1429001092910767\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013791458681225777\n",
      "          model: {}\n",
      "          policy_loss: -0.0159845482558012\n",
      "          total_loss: 7514.08984375\n",
      "          vf_explained_var: 0.5541303157806396\n",
      "          vf_loss: 7514.0908203125\n",
      "    num_agent_steps_sampled: 324000\n",
      "    num_agent_steps_trained: 324000\n",
      "    num_steps_sampled: 324000\n",
      "    num_steps_trained: 324000\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.839999999999996\n",
      "    ram_util_percent: 65.6\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07111037744927293\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10216389128855025\n",
      "    mean_inference_ms: 0.4969166362427934\n",
      "    mean_raw_obs_processing_ms: 0.04750806594925312\n",
      "  time_since_restore: 279.86789202690125\n",
      "  time_this_iter_s: 3.3440709114074707\n",
      "  time_total_s: 279.86789202690125\n",
      "  timers:\n",
      "    learn_throughput: 2148.856\n",
      "    learn_time_ms: 1861.456\n",
      "    load_throughput: 4702925.38\n",
      "    load_time_ms: 0.851\n",
      "    sample_throughput: 2887.956\n",
      "    sample_time_ms: 1385.063\n",
      "    update_time_ms: 1.308\n",
      "  timestamp: 1629485336\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 324000\n",
      "  training_iteration: 81\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         279.868</td><td style=\"text-align: right;\">324000</td><td style=\"text-align: right;\">-808.264</td><td style=\"text-align: right;\">              -494.2</td><td style=\"text-align: right;\">            -1787.83</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 332000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-02\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -494.20018185794504\n",
      "  episode_reward_mean: -775.3160524743602\n",
      "  episode_reward_min: -1772.5397490771331\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1660\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2818514108657837\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010063674300909042\n",
      "          model: {}\n",
      "          policy_loss: -0.015131683088839054\n",
      "          total_loss: 7614.55859375\n",
      "          vf_explained_var: 0.5766569375991821\n",
      "          vf_loss: 7614.56298828125\n",
      "    num_agent_steps_sampled: 332000\n",
      "    num_agent_steps_trained: 332000\n",
      "    num_steps_sampled: 332000\n",
      "    num_steps_trained: 332000\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.900000000000002\n",
      "    ram_util_percent: 66.125\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07102026323059256\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10206055054537871\n",
      "    mean_inference_ms: 0.49638265304655604\n",
      "    mean_raw_obs_processing_ms: 0.04744298520001368\n",
      "  time_since_restore: 286.479868888855\n",
      "  time_this_iter_s: 3.2146849632263184\n",
      "  time_total_s: 286.479868888855\n",
      "  timers:\n",
      "    learn_throughput: 2145.103\n",
      "    learn_time_ms: 1864.713\n",
      "    load_throughput: 4673839.982\n",
      "    load_time_ms: 0.856\n",
      "    sample_throughput: 2874.433\n",
      "    sample_time_ms: 1391.579\n",
      "    update_time_ms: 1.34\n",
      "  timestamp: 1629485342\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 332000\n",
      "  training_iteration: 83\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">          286.48</td><td style=\"text-align: right;\">332000</td><td style=\"text-align: right;\">-775.316</td><td style=\"text-align: right;\">              -494.2</td><td style=\"text-align: right;\">            -1772.54</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 340000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-11\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -496.28796498523644\n",
      "  episode_reward_mean: -744.5336173739156\n",
      "  episode_reward_min: -1772.5397490771331\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1700\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2769513130187988\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011985479854047298\n",
      "          model: {}\n",
      "          policy_loss: -0.01813066378235817\n",
      "          total_loss: 6506.54443359375\n",
      "          vf_explained_var: 0.6198861002922058\n",
      "          vf_loss: 6506.54931640625\n",
      "    num_agent_steps_sampled: 340000\n",
      "    num_agent_steps_trained: 340000\n",
      "    num_steps_sampled: 340000\n",
      "    num_steps_trained: 340000\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.34\n",
      "    ram_util_percent: 66.66\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07107693402743594\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10213469367565997\n",
      "    mean_inference_ms: 0.4967895383578538\n",
      "    mean_raw_obs_processing_ms: 0.047491092866331436\n",
      "  time_since_restore: 294.66577887535095\n",
      "  time_this_iter_s: 3.527911901473999\n",
      "  time_total_s: 294.66577887535095\n",
      "  timers:\n",
      "    learn_throughput: 2027.806\n",
      "    learn_time_ms: 1972.576\n",
      "    load_throughput: 4228448.723\n",
      "    load_time_ms: 0.946\n",
      "    sample_throughput: 2750.886\n",
      "    sample_time_ms: 1454.077\n",
      "    update_time_ms: 1.329\n",
      "  timestamp: 1629485351\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 340000\n",
      "  training_iteration: 85\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         294.666</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\">-744.534</td><td style=\"text-align: right;\">            -496.288</td><td style=\"text-align: right;\">            -1772.54</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 348000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-17\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -366.6225700801443\n",
      "  episode_reward_mean: -702.2920121904233\n",
      "  episode_reward_min: -1772.5397490771331\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1740\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.894886314868927\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013597758486866951\n",
      "          model: {}\n",
      "          policy_loss: -0.015195478685200214\n",
      "          total_loss: 6608.53759765625\n",
      "          vf_explained_var: 0.40700361132621765\n",
      "          vf_loss: 6608.5380859375\n",
      "    num_agent_steps_sampled: 348000\n",
      "    num_agent_steps_trained: 348000\n",
      "    num_steps_sampled: 348000\n",
      "    num_steps_trained: 348000\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.6\n",
      "    ram_util_percent: 66.76000000000002\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07113086827987597\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10220784952155208\n",
      "    mean_inference_ms: 0.4971753666050644\n",
      "    mean_raw_obs_processing_ms: 0.047539097789175866\n",
      "  time_since_restore: 301.3475377559662\n",
      "  time_this_iter_s: 3.363055944442749\n",
      "  time_total_s: 301.3475377559662\n",
      "  timers:\n",
      "    learn_throughput: 2004.126\n",
      "    learn_time_ms: 1995.882\n",
      "    load_throughput: 4348231.391\n",
      "    load_time_ms: 0.92\n",
      "    sample_throughput: 2755.34\n",
      "    sample_time_ms: 1451.726\n",
      "    update_time_ms: 1.381\n",
      "  timestamp: 1629485357\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 348000\n",
      "  training_iteration: 87\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         301.348</td><td style=\"text-align: right;\">348000</td><td style=\"text-align: right;\">-702.292</td><td style=\"text-align: right;\">            -366.623</td><td style=\"text-align: right;\">            -1772.54</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 356000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-24\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -366.6225700801443\n",
      "  episode_reward_mean: -698.5064725357158\n",
      "  episode_reward_min: -1804.07088610893\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1780\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1532264947891235\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011898976750671864\n",
      "          model: {}\n",
      "          policy_loss: -0.02045481838285923\n",
      "          total_loss: 8572.810546875\n",
      "          vf_explained_var: 0.6153269410133362\n",
      "          vf_loss: 8572.818359375\n",
      "    num_agent_steps_sampled: 356000\n",
      "    num_agent_steps_trained: 356000\n",
      "    num_steps_sampled: 356000\n",
      "    num_steps_trained: 356000\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.7\n",
      "    ram_util_percent: 66.36\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07114389955694676\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10223559482875047\n",
      "    mean_inference_ms: 0.4972642109839326\n",
      "    mean_raw_obs_processing_ms: 0.04755801658577164\n",
      "  time_since_restore: 308.2827994823456\n",
      "  time_this_iter_s: 3.588160991668701\n",
      "  time_total_s: 308.2827994823456\n",
      "  timers:\n",
      "    learn_throughput: 1976.964\n",
      "    learn_time_ms: 2023.304\n",
      "    load_throughput: 4213157.882\n",
      "    load_time_ms: 0.949\n",
      "    sample_throughput: 2723.063\n",
      "    sample_time_ms: 1468.934\n",
      "    update_time_ms: 1.457\n",
      "  timestamp: 1629485364\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 356000\n",
      "  training_iteration: 89\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         308.283</td><td style=\"text-align: right;\">356000</td><td style=\"text-align: right;\">-698.506</td><td style=\"text-align: right;\">            -366.623</td><td style=\"text-align: right;\">            -1804.07</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 364000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-31\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -251.45630504880916\n",
      "  episode_reward_mean: -663.4683699076355\n",
      "  episode_reward_min: -1804.07088610893\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1820\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.9531769156455994\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017534207552671432\n",
      "          model: {}\n",
      "          policy_loss: -0.021498924121260643\n",
      "          total_loss: 4533.3076171875\n",
      "          vf_explained_var: 0.7286509275436401\n",
      "          vf_loss: 4533.31103515625\n",
      "    num_agent_steps_sampled: 364000\n",
      "    num_agent_steps_trained: 364000\n",
      "    num_steps_sampled: 364000\n",
      "    num_steps_trained: 364000\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.660000000000004\n",
      "    ram_util_percent: 68.46000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0711659853679825\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10227415291792653\n",
      "    mean_inference_ms: 0.4973905519966965\n",
      "    mean_raw_obs_processing_ms: 0.04757872478588376\n",
      "  time_since_restore: 315.3147404193878\n",
      "  time_this_iter_s: 3.4044840335845947\n",
      "  time_total_s: 315.3147404193878\n",
      "  timers:\n",
      "    learn_throughput: 1971.012\n",
      "    learn_time_ms: 2029.414\n",
      "    load_throughput: 4088314.448\n",
      "    load_time_ms: 0.978\n",
      "    sample_throughput: 2651.807\n",
      "    sample_time_ms: 1508.405\n",
      "    update_time_ms: 1.516\n",
      "  timestamp: 1629485371\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 364000\n",
      "  training_iteration: 91\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         315.315</td><td style=\"text-align: right;\">364000</td><td style=\"text-align: right;\">-663.468</td><td style=\"text-align: right;\">            -251.456</td><td style=\"text-align: right;\">            -1804.07</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 372000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-38\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -251.45630504880916\n",
      "  episode_reward_mean: -645.9403975517781\n",
      "  episode_reward_min: -1728.8776258204562\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1860\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.8381274342536926\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013584040105342865\n",
      "          model: {}\n",
      "          policy_loss: -0.016646770760416985\n",
      "          total_loss: 2890.692138671875\n",
      "          vf_explained_var: 0.768486738204956\n",
      "          vf_loss: 2890.695068359375\n",
      "    num_agent_steps_sampled: 372000\n",
      "    num_agent_steps_trained: 372000\n",
      "    num_steps_sampled: 372000\n",
      "    num_steps_trained: 372000\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.160000000000004\n",
      "    ram_util_percent: 67.46000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07123988526361312\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10237865058823419\n",
      "    mean_inference_ms: 0.49786936735401527\n",
      "    mean_raw_obs_processing_ms: 0.04764452451010939\n",
      "  time_since_restore: 322.02294063568115\n",
      "  time_this_iter_s: 3.2619330883026123\n",
      "  time_total_s: 322.02294063568115\n",
      "  timers:\n",
      "    learn_throughput: 1974.427\n",
      "    learn_time_ms: 2025.904\n",
      "    load_throughput: 4154215.817\n",
      "    load_time_ms: 0.963\n",
      "    sample_throughput: 2628.883\n",
      "    sample_time_ms: 1521.559\n",
      "    update_time_ms: 1.52\n",
      "  timestamp: 1629485378\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 372000\n",
      "  training_iteration: 93\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         322.023</td><td style=\"text-align: right;\">372000</td><td style=\"text-align: right;\"> -645.94</td><td style=\"text-align: right;\">            -251.456</td><td style=\"text-align: right;\">            -1728.88</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 380000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-45\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -128.49092281635353\n",
      "  episode_reward_mean: -601.8772232079974\n",
      "  episode_reward_min: -1769.3963747194175\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1900\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1069345474243164\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009890632703900337\n",
      "          model: {}\n",
      "          policy_loss: -0.015983613207936287\n",
      "          total_loss: 5715.34716796875\n",
      "          vf_explained_var: 0.7970908880233765\n",
      "          vf_loss: 5715.353515625\n",
      "    num_agent_steps_sampled: 380000\n",
      "    num_agent_steps_trained: 380000\n",
      "    num_steps_sampled: 380000\n",
      "    num_steps_trained: 380000\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.24\n",
      "    ram_util_percent: 66.38\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07129270349677118\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10245220457196456\n",
      "    mean_inference_ms: 0.498219186700686\n",
      "    mean_raw_obs_processing_ms: 0.04769194037377519\n",
      "  time_since_restore: 328.98945689201355\n",
      "  time_this_iter_s: 3.2396399974823\n",
      "  time_total_s: 328.98945689201355\n",
      "  timers:\n",
      "    learn_throughput: 2051.549\n",
      "    learn_time_ms: 1949.746\n",
      "    load_throughput: 4461550.899\n",
      "    load_time_ms: 0.897\n",
      "    sample_throughput: 2709.885\n",
      "    sample_time_ms: 1476.077\n",
      "    update_time_ms: 1.45\n",
      "  timestamp: 1629485385\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 380000\n",
      "  training_iteration: 95\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         328.989</td><td style=\"text-align: right;\">380000</td><td style=\"text-align: right;\">-601.877</td><td style=\"text-align: right;\">            -128.491</td><td style=\"text-align: right;\">             -1769.4</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 388000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-53\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -122.16343090166565\n",
      "  episode_reward_mean: -523.9962195018411\n",
      "  episode_reward_min: -1769.3963747194175\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1940\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.625196635723114\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0127638578414917\n",
      "          model: {}\n",
      "          policy_loss: -0.018134335055947304\n",
      "          total_loss: 1832.400146484375\n",
      "          vf_explained_var: 0.8256890177726746\n",
      "          vf_loss: 1832.4053955078125\n",
      "    num_agent_steps_sampled: 388000\n",
      "    num_agent_steps_trained: 388000\n",
      "    num_steps_sampled: 388000\n",
      "    num_steps_trained: 388000\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 36.38333333333333\n",
      "    ram_util_percent: 67.23333333333333\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07133576160599375\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10250606085501084\n",
      "    mean_inference_ms: 0.498530637139076\n",
      "    mean_raw_obs_processing_ms: 0.04772011311049724\n",
      "  time_since_restore: 336.38775515556335\n",
      "  time_this_iter_s: 4.117885112762451\n",
      "  time_total_s: 336.38775515556335\n",
      "  timers:\n",
      "    learn_throughput: 2049.895\n",
      "    learn_time_ms: 1951.32\n",
      "    load_throughput: 4394011.838\n",
      "    load_time_ms: 0.91\n",
      "    sample_throughput: 2586.731\n",
      "    sample_time_ms: 1546.353\n",
      "    update_time_ms: 1.424\n",
      "  timestamp: 1629485393\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 388000\n",
      "  training_iteration: 97\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         336.388</td><td style=\"text-align: right;\">388000</td><td style=\"text-align: right;\">-523.996</td><td style=\"text-align: right;\">            -122.163</td><td style=\"text-align: right;\">             -1769.4</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 396000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-49-59\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2.52912217531191\n",
      "  episode_reward_mean: -548.826271675337\n",
      "  episode_reward_min: -1769.3963747194175\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1980\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1419079303741455\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0139545239508152\n",
      "          model: {}\n",
      "          policy_loss: -0.022646300494670868\n",
      "          total_loss: 3520.194091796875\n",
      "          vf_explained_var: 0.852955162525177\n",
      "          vf_loss: 3520.202392578125\n",
      "    num_agent_steps_sampled: 396000\n",
      "    num_agent_steps_trained: 396000\n",
      "    num_steps_sampled: 396000\n",
      "    num_steps_trained: 396000\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.18\n",
      "    ram_util_percent: 67.66\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07141419623342332\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10260007973192513\n",
      "    mean_inference_ms: 0.4991049651972073\n",
      "    mean_raw_obs_processing_ms: 0.047767174253463454\n",
      "  time_since_restore: 342.8990173339844\n",
      "  time_this_iter_s: 3.1951842308044434\n",
      "  time_total_s: 342.8990173339844\n",
      "  timers:\n",
      "    learn_throughput: 2077.828\n",
      "    learn_time_ms: 1925.087\n",
      "    load_throughput: 4516439.013\n",
      "    load_time_ms: 0.886\n",
      "    sample_throughput: 2613.36\n",
      "    sample_time_ms: 1530.596\n",
      "    update_time_ms: 1.356\n",
      "  timestamp: 1629485399\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 396000\n",
      "  training_iteration: 99\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         342.899</td><td style=\"text-align: right;\">396000</td><td style=\"text-align: right;\">-548.826</td><td style=\"text-align: right;\">            -2.52912</td><td style=\"text-align: right;\">             -1769.4</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 404000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-50-07\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2.52912217531191\n",
      "  episode_reward_mean: -500.4693218801559\n",
      "  episode_reward_min: -1749.7129137520612\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2020\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5574398040771484\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01063667144626379\n",
      "          model: {}\n",
      "          policy_loss: -0.01845693774521351\n",
      "          total_loss: 1235.53076171875\n",
      "          vf_explained_var: 0.9049233198165894\n",
      "          vf_loss: 1235.53857421875\n",
      "    num_agent_steps_sampled: 404000\n",
      "    num_agent_steps_trained: 404000\n",
      "    num_steps_sampled: 404000\n",
      "    num_steps_trained: 404000\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.050000000000004\n",
      "    ram_util_percent: 67.3\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07150256651353731\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10270838415636707\n",
      "    mean_inference_ms: 0.4997482598134415\n",
      "    mean_raw_obs_processing_ms: 0.047823995791188685\n",
      "  time_since_restore: 350.6344995498657\n",
      "  time_this_iter_s: 4.221503019332886\n",
      "  time_total_s: 350.6344995498657\n",
      "  timers:\n",
      "    learn_throughput: 1996.55\n",
      "    learn_time_ms: 2003.456\n",
      "    load_throughput: 4493094.804\n",
      "    load_time_ms: 0.89\n",
      "    sample_throughput: 2626.937\n",
      "    sample_time_ms: 1522.686\n",
      "    update_time_ms: 1.328\n",
      "  timestamp: 1629485407\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 404000\n",
      "  training_iteration: 101\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         350.634</td><td style=\"text-align: right;\">404000</td><td style=\"text-align: right;\">-500.469</td><td style=\"text-align: right;\">            -2.52912</td><td style=\"text-align: right;\">            -1749.71</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 412000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-50-14\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2.52912217531191\n",
      "  episode_reward_mean: -498.5790289645226\n",
      "  episode_reward_min: -1723.2982295313748\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2060\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1897404193878174\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011463725008070469\n",
      "          model: {}\n",
      "          policy_loss: -0.02069832570850849\n",
      "          total_loss: 4132.2431640625\n",
      "          vf_explained_var: 0.8964266777038574\n",
      "          vf_loss: 4132.251953125\n",
      "    num_agent_steps_sampled: 412000\n",
      "    num_agent_steps_trained: 412000\n",
      "    num_steps_sampled: 412000\n",
      "    num_steps_trained: 412000\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.78\n",
      "    ram_util_percent: 67.92\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07150915014736205\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10272277597198491\n",
      "    mean_inference_ms: 0.4998119716017322\n",
      "    mean_raw_obs_processing_ms: 0.04783184786129704\n",
      "  time_since_restore: 357.66578435897827\n",
      "  time_this_iter_s: 3.2793262004852295\n",
      "  time_total_s: 357.66578435897827\n",
      "  timers:\n",
      "    learn_throughput: 1961.163\n",
      "    learn_time_ms: 2039.606\n",
      "    load_throughput: 4278592.268\n",
      "    load_time_ms: 0.935\n",
      "    sample_throughput: 2633.64\n",
      "    sample_time_ms: 1518.811\n",
      "    update_time_ms: 1.321\n",
      "  timestamp: 1629485414\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 412000\n",
      "  training_iteration: 103\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         357.666</td><td style=\"text-align: right;\">412000</td><td style=\"text-align: right;\">-498.579</td><td style=\"text-align: right;\">            -2.52912</td><td style=\"text-align: right;\">             -1723.3</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 420000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-50-21\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -57.19103100704712\n",
      "  episode_reward_mean: -452.34100220458976\n",
      "  episode_reward_min: -1812.9580340260018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2100\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5983957648277283\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0060006300918757915\n",
      "          model: {}\n",
      "          policy_loss: -0.015968676656484604\n",
      "          total_loss: 2936.256591796875\n",
      "          vf_explained_var: 0.8553943037986755\n",
      "          vf_loss: 2936.26611328125\n",
      "    num_agent_steps_sampled: 420000\n",
      "    num_agent_steps_trained: 420000\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.060000000000002\n",
      "    ram_util_percent: 67.86\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07150506111925554\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10272457320504731\n",
      "    mean_inference_ms: 0.49978697866408694\n",
      "    mean_raw_obs_processing_ms: 0.04783251797798834\n",
      "  time_since_restore: 364.7674992084503\n",
      "  time_this_iter_s: 3.3286688327789307\n",
      "  time_total_s: 364.7674992084503\n",
      "  timers:\n",
      "    learn_throughput: 1925.071\n",
      "    learn_time_ms: 2077.846\n",
      "    load_throughput: 4390332.339\n",
      "    load_time_ms: 0.911\n",
      "    sample_throughput: 2677.499\n",
      "    sample_time_ms: 1493.932\n",
      "    update_time_ms: 1.37\n",
      "  timestamp: 1629485421\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 105\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         364.767</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\">-452.341</td><td style=\"text-align: right;\">             -57.191</td><td style=\"text-align: right;\">            -1812.96</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 428000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-50-29\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.48676704192136266\n",
      "  episode_reward_mean: -401.76998478100387\n",
      "  episode_reward_min: -1812.9580340260018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2140\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.2205180823802948\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014357643201947212\n",
      "          model: {}\n",
      "          policy_loss: -0.023579377681016922\n",
      "          total_loss: 412.3289489746094\n",
      "          vf_explained_var: 0.9397326111793518\n",
      "          vf_loss: 412.3380126953125\n",
      "    num_agent_steps_sampled: 428000\n",
      "    num_agent_steps_trained: 428000\n",
      "    num_steps_sampled: 428000\n",
      "    num_steps_trained: 428000\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.5\n",
      "    ram_util_percent: 67.55999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07147920891603145\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10270619878059038\n",
      "    mean_inference_ms: 0.4995969257245962\n",
      "    mean_raw_obs_processing_ms: 0.04782276369776338\n",
      "  time_since_restore: 372.3628628253937\n",
      "  time_this_iter_s: 3.810384750366211\n",
      "  time_total_s: 372.3628628253937\n",
      "  timers:\n",
      "    learn_throughput: 1880.42\n",
      "    learn_time_ms: 2127.184\n",
      "    load_throughput: 4324359.1\n",
      "    load_time_ms: 0.925\n",
      "    sample_throughput: 2731.951\n",
      "    sample_time_ms: 1464.155\n",
      "    update_time_ms: 1.382\n",
      "  timestamp: 1629485429\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 428000\n",
      "  training_iteration: 107\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         372.363</td><td style=\"text-align: right;\">428000</td><td style=\"text-align: right;\"> -401.77</td><td style=\"text-align: right;\">           -0.486767</td><td style=\"text-align: right;\">            -1812.96</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 436000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-50-37\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.48676704192136266\n",
      "  episode_reward_mean: -337.1318420514648\n",
      "  episode_reward_min: -1812.9580340260018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2180\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.48317816853523254\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006145931314677\n",
      "          model: {}\n",
      "          policy_loss: -0.018793759867548943\n",
      "          total_loss: 799.5115356445312\n",
      "          vf_explained_var: 0.958051860332489\n",
      "          vf_loss: 799.5240478515625\n",
      "    num_agent_steps_sampled: 436000\n",
      "    num_agent_steps_trained: 436000\n",
      "    num_steps_sampled: 436000\n",
      "    num_steps_trained: 436000\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.55\n",
      "    ram_util_percent: 66.83333333333333\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07154089561664662\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10280385453038918\n",
      "    mean_inference_ms: 0.4999949833867061\n",
      "    mean_raw_obs_processing_ms: 0.04788822587355227\n",
      "  time_since_restore: 380.3910298347473\n",
      "  time_this_iter_s: 4.112171173095703\n",
      "  time_total_s: 380.3910298347473\n",
      "  timers:\n",
      "    learn_throughput: 1804.459\n",
      "    learn_time_ms: 2216.731\n",
      "    load_throughput: 3901405.948\n",
      "    load_time_ms: 1.025\n",
      "    sample_throughput: 2622.421\n",
      "    sample_time_ms: 1525.308\n",
      "    update_time_ms: 1.678\n",
      "  timestamp: 1629485437\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 436000\n",
      "  training_iteration: 109\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         380.391</td><td style=\"text-align: right;\">436000</td><td style=\"text-align: right;\">-337.132</td><td style=\"text-align: right;\">           -0.486767</td><td style=\"text-align: right;\">            -1812.96</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 444000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-50-45\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -117.53094002136906\n",
      "  episode_reward_mean: -336.4494431396527\n",
      "  episode_reward_min: -1563.2426621589486\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2220\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.25610220432281494\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011380063369870186\n",
      "          model: {}\n",
      "          policy_loss: -0.02934354916214943\n",
      "          total_loss: 503.468505859375\n",
      "          vf_explained_var: 0.93242347240448\n",
      "          vf_loss: 503.486328125\n",
      "    num_agent_steps_sampled: 444000\n",
      "    num_agent_steps_trained: 444000\n",
      "    num_steps_sampled: 444000\n",
      "    num_steps_trained: 444000\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.516666666666666\n",
      "    ram_util_percent: 66.71666666666665\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07169788738723208\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10302191928598325\n",
      "    mean_inference_ms: 0.5010213370709548\n",
      "    mean_raw_obs_processing_ms: 0.04803363301760986\n",
      "  time_since_restore: 388.1591069698334\n",
      "  time_this_iter_s: 3.6948800086975098\n",
      "  time_total_s: 388.1591069698334\n",
      "  timers:\n",
      "    learn_throughput: 1814.176\n",
      "    learn_time_ms: 2204.857\n",
      "    load_throughput: 3908131.1\n",
      "    load_time_ms: 1.024\n",
      "    sample_throughput: 2596.859\n",
      "    sample_time_ms: 1540.323\n",
      "    update_time_ms: 1.716\n",
      "  timestamp: 1629485445\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 444000\n",
      "  training_iteration: 111\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         388.159</td><td style=\"text-align: right;\">444000</td><td style=\"text-align: right;\">-336.449</td><td style=\"text-align: right;\">            -117.531</td><td style=\"text-align: right;\">            -1563.24</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 452000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-50-52\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5891529305080412\n",
      "  episode_reward_mean: -342.4467095204089\n",
      "  episode_reward_min: -1563.2426621589486\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2260\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.2805686295032501\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005570209119468927\n",
      "          model: {}\n",
      "          policy_loss: -0.01515578106045723\n",
      "          total_loss: 360.9591369628906\n",
      "          vf_explained_var: 0.9663246870040894\n",
      "          vf_loss: 360.96868896484375\n",
      "    num_agent_steps_sampled: 452000\n",
      "    num_agent_steps_trained: 452000\n",
      "    num_steps_sampled: 452000\n",
      "    num_steps_trained: 452000\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.14\n",
      "    ram_util_percent: 66.64\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0718317467492672\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10321129736563811\n",
      "    mean_inference_ms: 0.5019123403898706\n",
      "    mean_raw_obs_processing_ms: 0.04815823521356673\n",
      "  time_since_restore: 395.7259588241577\n",
      "  time_this_iter_s: 3.7492380142211914\n",
      "  time_total_s: 395.7259588241577\n",
      "  timers:\n",
      "    learn_throughput: 1784.757\n",
      "    learn_time_ms: 2241.201\n",
      "    load_throughput: 4034148.312\n",
      "    load_time_ms: 0.992\n",
      "    sample_throughput: 2568.664\n",
      "    sample_time_ms: 1557.23\n",
      "    update_time_ms: 1.846\n",
      "  timestamp: 1629485452\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 452000\n",
      "  training_iteration: 113\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         395.726</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\">-342.447</td><td style=\"text-align: right;\">           -0.589153</td><td style=\"text-align: right;\">            -1563.24</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 460000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-00\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5526071383355003\n",
      "  episode_reward_mean: -305.7929809558207\n",
      "  episode_reward_min: -1781.3687062041015\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2300\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4043802320957184\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010161465033888817\n",
      "          model: {}\n",
      "          policy_loss: -0.0224758293479681\n",
      "          total_loss: 2612.506591796875\n",
      "          vf_explained_var: 0.8593878149986267\n",
      "          vf_loss: 2612.518798828125\n",
      "    num_agent_steps_sampled: 460000\n",
      "    num_agent_steps_trained: 460000\n",
      "    num_steps_sampled: 460000\n",
      "    num_steps_trained: 460000\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.45\n",
      "    ram_util_percent: 66.6\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0719134761175315\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10333990722982599\n",
      "    mean_inference_ms: 0.5024626146281533\n",
      "    mean_raw_obs_processing_ms: 0.04824178293044451\n",
      "  time_since_restore: 403.4932019710541\n",
      "  time_this_iter_s: 3.776362180709839\n",
      "  time_total_s: 403.4932019710541\n",
      "  timers:\n",
      "    learn_throughput: 1769.816\n",
      "    learn_time_ms: 2260.122\n",
      "    load_throughput: 3793776.089\n",
      "    load_time_ms: 1.054\n",
      "    sample_throughput: 2492.44\n",
      "    sample_time_ms: 1604.853\n",
      "    update_time_ms: 1.83\n",
      "  timestamp: 1629485460\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 460000\n",
      "  training_iteration: 115\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         403.493</td><td style=\"text-align: right;\">460000</td><td style=\"text-align: right;\">-305.793</td><td style=\"text-align: right;\">           -0.552607</td><td style=\"text-align: right;\">            -1781.37</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 468000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-09\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3543045935595232\n",
      "  episode_reward_mean: -316.2949826529386\n",
      "  episode_reward_min: -1781.3687062041015\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2340\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.16523562371730804\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015823109075427055\n",
      "          model: {}\n",
      "          policy_loss: -0.04339559003710747\n",
      "          total_loss: 444.0305480957031\n",
      "          vf_explained_var: 0.9395307302474976\n",
      "          vf_loss: 444.05792236328125\n",
      "    num_agent_steps_sampled: 468000\n",
      "    num_agent_steps_trained: 468000\n",
      "    num_steps_sampled: 468000\n",
      "    num_steps_trained: 468000\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.97142857142857\n",
      "    ram_util_percent: 66.78571428571429\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07205558918702007\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10353299068617677\n",
      "    mean_inference_ms: 0.5034134818749023\n",
      "    mean_raw_obs_processing_ms: 0.04836424922618834\n",
      "  time_since_restore: 411.9967019557953\n",
      "  time_this_iter_s: 4.340620994567871\n",
      "  time_total_s: 411.9967019557953\n",
      "  timers:\n",
      "    learn_throughput: 1738.26\n",
      "    learn_time_ms: 2301.152\n",
      "    load_throughput: 3812137.242\n",
      "    load_time_ms: 1.049\n",
      "    sample_throughput: 2417.443\n",
      "    sample_time_ms: 1654.641\n",
      "    update_time_ms: 1.828\n",
      "  timestamp: 1629485469\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 468000\n",
      "  training_iteration: 117\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         411.997</td><td style=\"text-align: right;\">468000</td><td style=\"text-align: right;\">-316.295</td><td style=\"text-align: right;\">           -0.354305</td><td style=\"text-align: right;\">            -1781.37</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 476000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-17\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3543045935595232\n",
      "  episode_reward_mean: -291.90122473155486\n",
      "  episode_reward_min: -1781.3687062041015\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2380\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.037978071719408035\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011732571758329868\n",
      "          model: {}\n",
      "          policy_loss: -0.033087000250816345\n",
      "          total_loss: 340.1856689453125\n",
      "          vf_explained_var: 0.9230901002883911\n",
      "          vf_loss: 340.2068786621094\n",
      "    num_agent_steps_sampled: 476000\n",
      "    num_agent_steps_trained: 476000\n",
      "    num_steps_sampled: 476000\n",
      "    num_steps_trained: 476000\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.5\n",
      "    ram_util_percent: 66.68333333333332\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07225920232127352\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10379154835367554\n",
      "    mean_inference_ms: 0.5047654488570877\n",
      "    mean_raw_obs_processing_ms: 0.048528928081228884\n",
      "  time_since_restore: 420.248069524765\n",
      "  time_this_iter_s: 4.208183765411377\n",
      "  time_total_s: 420.248069524765\n",
      "  timers:\n",
      "    learn_throughput: 1731.345\n",
      "    learn_time_ms: 2310.343\n",
      "    load_throughput: 3742408.209\n",
      "    load_time_ms: 1.069\n",
      "    sample_throughput: 2397.564\n",
      "    sample_time_ms: 1668.36\n",
      "    update_time_ms: 1.565\n",
      "  timestamp: 1629485477\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 476000\n",
      "  training_iteration: 119\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         420.248</td><td style=\"text-align: right;\">476000</td><td style=\"text-align: right;\">-291.901</td><td style=\"text-align: right;\">           -0.354305</td><td style=\"text-align: right;\">            -1781.37</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 484000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-24\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3543045935595232\n",
      "  episode_reward_mean: -258.676650922016\n",
      "  episode_reward_min: -819.0398331419522\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2420\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.2664121389389038\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009483801200985909\n",
      "          model: {}\n",
      "          policy_loss: -0.025507623329758644\n",
      "          total_loss: 247.2438201904297\n",
      "          vf_explained_var: 0.9749913215637207\n",
      "          vf_loss: 247.25970458984375\n",
      "    num_agent_steps_sampled: 484000\n",
      "    num_agent_steps_trained: 484000\n",
      "    num_steps_sampled: 484000\n",
      "    num_steps_trained: 484000\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.17999999999999\n",
      "    ram_util_percent: 66.75999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07245439977339448\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10403454275400362\n",
      "    mean_inference_ms: 0.5060700558187721\n",
      "    mean_raw_obs_processing_ms: 0.04868365640117877\n",
      "  time_since_restore: 427.5588493347168\n",
      "  time_this_iter_s: 3.6645748615264893\n",
      "  time_total_s: 427.5588493347168\n",
      "  timers:\n",
      "    learn_throughput: 1750.36\n",
      "    learn_time_ms: 2285.244\n",
      "    load_throughput: 3789577.159\n",
      "    load_time_ms: 1.056\n",
      "    sample_throughput: 2427.494\n",
      "    sample_time_ms: 1647.79\n",
      "    update_time_ms: 1.542\n",
      "  timestamp: 1629485484\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 484000\n",
      "  training_iteration: 121\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         427.559</td><td style=\"text-align: right;\">484000</td><td style=\"text-align: right;\">-258.677</td><td style=\"text-align: right;\">           -0.354305</td><td style=\"text-align: right;\">             -819.04</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 492000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-31\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3892086905210388\n",
      "  episode_reward_mean: -279.81531181167816\n",
      "  episode_reward_min: -1421.3665305702038\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2460\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.19299499690532684\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0075228032656013966\n",
      "          model: {}\n",
      "          policy_loss: -0.021675994619727135\n",
      "          total_loss: 236.41053771972656\n",
      "          vf_explained_var: 0.9634706974029541\n",
      "          vf_loss: 236.42459106445312\n",
      "    num_agent_steps_sampled: 492000\n",
      "    num_agent_steps_trained: 492000\n",
      "    num_steps_sampled: 492000\n",
      "    num_steps_trained: 492000\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.160000000000004\n",
      "    ram_util_percent: 66.85999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07256525797868413\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10418334389741485\n",
      "    mean_inference_ms: 0.506842118037096\n",
      "    mean_raw_obs_processing_ms: 0.048779996613454994\n",
      "  time_since_restore: 434.7763867378235\n",
      "  time_this_iter_s: 3.4730024337768555\n",
      "  time_total_s: 434.7763867378235\n",
      "  timers:\n",
      "    learn_throughput: 1783.335\n",
      "    learn_time_ms: 2242.988\n",
      "    load_throughput: 3771177.846\n",
      "    load_time_ms: 1.061\n",
      "    sample_throughput: 2416.382\n",
      "    sample_time_ms: 1655.368\n",
      "    update_time_ms: 1.429\n",
      "  timestamp: 1629485491\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 492000\n",
      "  training_iteration: 123\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         434.776</td><td style=\"text-align: right;\">492000</td><td style=\"text-align: right;\">-279.815</td><td style=\"text-align: right;\">           -0.389209</td><td style=\"text-align: right;\">            -1421.37</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 500000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-39\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4502226348995147\n",
      "  episode_reward_mean: -301.03637124972965\n",
      "  episode_reward_min: -1486.1523582495013\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2500\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.3781278431415558\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008015221916139126\n",
      "          model: {}\n",
      "          policy_loss: -0.023257767781615257\n",
      "          total_loss: 964.3396606445312\n",
      "          vf_explained_var: 0.9221048951148987\n",
      "          vf_loss: 964.3547973632812\n",
      "    num_agent_steps_sampled: 500000\n",
      "    num_agent_steps_trained: 500000\n",
      "    num_steps_sampled: 500000\n",
      "    num_steps_trained: 500000\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.880000000000003\n",
      "    ram_util_percent: 66.84\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07263999760819063\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10429256565748304\n",
      "    mean_inference_ms: 0.5073679193247229\n",
      "    mean_raw_obs_processing_ms: 0.048848008597570346\n",
      "  time_since_restore: 442.3886466026306\n",
      "  time_this_iter_s: 3.8506479263305664\n",
      "  time_total_s: 442.3886466026306\n",
      "  timers:\n",
      "    learn_throughput: 1812.351\n",
      "    learn_time_ms: 2207.077\n",
      "    load_throughput: 3931023.688\n",
      "    load_time_ms: 1.018\n",
      "    sample_throughput: 2386.949\n",
      "    sample_time_ms: 1675.779\n",
      "    update_time_ms: 1.451\n",
      "  timestamp: 1629485499\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 500000\n",
      "  training_iteration: 125\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         442.389</td><td style=\"text-align: right;\">500000</td><td style=\"text-align: right;\">-301.036</td><td style=\"text-align: right;\">           -0.450223</td><td style=\"text-align: right;\">            -1486.15</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 508000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-46\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4502226348995147\n",
      "  episode_reward_mean: -284.6694578185045\n",
      "  episode_reward_min: -1486.1523582495013\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2540\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.19965896010398865\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008224894292652607\n",
      "          model: {}\n",
      "          policy_loss: -0.03243985027074814\n",
      "          total_loss: 179.39529418945312\n",
      "          vf_explained_var: 0.9792578816413879\n",
      "          vf_loss: 179.41940307617188\n",
      "    num_agent_steps_sampled: 508000\n",
      "    num_agent_steps_trained: 508000\n",
      "    num_steps_sampled: 508000\n",
      "    num_steps_trained: 508000\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.93333333333333\n",
      "    ram_util_percent: 67.3\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07272730955329568\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10441824589321062\n",
      "    mean_inference_ms: 0.507943246297182\n",
      "    mean_raw_obs_processing_ms: 0.04892562429602572\n",
      "  time_since_restore: 449.74478936195374\n",
      "  time_this_iter_s: 3.615648031234741\n",
      "  time_total_s: 449.74478936195374\n",
      "  timers:\n",
      "    learn_throughput: 1858.356\n",
      "    learn_time_ms: 2152.44\n",
      "    load_throughput: 3913418.395\n",
      "    load_time_ms: 1.022\n",
      "    sample_throughput: 2475.745\n",
      "    sample_time_ms: 1615.676\n",
      "    update_time_ms: 1.47\n",
      "  timestamp: 1629485506\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 508000\n",
      "  training_iteration: 127\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         449.745</td><td style=\"text-align: right;\">508000</td><td style=\"text-align: right;\">-284.669</td><td style=\"text-align: right;\">           -0.450223</td><td style=\"text-align: right;\">            -1486.15</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 516000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-51-54\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6102728606037484\n",
      "  episode_reward_mean: -276.9959468303167\n",
      "  episode_reward_min: -1193.0202706133637\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2580\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.19972991943359375\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008281835354864597\n",
      "          model: {}\n",
      "          policy_loss: -0.02852977067232132\n",
      "          total_loss: 620.09814453125\n",
      "          vf_explained_var: 0.9336275458335876\n",
      "          vf_loss: 620.1182861328125\n",
      "    num_agent_steps_sampled: 516000\n",
      "    num_agent_steps_trained: 516000\n",
      "    num_steps_sampled: 516000\n",
      "    num_steps_trained: 516000\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.48\n",
      "    ram_util_percent: 66.9\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07278759378487847\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10451969265099485\n",
      "    mean_inference_ms: 0.5083513085358657\n",
      "    mean_raw_obs_processing_ms: 0.04898902265084766\n",
      "  time_since_restore: 456.99661135673523\n",
      "  time_this_iter_s: 3.6144089698791504\n",
      "  time_total_s: 456.99661135673523\n",
      "  timers:\n",
      "    learn_throughput: 1901.308\n",
      "    learn_time_ms: 2103.814\n",
      "    load_throughput: 4346541.62\n",
      "    load_time_ms: 0.92\n",
      "    sample_throughput: 2556.704\n",
      "    sample_time_ms: 1564.514\n",
      "    update_time_ms: 1.489\n",
      "  timestamp: 1629485514\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 516000\n",
      "  training_iteration: 129\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         456.997</td><td style=\"text-align: right;\">516000</td><td style=\"text-align: right;\">-276.996</td><td style=\"text-align: right;\">           -0.610273</td><td style=\"text-align: right;\">            -1193.02</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 524000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-01\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.39380693428998004\n",
      "  episode_reward_mean: -281.0545093286302\n",
      "  episode_reward_min: -1176.139190041442\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2620\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5193880796432495\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007803010288625956\n",
      "          model: {}\n",
      "          policy_loss: -0.024038735777139664\n",
      "          total_loss: 554.5653076171875\n",
      "          vf_explained_var: 0.9597111940383911\n",
      "          vf_loss: 554.5814819335938\n",
      "    num_agent_steps_sampled: 524000\n",
      "    num_agent_steps_trained: 524000\n",
      "    num_steps_sampled: 524000\n",
      "    num_steps_trained: 524000\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.42\n",
      "    ram_util_percent: 66.75999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07279309123829952\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10455605592717636\n",
      "    mean_inference_ms: 0.5084121585919184\n",
      "    mean_raw_obs_processing_ms: 0.04901467790120392\n",
      "  time_since_restore: 464.19348406791687\n",
      "  time_this_iter_s: 3.5898478031158447\n",
      "  time_total_s: 464.19348406791687\n",
      "  timers:\n",
      "    learn_throughput: 1907.192\n",
      "    learn_time_ms: 2097.324\n",
      "    load_throughput: 4410878.115\n",
      "    load_time_ms: 0.907\n",
      "    sample_throughput: 2564.727\n",
      "    sample_time_ms: 1559.62\n",
      "    update_time_ms: 1.489\n",
      "  timestamp: 1629485521\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 524000\n",
      "  training_iteration: 131\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         464.193</td><td style=\"text-align: right;\">524000</td><td style=\"text-align: right;\">-281.055</td><td style=\"text-align: right;\">           -0.393807</td><td style=\"text-align: right;\">            -1176.14</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 532000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-08\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.39380693428998004\n",
      "  episode_reward_mean: -296.840730943534\n",
      "  episode_reward_min: -1176.139190041442\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2660\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.2033504992723465\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008650118485093117\n",
      "          model: {}\n",
      "          policy_loss: -0.029817823320627213\n",
      "          total_loss: 403.174072265625\n",
      "          vf_explained_var: 0.9510040283203125\n",
      "          vf_loss: 403.1951599121094\n",
      "    num_agent_steps_sampled: 532000\n",
      "    num_agent_steps_trained: 532000\n",
      "    num_steps_sampled: 532000\n",
      "    num_steps_trained: 532000\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.220000000000006\n",
      "    ram_util_percent: 66.5\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07279396913117465\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10458253004215931\n",
      "    mean_inference_ms: 0.5084559797296451\n",
      "    mean_raw_obs_processing_ms: 0.04903355210784727\n",
      "  time_since_restore: 471.40856099128723\n",
      "  time_this_iter_s: 3.564866065979004\n",
      "  time_total_s: 471.40856099128723\n",
      "  timers:\n",
      "    learn_throughput: 1896.245\n",
      "    learn_time_ms: 2109.432\n",
      "    load_throughput: 4374534.835\n",
      "    load_time_ms: 0.914\n",
      "    sample_throughput: 2585.169\n",
      "    sample_time_ms: 1547.288\n",
      "    update_time_ms: 1.481\n",
      "  timestamp: 1629485528\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 532000\n",
      "  training_iteration: 133\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         471.409</td><td style=\"text-align: right;\">532000</td><td style=\"text-align: right;\">-296.841</td><td style=\"text-align: right;\">           -0.393807</td><td style=\"text-align: right;\">            -1176.14</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 540000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-16\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.39380693428998004\n",
      "  episode_reward_mean: -318.26481263609895\n",
      "  episode_reward_min: -1504.5983444590192\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2700\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5692239999771118\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009801557287573814\n",
      "          model: {}\n",
      "          policy_loss: -0.0314130000770092\n",
      "          total_loss: 1017.3955688476562\n",
      "          vf_explained_var: 0.9445459246635437\n",
      "          vf_loss: 1017.4171142578125\n",
      "    num_agent_steps_sampled: 540000\n",
      "    num_agent_steps_trained: 540000\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 540000\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.5\n",
      "    ram_util_percent: 66.3\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07279063054978803\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10460251519130104\n",
      "    mean_inference_ms: 0.5084964245770944\n",
      "    mean_raw_obs_processing_ms: 0.049049082272841764\n",
      "  time_since_restore: 478.66780161857605\n",
      "  time_this_iter_s: 3.574605703353882\n",
      "  time_total_s: 478.66780161857605\n",
      "  timers:\n",
      "    learn_throughput: 1895.713\n",
      "    learn_time_ms: 2110.024\n",
      "    load_throughput: 4403122.064\n",
      "    load_time_ms: 0.908\n",
      "    sample_throughput: 2646.453\n",
      "    sample_time_ms: 1511.457\n",
      "    update_time_ms: 1.473\n",
      "  timestamp: 1629485536\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 135\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         478.668</td><td style=\"text-align: right;\">540000</td><td style=\"text-align: right;\">-318.265</td><td style=\"text-align: right;\">           -0.393807</td><td style=\"text-align: right;\">             -1504.6</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 548000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-23\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.40520516610916996\n",
      "  episode_reward_mean: -312.06382093179354\n",
      "  episode_reward_min: -1504.5983444590192\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2740\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125000476837158\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.45203524827957153\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008877117186784744\n",
      "          model: {}\n",
      "          policy_loss: -0.03033849410712719\n",
      "          total_loss: 294.1210021972656\n",
      "          vf_explained_var: 0.9758987426757812\n",
      "          vf_loss: 294.14239501953125\n",
      "    num_agent_steps_sampled: 548000\n",
      "    num_agent_steps_trained: 548000\n",
      "    num_steps_sampled: 548000\n",
      "    num_steps_trained: 548000\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 36.74\n",
      "    ram_util_percent: 66.42\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07278617338578906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10461829938315961\n",
      "    mean_inference_ms: 0.5085403406895759\n",
      "    mean_raw_obs_processing_ms: 0.04906231739173077\n",
      "  time_since_restore: 485.88396072387695\n",
      "  time_this_iter_s: 3.603649139404297\n",
      "  time_total_s: 485.88396072387695\n",
      "  timers:\n",
      "    learn_throughput: 1904.402\n",
      "    learn_time_ms: 2100.397\n",
      "    load_throughput: 4451134.458\n",
      "    load_time_ms: 0.899\n",
      "    sample_throughput: 2654.039\n",
      "    sample_time_ms: 1507.137\n",
      "    update_time_ms: 1.444\n",
      "  timestamp: 1629485543\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 548000\n",
      "  training_iteration: 137\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         485.884</td><td style=\"text-align: right;\">548000</td><td style=\"text-align: right;\">-312.064</td><td style=\"text-align: right;\">           -0.405205</td><td style=\"text-align: right;\">             -1504.6</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 556000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-30\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.40520516610916996\n",
      "  episode_reward_mean: -303.5888129574334\n",
      "  episode_reward_min: -1504.5983444590192\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2780\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187499523162842\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.48138099908828735\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008577428758144379\n",
      "          model: {}\n",
      "          policy_loss: -0.03574135899543762\n",
      "          total_loss: 722.7014770507812\n",
      "          vf_explained_var: 0.9397444725036621\n",
      "          vf_loss: 722.7242431640625\n",
      "    num_agent_steps_sampled: 556000\n",
      "    num_agent_steps_trained: 556000\n",
      "    num_steps_sampled: 556000\n",
      "    num_steps_trained: 556000\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.339999999999996\n",
      "    ram_util_percent: 66.44000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0727790576460785\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1046285124630037\n",
      "    mean_inference_ms: 0.508571036114671\n",
      "    mean_raw_obs_processing_ms: 0.049072424212526417\n",
      "  time_since_restore: 493.0647189617157\n",
      "  time_this_iter_s: 3.56392502784729\n",
      "  time_total_s: 493.0647189617157\n",
      "  timers:\n",
      "    learn_throughput: 1906.705\n",
      "    learn_time_ms: 2097.86\n",
      "    load_throughput: 4440649.003\n",
      "    load_time_ms: 0.901\n",
      "    sample_throughput: 2662.023\n",
      "    sample_time_ms: 1502.617\n",
      "    update_time_ms: 1.426\n",
      "  timestamp: 1629485550\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 556000\n",
      "  training_iteration: 139\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         493.065</td><td style=\"text-align: right;\">556000</td><td style=\"text-align: right;\">-303.589</td><td style=\"text-align: right;\">           -0.405205</td><td style=\"text-align: right;\">             -1504.6</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 564000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-37\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3327938712640481\n",
      "  episode_reward_mean: -313.3842654206427\n",
      "  episode_reward_min: -1692.2088352137093\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2820\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187499523162842\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.29253995418548584\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.004903966560959816\n",
      "          model: {}\n",
      "          policy_loss: -0.018704885616898537\n",
      "          total_loss: 760.8428955078125\n",
      "          vf_explained_var: 0.9154450297355652\n",
      "          vf_loss: 760.85400390625\n",
      "    num_agent_steps_sampled: 564000\n",
      "    num_agent_steps_trained: 564000\n",
      "    num_steps_sampled: 564000\n",
      "    num_steps_trained: 564000\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.48\n",
      "    ram_util_percent: 66.5\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07277295439928347\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10464098195934099\n",
      "    mean_inference_ms: 0.508630286754224\n",
      "    mean_raw_obs_processing_ms: 0.049082888535255643\n",
      "  time_since_restore: 500.28911209106445\n",
      "  time_this_iter_s: 3.569317102432251\n",
      "  time_total_s: 500.28911209106445\n",
      "  timers:\n",
      "    learn_throughput: 1908.941\n",
      "    learn_time_ms: 2095.403\n",
      "    load_throughput: 4463568.787\n",
      "    load_time_ms: 0.896\n",
      "    sample_throughput: 2652.876\n",
      "    sample_time_ms: 1507.798\n",
      "    update_time_ms: 1.436\n",
      "  timestamp: 1629485557\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 564000\n",
      "  training_iteration: 141\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         500.289</td><td style=\"text-align: right;\">564000</td><td style=\"text-align: right;\">-313.384</td><td style=\"text-align: right;\">           -0.332794</td><td style=\"text-align: right;\">            -1692.21</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 572000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-44\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3327938712640481\n",
      "  episode_reward_mean: -354.3118059174976\n",
      "  episode_reward_min: -1793.878684087295\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2860\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.8941616415977478\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01656072400510311\n",
      "          model: {}\n",
      "          policy_loss: -0.04381180182099342\n",
      "          total_loss: 2666.342041015625\n",
      "          vf_explained_var: 0.8898111581802368\n",
      "          vf_loss: 2666.37353515625\n",
      "    num_agent_steps_sampled: 572000\n",
      "    num_agent_steps_trained: 572000\n",
      "    num_steps_sampled: 572000\n",
      "    num_steps_trained: 572000\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.26\n",
      "    ram_util_percent: 66.06\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07276642234144709\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10464996908184322\n",
      "    mean_inference_ms: 0.5086920346703695\n",
      "    mean_raw_obs_processing_ms: 0.0490910009973277\n",
      "  time_since_restore: 507.51253724098206\n",
      "  time_this_iter_s: 3.6069321632385254\n",
      "  time_total_s: 507.51253724098206\n",
      "  timers:\n",
      "    learn_throughput: 1909.089\n",
      "    learn_time_ms: 2095.241\n",
      "    load_throughput: 4434545.503\n",
      "    load_time_ms: 0.902\n",
      "    sample_throughput: 2651.161\n",
      "    sample_time_ms: 1508.773\n",
      "    update_time_ms: 1.438\n",
      "  timestamp: 1629485564\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 572000\n",
      "  training_iteration: 143\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         507.513</td><td style=\"text-align: right;\">572000</td><td style=\"text-align: right;\">-354.312</td><td style=\"text-align: right;\">           -0.332794</td><td style=\"text-align: right;\">            -1793.88</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 580000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-52\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.42100826121374185\n",
      "  episode_reward_mean: -339.9227554667377\n",
      "  episode_reward_min: -1793.878684087295\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2900\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.0447617769241333\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011814366094768047\n",
      "          model: {}\n",
      "          policy_loss: -0.030121181160211563\n",
      "          total_loss: 3339.402587890625\n",
      "          vf_explained_var: 0.8627030849456787\n",
      "          vf_loss: 3339.423583984375\n",
      "    num_agent_steps_sampled: 580000\n",
      "    num_agent_steps_trained: 580000\n",
      "    num_steps_sampled: 580000\n",
      "    num_steps_trained: 580000\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.68333333333334\n",
      "    ram_util_percent: 66.2\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07275855841605498\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10465508109858405\n",
      "    mean_inference_ms: 0.5087546775065159\n",
      "    mean_raw_obs_processing_ms: 0.04909786131812982\n",
      "  time_since_restore: 514.7796320915222\n",
      "  time_this_iter_s: 3.653256893157959\n",
      "  time_total_s: 514.7796320915222\n",
      "  timers:\n",
      "    learn_throughput: 1905.006\n",
      "    learn_time_ms: 2099.73\n",
      "    load_throughput: 4442295.125\n",
      "    load_time_ms: 0.9\n",
      "    sample_throughput: 2657.738\n",
      "    sample_time_ms: 1505.039\n",
      "    update_time_ms: 1.438\n",
      "  timestamp: 1629485572\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 580000\n",
      "  training_iteration: 145\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">          514.78</td><td style=\"text-align: right;\">580000</td><td style=\"text-align: right;\">-339.923</td><td style=\"text-align: right;\">           -0.421008</td><td style=\"text-align: right;\">            -1793.88</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 588000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-52-59\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4537255436550378\n",
      "  episode_reward_mean: -384.63813574392356\n",
      "  episode_reward_min: -1737.5808648440143\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2940\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.720223069190979\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011728649027645588\n",
      "          model: {}\n",
      "          policy_loss: -0.03086782619357109\n",
      "          total_loss: 1062.4534912109375\n",
      "          vf_explained_var: 0.929296612739563\n",
      "          vf_loss: 1062.4755859375\n",
      "    num_agent_steps_sampled: 588000\n",
      "    num_agent_steps_trained: 588000\n",
      "    num_steps_sampled: 588000\n",
      "    num_steps_trained: 588000\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.760000000000005\n",
      "    ram_util_percent: 69.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07277767125255971\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10469097595183124\n",
      "    mean_inference_ms: 0.5089783539338393\n",
      "    mean_raw_obs_processing_ms: 0.04912342479254967\n",
      "  time_since_restore: 522.202892780304\n",
      "  time_this_iter_s: 3.587932825088501\n",
      "  time_total_s: 522.202892780304\n",
      "  timers:\n",
      "    learn_throughput: 1903.243\n",
      "    learn_time_ms: 2101.675\n",
      "    load_throughput: 4434897.172\n",
      "    load_time_ms: 0.902\n",
      "    sample_throughput: 2625.046\n",
      "    sample_time_ms: 1523.783\n",
      "    update_time_ms: 1.446\n",
      "  timestamp: 1629485579\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 588000\n",
      "  training_iteration: 147\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         522.203</td><td style=\"text-align: right;\">588000</td><td style=\"text-align: right;\">-384.638</td><td style=\"text-align: right;\">           -0.453726</td><td style=\"text-align: right;\">            -1737.58</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 596000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-53-07\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5525094892197626\n",
      "  episode_reward_mean: -414.9459997182291\n",
      "  episode_reward_min: -1739.8457719918763\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2980\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.8421304225921631\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02318800985813141\n",
      "          model: {}\n",
      "          policy_loss: -0.05193726718425751\n",
      "          total_loss: 1533.60986328125\n",
      "          vf_explained_var: 0.8925516605377197\n",
      "          vf_loss: 1533.644287109375\n",
      "    num_agent_steps_sampled: 596000\n",
      "    num_agent_steps_trained: 596000\n",
      "    num_steps_sampled: 596000\n",
      "    num_steps_trained: 596000\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.459999999999994\n",
      "    ram_util_percent: 69.5\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07279555400169026\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10472834433522432\n",
      "    mean_inference_ms: 0.5091856080238566\n",
      "    mean_raw_obs_processing_ms: 0.049146701803909315\n",
      "  time_since_restore: 529.4337220191956\n",
      "  time_this_iter_s: 3.5822761058807373\n",
      "  time_total_s: 529.4337220191956\n",
      "  timers:\n",
      "    learn_throughput: 1901.643\n",
      "    learn_time_ms: 2103.444\n",
      "    load_throughput: 4503225.252\n",
      "    load_time_ms: 0.888\n",
      "    sample_throughput: 2619.525\n",
      "    sample_time_ms: 1526.995\n",
      "    update_time_ms: 1.447\n",
      "  timestamp: 1629485587\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 596000\n",
      "  training_iteration: 149\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         529.434</td><td style=\"text-align: right;\">596000</td><td style=\"text-align: right;\">-414.946</td><td style=\"text-align: right;\">           -0.552509</td><td style=\"text-align: right;\">            -1739.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 604000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-53-14\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.49285387966709054\n",
      "  episode_reward_mean: -357.1288808927116\n",
      "  episode_reward_min: -1739.8457719918763\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3020\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.7602370977401733\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011911097913980484\n",
      "          model: {}\n",
      "          policy_loss: -0.03858986124396324\n",
      "          total_loss: 993.3609008789062\n",
      "          vf_explained_var: 0.9422360062599182\n",
      "          vf_loss: 993.3859252929688\n",
      "    num_agent_steps_sampled: 604000\n",
      "    num_agent_steps_trained: 604000\n",
      "    num_steps_sampled: 604000\n",
      "    num_steps_trained: 604000\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.56\n",
      "    ram_util_percent: 68.50000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07280731831368682\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10475948302899342\n",
      "    mean_inference_ms: 0.5093479450064488\n",
      "    mean_raw_obs_processing_ms: 0.049165250996469234\n",
      "  time_since_restore: 536.7079949378967\n",
      "  time_this_iter_s: 3.5994350910186768\n",
      "  time_total_s: 536.7079949378967\n",
      "  timers:\n",
      "    learn_throughput: 1899.295\n",
      "    learn_time_ms: 2106.044\n",
      "    load_throughput: 4535240.721\n",
      "    load_time_ms: 0.882\n",
      "    sample_throughput: 2615.373\n",
      "    sample_time_ms: 1529.419\n",
      "    update_time_ms: 1.456\n",
      "  timestamp: 1629485594\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 604000\n",
      "  training_iteration: 151\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">         536.708</td><td style=\"text-align: right;\">604000</td><td style=\"text-align: right;\">-357.129</td><td style=\"text-align: right;\">           -0.492854</td><td style=\"text-align: right;\">            -1739.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 612000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-53-21\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.49285387966709054\n",
      "  episode_reward_mean: -358.1539546575087\n",
      "  episode_reward_min: -1646.6416084363216\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3060\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.7804085612297058\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012718611396849155\n",
      "          model: {}\n",
      "          policy_loss: -0.03613091632723808\n",
      "          total_loss: 2217.675048828125\n",
      "          vf_explained_var: 0.8766252994537354\n",
      "          vf_loss: 2217.69677734375\n",
      "    num_agent_steps_sampled: 612000\n",
      "    num_agent_steps_trained: 612000\n",
      "    num_steps_sampled: 612000\n",
      "    num_steps_trained: 612000\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.5\n",
      "    ram_util_percent: 68.24\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07280331720426371\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10476983637599294\n",
      "    mean_inference_ms: 0.5094475430990206\n",
      "    mean_raw_obs_processing_ms: 0.049171652113732985\n",
      "  time_since_restore: 543.9048309326172\n",
      "  time_this_iter_s: 3.57279896736145\n",
      "  time_total_s: 543.9048309326172\n",
      "  timers:\n",
      "    learn_throughput: 1900.381\n",
      "    learn_time_ms: 2104.841\n",
      "    load_throughput: 4616608.239\n",
      "    load_time_ms: 0.866\n",
      "    sample_throughput: 2617.86\n",
      "    sample_time_ms: 1527.966\n",
      "    update_time_ms: 1.468\n",
      "  timestamp: 1629485601\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 612000\n",
      "  training_iteration: 153\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   153</td><td style=\"text-align: right;\">         543.905</td><td style=\"text-align: right;\">612000</td><td style=\"text-align: right;\">-358.154</td><td style=\"text-align: right;\">           -0.492854</td><td style=\"text-align: right;\">            -1646.64</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 620000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-53-29\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3929215808827661\n",
      "  episode_reward_mean: -341.45148899579\n",
      "  episode_reward_min: -1646.6416084363216\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3100\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.7811005115509033\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01602937839925289\n",
      "          model: {}\n",
      "          policy_loss: -0.036535944789648056\n",
      "          total_loss: 454.30609130859375\n",
      "          vf_explained_var: 0.9727401733398438\n",
      "          vf_loss: 454.3243103027344\n",
      "    num_agent_steps_sampled: 620000\n",
      "    num_agent_steps_trained: 620000\n",
      "    num_steps_sampled: 620000\n",
      "    num_steps_trained: 620000\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.28\n",
      "    ram_util_percent: 67.0\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07280149794207845\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10477966825170054\n",
      "    mean_inference_ms: 0.5095515047588328\n",
      "    mean_raw_obs_processing_ms: 0.04917582994819819\n",
      "  time_since_restore: 551.42698097229\n",
      "  time_this_iter_s: 3.572986125946045\n",
      "  time_total_s: 551.42698097229\n",
      "  timers:\n",
      "    learn_throughput: 1884.239\n",
      "    learn_time_ms: 2122.873\n",
      "    load_throughput: 4520454.815\n",
      "    load_time_ms: 0.885\n",
      "    sample_throughput: 2605.215\n",
      "    sample_time_ms: 1535.382\n",
      "    update_time_ms: 1.466\n",
      "  timestamp: 1629485609\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 620000\n",
      "  training_iteration: 155\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">         551.427</td><td style=\"text-align: right;\">620000</td><td style=\"text-align: right;\">-341.451</td><td style=\"text-align: right;\">           -0.392922</td><td style=\"text-align: right;\">            -1646.64</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 628000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-53-36\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3929215808827661\n",
      "  episode_reward_mean: -331.4956964976131\n",
      "  episode_reward_min: -1646.6416084363216\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3140\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.886764407157898\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009473496116697788\n",
      "          model: {}\n",
      "          policy_loss: -0.03199653699994087\n",
      "          total_loss: 1159.69189453125\n",
      "          vf_explained_var: 0.9453511238098145\n",
      "          vf_loss: 1159.7132568359375\n",
      "    num_agent_steps_sampled: 628000\n",
      "    num_agent_steps_trained: 628000\n",
      "    num_steps_sampled: 628000\n",
      "    num_steps_trained: 628000\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.1\n",
      "    ram_util_percent: 66.6\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07280399189721949\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10478427634713995\n",
      "    mean_inference_ms: 0.5097321315756548\n",
      "    mean_raw_obs_processing_ms: 0.0491702995330798\n",
      "  time_since_restore: 558.6485590934753\n",
      "  time_this_iter_s: 3.5673270225524902\n",
      "  time_total_s: 558.6485590934753\n",
      "  timers:\n",
      "    learn_throughput: 1894.172\n",
      "    learn_time_ms: 2111.74\n",
      "    load_throughput: 4488046.653\n",
      "    load_time_ms: 0.891\n",
      "    sample_throughput: 2620.6\n",
      "    sample_time_ms: 1526.368\n",
      "    update_time_ms: 1.445\n",
      "  timestamp: 1629485616\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 628000\n",
      "  training_iteration: 157\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   157</td><td style=\"text-align: right;\">         558.649</td><td style=\"text-align: right;\">628000</td><td style=\"text-align: right;\">-331.496</td><td style=\"text-align: right;\">           -0.392922</td><td style=\"text-align: right;\">            -1646.64</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 636000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-53-43\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4187134709649353\n",
      "  episode_reward_mean: -357.10603405324497\n",
      "  episode_reward_min: -1792.607871692411\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3180\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.0731686353683472\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008291160687804222\n",
      "          model: {}\n",
      "          policy_loss: -0.024618029594421387\n",
      "          total_loss: 3013.588623046875\n",
      "          vf_explained_var: 0.863718569278717\n",
      "          vf_loss: 3013.603271484375\n",
      "    num_agent_steps_sampled: 636000\n",
      "    num_agent_steps_trained: 636000\n",
      "    num_steps_sampled: 636000\n",
      "    num_steps_trained: 636000\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.72\n",
      "    ram_util_percent: 66.74\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0728136492810861\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10479329349003041\n",
      "    mean_inference_ms: 0.5099965510763255\n",
      "    mean_raw_obs_processing_ms: 0.04916420997875104\n",
      "  time_since_restore: 565.9788999557495\n",
      "  time_this_iter_s: 3.6996827125549316\n",
      "  time_total_s: 565.9788999557495\n",
      "  timers:\n",
      "    learn_throughput: 1892.9\n",
      "    learn_time_ms: 2113.16\n",
      "    load_throughput: 4497310.28\n",
      "    load_time_ms: 0.889\n",
      "    sample_throughput: 2605.978\n",
      "    sample_time_ms: 1534.932\n",
      "    update_time_ms: 1.431\n",
      "  timestamp: 1629485623\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 636000\n",
      "  training_iteration: 159\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   159</td><td style=\"text-align: right;\">         565.979</td><td style=\"text-align: right;\">636000</td><td style=\"text-align: right;\">-357.106</td><td style=\"text-align: right;\">           -0.418713</td><td style=\"text-align: right;\">            -1792.61</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 644000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-53-50\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.9900678890726173\n",
      "  episode_reward_mean: -328.7900097143391\n",
      "  episode_reward_min: -1792.607871692411\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3220\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.24960826337337494\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012781028635799885\n",
      "          model: {}\n",
      "          policy_loss: -0.027991702780127525\n",
      "          total_loss: 150.3510284423828\n",
      "          vf_explained_var: 0.9556770324707031\n",
      "          vf_loss: 150.36447143554688\n",
      "    num_agent_steps_sampled: 644000\n",
      "    num_agent_steps_trained: 644000\n",
      "    num_steps_sampled: 644000\n",
      "    num_steps_trained: 644000\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.36\n",
      "    ram_util_percent: 67.1\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07282626377052628\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10480334039855788\n",
      "    mean_inference_ms: 0.5102944876545279\n",
      "    mean_raw_obs_processing_ms: 0.04915802751052633\n",
      "  time_since_restore: 573.1698980331421\n",
      "  time_this_iter_s: 3.563778877258301\n",
      "  time_total_s: 573.1698980331421\n",
      "  timers:\n",
      "    learn_throughput: 1902.507\n",
      "    learn_time_ms: 2102.489\n",
      "    load_throughput: 4484807.399\n",
      "    load_time_ms: 0.892\n",
      "    sample_throughput: 2602.058\n",
      "    sample_time_ms: 1537.245\n",
      "    update_time_ms: 1.439\n",
      "  timestamp: 1629485630\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 644000\n",
      "  training_iteration: 161\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   161</td><td style=\"text-align: right;\">          573.17</td><td style=\"text-align: right;\">644000</td><td style=\"text-align: right;\"> -328.79</td><td style=\"text-align: right;\">           -0.990068</td><td style=\"text-align: right;\">            -1792.61</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 652000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-00\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5035122220619553\n",
      "  episode_reward_mean: -306.5198369490692\n",
      "  episode_reward_min: -1792.607871692411\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3260\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.6601067185401917\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009990016929805279\n",
      "          model: {}\n",
      "          policy_loss: -0.03877044841647148\n",
      "          total_loss: 480.9149475097656\n",
      "          vf_explained_var: 0.9612283110618591\n",
      "          vf_loss: 480.94232177734375\n",
      "    num_agent_steps_sampled: 652000\n",
      "    num_agent_steps_trained: 652000\n",
      "    num_steps_sampled: 652000\n",
      "    num_steps_trained: 652000\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.42857142857143\n",
      "    ram_util_percent: 70.04285714285713\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07288229892645198\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1048673323670944\n",
      "    mean_inference_ms: 0.5108171439789037\n",
      "    mean_raw_obs_processing_ms: 0.04919402984976992\n",
      "  time_since_restore: 582.5932188034058\n",
      "  time_this_iter_s: 4.640837907791138\n",
      "  time_total_s: 582.5932188034058\n",
      "  timers:\n",
      "    learn_throughput: 1760.619\n",
      "    learn_time_ms: 2271.928\n",
      "    load_throughput: 3634815.088\n",
      "    load_time_ms: 1.1\n",
      "    sample_throughput: 2517.344\n",
      "    sample_time_ms: 1588.977\n",
      "    update_time_ms: 1.474\n",
      "  timestamp: 1629485640\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 652000\n",
      "  training_iteration: 163\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   163</td><td style=\"text-align: right;\">         582.593</td><td style=\"text-align: right;\">652000</td><td style=\"text-align: right;\"> -306.52</td><td style=\"text-align: right;\">           -0.503512</td><td style=\"text-align: right;\">            -1792.61</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 660000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-08\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5035122220619553\n",
      "  episode_reward_mean: -388.0944310101997\n",
      "  episode_reward_min: -1742.7633872754936\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3300\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7437785863876343\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018082601949572563\n",
      "          model: {}\n",
      "          policy_loss: -0.036602262407541275\n",
      "          total_loss: 5048.36767578125\n",
      "          vf_explained_var: 0.8782656788825989\n",
      "          vf_loss: 5048.38330078125\n",
      "    num_agent_steps_sampled: 660000\n",
      "    num_agent_steps_trained: 660000\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 660000\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.6\n",
      "    ram_util_percent: 68.53999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07304177500893362\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10506465202075774\n",
      "    mean_inference_ms: 0.5119732848568769\n",
      "    mean_raw_obs_processing_ms: 0.049307600466327386\n",
      "  time_since_restore: 590.8231298923492\n",
      "  time_this_iter_s: 3.6938669681549072\n",
      "  time_total_s: 590.8231298923492\n",
      "  timers:\n",
      "    learn_throughput: 1766.983\n",
      "    learn_time_ms: 2263.746\n",
      "    load_throughput: 3606297.236\n",
      "    load_time_ms: 1.109\n",
      "    sample_throughput: 2398.104\n",
      "    sample_time_ms: 1667.984\n",
      "    update_time_ms: 1.465\n",
      "  timestamp: 1629485648\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 165\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   165</td><td style=\"text-align: right;\">         590.823</td><td style=\"text-align: right;\">660000</td><td style=\"text-align: right;\">-388.094</td><td style=\"text-align: right;\">           -0.503512</td><td style=\"text-align: right;\">            -1742.76</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 668000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-16\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5035122220619553\n",
      "  episode_reward_mean: -411.03829777938313\n",
      "  episode_reward_min: -1805.386641214468\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3340\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.7736090421676636\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008705724962055683\n",
      "          model: {}\n",
      "          policy_loss: -0.026969248428940773\n",
      "          total_loss: 2617.94384765625\n",
      "          vf_explained_var: 0.8607774972915649\n",
      "          vf_loss: 2617.960693359375\n",
      "    num_agent_steps_sampled: 668000\n",
      "    num_agent_steps_trained: 668000\n",
      "    num_steps_sampled: 668000\n",
      "    num_steps_trained: 668000\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.659999999999997\n",
      "    ram_util_percent: 67.38\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07320057495078025\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10526770509668375\n",
      "    mean_inference_ms: 0.513105788631345\n",
      "    mean_raw_obs_processing_ms: 0.04942228836195013\n",
      "  time_since_restore: 598.2238249778748\n",
      "  time_this_iter_s: 3.76971697807312\n",
      "  time_total_s: 598.2238249778748\n",
      "  timers:\n",
      "    learn_throughput: 1759.552\n",
      "    learn_time_ms: 2273.306\n",
      "    load_throughput: 3563857.592\n",
      "    load_time_ms: 1.122\n",
      "    sample_throughput: 2386.233\n",
      "    sample_time_ms: 1676.282\n",
      "    update_time_ms: 1.478\n",
      "  timestamp: 1629485656\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 668000\n",
      "  training_iteration: 167\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   167</td><td style=\"text-align: right;\">         598.224</td><td style=\"text-align: right;\">668000</td><td style=\"text-align: right;\">-411.038</td><td style=\"text-align: right;\">           -0.503512</td><td style=\"text-align: right;\">            -1805.39</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 676000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-23\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3894724863774517\n",
      "  episode_reward_mean: -364.46238876444676\n",
      "  episode_reward_min: -1805.386641214468\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3380\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.654144823551178\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01701219007372856\n",
      "          model: {}\n",
      "          policy_loss: -0.04695107415318489\n",
      "          total_loss: 763.7318115234375\n",
      "          vf_explained_var: 0.9163076281547546\n",
      "          vf_loss: 763.7593383789062\n",
      "    num_agent_steps_sampled: 676000\n",
      "    num_agent_steps_trained: 676000\n",
      "    num_steps_sampled: 676000\n",
      "    num_steps_trained: 676000\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.800000000000004\n",
      "    ram_util_percent: 68.18333333333334\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07329035554562066\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10538730582838475\n",
      "    mean_inference_ms: 0.5137869297248054\n",
      "    mean_raw_obs_processing_ms: 0.049484003808229655\n",
      "  time_since_restore: 605.5950253009796\n",
      "  time_this_iter_s: 3.634733200073242\n",
      "  time_total_s: 605.5950253009796\n",
      "  timers:\n",
      "    learn_throughput: 1761.883\n",
      "    learn_time_ms: 2270.298\n",
      "    load_throughput: 3534501.022\n",
      "    load_time_ms: 1.132\n",
      "    sample_throughput: 2376.139\n",
      "    sample_time_ms: 1683.403\n",
      "    update_time_ms: 1.483\n",
      "  timestamp: 1629485663\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 676000\n",
      "  training_iteration: 169\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   169</td><td style=\"text-align: right;\">         605.595</td><td style=\"text-align: right;\">676000</td><td style=\"text-align: right;\">-364.462</td><td style=\"text-align: right;\">           -0.389472</td><td style=\"text-align: right;\">            -1805.39</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 684000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-30\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.3894724863774517\n",
      "  episode_reward_mean: -344.9317746860801\n",
      "  episode_reward_min: -1805.386641214468\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3420\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.7882096767425537\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013849077746272087\n",
      "          model: {}\n",
      "          policy_loss: -0.04154260829091072\n",
      "          total_loss: 863.0398559570312\n",
      "          vf_explained_var: 0.9423192739486694\n",
      "          vf_loss: 863.0656127929688\n",
      "    num_agent_steps_sampled: 684000\n",
      "    num_agent_steps_trained: 684000\n",
      "    num_steps_sampled: 684000\n",
      "    num_steps_trained: 684000\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.4\n",
      "    ram_util_percent: 67.92\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07331904049503177\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10542403965023789\n",
      "    mean_inference_ms: 0.5141095366967913\n",
      "    mean_raw_obs_processing_ms: 0.04949778590540582\n",
      "  time_since_restore: 612.8721354007721\n",
      "  time_this_iter_s: 3.682375907897949\n",
      "  time_total_s: 612.8721354007721\n",
      "  timers:\n",
      "    learn_throughput: 1754.885\n",
      "    learn_time_ms: 2279.352\n",
      "    load_throughput: 3501088.481\n",
      "    load_time_ms: 1.143\n",
      "    sample_throughput: 2376.972\n",
      "    sample_time_ms: 1682.813\n",
      "    update_time_ms: 1.465\n",
      "  timestamp: 1629485670\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 684000\n",
      "  training_iteration: 171\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   171</td><td style=\"text-align: right;\">         612.872</td><td style=\"text-align: right;\">684000</td><td style=\"text-align: right;\">-344.932</td><td style=\"text-align: right;\">           -0.389472</td><td style=\"text-align: right;\">            -1805.39</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 692000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-39\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5713932184144711\n",
      "  episode_reward_mean: -419.7507131007166\n",
      "  episode_reward_min: -1840.460248550385\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3460\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.9425163269042969\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015205838717520237\n",
      "          model: {}\n",
      "          policy_loss: -0.03855326771736145\n",
      "          total_loss: 3742.342529296875\n",
      "          vf_explained_var: 0.910480797290802\n",
      "          vf_loss: 3742.364013671875\n",
      "    num_agent_steps_sampled: 692000\n",
      "    num_agent_steps_trained: 692000\n",
      "    num_steps_sampled: 692000\n",
      "    num_steps_trained: 692000\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.82857142857143\n",
      "    ram_util_percent: 68.14285714285714\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07335425238163223\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10546838210469577\n",
      "    mean_inference_ms: 0.5144668781587887\n",
      "    mean_raw_obs_processing_ms: 0.04951874861251533\n",
      "  time_since_restore: 621.0832033157349\n",
      "  time_this_iter_s: 4.467513799667358\n",
      "  time_total_s: 621.0832033157349\n",
      "  timers:\n",
      "    learn_throughput: 1840.145\n",
      "    learn_time_ms: 2173.742\n",
      "    load_throughput: 4163597.469\n",
      "    load_time_ms: 0.961\n",
      "    sample_throughput: 2397.677\n",
      "    sample_time_ms: 1668.281\n",
      "    update_time_ms: 1.494\n",
      "  timestamp: 1629485679\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 692000\n",
      "  training_iteration: 173\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   173</td><td style=\"text-align: right;\">         621.083</td><td style=\"text-align: right;\">692000</td><td style=\"text-align: right;\">-419.751</td><td style=\"text-align: right;\">           -0.571393</td><td style=\"text-align: right;\">            -1840.46</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 700000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-46\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5713932184144711\n",
      "  episode_reward_mean: -424.4553669477875\n",
      "  episode_reward_min: -1840.460248550385\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3500\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.0744554996490479\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01430294569581747\n",
      "          model: {}\n",
      "          policy_loss: -0.04624783992767334\n",
      "          total_loss: 1670.20458984375\n",
      "          vf_explained_var: 0.9181616306304932\n",
      "          vf_loss: 1670.23486328125\n",
      "    num_agent_steps_sampled: 700000\n",
      "    num_agent_steps_trained: 700000\n",
      "    num_steps_sampled: 700000\n",
      "    num_steps_trained: 700000\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.4\n",
      "    ram_util_percent: 66.5\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07341210388764305\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10553995120015496\n",
      "    mean_inference_ms: 0.5149440762426939\n",
      "    mean_raw_obs_processing_ms: 0.049558548535979234\n",
      "  time_since_restore: 628.5681490898132\n",
      "  time_this_iter_s: 3.7753689289093018\n",
      "  time_total_s: 628.5681490898132\n",
      "  timers:\n",
      "    learn_throughput: 1853.626\n",
      "    learn_time_ms: 2157.933\n",
      "    load_throughput: 4258500.901\n",
      "    load_time_ms: 0.939\n",
      "    sample_throughput: 2485.074\n",
      "    sample_time_ms: 1609.61\n",
      "    update_time_ms: 1.504\n",
      "  timestamp: 1629485686\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 700000\n",
      "  training_iteration: 175\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   175</td><td style=\"text-align: right;\">         628.568</td><td style=\"text-align: right;\">700000</td><td style=\"text-align: right;\">-424.455</td><td style=\"text-align: right;\">           -0.571393</td><td style=\"text-align: right;\">            -1840.46</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 708000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-54-54\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1.024236947236682\n",
      "  episode_reward_mean: -442.42742380671297\n",
      "  episode_reward_min: -1771.0964883529466\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3540\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3762307167053223\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018532076850533485\n",
      "          model: {}\n",
      "          policy_loss: -0.04545290023088455\n",
      "          total_loss: 3635.40869140625\n",
      "          vf_explained_var: 0.8810557126998901\n",
      "          vf_loss: 3635.432861328125\n",
      "    num_agent_steps_sampled: 708000\n",
      "    num_agent_steps_trained: 708000\n",
      "    num_steps_sampled: 708000\n",
      "    num_steps_trained: 708000\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.060000000000002\n",
      "    ram_util_percent: 66.32\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07348942027980676\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1056403282720083\n",
      "    mean_inference_ms: 0.5154955098216657\n",
      "    mean_raw_obs_processing_ms: 0.04961585748457137\n",
      "  time_since_restore: 636.2481849193573\n",
      "  time_this_iter_s: 3.835089921951294\n",
      "  time_total_s: 636.2481849193573\n",
      "  timers:\n",
      "    learn_throughput: 1835.484\n",
      "    learn_time_ms: 2179.261\n",
      "    load_throughput: 4311800.565\n",
      "    load_time_ms: 0.928\n",
      "    sample_throughput: 2474.945\n",
      "    sample_time_ms: 1616.198\n",
      "    update_time_ms: 1.536\n",
      "  timestamp: 1629485694\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 708000\n",
      "  training_iteration: 177\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   177</td><td style=\"text-align: right;\">         636.248</td><td style=\"text-align: right;\">708000</td><td style=\"text-align: right;\">-442.427</td><td style=\"text-align: right;\">            -1.02424</td><td style=\"text-align: right;\">             -1771.1</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 716000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-01\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1.024236947236682\n",
      "  episode_reward_mean: -419.394836732181\n",
      "  episode_reward_min: -1752.7268506724101\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3580\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.8663357496261597\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01728653535246849\n",
      "          model: {}\n",
      "          policy_loss: -0.03381729871034622\n",
      "          total_loss: 3777.382080078125\n",
      "          vf_explained_var: 0.8947741389274597\n",
      "          vf_loss: 3777.396484375\n",
      "    num_agent_steps_sampled: 716000\n",
      "    num_agent_steps_trained: 716000\n",
      "    num_steps_sampled: 716000\n",
      "    num_steps_trained: 716000\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.339999999999996\n",
      "    ram_util_percent: 66.6\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07354031446112595\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10570853327456355\n",
      "    mean_inference_ms: 0.5158907712114847\n",
      "    mean_raw_obs_processing_ms: 0.04965174287584226\n",
      "  time_since_restore: 643.5089039802551\n",
      "  time_this_iter_s: 3.577075958251953\n",
      "  time_total_s: 643.5089039802551\n",
      "  timers:\n",
      "    learn_throughput: 1837.988\n",
      "    learn_time_ms: 2176.292\n",
      "    load_throughput: 4322576.456\n",
      "    load_time_ms: 0.925\n",
      "    sample_throughput: 2487.401\n",
      "    sample_time_ms: 1608.104\n",
      "    update_time_ms: 1.531\n",
      "  timestamp: 1629485701\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 716000\n",
      "  training_iteration: 179\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   179</td><td style=\"text-align: right;\">         643.509</td><td style=\"text-align: right;\">716000</td><td style=\"text-align: right;\">-419.395</td><td style=\"text-align: right;\">            -1.02424</td><td style=\"text-align: right;\">            -1752.73</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 724000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-09\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4980938105568903\n",
      "  episode_reward_mean: -405.3809569848612\n",
      "  episode_reward_min: -1752.7268506724101\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3620\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1243155002593994\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01688745990395546\n",
      "          model: {}\n",
      "          policy_loss: -0.04621937870979309\n",
      "          total_loss: 779.7901000976562\n",
      "          vf_explained_var: 0.9538249969482422\n",
      "          vf_loss: 779.8170166015625\n",
      "    num_agent_steps_sampled: 724000\n",
      "    num_agent_steps_trained: 724000\n",
      "    num_steps_sampled: 724000\n",
      "    num_steps_trained: 724000\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.449999999999996\n",
      "    ram_util_percent: 66.85000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07357007900754732\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10574987953328599\n",
      "    mean_inference_ms: 0.51615965305305\n",
      "    mean_raw_obs_processing_ms: 0.04967229511823116\n",
      "  time_since_restore: 651.2662155628204\n",
      "  time_this_iter_s: 3.973223924636841\n",
      "  time_total_s: 651.2662155628204\n",
      "  timers:\n",
      "    learn_throughput: 1807.89\n",
      "    learn_time_ms: 2212.524\n",
      "    load_throughput: 4402890.959\n",
      "    load_time_ms: 0.908\n",
      "    sample_throughput: 2469.393\n",
      "    sample_time_ms: 1619.831\n",
      "    update_time_ms: 1.607\n",
      "  timestamp: 1629485709\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 724000\n",
      "  training_iteration: 181\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   181</td><td style=\"text-align: right;\">         651.266</td><td style=\"text-align: right;\">724000</td><td style=\"text-align: right;\">-405.381</td><td style=\"text-align: right;\">           -0.498094</td><td style=\"text-align: right;\">            -1752.73</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 732000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-17\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4980938105568903\n",
      "  episode_reward_mean: -402.81989696980304\n",
      "  episode_reward_min: -1742.7077997978438\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3660\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.4922083616256714\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016712432727217674\n",
      "          model: {}\n",
      "          policy_loss: -0.039079971611499786\n",
      "          total_loss: 3917.011474609375\n",
      "          vf_explained_var: 0.8304048180580139\n",
      "          vf_loss: 3917.03173828125\n",
      "    num_agent_steps_sampled: 732000\n",
      "    num_agent_steps_trained: 732000\n",
      "    num_steps_sampled: 732000\n",
      "    num_steps_trained: 732000\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.61666666666667\n",
      "    ram_util_percent: 67.58333333333333\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07365875243581926\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10584955599181796\n",
      "    mean_inference_ms: 0.5168029598379507\n",
      "    mean_raw_obs_processing_ms: 0.049729789251298194\n",
      "  time_since_restore: 659.740784406662\n",
      "  time_this_iter_s: 4.117811918258667\n",
      "  time_total_s: 659.740784406662\n",
      "  timers:\n",
      "    learn_throughput: 1816.296\n",
      "    learn_time_ms: 2202.284\n",
      "    load_throughput: 4076295.252\n",
      "    load_time_ms: 0.981\n",
      "    sample_throughput: 2414.491\n",
      "    sample_time_ms: 1656.664\n",
      "    update_time_ms: 1.56\n",
      "  timestamp: 1629485717\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 732000\n",
      "  training_iteration: 183\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   183</td><td style=\"text-align: right;\">         659.741</td><td style=\"text-align: right;\">732000</td><td style=\"text-align: right;\"> -402.82</td><td style=\"text-align: right;\">           -0.498094</td><td style=\"text-align: right;\">            -1742.71</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 740000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-25\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6264160574374094\n",
      "  episode_reward_mean: -346.2275642612471\n",
      "  episode_reward_min: -1734.8318153402058\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3700\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.6092731356620789\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014912248589098454\n",
      "          model: {}\n",
      "          policy_loss: -0.03315157815814018\n",
      "          total_loss: 596.8392333984375\n",
      "          vf_explained_var: 0.8841275572776794\n",
      "          vf_loss: 596.8554077148438\n",
      "    num_agent_steps_sampled: 740000\n",
      "    num_agent_steps_trained: 740000\n",
      "    num_steps_sampled: 740000\n",
      "    num_steps_trained: 740000\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.48\n",
      "    ram_util_percent: 67.22\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07376206414201078\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10596652561217715\n",
      "    mean_inference_ms: 0.5174769868851439\n",
      "    mean_raw_obs_processing_ms: 0.04979681529229849\n",
      "  time_since_restore: 666.8033351898193\n",
      "  time_this_iter_s: 3.3522839546203613\n",
      "  time_total_s: 666.8033351898193\n",
      "  timers:\n",
      "    learn_throughput: 1831.168\n",
      "    learn_time_ms: 2184.398\n",
      "    load_throughput: 3584645.429\n",
      "    load_time_ms: 1.116\n",
      "    sample_throughput: 2450.935\n",
      "    sample_time_ms: 1632.03\n",
      "    update_time_ms: 1.593\n",
      "  timestamp: 1629485725\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 740000\n",
      "  training_iteration: 185\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   185</td><td style=\"text-align: right;\">         666.803</td><td style=\"text-align: right;\">740000</td><td style=\"text-align: right;\">-346.228</td><td style=\"text-align: right;\">           -0.626416</td><td style=\"text-align: right;\">            -1734.83</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 748000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-31\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6264160574374094\n",
      "  episode_reward_mean: -356.2098147036081\n",
      "  episode_reward_min: -1734.8318153402058\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3740\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.48390495777130127\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018819371238350868\n",
      "          model: {}\n",
      "          policy_loss: -0.04262881726026535\n",
      "          total_loss: 324.3163146972656\n",
      "          vf_explained_var: 0.932930052280426\n",
      "          vf_loss: 324.3375549316406\n",
      "    num_agent_steps_sampled: 748000\n",
      "    num_agent_steps_trained: 748000\n",
      "    num_steps_sampled: 748000\n",
      "    num_steps_trained: 748000\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.25\n",
      "    ram_util_percent: 67.325\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07378412652858235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10598693039274845\n",
      "    mean_inference_ms: 0.5175802620600575\n",
      "    mean_raw_obs_processing_ms: 0.049807315527613534\n",
      "  time_since_restore: 673.1313240528107\n",
      "  time_this_iter_s: 3.169794797897339\n",
      "  time_total_s: 673.1313240528107\n",
      "  timers:\n",
      "    learn_throughput: 1899.361\n",
      "    learn_time_ms: 2105.971\n",
      "    load_throughput: 3650633.418\n",
      "    load_time_ms: 1.096\n",
      "    sample_throughput: 2538.92\n",
      "    sample_time_ms: 1575.473\n",
      "    update_time_ms: 1.526\n",
      "  timestamp: 1629485731\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 748000\n",
      "  training_iteration: 187\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   187</td><td style=\"text-align: right;\">         673.131</td><td style=\"text-align: right;\">748000</td><td style=\"text-align: right;\"> -356.21</td><td style=\"text-align: right;\">           -0.626416</td><td style=\"text-align: right;\">            -1734.83</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 756000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-37\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.9512539474326712\n",
      "  episode_reward_mean: -413.49796869150833\n",
      "  episode_reward_min: -1725.818419001295\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3780\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.3007590770721436\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015845274552702904\n",
      "          model: {}\n",
      "          policy_loss: -0.037518151104450226\n",
      "          total_loss: 2880.631103515625\n",
      "          vf_explained_var: 0.8675475120544434\n",
      "          vf_loss: 2880.650390625\n",
      "    num_agent_steps_sampled: 756000\n",
      "    num_agent_steps_trained: 756000\n",
      "    num_steps_sampled: 756000\n",
      "    num_steps_trained: 756000\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.924999999999997\n",
      "    ram_util_percent: 66.725\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07371505468269046\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10589561729905995\n",
      "    mean_inference_ms: 0.5170893330102853\n",
      "    mean_raw_obs_processing_ms: 0.04975119142927513\n",
      "  time_since_restore: 679.4645462036133\n",
      "  time_this_iter_s: 3.1936681270599365\n",
      "  time_total_s: 679.4645462036133\n",
      "  timers:\n",
      "    learn_throughput: 1950.752\n",
      "    learn_time_ms: 2050.491\n",
      "    load_throughput: 3683980.589\n",
      "    load_time_ms: 1.086\n",
      "    sample_throughput: 2600.125\n",
      "    sample_time_ms: 1538.388\n",
      "    update_time_ms: 1.49\n",
      "  timestamp: 1629485737\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 756000\n",
      "  training_iteration: 189\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   189</td><td style=\"text-align: right;\">         679.465</td><td style=\"text-align: right;\">756000</td><td style=\"text-align: right;\">-413.498</td><td style=\"text-align: right;\">           -0.951254</td><td style=\"text-align: right;\">            -1725.82</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 764000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-44\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6663595071827352\n",
      "  episode_reward_mean: -460.2685521715134\n",
      "  episode_reward_min: -1701.7328996429676\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3820\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.575251817703247\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013168114237487316\n",
      "          model: {}\n",
      "          policy_loss: -0.03643466532230377\n",
      "          total_loss: 3753.357666015625\n",
      "          vf_explained_var: 0.8669828772544861\n",
      "          vf_loss: 3753.378662109375\n",
      "    num_agent_steps_sampled: 764000\n",
      "    num_agent_steps_trained: 764000\n",
      "    num_steps_sampled: 764000\n",
      "    num_steps_trained: 764000\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.339999999999996\n",
      "    ram_util_percent: 65.82000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07363361131967527\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10578754691206584\n",
      "    mean_inference_ms: 0.5165305046369384\n",
      "    mean_raw_obs_processing_ms: 0.04968498094552183\n",
      "  time_since_restore: 686.3214800357819\n",
      "  time_this_iter_s: 3.4503870010375977\n",
      "  time_total_s: 686.3214800357819\n",
      "  timers:\n",
      "    learn_throughput: 2001.7\n",
      "    learn_time_ms: 1998.301\n",
      "    load_throughput: 3670520.697\n",
      "    load_time_ms: 1.09\n",
      "    sample_throughput: 2665.105\n",
      "    sample_time_ms: 1500.879\n",
      "    update_time_ms: 1.387\n",
      "  timestamp: 1629485744\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 764000\n",
      "  training_iteration: 191\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   191</td><td style=\"text-align: right;\">         686.321</td><td style=\"text-align: right;\">764000</td><td style=\"text-align: right;\">-460.269</td><td style=\"text-align: right;\">            -0.66636</td><td style=\"text-align: right;\">            -1701.73</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 772000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-51\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5932351993647459\n",
      "  episode_reward_mean: -428.9028202610844\n",
      "  episode_reward_min: -1725.2972101013158\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3860\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7862921953201294\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01735580898821354\n",
      "          model: {}\n",
      "          policy_loss: -0.04445483535528183\n",
      "          total_loss: 2173.98291015625\n",
      "          vf_explained_var: 0.9282838106155396\n",
      "          vf_loss: 2174.007568359375\n",
      "    num_agent_steps_sampled: 772000\n",
      "    num_agent_steps_trained: 772000\n",
      "    num_steps_sampled: 772000\n",
      "    num_steps_trained: 772000\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.1\n",
      "    ram_util_percent: 66.58\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0735796581540143\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10571890824663008\n",
      "    mean_inference_ms: 0.5161619939578729\n",
      "    mean_raw_obs_processing_ms: 0.04963979206169382\n",
      "  time_since_restore: 693.303943157196\n",
      "  time_this_iter_s: 3.628121852874756\n",
      "  time_total_s: 693.303943157196\n",
      "  timers:\n",
      "    learn_throughput: 2081.018\n",
      "    learn_time_ms: 1922.137\n",
      "    load_throughput: 4098801.915\n",
      "    load_time_ms: 0.976\n",
      "    sample_throughput: 2801.018\n",
      "    sample_time_ms: 1428.052\n",
      "    update_time_ms: 1.357\n",
      "  timestamp: 1629485751\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 772000\n",
      "  training_iteration: 193\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   193</td><td style=\"text-align: right;\">         693.304</td><td style=\"text-align: right;\">772000</td><td style=\"text-align: right;\">-428.903</td><td style=\"text-align: right;\">           -0.593235</td><td style=\"text-align: right;\">             -1725.3</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 780000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-55-58\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5932351993647459\n",
      "  episode_reward_mean: -415.2219456274296\n",
      "  episode_reward_min: -1725.2972101013158\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3900\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7569597959518433\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018201418220996857\n",
      "          model: {}\n",
      "          policy_loss: -0.041970767080783844\n",
      "          total_loss: 4297.71240234375\n",
      "          vf_explained_var: 0.8654174208641052\n",
      "          vf_loss: 4297.73291015625\n",
      "    num_agent_steps_sampled: 780000\n",
      "    num_agent_steps_trained: 780000\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 780000\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.54\n",
      "    ram_util_percent: 67.11999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07355889557013065\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10569760833019272\n",
      "    mean_inference_ms: 0.516011003298461\n",
      "    mean_raw_obs_processing_ms: 0.04962170026507764\n",
      "  time_since_restore: 700.4853012561798\n",
      "  time_this_iter_s: 3.874582052230835\n",
      "  time_total_s: 700.4853012561798\n",
      "  timers:\n",
      "    learn_throughput: 2064.91\n",
      "    learn_time_ms: 1937.131\n",
      "    load_throughput: 4625135.359\n",
      "    load_time_ms: 0.865\n",
      "    sample_throughput: 2806.434\n",
      "    sample_time_ms: 1425.296\n",
      "    update_time_ms: 1.285\n",
      "  timestamp: 1629485758\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 195\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   195</td><td style=\"text-align: right;\">         700.485</td><td style=\"text-align: right;\">780000</td><td style=\"text-align: right;\">-415.222</td><td style=\"text-align: right;\">           -0.593235</td><td style=\"text-align: right;\">             -1725.3</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 788000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-56-06\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.7387078663495701\n",
      "  episode_reward_mean: -396.37532088043884\n",
      "  episode_reward_min: -1725.2972101013158\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3940\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2612919807434082\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010852253995835781\n",
      "          model: {}\n",
      "          policy_loss: -0.037197984755039215\n",
      "          total_loss: 2075.14306640625\n",
      "          vf_explained_var: 0.8912317156791687\n",
      "          vf_loss: 2075.16796875\n",
      "    num_agent_steps_sampled: 788000\n",
      "    num_agent_steps_trained: 788000\n",
      "    num_steps_sampled: 788000\n",
      "    num_steps_trained: 788000\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.239999999999995\n",
      "    ram_util_percent: 67.1\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0735788652388084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10572786424876587\n",
      "    mean_inference_ms: 0.5161113668296405\n",
      "    mean_raw_obs_processing_ms: 0.04963742772143963\n",
      "  time_since_restore: 708.0835802555084\n",
      "  time_this_iter_s: 3.9144999980926514\n",
      "  time_total_s: 708.0835802555084\n",
      "  timers:\n",
      "    learn_throughput: 1998.432\n",
      "    learn_time_ms: 2001.57\n",
      "    load_throughput: 4559893.458\n",
      "    load_time_ms: 0.877\n",
      "    sample_throughput: 2688.743\n",
      "    sample_time_ms: 1487.684\n",
      "    update_time_ms: 1.34\n",
      "  timestamp: 1629485766\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 788000\n",
      "  training_iteration: 197\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   197</td><td style=\"text-align: right;\">         708.084</td><td style=\"text-align: right;\">788000</td><td style=\"text-align: right;\">-396.375</td><td style=\"text-align: right;\">           -0.738708</td><td style=\"text-align: right;\">             -1725.3</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 796000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-56-13\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.7387078663495701\n",
      "  episode_reward_mean: -335.3502902095717\n",
      "  episode_reward_min: -1717.1613038534406\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3980\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.1089630126953125\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016304779797792435\n",
      "          model: {}\n",
      "          policy_loss: -0.04409853741526604\n",
      "          total_loss: 3114.7099609375\n",
      "          vf_explained_var: 0.789918839931488\n",
      "          vf_loss: 3114.735595703125\n",
      "    num_agent_steps_sampled: 796000\n",
      "    num_agent_steps_trained: 796000\n",
      "    num_steps_sampled: 796000\n",
      "    num_steps_trained: 796000\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.516666666666666\n",
      "    ram_util_percent: 66.56666666666666\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07360681310515012\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10576839922144814\n",
      "    mean_inference_ms: 0.516251280681646\n",
      "    mean_raw_obs_processing_ms: 0.04966218507280912\n",
      "  time_since_restore: 715.3529920578003\n",
      "  time_this_iter_s: 3.600825786590576\n",
      "  time_total_s: 715.3529920578003\n",
      "  timers:\n",
      "    learn_throughput: 1934.134\n",
      "    learn_time_ms: 2068.11\n",
      "    load_throughput: 4432553.765\n",
      "    load_time_ms: 0.902\n",
      "    sample_throughput: 2641.098\n",
      "    sample_time_ms: 1514.521\n",
      "    update_time_ms: 1.384\n",
      "  timestamp: 1629485773\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 796000\n",
      "  training_iteration: 199\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   199</td><td style=\"text-align: right;\">         715.353</td><td style=\"text-align: right;\">796000</td><td style=\"text-align: right;\"> -335.35</td><td style=\"text-align: right;\">           -0.738708</td><td style=\"text-align: right;\">            -1717.16</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 804000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-56-22\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1.4675639786346126\n",
      "  episode_reward_mean: -337.91408777699564\n",
      "  episode_reward_min: -1707.6165098933404\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4020\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.9313493967056274\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01894044689834118\n",
      "          model: {}\n",
      "          policy_loss: -0.04346625134348869\n",
      "          total_loss: 908.5494384765625\n",
      "          vf_explained_var: 0.8422393202781677\n",
      "          vf_loss: 908.5714111328125\n",
      "    num_agent_steps_sampled: 804000\n",
      "    num_agent_steps_trained: 804000\n",
      "    num_steps_sampled: 804000\n",
      "    num_steps_trained: 804000\n",
      "  iterations_since_restore: 201\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.785714285714285\n",
      "    ram_util_percent: 68.04285714285713\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07364359168586958\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10582049039268483\n",
      "    mean_inference_ms: 0.5164418085198084\n",
      "    mean_raw_obs_processing_ms: 0.04969723968553254\n",
      "  time_since_restore: 723.8820788860321\n",
      "  time_this_iter_s: 4.351891994476318\n",
      "  time_total_s: 723.8820788860321\n",
      "  timers:\n",
      "    learn_throughput: 1823.381\n",
      "    learn_time_ms: 2193.727\n",
      "    load_throughput: 4166803.1\n",
      "    load_time_ms: 0.96\n",
      "    sample_throughput: 2571.101\n",
      "    sample_time_ms: 1555.754\n",
      "    update_time_ms: 1.465\n",
      "  timestamp: 1629485782\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 804000\n",
      "  training_iteration: 201\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         723.882</td><td style=\"text-align: right;\">804000</td><td style=\"text-align: right;\">-337.914</td><td style=\"text-align: right;\">            -1.46756</td><td style=\"text-align: right;\">            -1707.62</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 808000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-56-28\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.998525084136713\n",
      "  episode_reward_mean: -330.5384884550906\n",
      "  episode_reward_min: -1640.8732397589874\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4040\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.9319899082183838\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010221939533948898\n",
      "          model: {}\n",
      "          policy_loss: -0.04612654820084572\n",
      "          total_loss: 520.7274780273438\n",
      "          vf_explained_var: 0.9480147361755371\n",
      "          vf_loss: 520.761962890625\n",
      "    num_agent_steps_sampled: 808000\n",
      "    num_agent_steps_trained: 808000\n",
      "    num_steps_sampled: 808000\n",
      "    num_steps_trained: 808000\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.150000000000006\n",
      "    ram_util_percent: 68.80000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07368444385085406\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10587321453932694\n",
      "    mean_inference_ms: 0.5166950908041191\n",
      "    mean_raw_obs_processing_ms: 0.04973103257247814\n",
      "  time_since_restore: 729.7095687389374\n",
      "  time_this_iter_s: 5.827489852905273\n",
      "  time_total_s: 729.7095687389374\n",
      "  timers:\n",
      "    learn_throughput: 1692.697\n",
      "    learn_time_ms: 2363.093\n",
      "    load_throughput: 3964370.51\n",
      "    load_time_ms: 1.009\n",
      "    sample_throughput: 2448.625\n",
      "    sample_time_ms: 1633.57\n",
      "    update_time_ms: 1.477\n",
      "  timestamp: 1629485788\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 808000\n",
      "  training_iteration: 202\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   202</td><td style=\"text-align: right;\">          729.71</td><td style=\"text-align: right;\">808000</td><td style=\"text-align: right;\">-330.538</td><td style=\"text-align: right;\">           -0.998525</td><td style=\"text-align: right;\">            -1640.87</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 816000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-56-38\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.643711586059994\n",
      "  episode_reward_mean: -393.4574893702662\n",
      "  episode_reward_min: -1782.4562019484815\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4080\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.5021989345550537\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012273138388991356\n",
      "          model: {}\n",
      "          policy_loss: -0.03584987670183182\n",
      "          total_loss: 8533.474609375\n",
      "          vf_explained_var: 0.8117124438285828\n",
      "          vf_loss: 8533.4892578125\n",
      "    num_agent_steps_sampled: 816000\n",
      "    num_agent_steps_trained: 816000\n",
      "    num_steps_sampled: 816000\n",
      "    num_steps_trained: 816000\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.82857142857143\n",
      "    ram_util_percent: 68.12857142857145\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07387473536198437\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10610892697575507\n",
      "    mean_inference_ms: 0.5179712992214185\n",
      "    mean_raw_obs_processing_ms: 0.049872165793683594\n",
      "  time_since_restore: 739.7876527309418\n",
      "  time_this_iter_s: 5.212205171585083\n",
      "  time_total_s: 739.7876527309418\n",
      "  timers:\n",
      "    learn_throughput: 1574.264\n",
      "    learn_time_ms: 2540.869\n",
      "    load_throughput: 3754720.14\n",
      "    load_time_ms: 1.065\n",
      "    sample_throughput: 2260.375\n",
      "    sample_time_ms: 1769.618\n",
      "    update_time_ms: 1.565\n",
      "  timestamp: 1629485798\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 816000\n",
      "  training_iteration: 204\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   204</td><td style=\"text-align: right;\">         739.788</td><td style=\"text-align: right;\">816000</td><td style=\"text-align: right;\">-393.457</td><td style=\"text-align: right;\">           -0.643712</td><td style=\"text-align: right;\">            -1782.46</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 824000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-56-47\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.643711586059994\n",
      "  episode_reward_mean: -414.2209251545864\n",
      "  episode_reward_min: -1782.4562019484815\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4120\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.5817409753799438\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013129107654094696\n",
      "          model: {}\n",
      "          policy_loss: -0.045049477368593216\n",
      "          total_loss: 3556.67724609375\n",
      "          vf_explained_var: 0.8627921342849731\n",
      "          vf_loss: 3556.700439453125\n",
      "    num_agent_steps_sampled: 824000\n",
      "    num_agent_steps_trained: 824000\n",
      "    num_steps_sampled: 824000\n",
      "    num_steps_trained: 824000\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.48333333333333\n",
      "    ram_util_percent: 67.71666666666668\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07416013495863005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10645886622771035\n",
      "    mean_inference_ms: 0.5199128815912907\n",
      "    mean_raw_obs_processing_ms: 0.05007766967446686\n",
      "  time_since_restore: 748.4746417999268\n",
      "  time_this_iter_s: 4.120248079299927\n",
      "  time_total_s: 748.4746417999268\n",
      "  timers:\n",
      "    learn_throughput: 1553.968\n",
      "    learn_time_ms: 2574.056\n",
      "    load_throughput: 3648648.602\n",
      "    load_time_ms: 1.096\n",
      "    sample_throughput: 2163.135\n",
      "    sample_time_ms: 1849.168\n",
      "    update_time_ms: 1.608\n",
      "  timestamp: 1629485807\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 824000\n",
      "  training_iteration: 206\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   206</td><td style=\"text-align: right;\">         748.475</td><td style=\"text-align: right;\">824000</td><td style=\"text-align: right;\">-414.221</td><td style=\"text-align: right;\">           -0.643712</td><td style=\"text-align: right;\">            -1782.46</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 832000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-56-54\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4851645941156901\n",
      "  episode_reward_mean: -461.3456050805496\n",
      "  episode_reward_min: -1782.4562019484815\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4160\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 3.1205251216888428\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012720542028546333\n",
      "          model: {}\n",
      "          policy_loss: -0.03862043470144272\n",
      "          total_loss: 7830.126953125\n",
      "          vf_explained_var: 0.851412296295166\n",
      "          vf_loss: 7830.14404296875\n",
      "    num_agent_steps_sampled: 832000\n",
      "    num_agent_steps_trained: 832000\n",
      "    num_steps_sampled: 832000\n",
      "    num_steps_trained: 832000\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.93333333333333\n",
      "    ram_util_percent: 67.41666666666667\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0743371172489385\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10668383521562745\n",
      "    mean_inference_ms: 0.5210971890528422\n",
      "    mean_raw_obs_processing_ms: 0.050209370152718764\n",
      "  time_since_restore: 756.1354508399963\n",
      "  time_this_iter_s: 4.023824214935303\n",
      "  time_total_s: 756.1354508399963\n",
      "  timers:\n",
      "    learn_throughput: 1536.868\n",
      "    learn_time_ms: 2602.696\n",
      "    load_throughput: 3659392.327\n",
      "    load_time_ms: 1.093\n",
      "    sample_throughput: 2188.204\n",
      "    sample_time_ms: 1827.983\n",
      "    update_time_ms: 1.721\n",
      "  timestamp: 1629485814\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 832000\n",
      "  training_iteration: 208\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   208</td><td style=\"text-align: right;\">         756.135</td><td style=\"text-align: right;\">832000</td><td style=\"text-align: right;\">-461.346</td><td style=\"text-align: right;\">           -0.485165</td><td style=\"text-align: right;\">            -1782.46</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 836000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-00\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4851645941156901\n",
      "  episode_reward_mean: -446.5404035816671\n",
      "  episode_reward_min: -1721.891140777082\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4180\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.8882673978805542\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01157415471971035\n",
      "          model: {}\n",
      "          policy_loss: -0.04678485915064812\n",
      "          total_loss: 4106.4462890625\n",
      "          vf_explained_var: 0.8765762448310852\n",
      "          vf_loss: 4106.47314453125\n",
      "    num_agent_steps_sampled: 836000\n",
      "    num_agent_steps_trained: 836000\n",
      "    num_steps_sampled: 836000\n",
      "    num_steps_trained: 836000\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.2625\n",
      "    ram_util_percent: 68.3375\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07444243530733698\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10681779256788781\n",
      "    mean_inference_ms: 0.5218232010606009\n",
      "    mean_raw_obs_processing_ms: 0.050287668759580136\n",
      "  time_since_restore: 762.0941278934479\n",
      "  time_this_iter_s: 5.958677053451538\n",
      "  time_total_s: 762.0941278934479\n",
      "  timers:\n",
      "    learn_throughput: 1484.377\n",
      "    learn_time_ms: 2694.732\n",
      "    load_throughput: 3629782.134\n",
      "    load_time_ms: 1.102\n",
      "    sample_throughput: 2028.864\n",
      "    sample_time_ms: 1971.547\n",
      "    update_time_ms: 1.772\n",
      "  timestamp: 1629485820\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 836000\n",
      "  training_iteration: 209\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   209</td><td style=\"text-align: right;\">         762.094</td><td style=\"text-align: right;\">836000</td><td style=\"text-align: right;\"> -446.54</td><td style=\"text-align: right;\">           -0.485165</td><td style=\"text-align: right;\">            -1721.89</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 840000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-06\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4851645941156901\n",
      "  episode_reward_mean: -423.6737503005936\n",
      "  episode_reward_min: -1721.891140777082\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4200\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.148950457572937\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009861799888312817\n",
      "          model: {}\n",
      "          policy_loss: -0.04267974942922592\n",
      "          total_loss: 2002.67822265625\n",
      "          vf_explained_var: 0.8684428334236145\n",
      "          vf_loss: 2002.703857421875\n",
      "    num_agent_steps_sampled: 840000\n",
      "    num_agent_steps_trained: 840000\n",
      "    num_steps_sampled: 840000\n",
      "    num_steps_trained: 840000\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.388888888888886\n",
      "    ram_util_percent: 68.46666666666665\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07455281732612153\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10695742066691315\n",
      "    mean_inference_ms: 0.5225808524655513\n",
      "    mean_raw_obs_processing_ms: 0.050369587167212855\n",
      "  time_since_restore: 767.9268867969513\n",
      "  time_this_iter_s: 5.832758903503418\n",
      "  time_total_s: 767.9268867969513\n",
      "  timers:\n",
      "    learn_throughput: 1441.1\n",
      "    learn_time_ms: 2775.658\n",
      "    load_throughput: 3566660.856\n",
      "    load_time_ms: 1.121\n",
      "    sample_throughput: 1945.762\n",
      "    sample_time_ms: 2055.75\n",
      "    update_time_ms: 1.891\n",
      "  timestamp: 1629485826\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 840000\n",
      "  training_iteration: 210\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   210</td><td style=\"text-align: right;\">         767.927</td><td style=\"text-align: right;\">840000</td><td style=\"text-align: right;\">-423.674</td><td style=\"text-align: right;\">           -0.485165</td><td style=\"text-align: right;\">            -1721.89</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 848000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-14\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.40470208769798016\n",
      "  episode_reward_mean: -485.5370130202897\n",
      "  episode_reward_min: -1723.1772305951688\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4240\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.17799973487854\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01395661011338234\n",
      "          model: {}\n",
      "          policy_loss: -0.04726429283618927\n",
      "          total_loss: 3654.28369140625\n",
      "          vf_explained_var: 0.8893581032752991\n",
      "          vf_loss: 3654.306884765625\n",
      "    num_agent_steps_sampled: 848000\n",
      "    num_agent_steps_trained: 848000\n",
      "    num_steps_sampled: 848000\n",
      "    num_steps_trained: 848000\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.9\n",
      "    ram_util_percent: 68.28\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07478280541630117\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10724571409769716\n",
      "    mean_inference_ms: 0.5241619251332271\n",
      "    mean_raw_obs_processing_ms: 0.05053869539486544\n",
      "  time_since_restore: 776.1009728908539\n",
      "  time_this_iter_s: 4.005574941635132\n",
      "  time_total_s: 776.1009728908539\n",
      "  timers:\n",
      "    learn_throughput: 1520.524\n",
      "    learn_time_ms: 2630.672\n",
      "    load_throughput: 3830064.834\n",
      "    load_time_ms: 1.044\n",
      "    sample_throughput: 1999.36\n",
      "    sample_time_ms: 2000.64\n",
      "    update_time_ms: 1.797\n",
      "  timestamp: 1629485834\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 848000\n",
      "  training_iteration: 212\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   212</td><td style=\"text-align: right;\">         776.101</td><td style=\"text-align: right;\">848000</td><td style=\"text-align: right;\">-485.537</td><td style=\"text-align: right;\">           -0.404702</td><td style=\"text-align: right;\">            -1723.18</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 856000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-22\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.40470208769798016\n",
      "  episode_reward_mean: -434.8148018625667\n",
      "  episode_reward_min: -1723.1772305951688\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4280\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.8777879476547241\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011590884067118168\n",
      "          model: {}\n",
      "          policy_loss: -0.04852188006043434\n",
      "          total_loss: 3369.28466796875\n",
      "          vf_explained_var: 0.8882917761802673\n",
      "          vf_loss: 3369.3134765625\n",
      "    num_agent_steps_sampled: 856000\n",
      "    num_agent_steps_trained: 856000\n",
      "    num_steps_sampled: 856000\n",
      "    num_steps_trained: 856000\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.08\n",
      "    ram_util_percent: 68.0\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07495822289788318\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1074662176063287\n",
      "    mean_inference_ms: 0.5253426840147525\n",
      "    mean_raw_obs_processing_ms: 0.05067028059690318\n",
      "  time_since_restore: 783.7933688163757\n",
      "  time_this_iter_s: 3.713252067565918\n",
      "  time_total_s: 783.7933688163757\n",
      "  timers:\n",
      "    learn_throughput: 1586.276\n",
      "    learn_time_ms: 2521.629\n",
      "    load_throughput: 4079566.201\n",
      "    load_time_ms: 0.98\n",
      "    sample_throughput: 2137.515\n",
      "    sample_time_ms: 1871.332\n",
      "    update_time_ms: 1.777\n",
      "  timestamp: 1629485842\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 856000\n",
      "  training_iteration: 214\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   214</td><td style=\"text-align: right;\">         783.793</td><td style=\"text-align: right;\">856000</td><td style=\"text-align: right;\">-434.815</td><td style=\"text-align: right;\">           -0.404702</td><td style=\"text-align: right;\">            -1723.18</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 864000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-30\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5607349408894178\n",
      "  episode_reward_mean: -429.7895049622719\n",
      "  episode_reward_min: -1723.1772305951688\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4320\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.6779365539550781\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013717212714254856\n",
      "          model: {}\n",
      "          policy_loss: -0.03797063231468201\n",
      "          total_loss: 4189.23046875\n",
      "          vf_explained_var: 0.8640437722206116\n",
      "          vf_loss: 4189.2451171875\n",
      "    num_agent_steps_sampled: 864000\n",
      "    num_agent_steps_trained: 864000\n",
      "    num_steps_sampled: 864000\n",
      "    num_steps_trained: 864000\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.42\n",
      "    ram_util_percent: 66.9\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07498636428880485\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10750978919869696\n",
      "    mean_inference_ms: 0.5254878286317508\n",
      "    mean_raw_obs_processing_ms: 0.05070192447902335\n",
      "  time_since_restore: 791.2349407672882\n",
      "  time_this_iter_s: 3.679172992706299\n",
      "  time_total_s: 791.2349407672882\n",
      "  timers:\n",
      "    learn_throughput: 1615.723\n",
      "    learn_time_ms: 2475.671\n",
      "    load_throughput: 4196612.137\n",
      "    load_time_ms: 0.953\n",
      "    sample_throughput: 2231.023\n",
      "    sample_time_ms: 1792.9\n",
      "    update_time_ms: 1.719\n",
      "  timestamp: 1629485850\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 864000\n",
      "  training_iteration: 216\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   216</td><td style=\"text-align: right;\">         791.235</td><td style=\"text-align: right;\">864000</td><td style=\"text-align: right;\"> -429.79</td><td style=\"text-align: right;\">           -0.560735</td><td style=\"text-align: right;\">            -1723.18</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 872000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-37\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5833403377885203\n",
      "  episode_reward_mean: -372.35874356085355\n",
      "  episode_reward_min: -1696.0342621879606\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4360\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.9977622032165527\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012432415969669819\n",
      "          model: {}\n",
      "          policy_loss: -0.05395560711622238\n",
      "          total_loss: 763.6900634765625\n",
      "          vf_explained_var: 0.9160614013671875\n",
      "          vf_loss: 763.7227172851562\n",
      "    num_agent_steps_sampled: 872000\n",
      "    num_agent_steps_trained: 872000\n",
      "    num_steps_sampled: 872000\n",
      "    num_steps_trained: 872000\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.52\n",
      "    ram_util_percent: 66.9\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07498249812333144\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10751548828964377\n",
      "    mean_inference_ms: 0.5254493409275647\n",
      "    mean_raw_obs_processing_ms: 0.05071069059586697\n",
      "  time_since_restore: 798.5300986766815\n",
      "  time_this_iter_s: 3.698718786239624\n",
      "  time_total_s: 798.5300986766815\n",
      "  timers:\n",
      "    learn_throughput: 1633.868\n",
      "    learn_time_ms: 2448.179\n",
      "    load_throughput: 4267274.392\n",
      "    load_time_ms: 0.937\n",
      "    sample_throughput: 2241.932\n",
      "    sample_time_ms: 1784.175\n",
      "    update_time_ms: 1.605\n",
      "  timestamp: 1629485857\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 872000\n",
      "  training_iteration: 218\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   218</td><td style=\"text-align: right;\">          798.53</td><td style=\"text-align: right;\">872000</td><td style=\"text-align: right;\">-372.359</td><td style=\"text-align: right;\">            -0.58334</td><td style=\"text-align: right;\">            -1696.03</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 880000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-46\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.491115817303045\n",
      "  episode_reward_mean: -420.82084569625215\n",
      "  episode_reward_min: -1742.680569741619\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4400\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.19242787361145\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011983662843704224\n",
      "          model: {}\n",
      "          policy_loss: -0.043575890362262726\n",
      "          total_loss: 3021.216796875\n",
      "          vf_explained_var: 0.9123699069023132\n",
      "          vf_loss: 3021.239990234375\n",
      "    num_agent_steps_sampled: 880000\n",
      "    num_agent_steps_trained: 880000\n",
      "    num_steps_sampled: 880000\n",
      "    num_steps_trained: 880000\n",
      "  iterations_since_restore: 220\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 43.88333333333333\n",
      "    ram_util_percent: 67.93333333333332\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07498531405140291\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10752790826893728\n",
      "    mean_inference_ms: 0.5254647183746998\n",
      "    mean_raw_obs_processing_ms: 0.05072260658779644\n",
      "  time_since_restore: 807.1213445663452\n",
      "  time_this_iter_s: 4.184781074523926\n",
      "  time_total_s: 807.1213445663452\n",
      "  timers:\n",
      "    learn_throughput: 1729.675\n",
      "    learn_time_ms: 2312.573\n",
      "    load_throughput: 4308589.332\n",
      "    load_time_ms: 0.928\n",
      "    sample_throughput: 2499.518\n",
      "    sample_time_ms: 1600.308\n",
      "    update_time_ms: 1.457\n",
      "  timestamp: 1629485866\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 880000\n",
      "  training_iteration: 220\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   220</td><td style=\"text-align: right;\">         807.121</td><td style=\"text-align: right;\">880000</td><td style=\"text-align: right;\">-420.821</td><td style=\"text-align: right;\">           -0.491116</td><td style=\"text-align: right;\">            -1742.68</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 888000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-57-53\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.38235600621524346\n",
      "  episode_reward_mean: -420.4279492497215\n",
      "  episode_reward_min: -1742.680569741619\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4440\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7697092294692993\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011625428684055805\n",
      "          model: {}\n",
      "          policy_loss: -0.04216347634792328\n",
      "          total_loss: 1492.9573974609375\n",
      "          vf_explained_var: 0.9502371549606323\n",
      "          vf_loss: 1492.9796142578125\n",
      "    num_agent_steps_sampled: 888000\n",
      "    num_agent_steps_trained: 888000\n",
      "    num_steps_sampled: 888000\n",
      "    num_steps_trained: 888000\n",
      "  iterations_since_restore: 222\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.68000000000001\n",
      "    ram_util_percent: 68.0\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07500110730406567\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10755612300526338\n",
      "    mean_inference_ms: 0.5255648733577666\n",
      "    mean_raw_obs_processing_ms: 0.05074176315957743\n",
      "  time_since_restore: 814.3302655220032\n",
      "  time_this_iter_s: 3.575655937194824\n",
      "  time_total_s: 814.3302655220032\n",
      "  timers:\n",
      "    learn_throughput: 1778.339\n",
      "    learn_time_ms: 2249.29\n",
      "    load_throughput: 4284054.951\n",
      "    load_time_ms: 0.934\n",
      "    sample_throughput: 2552.657\n",
      "    sample_time_ms: 1566.995\n",
      "    update_time_ms: 1.461\n",
      "  timestamp: 1629485873\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 888000\n",
      "  training_iteration: 222\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   222</td><td style=\"text-align: right;\">          814.33</td><td style=\"text-align: right;\">888000</td><td style=\"text-align: right;\">-420.428</td><td style=\"text-align: right;\">           -0.382356</td><td style=\"text-align: right;\">            -1742.68</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 896000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-01\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.37098508912918443\n",
      "  episode_reward_mean: -482.9566561446739\n",
      "  episode_reward_min: -1781.7745158731016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4480\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.4478700160980225\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010555516928434372\n",
      "          model: {}\n",
      "          policy_loss: -0.03495396301150322\n",
      "          total_loss: 6123.31787109375\n",
      "          vf_explained_var: 0.8578919172286987\n",
      "          vf_loss: 6123.33349609375\n",
      "    num_agent_steps_sampled: 896000\n",
      "    num_agent_steps_trained: 896000\n",
      "    num_steps_sampled: 896000\n",
      "    num_steps_trained: 896000\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 43.61666666666667\n",
      "    ram_util_percent: 67.75\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07504286518608107\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10761427858125026\n",
      "    mean_inference_ms: 0.5258255814505646\n",
      "    mean_raw_obs_processing_ms: 0.05077803763767432\n",
      "  time_since_restore: 822.3467071056366\n",
      "  time_this_iter_s: 4.184549808502197\n",
      "  time_total_s: 822.3467071056366\n",
      "  timers:\n",
      "    learn_throughput: 1778.804\n",
      "    learn_time_ms: 2248.702\n",
      "    load_throughput: 4350599.279\n",
      "    load_time_ms: 0.919\n",
      "    sample_throughput: 2499.977\n",
      "    sample_time_ms: 1600.015\n",
      "    update_time_ms: 1.449\n",
      "  timestamp: 1629485881\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 896000\n",
      "  training_iteration: 224\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   224</td><td style=\"text-align: right;\">         822.347</td><td style=\"text-align: right;\">896000</td><td style=\"text-align: right;\">-482.957</td><td style=\"text-align: right;\">           -0.370985</td><td style=\"text-align: right;\">            -1781.77</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 904000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-09\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.37098508912918443\n",
      "  episode_reward_mean: -510.0263501976933\n",
      "  episode_reward_min: -1781.7745158731016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4520\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.9314513206481934\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012401551939547062\n",
      "          model: {}\n",
      "          policy_loss: -0.04108237102627754\n",
      "          total_loss: 2733.919921875\n",
      "          vf_explained_var: 0.9001261591911316\n",
      "          vf_loss: 2733.93994140625\n",
      "    num_agent_steps_sampled: 904000\n",
      "    num_agent_steps_trained: 904000\n",
      "    num_steps_sampled: 904000\n",
      "    num_steps_trained: 904000\n",
      "  iterations_since_restore: 226\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.766666666666666\n",
      "    ram_util_percent: 67.31666666666668\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07509077621994625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10767516279446507\n",
      "    mean_inference_ms: 0.5261214250687875\n",
      "    mean_raw_obs_processing_ms: 0.050817371292445575\n",
      "  time_since_restore: 830.2454853057861\n",
      "  time_this_iter_s: 3.8559272289276123\n",
      "  time_total_s: 830.2454853057861\n",
      "  timers:\n",
      "    learn_throughput: 1762.979\n",
      "    learn_time_ms: 2268.887\n",
      "    load_throughput: 4318126.271\n",
      "    load_time_ms: 0.926\n",
      "    sample_throughput: 2460.747\n",
      "    sample_time_ms: 1625.523\n",
      "    update_time_ms: 1.44\n",
      "  timestamp: 1629485889\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 904000\n",
      "  training_iteration: 226\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   226</td><td style=\"text-align: right;\">         830.245</td><td style=\"text-align: right;\">904000</td><td style=\"text-align: right;\">-510.026</td><td style=\"text-align: right;\">           -0.370985</td><td style=\"text-align: right;\">            -1781.77</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 912000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-16\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.37098508912918443\n",
      "  episode_reward_mean: -482.7885712644875\n",
      "  episode_reward_min: -1772.7420557672751\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4560\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.058946132659912\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011392088606953621\n",
      "          model: {}\n",
      "          policy_loss: -0.04266643524169922\n",
      "          total_loss: 3766.876953125\n",
      "          vf_explained_var: 0.8861501812934875\n",
      "          vf_loss: 3766.89990234375\n",
      "    num_agent_steps_sampled: 912000\n",
      "    num_agent_steps_trained: 912000\n",
      "    num_steps_sampled: 912000\n",
      "    num_steps_trained: 912000\n",
      "  iterations_since_restore: 228\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.080000000000002\n",
      "    ram_util_percent: 67.4\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07515080822698733\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10774880907834478\n",
      "    mean_inference_ms: 0.5264984083799326\n",
      "    mean_raw_obs_processing_ms: 0.05086323155815691\n",
      "  time_since_restore: 837.6712353229523\n",
      "  time_this_iter_s: 3.7020230293273926\n",
      "  time_total_s: 837.6712353229523\n",
      "  timers:\n",
      "    learn_throughput: 1759.521\n",
      "    learn_time_ms: 2273.346\n",
      "    load_throughput: 4260555.64\n",
      "    load_time_ms: 0.939\n",
      "    sample_throughput: 2447.792\n",
      "    sample_time_ms: 1634.125\n",
      "    update_time_ms: 1.433\n",
      "  timestamp: 1629485896\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 912000\n",
      "  training_iteration: 228\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   228</td><td style=\"text-align: right;\">         837.671</td><td style=\"text-align: right;\">912000</td><td style=\"text-align: right;\">-482.789</td><td style=\"text-align: right;\">           -0.370985</td><td style=\"text-align: right;\">            -1772.74</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 920000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-24\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2.7204435411331382\n",
      "  episode_reward_mean: -444.84818752235793\n",
      "  episode_reward_min: -1742.3465338695794\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4600\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.7210471630096436\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018152691423892975\n",
      "          model: {}\n",
      "          policy_loss: -0.05257149413228035\n",
      "          total_loss: 5376.673828125\n",
      "          vf_explained_var: 0.8682278394699097\n",
      "          vf_loss: 5376.69580078125\n",
      "    num_agent_steps_sampled: 920000\n",
      "    num_agent_steps_trained: 920000\n",
      "    num_steps_sampled: 920000\n",
      "    num_steps_trained: 920000\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.7\n",
      "    ram_util_percent: 67.25999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07516464264613942\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10777105056416342\n",
      "    mean_inference_ms: 0.5266055136863685\n",
      "    mean_raw_obs_processing_ms: 0.05087658789547854\n",
      "  time_since_restore: 845.3861594200134\n",
      "  time_this_iter_s: 3.8328001499176025\n",
      "  time_total_s: 845.3861594200134\n",
      "  timers:\n",
      "    learn_throughput: 1803.706\n",
      "    learn_time_ms: 2217.656\n",
      "    load_throughput: 4316348.761\n",
      "    load_time_ms: 0.927\n",
      "    sample_throughput: 2496.485\n",
      "    sample_time_ms: 1602.253\n",
      "    update_time_ms: 1.413\n",
      "  timestamp: 1629485904\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 920000\n",
      "  training_iteration: 230\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   230</td><td style=\"text-align: right;\">         845.386</td><td style=\"text-align: right;\">920000</td><td style=\"text-align: right;\">-444.848</td><td style=\"text-align: right;\">            -2.72044</td><td style=\"text-align: right;\">            -1742.35</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 928000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-31\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.524659172960005\n",
      "  episode_reward_mean: -442.16642688144617\n",
      "  episode_reward_min: -1708.6523850329477\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4640\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.8590129613876343\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013450021855533123\n",
      "          model: {}\n",
      "          policy_loss: -0.03631405159831047\n",
      "          total_loss: 3411.929443359375\n",
      "          vf_explained_var: 0.8695670366287231\n",
      "          vf_loss: 3411.943359375\n",
      "    num_agent_steps_sampled: 928000\n",
      "    num_agent_steps_trained: 928000\n",
      "    num_steps_sampled: 928000\n",
      "    num_steps_trained: 928000\n",
      "  iterations_since_restore: 232\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.279999999999994\n",
      "    ram_util_percent: 67.3\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07515582098616573\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10776773831322012\n",
      "    mean_inference_ms: 0.5265767369985661\n",
      "    mean_raw_obs_processing_ms: 0.050873557044482876\n",
      "  time_since_restore: 852.5952613353729\n",
      "  time_this_iter_s: 3.597775936126709\n",
      "  time_total_s: 852.5952613353729\n",
      "  timers:\n",
      "    learn_throughput: 1808.87\n",
      "    learn_time_ms: 2211.325\n",
      "    load_throughput: 4362250.65\n",
      "    load_time_ms: 0.917\n",
      "    sample_throughput: 2486.508\n",
      "    sample_time_ms: 1608.682\n",
      "    update_time_ms: 1.414\n",
      "  timestamp: 1629485911\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 928000\n",
      "  training_iteration: 232\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   232</td><td style=\"text-align: right;\">         852.595</td><td style=\"text-align: right;\">928000</td><td style=\"text-align: right;\">-442.166</td><td style=\"text-align: right;\">           -0.524659</td><td style=\"text-align: right;\">            -1708.65</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 936000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-39\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.524659172960005\n",
      "  episode_reward_mean: -492.53260817734065\n",
      "  episode_reward_min: -1701.6773206832497\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4680\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.9117308855056763\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011648512445390224\n",
      "          model: {}\n",
      "          policy_loss: -0.04716913402080536\n",
      "          total_loss: 3653.754150390625\n",
      "          vf_explained_var: 0.8790267705917358\n",
      "          vf_loss: 3653.78125\n",
      "    num_agent_steps_sampled: 936000\n",
      "    num_agent_steps_trained: 936000\n",
      "    num_steps_sampled: 936000\n",
      "    num_steps_trained: 936000\n",
      "  iterations_since_restore: 234\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.540000000000006\n",
      "    ram_util_percent: 66.75999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07514473732085189\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10775988734470365\n",
      "    mean_inference_ms: 0.5265492266512933\n",
      "    mean_raw_obs_processing_ms: 0.050867931278879654\n",
      "  time_since_restore: 859.9015703201294\n",
      "  time_this_iter_s: 3.691873073577881\n",
      "  time_total_s: 859.9015703201294\n",
      "  timers:\n",
      "    learn_throughput: 1827.838\n",
      "    learn_time_ms: 2188.378\n",
      "    load_throughput: 4375219.319\n",
      "    load_time_ms: 0.914\n",
      "    sample_throughput: 2562.983\n",
      "    sample_time_ms: 1560.681\n",
      "    update_time_ms: 1.416\n",
      "  timestamp: 1629485919\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 936000\n",
      "  training_iteration: 234\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   234</td><td style=\"text-align: right;\">         859.902</td><td style=\"text-align: right;\">936000</td><td style=\"text-align: right;\">-492.533</td><td style=\"text-align: right;\">           -0.524659</td><td style=\"text-align: right;\">            -1701.68</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 944000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-46\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5096034328184365\n",
      "  episode_reward_mean: -434.06124234777434\n",
      "  episode_reward_min: -1688.304994277736\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4720\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.3112857341766357\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012361150234937668\n",
      "          model: {}\n",
      "          policy_loss: -0.04596623033285141\n",
      "          total_loss: 6604.7685546875\n",
      "          vf_explained_var: 0.8238652944564819\n",
      "          vf_loss: 6604.79345703125\n",
      "    num_agent_steps_sampled: 944000\n",
      "    num_agent_steps_trained: 944000\n",
      "    num_steps_sampled: 944000\n",
      "    num_steps_trained: 944000\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.64\n",
      "    ram_util_percent: 67.92\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07514099680074043\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1077613516666329\n",
      "    mean_inference_ms: 0.5265570309514586\n",
      "    mean_raw_obs_processing_ms: 0.05086735103181961\n",
      "  time_since_restore: 867.5496203899384\n",
      "  time_this_iter_s: 3.6351561546325684\n",
      "  time_total_s: 867.5496203899384\n",
      "  timers:\n",
      "    learn_throughput: 1836.891\n",
      "    learn_time_ms: 2177.593\n",
      "    load_throughput: 4542116.577\n",
      "    load_time_ms: 0.881\n",
      "    sample_throughput: 2586.605\n",
      "    sample_time_ms: 1546.429\n",
      "    update_time_ms: 1.424\n",
      "  timestamp: 1629485926\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 944000\n",
      "  training_iteration: 236\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   236</td><td style=\"text-align: right;\">          867.55</td><td style=\"text-align: right;\">944000</td><td style=\"text-align: right;\">-434.061</td><td style=\"text-align: right;\">           -0.509603</td><td style=\"text-align: right;\">             -1688.3</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 952000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-58-54\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5096034328184365\n",
      "  episode_reward_mean: -432.3432689327599\n",
      "  episode_reward_min: -1703.6412852961519\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4760\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.9917908906936646\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018740421161055565\n",
      "          model: {}\n",
      "          policy_loss: -0.05492956563830376\n",
      "          total_loss: 3218.538330078125\n",
      "          vf_explained_var: 0.9154919385910034\n",
      "          vf_loss: 3218.561279296875\n",
      "    num_agent_steps_sampled: 952000\n",
      "    num_agent_steps_trained: 952000\n",
      "    num_steps_sampled: 952000\n",
      "    num_steps_trained: 952000\n",
      "  iterations_since_restore: 238\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.050000000000004\n",
      "    ram_util_percent: 68.03333333333333\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.075137370066784\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10776293435912869\n",
      "    mean_inference_ms: 0.526560788043966\n",
      "    mean_raw_obs_processing_ms: 0.050867014843420454\n",
      "  time_since_restore: 875.0438809394836\n",
      "  time_this_iter_s: 3.84354567527771\n",
      "  time_total_s: 875.0438809394836\n",
      "  timers:\n",
      "    learn_throughput: 1829.335\n",
      "    learn_time_ms: 2186.587\n",
      "    load_throughput: 4633694.037\n",
      "    load_time_ms: 0.863\n",
      "    sample_throughput: 2590.145\n",
      "    sample_time_ms: 1544.315\n",
      "    update_time_ms: 1.438\n",
      "  timestamp: 1629485934\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 952000\n",
      "  training_iteration: 238\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   238</td><td style=\"text-align: right;\">         875.044</td><td style=\"text-align: right;\">952000</td><td style=\"text-align: right;\">-432.343</td><td style=\"text-align: right;\">           -0.509603</td><td style=\"text-align: right;\">            -1703.64</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 960000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-01\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5096034328184365\n",
      "  episode_reward_mean: -515.9531829189144\n",
      "  episode_reward_min: -1762.3615926464388\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4800\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 3.0786020755767822\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012069487944245338\n",
      "          model: {}\n",
      "          policy_loss: -0.038057632744312286\n",
      "          total_loss: 6750.1220703125\n",
      "          vf_explained_var: 0.8567359447479248\n",
      "          vf_loss: 6750.138671875\n",
      "    num_agent_steps_sampled: 960000\n",
      "    num_agent_steps_trained: 960000\n",
      "    num_steps_sampled: 960000\n",
      "    num_steps_trained: 960000\n",
      "  iterations_since_restore: 240\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.339999999999996\n",
      "    ram_util_percent: 67.75999999999999\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07513501581623185\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10776851722715179\n",
      "    mean_inference_ms: 0.5265681278553648\n",
      "    mean_raw_obs_processing_ms: 0.05086960347899618\n",
      "  time_since_restore: 882.4591779708862\n",
      "  time_this_iter_s: 3.653186082839966\n",
      "  time_total_s: 882.4591779708862\n",
      "  timers:\n",
      "    learn_throughput: 1855.555\n",
      "    learn_time_ms: 2155.689\n",
      "    load_throughput: 4731841.155\n",
      "    load_time_ms: 0.845\n",
      "    sample_throughput: 2588.766\n",
      "    sample_time_ms: 1545.138\n",
      "    update_time_ms: 1.47\n",
      "  timestamp: 1629485941\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 960000\n",
      "  training_iteration: 240\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   240</td><td style=\"text-align: right;\">         882.459</td><td style=\"text-align: right;\">960000</td><td style=\"text-align: right;\">-515.953</td><td style=\"text-align: right;\">           -0.509603</td><td style=\"text-align: right;\">            -1762.36</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 968000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-09\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4859573968954919\n",
      "  episode_reward_mean: -501.6959145207246\n",
      "  episode_reward_min: -1787.3999017444694\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4840\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.5437878370285034\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011585949920117855\n",
      "          model: {}\n",
      "          policy_loss: -0.04287157952785492\n",
      "          total_loss: 2043.4444580078125\n",
      "          vf_explained_var: 0.9004544019699097\n",
      "          vf_loss: 2043.467529296875\n",
      "    num_agent_steps_sampled: 968000\n",
      "    num_agent_steps_trained: 968000\n",
      "    num_steps_sampled: 968000\n",
      "    num_steps_trained: 968000\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.38\n",
      "    ram_util_percent: 67.74000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0751273499220401\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10776554507142495\n",
      "    mean_inference_ms: 0.5265598528816514\n",
      "    mean_raw_obs_processing_ms: 0.05086794332483929\n",
      "  time_since_restore: 889.7342500686646\n",
      "  time_this_iter_s: 3.5736660957336426\n",
      "  time_total_s: 889.7342500686646\n",
      "  timers:\n",
      "    learn_throughput: 1850.933\n",
      "    learn_time_ms: 2161.073\n",
      "    load_throughput: 4776567.589\n",
      "    load_time_ms: 0.837\n",
      "    sample_throughput: 2586.744\n",
      "    sample_time_ms: 1546.345\n",
      "    update_time_ms: 1.474\n",
      "  timestamp: 1629485949\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 968000\n",
      "  training_iteration: 242\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   242</td><td style=\"text-align: right;\">         889.734</td><td style=\"text-align: right;\">968000</td><td style=\"text-align: right;\">-501.696</td><td style=\"text-align: right;\">           -0.485957</td><td style=\"text-align: right;\">             -1787.4</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 976000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-16\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.4859573968954919\n",
      "  episode_reward_mean: -524.0239088111454\n",
      "  episode_reward_min: -1787.3999017444694\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4880\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.698204278945923\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014877956360578537\n",
      "          model: {}\n",
      "          policy_loss: -0.04541883245110512\n",
      "          total_loss: 6345.044921875\n",
      "          vf_explained_var: 0.8227539658546448\n",
      "          vf_loss: 6345.06494140625\n",
      "    num_agent_steps_sampled: 976000\n",
      "    num_agent_steps_trained: 976000\n",
      "    num_steps_sampled: 976000\n",
      "    num_steps_trained: 976000\n",
      "  iterations_since_restore: 244\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.2\n",
      "    ram_util_percent: 67.8\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07511785259350388\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10775910140224243\n",
      "    mean_inference_ms: 0.5265370535172909\n",
      "    mean_raw_obs_processing_ms: 0.05086423255829826\n",
      "  time_since_restore: 897.0053458213806\n",
      "  time_this_iter_s: 3.580742835998535\n",
      "  time_total_s: 897.0053458213806\n",
      "  timers:\n",
      "    learn_throughput: 1854.452\n",
      "    learn_time_ms: 2156.971\n",
      "    load_throughput: 4717471.6\n",
      "    load_time_ms: 0.848\n",
      "    sample_throughput: 2585.755\n",
      "    sample_time_ms: 1546.937\n",
      "    update_time_ms: 1.49\n",
      "  timestamp: 1629485956\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 976000\n",
      "  training_iteration: 244\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   244</td><td style=\"text-align: right;\">         897.005</td><td style=\"text-align: right;\">976000</td><td style=\"text-align: right;\">-524.024</td><td style=\"text-align: right;\">           -0.485957</td><td style=\"text-align: right;\">             -1787.4</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 984000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-23\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.7765879538673393\n",
      "  episode_reward_mean: -450.4156897296482\n",
      "  episode_reward_min: -1768.1226138890452\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4920\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7089354991912842\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010718145407736301\n",
      "          model: {}\n",
      "          policy_loss: -0.04870002344250679\n",
      "          total_loss: 2852.10888671875\n",
      "          vf_explained_var: 0.859673023223877\n",
      "          vf_loss: 2852.139404296875\n",
      "    num_agent_steps_sampled: 984000\n",
      "    num_agent_steps_trained: 984000\n",
      "    num_steps_sampled: 984000\n",
      "    num_steps_trained: 984000\n",
      "  iterations_since_restore: 246\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.1\n",
      "    ram_util_percent: 67.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07509239649339192\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10773271816846922\n",
      "    mean_inference_ms: 0.5264346940025011\n",
      "    mean_raw_obs_processing_ms: 0.05084850686521069\n",
      "  time_since_restore: 904.1703455448151\n",
      "  time_this_iter_s: 3.5497288703918457\n",
      "  time_total_s: 904.1703455448151\n",
      "  timers:\n",
      "    learn_throughput: 1874.958\n",
      "    learn_time_ms: 2133.381\n",
      "    load_throughput: 4600152.45\n",
      "    load_time_ms: 0.87\n",
      "    sample_throughput: 2627.7\n",
      "    sample_time_ms: 1522.244\n",
      "    update_time_ms: 1.502\n",
      "  timestamp: 1629485963\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 984000\n",
      "  training_iteration: 246\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   246</td><td style=\"text-align: right;\">          904.17</td><td style=\"text-align: right;\">984000</td><td style=\"text-align: right;\">-450.416</td><td style=\"text-align: right;\">           -0.776588</td><td style=\"text-align: right;\">            -1768.12</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 992000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-30\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.7765879538673393\n",
      "  episode_reward_mean: -430.0051474475684\n",
      "  episode_reward_min: -1768.1226138890452\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4960\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.603823184967041\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0142340874299407\n",
      "          model: {}\n",
      "          policy_loss: -0.036697667092084885\n",
      "          total_loss: 5219.11474609375\n",
      "          vf_explained_var: 0.8730764985084534\n",
      "          vf_loss: 5219.1279296875\n",
      "    num_agent_steps_sampled: 992000\n",
      "    num_agent_steps_trained: 992000\n",
      "    num_steps_sampled: 992000\n",
      "    num_steps_trained: 992000\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.44\n",
      "    ram_util_percent: 67.38000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0750632933545619\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10770286419671227\n",
      "    mean_inference_ms: 0.5263058762150784\n",
      "    mean_raw_obs_processing_ms: 0.05083243712697413\n",
      "  time_since_restore: 911.3735752105713\n",
      "  time_this_iter_s: 3.594831705093384\n",
      "  time_total_s: 911.3735752105713\n",
      "  timers:\n",
      "    learn_throughput: 1899.807\n",
      "    learn_time_ms: 2105.477\n",
      "    load_throughput: 4414940.659\n",
      "    load_time_ms: 0.906\n",
      "    sample_throughput: 2629.853\n",
      "    sample_time_ms: 1520.997\n",
      "    update_time_ms: 1.481\n",
      "  timestamp: 1629485970\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 992000\n",
      "  training_iteration: 248\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   248</td><td style=\"text-align: right;\">         911.374</td><td style=\"text-align: right;\">992000</td><td style=\"text-align: right;\">-430.005</td><td style=\"text-align: right;\">           -0.776588</td><td style=\"text-align: right;\">            -1768.12</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1000000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-38\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1.092416319749448\n",
      "  episode_reward_mean: -396.68472084803636\n",
      "  episode_reward_min: -1706.1045476478896\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5000\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7113450765609741\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012752948328852654\n",
      "          model: {}\n",
      "          policy_loss: -0.0448153093457222\n",
      "          total_loss: 2837.4404296875\n",
      "          vf_explained_var: 0.8846222162246704\n",
      "          vf_loss: 2837.46337890625\n",
      "    num_agent_steps_sampled: 1000000\n",
      "    num_agent_steps_trained: 1000000\n",
      "    num_steps_sampled: 1000000\n",
      "    num_steps_trained: 1000000\n",
      "  iterations_since_restore: 250\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.98333333333333\n",
      "    ram_util_percent: 67.43333333333334\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0750558009113478\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10770014851078409\n",
      "    mean_inference_ms: 0.5263101733720836\n",
      "    mean_raw_obs_processing_ms: 0.05083429310174261\n",
      "  time_since_restore: 918.9597401618958\n",
      "  time_this_iter_s: 3.77091383934021\n",
      "  time_total_s: 918.9597401618958\n",
      "  timers:\n",
      "    learn_throughput: 1900.876\n",
      "    learn_time_ms: 2104.293\n",
      "    load_throughput: 4393896.76\n",
      "    load_time_ms: 0.91\n",
      "    sample_throughput: 2598.414\n",
      "    sample_time_ms: 1539.401\n",
      "    update_time_ms: 1.451\n",
      "  timestamp: 1629485978\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1000000\n",
      "  training_iteration: 250\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">          918.96</td><td style=\"text-align: right;\">1000000</td><td style=\"text-align: right;\">-396.685</td><td style=\"text-align: right;\">            -1.09242</td><td style=\"text-align: right;\">             -1706.1</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1008000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-45\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5779007219262546\n",
      "  episode_reward_mean: -466.3055574845304\n",
      "  episode_reward_min: -1723.9865976156811\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5040\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 3.512138605117798\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012688427232205868\n",
      "          model: {}\n",
      "          policy_loss: -0.040724992752075195\n",
      "          total_loss: 10429.962890625\n",
      "          vf_explained_var: 0.8005675077438354\n",
      "          vf_loss: 10429.98046875\n",
      "    num_agent_steps_sampled: 1008000\n",
      "    num_agent_steps_trained: 1008000\n",
      "    num_steps_sampled: 1008000\n",
      "    num_steps_trained: 1008000\n",
      "  iterations_since_restore: 252\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.839999999999996\n",
      "    ram_util_percent: 67.42\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0750627366537666\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10771259404660133\n",
      "    mean_inference_ms: 0.5263956410148044\n",
      "    mean_raw_obs_processing_ms: 0.050844161256603716\n",
      "  time_since_restore: 926.2322890758514\n",
      "  time_this_iter_s: 3.667091131210327\n",
      "  time_total_s: 926.2322890758514\n",
      "  timers:\n",
      "    learn_throughput: 1902.682\n",
      "    learn_time_ms: 2102.296\n",
      "    load_throughput: 4409023.442\n",
      "    load_time_ms: 0.907\n",
      "    sample_throughput: 2595.447\n",
      "    sample_time_ms: 1541.16\n",
      "    update_time_ms: 1.451\n",
      "  timestamp: 1629485985\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1008000\n",
      "  training_iteration: 252\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   252</td><td style=\"text-align: right;\">         926.232</td><td style=\"text-align: right;\">1008000</td><td style=\"text-align: right;\">-466.306</td><td style=\"text-align: right;\">           -0.577901</td><td style=\"text-align: right;\">            -1723.99</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1016000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_13-59-52\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.5779007219262546\n",
      "  episode_reward_mean: -393.8844554679835\n",
      "  episode_reward_min: -1809.4552244633817\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5080\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.0873383283615112\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01715308614075184\n",
      "          model: {}\n",
      "          policy_loss: -0.047008391469717026\n",
      "          total_loss: 846.0406494140625\n",
      "          vf_explained_var: 0.890026330947876\n",
      "          vf_loss: 846.0584716796875\n",
      "    num_agent_steps_sampled: 1016000\n",
      "    num_agent_steps_trained: 1016000\n",
      "    num_steps_sampled: 1016000\n",
      "    num_steps_trained: 1016000\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.739999999999995\n",
      "    ram_util_percent: 67.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07506269491284401\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10771635834032853\n",
      "    mean_inference_ms: 0.5264461417090909\n",
      "    mean_raw_obs_processing_ms: 0.05084672528400458\n",
      "  time_since_restore: 933.4089510440826\n",
      "  time_this_iter_s: 3.57391095161438\n",
      "  time_total_s: 933.4089510440826\n",
      "  timers:\n",
      "    learn_throughput: 1908.394\n",
      "    learn_time_ms: 2096.003\n",
      "    load_throughput: 4431031.878\n",
      "    load_time_ms: 0.903\n",
      "    sample_throughput: 2601.038\n",
      "    sample_time_ms: 1537.848\n",
      "    update_time_ms: 1.495\n",
      "  timestamp: 1629485992\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1016000\n",
      "  training_iteration: 254\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   254</td><td style=\"text-align: right;\">         933.409</td><td style=\"text-align: right;\">1016000</td><td style=\"text-align: right;\">-393.884</td><td style=\"text-align: right;\">           -0.577901</td><td style=\"text-align: right;\">            -1809.46</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1024000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-00\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.61433177417204\n",
      "  episode_reward_mean: -466.3821209909292\n",
      "  episode_reward_min: -1809.4552244633817\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5120\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 3.335404872894287\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013441285118460655\n",
      "          model: {}\n",
      "          policy_loss: -0.04106750711798668\n",
      "          total_loss: 8219.513671875\n",
      "          vf_explained_var: 0.8317705392837524\n",
      "          vf_loss: 8219.5302734375\n",
      "    num_agent_steps_sampled: 1024000\n",
      "    num_agent_steps_trained: 1024000\n",
      "    num_steps_sampled: 1024000\n",
      "    num_steps_trained: 1024000\n",
      "  iterations_since_restore: 256\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.160000000000004\n",
      "    ram_util_percent: 67.96000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07504224258727954\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10769539111706429\n",
      "    mean_inference_ms: 0.5263742113259754\n",
      "    mean_raw_obs_processing_ms: 0.05083409257896209\n",
      "  time_since_restore: 940.7449221611023\n",
      "  time_this_iter_s: 3.624652147293091\n",
      "  time_total_s: 940.7449221611023\n",
      "  timers:\n",
      "    learn_throughput: 1896.622\n",
      "    learn_time_ms: 2109.013\n",
      "    load_throughput: 4331728.073\n",
      "    load_time_ms: 0.923\n",
      "    sample_throughput: 2594.228\n",
      "    sample_time_ms: 1541.885\n",
      "    update_time_ms: 1.483\n",
      "  timestamp: 1629486000\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1024000\n",
      "  training_iteration: 256\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   256</td><td style=\"text-align: right;\">         940.745</td><td style=\"text-align: right;\">1024000</td><td style=\"text-align: right;\">-466.382</td><td style=\"text-align: right;\">           -0.614332</td><td style=\"text-align: right;\">            -1809.46</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1032000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-07\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6232579943524839\n",
      "  episode_reward_mean: -407.82636247461824\n",
      "  episode_reward_min: -1686.5901611801767\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5160\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.2298680543899536\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01479250006377697\n",
      "          model: {}\n",
      "          policy_loss: -0.05663120001554489\n",
      "          total_loss: 975.8499145507812\n",
      "          vf_explained_var: 0.9187660813331604\n",
      "          vf_loss: 975.881103515625\n",
      "    num_agent_steps_sampled: 1032000\n",
      "    num_agent_steps_trained: 1032000\n",
      "    num_steps_sampled: 1032000\n",
      "    num_steps_trained: 1032000\n",
      "  iterations_since_restore: 258\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.4\n",
      "    ram_util_percent: 67.8\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07501606530148314\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10766749605424743\n",
      "    mean_inference_ms: 0.5262621143725265\n",
      "    mean_raw_obs_processing_ms: 0.05081788488844202\n",
      "  time_since_restore: 947.9334650039673\n",
      "  time_this_iter_s: 3.570841073989868\n",
      "  time_total_s: 947.9334650039673\n",
      "  timers:\n",
      "    learn_throughput: 1896.816\n",
      "    learn_time_ms: 2108.797\n",
      "    load_throughput: 4479179.838\n",
      "    load_time_ms: 0.893\n",
      "    sample_throughput: 2596.293\n",
      "    sample_time_ms: 1540.658\n",
      "    update_time_ms: 1.513\n",
      "  timestamp: 1629486007\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1032000\n",
      "  training_iteration: 258\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   258</td><td style=\"text-align: right;\">         947.933</td><td style=\"text-align: right;\">1032000</td><td style=\"text-align: right;\">-407.826</td><td style=\"text-align: right;\">           -0.623258</td><td style=\"text-align: right;\">            -1686.59</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1040000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-14\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6232579943524839\n",
      "  episode_reward_mean: -464.01890505078796\n",
      "  episode_reward_min: -1702.6667837847099\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5200\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.133274555206299\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01258645486086607\n",
      "          model: {}\n",
      "          policy_loss: -0.05053875222802162\n",
      "          total_loss: 3443.409423828125\n",
      "          vf_explained_var: 0.8844317197799683\n",
      "          vf_loss: 3443.438720703125\n",
      "    num_agent_steps_sampled: 1040000\n",
      "    num_agent_steps_trained: 1040000\n",
      "    num_steps_sampled: 1040000\n",
      "    num_steps_trained: 1040000\n",
      "  iterations_since_restore: 260\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.379999999999995\n",
      "    ram_util_percent: 67.58\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07499226774233915\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10764098424609234\n",
      "    mean_inference_ms: 0.5261639199375167\n",
      "    mean_raw_obs_processing_ms: 0.050802474261997015\n",
      "  time_since_restore: 955.1431007385254\n",
      "  time_this_iter_s: 3.587496042251587\n",
      "  time_total_s: 955.1431007385254\n",
      "  timers:\n",
      "    learn_throughput: 1902.389\n",
      "    learn_time_ms: 2102.619\n",
      "    load_throughput: 4404856.123\n",
      "    load_time_ms: 0.908\n",
      "    sample_throughput: 2650.49\n",
      "    sample_time_ms: 1509.155\n",
      "    update_time_ms: 1.512\n",
      "  timestamp: 1629486014\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1040000\n",
      "  training_iteration: 260\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   260</td><td style=\"text-align: right;\">         955.143</td><td style=\"text-align: right;\">1040000</td><td style=\"text-align: right;\">-464.019</td><td style=\"text-align: right;\">           -0.623258</td><td style=\"text-align: right;\">            -1702.67</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1048000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-22\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6232579943524839\n",
      "  episode_reward_mean: -498.35048864562646\n",
      "  episode_reward_min: -1755.306085904107\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5240\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 3.6932573318481445\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010512660257518291\n",
      "          model: {}\n",
      "          policy_loss: -0.03120679222047329\n",
      "          total_loss: 8192.8134765625\n",
      "          vf_explained_var: 0.844706654548645\n",
      "          vf_loss: 8192.8271484375\n",
      "    num_agent_steps_sampled: 1048000\n",
      "    num_agent_steps_trained: 1048000\n",
      "    num_steps_sampled: 1048000\n",
      "    num_steps_trained: 1048000\n",
      "  iterations_since_restore: 262\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.220000000000006\n",
      "    ram_util_percent: 67.64000000000001\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07496849162925798\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10761425209762518\n",
      "    mean_inference_ms: 0.5260680798736609\n",
      "    mean_raw_obs_processing_ms: 0.050787846409628426\n",
      "  time_since_restore: 962.3164956569672\n",
      "  time_this_iter_s: 3.567342758178711\n",
      "  time_total_s: 962.3164956569672\n",
      "  timers:\n",
      "    learn_throughput: 1904.866\n",
      "    learn_time_ms: 2099.885\n",
      "    load_throughput: 4399773.419\n",
      "    load_time_ms: 0.909\n",
      "    sample_throughput: 2663.119\n",
      "    sample_time_ms: 1501.998\n",
      "    update_time_ms: 1.513\n",
      "  timestamp: 1629486022\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1048000\n",
      "  training_iteration: 262\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   262</td><td style=\"text-align: right;\">         962.316</td><td style=\"text-align: right;\">1048000</td><td style=\"text-align: right;\"> -498.35</td><td style=\"text-align: right;\">           -0.623258</td><td style=\"text-align: right;\">            -1755.31</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1056000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-29\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.9537147784149033\n",
      "  episode_reward_mean: -493.63796579181917\n",
      "  episode_reward_min: -1755.306085904107\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5280\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.612837314605713\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012716633267700672\n",
      "          model: {}\n",
      "          policy_loss: -0.050649166107177734\n",
      "          total_loss: 1520.16259765625\n",
      "          vf_explained_var: 0.9075784087181091\n",
      "          vf_loss: 1520.19140625\n",
      "    num_agent_steps_sampled: 1056000\n",
      "    num_agent_steps_trained: 1056000\n",
      "    num_steps_sampled: 1056000\n",
      "    num_steps_trained: 1056000\n",
      "  iterations_since_restore: 264\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.94\n",
      "    ram_util_percent: 67.7\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07494685900597932\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10759360150069806\n",
      "    mean_inference_ms: 0.5259706772581663\n",
      "    mean_raw_obs_processing_ms: 0.05077733971758883\n",
      "  time_since_restore: 969.6620454788208\n",
      "  time_this_iter_s: 3.6351449489593506\n",
      "  time_total_s: 969.6620454788208\n",
      "  timers:\n",
      "    learn_throughput: 1893.989\n",
      "    learn_time_ms: 2111.944\n",
      "    load_throughput: 4274232.141\n",
      "    load_time_ms: 0.936\n",
      "    sample_throughput: 2654.385\n",
      "    sample_time_ms: 1506.94\n",
      "    update_time_ms: 1.471\n",
      "  timestamp: 1629486029\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1056000\n",
      "  training_iteration: 264\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   264</td><td style=\"text-align: right;\">         969.662</td><td style=\"text-align: right;\">1056000</td><td style=\"text-align: right;\">-493.638</td><td style=\"text-align: right;\">           -0.953715</td><td style=\"text-align: right;\">            -1755.31</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1064000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-36\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.9537147784149033\n",
      "  episode_reward_mean: -506.02697679994066\n",
      "  episode_reward_min: -1755.306085904107\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5320\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.7848691940307617\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014444910921156406\n",
      "          model: {}\n",
      "          policy_loss: -0.05225640907883644\n",
      "          total_loss: 5243.88232421875\n",
      "          vf_explained_var: 0.8463694453239441\n",
      "          vf_loss: 5243.90966796875\n",
      "    num_agent_steps_sampled: 1064000\n",
      "    num_agent_steps_trained: 1064000\n",
      "    num_steps_sampled: 1064000\n",
      "    num_steps_trained: 1064000\n",
      "  iterations_since_restore: 266\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.78\n",
      "    ram_util_percent: 67.5\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07492615889032031\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10757553309810385\n",
      "    mean_inference_ms: 0.5258678275318036\n",
      "    mean_raw_obs_processing_ms: 0.0507683871692136\n",
      "  time_since_restore: 976.9050805568695\n",
      "  time_this_iter_s: 3.57395601272583\n",
      "  time_total_s: 976.9050805568695\n",
      "  timers:\n",
      "    learn_throughput: 1901.377\n",
      "    learn_time_ms: 2103.739\n",
      "    load_throughput: 4406475.81\n",
      "    load_time_ms: 0.908\n",
      "    sample_throughput: 2656.063\n",
      "    sample_time_ms: 1505.989\n",
      "    update_time_ms: 1.484\n",
      "  timestamp: 1629486036\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1064000\n",
      "  training_iteration: 266\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   266</td><td style=\"text-align: right;\">         976.905</td><td style=\"text-align: right;\">1064000</td><td style=\"text-align: right;\">-506.027</td><td style=\"text-align: right;\">           -0.953715</td><td style=\"text-align: right;\">            -1755.31</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1072000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-43\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1.0629856956420398\n",
      "  episode_reward_mean: -483.6264358865987\n",
      "  episode_reward_min: -1752.2636166669397\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5360\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.802149772644043\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014132510870695114\n",
      "          model: {}\n",
      "          policy_loss: -0.050237905234098434\n",
      "          total_loss: 3773.263671875\n",
      "          vf_explained_var: 0.8956251740455627\n",
      "          vf_loss: 3773.289794921875\n",
      "    num_agent_steps_sampled: 1072000\n",
      "    num_agent_steps_trained: 1072000\n",
      "    num_steps_sampled: 1072000\n",
      "    num_steps_trained: 1072000\n",
      "  iterations_since_restore: 268\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.840000000000003\n",
      "    ram_util_percent: 67.72\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0749046273171237\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10755687083657012\n",
      "    mean_inference_ms: 0.5257678304961175\n",
      "    mean_raw_obs_processing_ms: 0.050758775498413594\n",
      "  time_since_restore: 984.0970394611359\n",
      "  time_this_iter_s: 3.5646541118621826\n",
      "  time_total_s: 984.0970394611359\n",
      "  timers:\n",
      "    learn_throughput: 1900.418\n",
      "    learn_time_ms: 2104.8\n",
      "    load_throughput: 4391021.776\n",
      "    load_time_ms: 0.911\n",
      "    sample_throughput: 2657.109\n",
      "    sample_time_ms: 1505.395\n",
      "    update_time_ms: 1.456\n",
      "  timestamp: 1629486043\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1072000\n",
      "  training_iteration: 268\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   268</td><td style=\"text-align: right;\">         984.097</td><td style=\"text-align: right;\">1072000</td><td style=\"text-align: right;\">-483.626</td><td style=\"text-align: right;\">            -1.06299</td><td style=\"text-align: right;\">            -1752.26</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1080000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-51\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6094119017273052\n",
      "  episode_reward_mean: -537.0676206809925\n",
      "  episode_reward_min: -1752.2636166669397\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5400\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 2.9378278255462646\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016696639358997345\n",
      "          model: {}\n",
      "          policy_loss: -0.052778713405132294\n",
      "          total_loss: 5848.787109375\n",
      "          vf_explained_var: 0.862409234046936\n",
      "          vf_loss: 5848.81201171875\n",
      "    num_agent_steps_sampled: 1080000\n",
      "    num_agent_steps_trained: 1080000\n",
      "    num_steps_sampled: 1080000\n",
      "    num_steps_trained: 1080000\n",
      "  iterations_since_restore: 270\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.739999999999995\n",
      "    ram_util_percent: 67.6\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07487945947118685\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10753224223318966\n",
      "    mean_inference_ms: 0.5256486050202964\n",
      "    mean_raw_obs_processing_ms: 0.050744744708771765\n",
      "  time_since_restore: 991.3526384830475\n",
      "  time_this_iter_s: 3.666236162185669\n",
      "  time_total_s: 991.3526384830475\n",
      "  timers:\n",
      "    learn_throughput: 1893.454\n",
      "    learn_time_ms: 2112.542\n",
      "    load_throughput: 4527530.225\n",
      "    load_time_ms: 0.883\n",
      "    sample_throughput: 2662.421\n",
      "    sample_time_ms: 1502.392\n",
      "    update_time_ms: 1.442\n",
      "  timestamp: 1629486051\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1080000\n",
      "  training_iteration: 270\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   270</td><td style=\"text-align: right;\">         991.353</td><td style=\"text-align: right;\">1080000</td><td style=\"text-align: right;\">-537.068</td><td style=\"text-align: right;\">           -0.609412</td><td style=\"text-align: right;\">            -1752.26</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_Pendulum-v0_94afa_00000:\n",
      "  agent_timesteps_total: 1088000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-08-20_14-00-59\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.6094119017273052\n",
      "  episode_reward_mean: -522.4562899511418\n",
      "  episode_reward_min: -1752.2636166669397\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5440\n",
      "  experiment_id: fa433538c43746d38e14cd583a10b5fe\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.708593726158142\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 1.7577109336853027\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01734042726457119\n",
      "          model: {}\n",
      "          policy_loss: -0.0588061697781086\n",
      "          total_loss: 802.9971923828125\n",
      "          vf_explained_var: 0.9539178609848022\n",
      "          vf_loss: 803.0264282226562\n",
      "    num_agent_steps_sampled: 1088000\n",
      "    num_agent_steps_trained: 1088000\n",
      "    num_steps_sampled: 1088000\n",
      "    num_steps_trained: 1088000\n",
      "  iterations_since_restore: 272\n",
      "  node_ip: 192.168.0.32\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.43333333333334\n",
      "    ram_util_percent: 67.71666666666667\n",
      "  pid: 58394\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07487785146935268\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1075366359631122\n",
      "    mean_inference_ms: 0.525666562135165\n",
      "    mean_raw_obs_processing_ms: 0.050750407922755654\n",
      "  time_since_restore: 999.4016525745392\n",
      "  time_this_iter_s: 3.85932993888855\n",
      "  time_total_s: 999.4016525745392\n",
      "  timers:\n",
      "    learn_throughput: 1847.999\n",
      "    learn_time_ms: 2164.504\n",
      "    load_throughput: 4276411.093\n",
      "    load_time_ms: 0.935\n",
      "    sample_throughput: 2600.903\n",
      "    sample_time_ms: 1537.927\n",
      "    update_time_ms: 1.435\n",
      "  timestamp: 1629486059\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1088000\n",
      "  training_iteration: 272\n",
      "  trial_id: 94afa_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   272</td><td style=\"text-align: right;\">         999.402</td><td style=\"text-align: right;\">1088000</td><td style=\"text-align: right;\">-522.456</td><td style=\"text-align: right;\">           -0.609412</td><td style=\"text-align: right;\">            -1752.26</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 14:01:01,770\tWARNING tune.py:507 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/4.58 GiB heap, 0.0/2.29 GiB objects (0.0/3.0 CPU_group_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_1_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_0_83df6dab55d351aba6c73e0380835aa8, 0.0/1.0 CPU_group_2_83df6dab55d351aba6c73e0380835aa8)<br>Result logdir: /Users/mingjunwang/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_Pendulum-v0_94afa_00000</td><td>RUNNING </td><td>192.168.0.32:58394</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   273</td><td style=\"text-align: right;\">         1003.27</td><td style=\"text-align: right;\">1092000</td><td style=\"text-align: right;\"> -527.75</td><td style=\"text-align: right;\">           -0.609412</td><td style=\"text-align: right;\">            -1742.39</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m 2021-08-20 14:01:03,210\tERROR worker.py:421 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 632, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 486, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 523, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 530, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/_private/function_manager.py\", line 563, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     return next(self.local_it)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 338, in gen_rollouts\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     yield self.sample()\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 739, in sample\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     batches = [self.input_reader.next()]\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 101, in next\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     batches = [self.get_data()]\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 231, in get_data\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     item = next(self.rollout_provider)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 624, in _env_runner\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     eval_results = _do_policy_eval(\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 1031, in _do_policy_eval\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     policy.compute_actions_from_input_dict(\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/policy/tf_policy.py\", line 387, in compute_actions_from_input_dict\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     fetched = builder.get(to_fetch)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/utils/tf_run_builder.py\", line 42, in get\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     self._executed = run_timeline(\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/utils/tf_run_builder.py\", line 89, in run_timeline\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1175, in _run\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     fetch_handler = _FetchHandler(\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 487, in __init__\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     self._fetch_mapper = _FetchMapper.for_fetch(fetches)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/contextlib.py\", line 124, in __exit__\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     next(self.gen)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 5619, in get_controller\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     yield g\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/contextlib.py\", line 124, in __exit__\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     next(self.gen)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 5427, in get_controller\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     if self._enforce_nesting:\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/worker.py\", line 418, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=58393)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m 2021-08-20 14:01:03,208\tERROR worker.py:421 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"python/ray/_raylet.pyx\", line 632, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"python/ray/_raylet.pyx\", line 486, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"python/ray/_raylet.pyx\", line 523, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"python/ray/_raylet.pyx\", line 530, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/_private/function_manager.py\", line 563, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     return next(self.local_it)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 338, in gen_rollouts\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     yield self.sample()\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 739, in sample\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     batches = [self.input_reader.next()]\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 101, in next\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     batches = [self.get_data()]\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 231, in get_data\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     item = next(self.rollout_provider)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 624, in _env_runner\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     eval_results = _do_policy_eval(\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 1031, in _do_policy_eval\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     policy.compute_actions_from_input_dict(\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/policy/tf_policy.py\", line 387, in compute_actions_from_input_dict\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     fetched = builder.get(to_fetch)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/utils/tf_run_builder.py\", line 42, in get\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     self._executed = run_timeline(\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/utils/tf_run_builder.py\", line 89, in run_timeline\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1130, in _run\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     subfeed_t = self.graph.as_graph_element(\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3755, in as_graph_element\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3775, in _as_graph_element_locked\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     temp_obj = _as_graph_element(obj)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 206, in _as_graph_element\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     conv_fn = getattr(obj, \"_as_graph_element\", None)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 392, in __getattr__\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     def __getattr__(self, name):\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/worker.py\", line 418, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=58392)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m 2021-08-20 14:01:03,271\tERROR worker.py:421 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 632, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 486, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 523, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 530, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/_private/function_manager.py\", line 563, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/tune/trainable.py\", line 178, in train_buffered\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     result = self.train()\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/agents/trainer.py\", line 629, in train\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     result = Trainable.train(self)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/tune/trainable.py\", line 237, in train\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     result = self.step()\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/rllib/agents/trainer_template.py\", line 170, in step\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     res = next(self.train_exec_impl)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 756, in __next__\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     return next(self.built_iterator)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   [Previous line repeated 1 more time]\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 876, in apply_flatten\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 828, in add_wait_hooks\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     item = next(it)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   [Previous line repeated 1 more time]\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/util/iter.py\", line 471, in base_iterator\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     yield ray.get(futures, timeout=timeout)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 82, in wrapper\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/worker.py\", line 1557, in get\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     values, debugger_breakpoint = worker.get_objects(\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/worker.py\", line 340, in get_objects\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     data_metadata_pairs = self.core_worker.get_objects(\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m   File \"/opt/miniconda3/envs/env39/lib/python3.9/site-packages/ray/worker.py\", line 418, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=58394)\u001b[0m SystemExit: 1\n",
      "2021-08-20 14:01:03,404\tERROR tune.py:546 -- Trials did not complete: [PPO_Pendulum-v0_94afa_00000]\n",
      "2021-08-20 14:01:03,405\tINFO tune.py:550 -- Total run time: 1024.38 seconds (1024.07 seconds for the tuning loop).\n",
      "2021-08-20 14:01:03,405\tWARNING tune.py:554 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7fec26194550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg = 'PPO'\n",
    "tune.run(alg,\n",
    "    stop={\"training_iteration\": 300},\n",
    "    config={\n",
    "        'env':'Pendulum-v0',\n",
    "        'num_gpus':0,\n",
    "        'num_workers':2,\n",
    "        'lr':tune.grid_search([.001,])     \n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
