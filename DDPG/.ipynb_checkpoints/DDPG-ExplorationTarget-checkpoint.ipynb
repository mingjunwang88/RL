{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_state:  2\n",
      "dim_action:  1\n",
      "action sample:  [0.39876872]\n",
      "...saving check point...\n",
      "...save checkout...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as f\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "#import gym_cartpole_swingup  #pip install gym_cartpole_swingup\n",
    "\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "###################################################\n",
    "# Deep Deterministic Policy Gradient\n",
    "###################################################\n",
    "\n",
    "class Noise():\n",
    "    def __init__(self,mu,sigma=0.15,theta=0.2,dt=1e-2,x0=None):\n",
    "        self.theta = theta\n",
    "        self.mu=mu\n",
    "        self.sigma = sigma\n",
    "        self.dt=dt\n",
    "        self.x0=x0\n",
    "        self.reset()\n",
    "    \n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
    "        self.sigma * np.sqrt(self.dt)*np.random.normal(size=self.mu.shape)\n",
    "        self.prev = x\n",
    "        return x\n",
    "    \n",
    "    def reset(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\n",
    "        \n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, dim_state, dim_action, fc1, fc2, alpha, min_action, max_action, checkpoint='actor_ddpg_v2' ):\n",
    "        super(Actor, self).__init__()\n",
    "        self.dim_state = dim_state\n",
    "        self.dim_action = dim_action\n",
    "        self.min_action = min_action\n",
    "        self.max_action = max_action\n",
    "        \n",
    "        self.linear1 = nn.Linear(dim_state, fc1)\n",
    "        self.linear2 = nn.Linear(fc1, fc2)\n",
    "        self.linear3 = nn.Linear(fc2, dim_action)\n",
    "        \n",
    "        self.device = t.device('cpu' if t.cuda.is_available() else 'cpu')\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha, weight_decay=1e-4)\n",
    "        self.to(self.device)\n",
    "        self.path = checkpoint\n",
    "        \n",
    "    def forward(self, state):\n",
    "        output = state.to(self.device)\n",
    "        \n",
    "        output = f.relu(self.linear1(output))\n",
    "        output = f.relu(self.linear2(output))\n",
    "        #output = t.tanh(self.linear3(output)) * self.max_action\n",
    "        output = t.clamp(self.linear3(output), self.min_action, self.max_action)\n",
    "        return output\n",
    "    \n",
    "    def saveCheckpoint(self):\n",
    "        print ('...saving check point...')\n",
    "        t.save(self.state_dict(), self.path)\n",
    "    \n",
    "    def loadCheckpoint(self):\n",
    "        print('...loading check point')\n",
    "        self.load_state_dict(t.load(self.path))\n",
    "    \n",
    "class Critic(nn.Module):   \n",
    "    def __init__(self, dim_state, dim_action, fc1, fc2, alpha,checkpoint='critic_ddpg_v2'):\n",
    "        super(Critic, self).__init__()\n",
    "        self.dim_state = dim_state\n",
    "        self.dim_action = dim_action\n",
    "        self.path = checkpoint\n",
    "        \n",
    "        self.linear1 = nn.Linear(dim_state+ dim_action, fc1)\n",
    "        #self.linear2 = nn.Linear(fc1, fc2)\n",
    "        self.linear3 = nn.Linear(fc1,1)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr = alpha, weight_decay=1e-4)\n",
    "        self.device = t.device('cpu' if t.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        state = state.to(self.device)\n",
    "        action = action.to(self.device)\n",
    "        \n",
    "        output = t.relu(self.linear1(t.cat((state, action), dim=1)))\n",
    "        #output = t.relu(self.linear2(output))\n",
    "        output = self.linear3(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def saveCheckpoint(self):\n",
    "        print('...save checkout...')\n",
    "        t.save(self.state_dict(), self.path)\n",
    "    \n",
    "    def loadCheckpoint(self):\n",
    "        print ('...load checj point...')\n",
    "        self.load_state_dict(t.load(self.path))\n",
    "        \n",
    "        \n",
    "class replayBuffer():\n",
    "    def __init__(self, maxm_size, dim_state, dim_action):\n",
    "        self.counter = 0\n",
    "        self.state_mem = np.zeros((maxm_size, dim_state))\n",
    "        self.action_mem = np.zeros((maxm_size, dim_action))\n",
    "        self.reward_mem = np.zeros(maxm_size)\n",
    "        self.state_new_mem = np.zeros((maxm_size, dim_state))\n",
    "        self.done_mem = np.zeros(maxm_size)\n",
    "        self.maxm_size = maxm_size\n",
    "        \n",
    "    def store_Transaction(self, state, action, reward, state_new, done):\n",
    "        index = self.counter % self.maxm_size\n",
    "        \n",
    "        self.state_mem[index] = state\n",
    "        self.action_mem[index] = action\n",
    "        self.reward_mem[index] = reward\n",
    "        self.state_new_mem[index] =state_new\n",
    "        self.done_mem[index] = 1.0 - done\n",
    "        \n",
    "        self.counter+=1\n",
    "    \n",
    "    def sample_batch(self, batch_size=64):\n",
    "        maxm_size = min(self.counter, self.maxm_size)\n",
    "        batch = np.random.choice(maxm_size, batch_size)\n",
    "        \n",
    "        state_batch = self.state_mem[batch]\n",
    "        action_batch = self.action_mem[batch]\n",
    "        reward_batch = self.reward_mem[batch]\n",
    "        state_new_batch = self.state_new_mem[batch]\n",
    "        done_batch = self.done_mem[batch]\n",
    "        \n",
    "        return state_batch, action_batch,reward_batch,state_new_batch,done_batch\n",
    "        \n",
    "    \n",
    "class Agent():\n",
    "    def __init__(self, env, dim_state, dim_action, fc1, fc2, alpha, gamma,min_action, max_action, maxm_size, maxm_iters=50, batch_size=64):\n",
    "        self.dim_state = dim_state\n",
    "        self.dim_action = dim_action\n",
    "        self.maxm_iters = maxm_iters\n",
    "        self.device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.actor=Actor(dim_state, dim_action, fc1, fc2, alpha, min_action, max_action, checkpoint='actor').to(self.device)\n",
    "        self.critic=Critic(dim_state, dim_action, fc1, fc2, alpha,checkpoint='critic').to(self.device)\n",
    "        self.tau = 0.005\n",
    "\n",
    "        #Initilize the target networks           \n",
    "        self.actor_t = Actor(dim_state, dim_action, fc1, fc2, alpha, min_action, max_action, checkpoint='actor').to(self.device)\n",
    "        self.actor_t.load_state_dict(self.actor.state_dict())\n",
    "        \n",
    "        self.critic_t = Critic(dim_state, dim_action, fc1, fc2, alpha,checkpoint='critic').to(self.device)\n",
    "        self.critic_t.load_state_dict(self.critic.state_dict())\n",
    "        \n",
    "        self.buffer = replayBuffer(maxm_size, dim_state, dim_action) # maxm_size, dim_state, dim_action):\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size   \n",
    "        self.noise = Noise(mu=np.zeros(dim_action))\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.env = env\n",
    "        \n",
    "        \n",
    "    def plot_learning_curve(self,x, scores, figure_file='test'):\n",
    "        running_avg = np.zeros(len(scores))\n",
    "        for i in range(len(running_avg)):\n",
    "            running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
    "        plt.plot(x, running_avg)\n",
    "        #plt.title('Running average of previous 100 scores')\n",
    "        plt.savefig('ddpg_v2.png')\n",
    "        \n",
    "    def update_parms(self):\n",
    "        \n",
    "        critic_dict = dict(self.critic_t.named_parameters())\n",
    "        critic_t_dict = dict(self.critic.named_parameters())\n",
    "        \n",
    "        actor_t_dict = dict(self.actor_t.named_parameters())\n",
    "        actor_dict = dict(self.actor.named_parameters())\n",
    "        \n",
    "        #Update the critic\n",
    "        for i in critic_dict:\n",
    "            critic_dict[i] = self.tau*critic_dict[i].clone() + (1-self.tau)*critic_t_dict[i].clone()\n",
    "        self.critic_t.load_state_dict(critic_dict)\n",
    "        \n",
    "        #Update the actor\n",
    "        for j in actor_dict:\n",
    "            actor_dict[j] = self.tau*actor_dict[j].clone() + (1-self.tau)*actor_t_dict[j].clone()\n",
    "        self.actor_t.load_state_dict(actor_dict)\n",
    "           \n",
    "    def learn(self):\n",
    "\n",
    "        reward_list = []  \n",
    "        reward_list_n= []\n",
    "        n=0\n",
    "           \n",
    "        for i in range(self.maxm_iters):\n",
    "            self.noise.reset()\n",
    "            \n",
    "            done= False\n",
    "            state = self.env.reset()       \n",
    "            total_reward= 0\n",
    "            \n",
    "            while not done:   \n",
    "                n+=1\n",
    "                self.critic.train()\n",
    "                self.actor.train()\n",
    "                \n",
    "                self.critic.optimizer.zero_grad()\n",
    "                self.actor.optimizer.zero_grad()\n",
    "                \n",
    "                action = self.actor(t.tensor(state).float().to(self.device)).cpu().detach().numpy() + self.noise()\n",
    "                if n % 200 == 0:\n",
    "                    #print(f'action {n}: ', action)\n",
    "                    pass\n",
    "\n",
    "                state_new, reward, done, _ = self.env.step(action)\n",
    "                reward_list_n.append(reward)\n",
    "                total_reward+=reward\n",
    "        \n",
    "                self.buffer.store_Transaction(state, action, reward, state_new, done)\n",
    "\n",
    "                if self.buffer.counter >= self.batch_size:\n",
    "                    state_batch, action_batch, reward_batch, state_new_batch, done_batch = self.buffer.sample_batch()\n",
    "                    \n",
    "                    state_batch = t.tensor(state_batch, dtype=t.float).to(self.actor.device)\n",
    "                    action_batch = t.tensor(action_batch, dtype=t.float).to(self.actor.device)\n",
    "                    reward_batch = t.tensor(reward_batch, dtype=t.float).to(self.actor.device).view(-1,1)\n",
    "                    state_new_batch = t.tensor(state_new_batch, dtype=t.float).to(self.actor.device)\n",
    "                    done_batch = t.tensor(done_batch, dtype=t.float).to(self.actor.device).view(-1,1)                    \n",
    "                        \n",
    "                    ##Update the critic\n",
    "                    with t.no_grad():\n",
    "                        #target = t.tensor(reward_batch)  \n",
    "                        target = reward_batch.clone().detach()\n",
    "                        target += self.gamma*self.critic_t(state_new_batch,self.actor_t(state_new_batch))*done_batch\n",
    "                    preds = self.critic(state_batch, action_batch)\n",
    "\n",
    "                    loss_critic = self.loss(target, preds)\n",
    "                    loss_critic.backward()\n",
    "                    self.critic.optimizer.step()\n",
    "        \n",
    "                    ##Update the actor\n",
    "                    loss_actor = -self.critic(state_batch, self.actor(state_batch))\n",
    "                    loss_actor = loss_actor.mean()\n",
    "                    loss_actor.backward()                    \n",
    "                    self.actor.optimizer.step()                    \n",
    "                    \n",
    "                    self.update_parms()\n",
    "        \n",
    "                state = state_new\n",
    "                if n % 100 ==0:\n",
    "                    #print(f'step {n} reward: ', reward, f'action: ', action)\n",
    "                    pass\n",
    "            reward_list.append(total_reward)\n",
    "        \n",
    "        x = [i+1 for i in range(self.maxm_iters)]\n",
    "        self.plot_learning_curve(x, reward_list)\n",
    "        #x = [i+1 for i in range(n)]\n",
    "        #self.plot_learning_curve(x, reward_list_n)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    #env = gym.make('Pendulum-v1')\n",
    "    env = gym.make('MountainCarContinuous-v0')\n",
    "    \n",
    "    dim_state = env.observation_space.shape[0]\n",
    "    dim_action = env.action_space.shape[0]\n",
    "    max_action = float(env.action_space.high[0])\n",
    "    min_action = float(env.action_space.low[0])\n",
    "    print('dim_state: ', dim_state)\n",
    "    print ('dim_action: ', dim_action)\n",
    "    print('action sample: ', env.action_space.sample())\n",
    "    agent = Agent(env,dim_state,dim_action, 200, 100, 2e-3, 0.99,min_action, max_action, 100000, maxm_iters=300)\n",
    "    agent.learn()\n",
    "    agent.actor.saveCheckpoint()\n",
    "    agent.critic.saveCheckpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0815386], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v1')\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_state:  3\n",
      "dim_action:  1\n",
      "action sample:  [-0.615858]\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as f\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "#import gym_cartpole_swingup  #pip install gym_cartpole_swingup\n",
    "\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "###################################################\n",
    "# Deep Deterministic Policy Gradient\n",
    "###################################################\n",
    "\n",
    "class Noise():\n",
    "    def __init__(self,mu,sigma=0.15,theta=0.2,dt=1e-2,x0=None):\n",
    "        self.theta = theta\n",
    "        self.mu=mu\n",
    "        self.sigma = sigma\n",
    "        self.dt=dt\n",
    "        self.x0=x0\n",
    "        self.reset()\n",
    "    \n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
    "        self.sigma * np.sqrt(self.dt)*np.random.normal(size=self.mu.shape)\n",
    "        self.prev = x\n",
    "        return x\n",
    "    \n",
    "    def reset(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\n",
    "        \n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, dim_state, dim_action, fc1, fc2, alpha, min_action, max_action, checkpoint='actor_ddpg_v2' ):\n",
    "        super(Actor, self).__init__()\n",
    "        self.dim_state = dim_state\n",
    "        self.dim_action = dim_action\n",
    "        self.min_action = min_action\n",
    "        self.max_action = max_action\n",
    "        \n",
    "        self.linear1 = nn.Linear(dim_state, fc1)\n",
    "        self.linear2 = nn.Linear(fc1, fc2)\n",
    "        self.linear3 = nn.Linear(fc2, dim_action)\n",
    "        \n",
    "        self.device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha, weight_decay=1e-4)\n",
    "        self.to(self.device)\n",
    "        self.path = checkpoint\n",
    "        \n",
    "    def forward(self, state):\n",
    "        output = state.to(self.device)\n",
    "        \n",
    "        output = f.relu(self.linear1(output))\n",
    "        output = f.relu(self.linear2(output))\n",
    "        #output = t.tanh(self.linear3(output)) * self.max_action\n",
    "        output = t.clamp(self.linear3(output), self.min_action, self.max_action)\n",
    "        return output\n",
    "    \n",
    "    def saveCheckpoint(self):\n",
    "        print ('...saving check point...')\n",
    "        t.save(self.state_dict(), self.path)\n",
    "    \n",
    "    def loadCheckpoint(self):\n",
    "        print('...loading check point')\n",
    "        self.load_state_dict(t.load(self.path))\n",
    "    \n",
    "class Critic(nn.Module):   \n",
    "    def __init__(self, dim_state, dim_action, fc1, fc2, alpha,checkpoint='critic_ddpg_v2'):\n",
    "        super(Critic, self).__init__()\n",
    "        self.dim_state = dim_state\n",
    "        self.dim_action = dim_action\n",
    "        self.path = checkpoint\n",
    "        \n",
    "        self.linear1 = nn.Linear(dim_state+ dim_action, fc1)\n",
    "        self.linear2 = nn.Linear(fc1, fc2)\n",
    "        self.linear3 = nn.Linear(fc2, 1)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr = alpha, weight_decay=1e-4)\n",
    "        self.device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        state = state.to(self.device)\n",
    "        action = action.to(self.device)\n",
    "        \n",
    "        output = t.relu(self.linear1(t.cat((state, action), dim=1)))\n",
    "        output = t.relu(self.linear2(output))\n",
    "        output = self.linear3(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def saveCheckpoint(self):\n",
    "        print('...save checkout...')\n",
    "        t.save(self.state_dict(), self.path)\n",
    "    \n",
    "    def loadCheckpoint(self):\n",
    "        print ('...load checj point...')\n",
    "        self.load_state_dict(t.load(self.path))\n",
    "        \n",
    "        \n",
    "class replayBuffer():\n",
    "    def __init__(self, maxm_size, dim_state, dim_action):\n",
    "        self.counter = 0\n",
    "        self.state_mem = np.zeros((maxm_size, dim_state))\n",
    "        self.action_mem = np.zeros((maxm_size, dim_action))\n",
    "        self.reward_mem = np.zeros(maxm_size)\n",
    "        self.state_new_mem = np.zeros((maxm_size, dim_state))\n",
    "        self.done_mem = np.zeros(maxm_size)\n",
    "        self.maxm_size = maxm_size\n",
    "        \n",
    "    def store_Transaction(self, state, action, reward, state_new, done):\n",
    "        index = self.counter % self.maxm_size\n",
    "        \n",
    "        self.state_mem[index] = state\n",
    "        self.action_mem[index] = action\n",
    "        self.reward_mem[index] = reward\n",
    "        self.state_new_mem[index] =state_new\n",
    "        self.done_mem[index] = 1.0 - done\n",
    "        \n",
    "        self.counter+=1\n",
    "    \n",
    "    def sample_batch(self, batch_size=64):\n",
    "        maxm_size = min(self.counter, self.maxm_size)\n",
    "        batch = np.random.choice(maxm_size, batch_size)\n",
    "        \n",
    "        state_batch = self.state_mem[batch]\n",
    "        action_batch = self.action_mem[batch]\n",
    "        reward_batch = self.reward_mem[batch]\n",
    "        state_new_batch = self.state_new_mem[batch]\n",
    "        done_batch = self.done_mem[batch]\n",
    "        \n",
    "        return state_batch, action_batch,reward_batch,state_new_batch,done_batch\n",
    "        \n",
    "    \n",
    "class Agent():\n",
    "    def __init__(self, env, dim_state, dim_action, fc1, fc2, alpha, gamma,min_action, max_action, maxm_size, maxm_iters=50, batch_size=64):\n",
    "        self.dim_state = dim_state\n",
    "        self.dim_action = dim_action\n",
    "        self.maxm_iters = maxm_iters\n",
    "        self.device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.actor=Actor(dim_state, dim_action, fc1, fc2, alpha, min_action, max_action, checkpoint='actor').to(self.device)\n",
    "        self.critic=Critic(dim_state, dim_action, fc1, fc2, alpha,checkpoint='critic').to(self.device)\n",
    "        self.tau = 0.005\n",
    "\n",
    "        #Initilize the target networks           \n",
    "        self.actor_t = Actor(dim_state, dim_action, fc1, fc2, alpha, min_action, max_action, checkpoint='actor').to(self.device)\n",
    "        self.actor_t.load_state_dict(self.actor.state_dict())\n",
    "        \n",
    "        self.critic_t = Critic(dim_state, dim_action, fc1, fc2, alpha,checkpoint='critic').to(self.device)\n",
    "        self.critic_t.load_state_dict(self.critic.state_dict())\n",
    "        \n",
    "        self.buffer = replayBuffer(maxm_size, dim_state, dim_action) # maxm_size, dim_state, dim_action):\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size   \n",
    "        self.noise = Noise(mu=np.zeros(dim_action))\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.env = env\n",
    "        \n",
    "        \n",
    "    def plot_learning_curve(self,x, scores, figure_file='test'):\n",
    "        running_avg = np.zeros(len(scores))\n",
    "        for i in range(len(running_avg)):\n",
    "            running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
    "        plt.plot(x, running_avg)\n",
    "        #plt.title('Running average of previous 100 scores')\n",
    "        plt.savefig('ddpg_v2.png')\n",
    "        \n",
    "    def update_parms(self):\n",
    "        \n",
    "        critic_dict = dict(self.critic_t.named_parameters())\n",
    "        critic_t_dict = dict(self.critic.named_parameters())\n",
    "        \n",
    "        actor_t_dict = dict(self.actor_t.named_parameters())\n",
    "        actor_dict = dict(self.actor.named_parameters())\n",
    "        \n",
    "        #Update the critic\n",
    "        for i in critic_dict:\n",
    "            critic_dict[i] = self.tau*critic_dict[i].clone() + (1-self.tau)*critic_t_dict[i].clone()\n",
    "        self.critic_t.load_state_dict(critic_dict)\n",
    "        \n",
    "        #Update the actor\n",
    "        for j in actor_dict:\n",
    "            actor_dict[j] = self.tau*actor_dict[j].clone() + (1-self.tau)*actor_t_dict[j].clone()\n",
    "        self.actor_t.load_state_dict(actor_dict)\n",
    "           \n",
    "    def learn(self):\n",
    "\n",
    "        reward_list = []  \n",
    "        reward_list_n= []\n",
    "        n=0\n",
    "           \n",
    "        for i in range(self.maxm_iters):\n",
    "            self.noise.reset()\n",
    "            \n",
    "            done= False\n",
    "            state = self.env.reset()       \n",
    "            total_reward= 0\n",
    "            \n",
    "            while not done:   \n",
    "                n+=1\n",
    "                self.critic.train()\n",
    "                self.actor.train()\n",
    "                \n",
    "                self.critic.optimizer.zero_grad()\n",
    "                self.actor.optimizer.zero_grad()\n",
    "                \n",
    "                action = self.actor(t.tensor(state).float().to(self.device)).cpu().detach().numpy() + self.noise()\n",
    "                if n % 200 == 0:\n",
    "                    #print(f'action {n}: ', action)\n",
    "                    pass\n",
    "\n",
    "                state_new, reward, done, _ = self.env.step(action)\n",
    "                reward_list_n.append(reward)\n",
    "                total_reward+=reward\n",
    "        \n",
    "                self.buffer.store_Transaction(state, action, reward, state_new, done)\n",
    "\n",
    "                if self.buffer.counter >= self.batch_size:\n",
    "                    state_batch, action_batch, reward_batch, state_new_batch, done_batch = self.buffer.sample_batch()\n",
    "                    \n",
    "                    state_batch = t.tensor(state_batch, dtype=t.float).to(self.actor.device)\n",
    "                    action_batch = t.tensor(action_batch, dtype=t.float).to(self.actor.device)\n",
    "                    reward_batch = t.tensor(reward_batch, dtype=t.float).to(self.actor.device).view(-1,1)\n",
    "                    state_new_batch = t.tensor(state_new_batch, dtype=t.float).to(self.actor.device)\n",
    "                    done_batch = t.tensor(done_batch, dtype=t.float).to(self.actor.device).view(-1,1)                    \n",
    "                        \n",
    "                    ##Update the critic\n",
    "                    with t.no_grad():\n",
    "                        #target = t.tensor(reward_batch)  \n",
    "                        target = reward_batch.clone().detach()\n",
    "                        target += self.gamma*self.critic_t(state_new_batch,self.actor_t(state_new_batch))*done_batch\n",
    "                    preds = self.critic(state_batch, action_batch)\n",
    "\n",
    "                    loss_critic = self.loss(target, preds)\n",
    "                    loss_critic.backward()\n",
    "                    self.critic.optimizer.step()\n",
    "        \n",
    "                    ##Update the actor\n",
    "                    loss_actor = -self.critic(state_batch, self.actor(state_batch))\n",
    "                    loss_actor = loss_actor.mean()\n",
    "                    loss_actor.backward()                    \n",
    "                    self.actor.optimizer.step()                    \n",
    "                    \n",
    "                    self.update_parms()\n",
    "        \n",
    "                state = state_new\n",
    "                if n % 100 ==0:\n",
    "                    #print(f'step {n} reward: ', reward, f'action: ', action)\n",
    "                    pass\n",
    "            reward_list.append(total_reward)\n",
    "        \n",
    "        x = [i+1 for i in range(self.maxm_iters)]\n",
    "        self.plot_learning_curve(x, reward_list)\n",
    "        #x = [i+1 for i in range(n)]\n",
    "        #self.plot_learning_curve(x, reward_list_n)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    env = gym.make('Pendulum-v1')\n",
    "    #env = gym.make('MountainCarContinuous-v0')\n",
    "    \n",
    "    dim_state = env.observation_space.shape[0]\n",
    "    dim_action = env.action_space.shape[0]\n",
    "    max_action = float(env.action_space.high[0])\n",
    "    min_action = float(env.action_space.low[0])\n",
    "    print('dim_state: ', dim_state)\n",
    "    print ('dim_action: ', dim_action)\n",
    "    print('action sample: ', env.action_space.sample())\n",
    "    agent = Agent(env,dim_state,dim_action, 50, 40, 2.5e-3, 0.99,min_action, max_action, 1000000, maxm_iters=800)\n",
    "    agent.learn()\n",
    "    agent.actor.saveCheckpoint()\n",
    "    agent.critic.saveCheckpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_state:  17\n",
      "dim_action:  4\n",
      "action sample:  [ 2.4623775 12.36101    6.5643554 12.499605 ]\n",
      "...saving check point...\n",
      "...save checkout...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from supplychain import SimpleSupplyChain\n",
    "if __name__ == '__main__':\n",
    "    #env = gym.make('Pendulum-v1')\n",
    "    #env = gym.make('MountainCarContinuous-v0')\n",
    "    env = SimpleSupplyChain()\n",
    "    \n",
    "    dim_state = env.observation_space.shape[0]\n",
    "    dim_action = env.action_space.shape[0]\n",
    "    max_action = float(env.action_space.high[0])\n",
    "    min_action = float(env.action_space.low[0])\n",
    "    print('dim_state: ', dim_state)\n",
    "    print ('dim_action: ', dim_action)\n",
    "    print('action sample: ', env.action_space.sample())\n",
    "    agent = Agent(env,dim_state,dim_action, 200, 100, 2e-3, 0.99,min_action, max_action, 100000, maxm_iters=800)\n",
    "    agent.learn()\n",
    "    agent.actor.saveCheckpoint()\n",
    "    agent.critic.saveCheckpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
