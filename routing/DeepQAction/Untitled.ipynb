{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f10b2ee0-e20d-4069-9d48-97ad72cdc46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[5], edge_index=[2, 12], y=[5])\n",
      "tensor([0.5000, 0.2000, 0.3000, 0.1000, 0.2000])\n",
      "tensor([1, 2, 3, 4, 5])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4],\n",
      "        [1, 3, 4, 0, 2, 3, 1, 4, 0, 1, 0, 2]])\n",
      "tensor([False, False, False,  True, False])\n",
      "tensor([ True,  True,  True, False,  True])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.utils import to_networkx, from_networkx\n",
    "# Make the networkx graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add some cars (just do 4 for now)\n",
    "G.add_nodes_from([\n",
    "      (1, {'y': 1, 'x': 0.5}),\n",
    "      (2, {'y': 2, 'x': 0.2}),\n",
    "      (3, {'y': 3, 'x': 0.3}),\n",
    "      (4, {'y': 4, 'x': 0.1}),\n",
    "      (5, {'y': 5, 'x': 0.2}),\n",
    "])\n",
    "\n",
    "# Add some edges\n",
    "G.add_edges_from([\n",
    "                  (1, 2), (1, 4), (1, 5),\n",
    "                  (2, 3), (2, 4),\n",
    "                  (3, 2), (3, 5),\n",
    "                  (4, 1), (4, 2),\n",
    "                  (5, 1), (5, 3)\n",
    "])\n",
    "\n",
    "# Convert the graph into PyTorch geometric\n",
    "pyg_graph = from_networkx(G)\n",
    "\n",
    "print(pyg_graph)\n",
    "# Data(edge_index=[2, 12], x=[5], y=[5])\n",
    "print(pyg_graph.x)\n",
    "# tensor([0.5000, 0.2000, 0.3000, 0.1000, 0.2000])\n",
    "print(pyg_graph.y)\n",
    "# tensor([1, 2, 3, 4, 5])\n",
    "print(pyg_graph.edge_index)\n",
    "# tensor([[0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4],\n",
    "#         [1, 3, 4, 0, 2, 3, 1, 4, 0, 1, 0, 2]])\n",
    "\n",
    "# Split the data \n",
    "train_ratio = 0.2\n",
    "num_nodes = pyg_graph.x.shape[0]\n",
    "num_train = int(num_nodes * train_ratio)\n",
    "idx = [i for i in range(num_nodes)]\n",
    "\n",
    "np.random.shuffle(idx)\n",
    "train_mask = torch.full_like(pyg_graph.y, False, dtype=bool)\n",
    "train_mask[idx[:num_train]] = True\n",
    "test_mask = torch.full_like(pyg_graph.y, False, dtype=bool)\n",
    "test_mask[idx[num_train:]] = True\n",
    "\n",
    "print(train_mask)\n",
    "# tensor([ True, False, False, False, False])\n",
    "print(test_mask)\n",
    "# tensor([False,  True,  True,  True,  True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ff9988d-bf0d-4192-ab5a-2a0688ba2e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25dee8cc-49ad-4ad0-95e3-b8a7a9418ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "tensor(140)\n",
      "tensor(500)\n",
      "tensor(1000)\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "print(data)\n",
    "print(data.train_mask.sum())\n",
    "print(data.val_mask.sum())\n",
    "print(data.test_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b08726f-86c2-403f-b86d-c7b79f9a5016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a5400e-2c0a-47e8-85bc-4feb932a420c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 4016], x=[1067, 21], y=[32], batch=[1067], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3806], x=[972, 21], y=[32], batch=[972], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3996], x=[1045, 21], y=[32], batch=[1045], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3792], x=[1017, 21], y=[32], batch=[1017], ptr=[33])\n",
      "DataBatch(edge_index=[2, 4122], x=[1071, 21], y=[32], batch=[1071], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3882], x=[990, 21], y=[32], batch=[990], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3698], x=[963, 21], y=[32], batch=[963], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3460], x=[892, 21], y=[32], batch=[892], ptr=[33])\n",
      "DataBatch(edge_index=[2, 4092], x=[1122, 21], y=[32], batch=[1122], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3864], x=[1045, 21], y=[32], batch=[1045], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3886], x=[977, 21], y=[32], batch=[977], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3932], x=[1004, 21], y=[32], batch=[1004], ptr=[33])\n",
      "DataBatch(edge_index=[2, 4130], x=[1074, 21], y=[32], batch=[1074], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3558], x=[906, 21], y=[32], batch=[906], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3664], x=[1064, 21], y=[32], batch=[1064], ptr=[33])\n",
      "DataBatch(edge_index=[2, 4494], x=[1167, 21], y=[32], batch=[1167], ptr=[33])\n",
      "DataBatch(edge_index=[2, 4294], x=[1102, 21], y=[32], batch=[1102], ptr=[33])\n",
      "DataBatch(edge_index=[2, 4310], x=[1156, 21], y=[32], batch=[1156], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3568], x=[946, 21], y=[24], batch=[946], ptr=[25])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "\n",
    "data_list = [i for i in dataset]\n",
    "loader = DataLoader(data_list, batch_size=32, shuffle=True)\n",
    "for i in loader:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8925b9ca-8e35-4f43-83c9-586bf0755f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3381, 0.6711, 0.3586, 0.3750, 0.6673],\n",
      "        [0.5826, 0.5489, 0.1666, 0.7584, 0.5811],\n",
      "        [0.1094, 0.0598, 0.9345, 0.0498, 0.9743],\n",
      "        [0.8946, 0.8983, 0.3115, 0.4215, 0.3810],\n",
      "        [0.2878, 0.7763, 0.1963, 0.1039, 0.0451],\n",
      "        [0.9691, 0.7604, 0.1078, 0.1348, 0.6553],\n",
      "        [0.8809, 0.0026, 0.6332, 0.4650, 0.4761],\n",
      "        [0.9440, 0.4283, 0.4445, 0.1092, 0.7236],\n",
      "        [0.3010, 0.2219, 0.2635, 0.0074, 0.9433],\n",
      "        [0.0693, 0.8644, 0.4994, 0.6155, 0.2066]])\n",
      "tensor([0.5826, 0.5489, 0.1666, 0.7584, 0.5811])\n",
      "tensor([[0.5826, 0.5489, 0.1666, 0.7584, 0.5811]])\n",
      "tensor([[0.5826, 0.5489, 0.1666, 0.7584, 0.5811],\n",
      "        [0.5826, 0.5489, 0.1666, 0.7584, 0.5811],\n",
      "        [0.5826, 0.5489, 0.1666, 0.7584, 0.5811],\n",
      "        [0.5826, 0.5489, 0.1666, 0.7584, 0.5811],\n",
      "        [0.5826, 0.5489, 0.1666, 0.7584, 0.5811]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a =torch.rand(10,5)\n",
    "print(a)\n",
    "print(a[1])\n",
    "b = [1]\n",
    "c = torch.tensor(b)\n",
    "print(a[b])\n",
    "print(a[c.repeat(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10b0895e-6757-4a9a-8e49-0a2a59e17421",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [10, 1]] is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m z \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m/\u001b[39m y[:, np\u001b[38;5;241m.\u001b[39mnewaxis])  \u001b[38;5;66;03m# anomaly detection will point here\u001b[39;00m\n\u001b[1;32m      7\u001b[0m c \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mabs_()  \u001b[38;5;66;03m# but the problem is here\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m z\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/M1Max/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/M1Max/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [10, 1]] is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    x = torch.rand(10, 20, requires_grad=True)\n",
    "    y = torch.rand(10)\n",
    "    z = (x / y[:, np.newaxis])  # anomaly detection will point here\n",
    "    c = y.abs_()  # but the problem is here\n",
    "    z.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8187ccd8-b50a-43cd-91db-773dc10b0597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "None\n",
      "3\n",
      "4\n",
      "1\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "print(data.x)\n",
    "print(data.edge_index)\n",
    "print(data.y)\n",
    "print(data.num_nodes)\n",
    "print(data.num_edges)\n",
    "print(data.num_node_features)\n",
    "print(data.has_isolated_nodes())\n",
    "print(data.is_directed())\n",
    "print(data.has_self_loops())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd0c90c7-2b81-4d8e-9275-d8c23f87afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 3772], x=[967, 21], y=[32], batch=[967], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 4358], x=[1100, 21], y=[32], batch=[1100], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 4200], x=[1096, 21], y=[32], batch=[1096], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 3984], x=[1060, 21], y=[32], batch=[1060], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 3944], x=[1038, 21], y=[32], batch=[1038], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 4458], x=[1147, 21], y=[32], batch=[1147], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 4208], x=[1124, 21], y=[32], batch=[1124], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 4170], x=[1151, 21], y=[32], batch=[1151], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 4054], x=[1013, 21], y=[32], batch=[1013], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 3602], x=[966, 21], y=[32], batch=[966], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 3628], x=[969, 21], y=[32], batch=[969], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 3532], x=[939, 21], y=[32], batch=[939], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 4232], x=[1107, 21], y=[32], batch=[1107], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 3518], x=[905, 21], y=[32], batch=[905], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 3928], x=[1010, 21], y=[32], batch=[1010], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 3860], x=[959, 21], y=[32], batch=[959], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 4028], x=[1059, 21], y=[32], batch=[1059], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 3762], x=[1059, 21], y=[32], batch=[1059], ptr=[33]) 32\n",
      "DataBatch(edge_index=[2, 3326], x=[911, 21], y=[24], batch=[911], ptr=[25]) 24\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "for batch in loader:\n",
    "    print(batch, batch.num_graphs)\n",
    "    #print(batch.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bae65723-48bf-448d-8f44-521933d78c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch_geometric.data.batch.DataBatch'> DataBatch(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], batch=[2708], ptr=[2])\n",
      "<class 'torch_geometric.data.data.Data'> 1433\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "loader = DataLoader(dataset)\n",
    "for i in loader:\n",
    "    print(type(i), i)\n",
    "\n",
    "for i in dataset:\n",
    "    print(type(i), i.num_node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce4b0d3d-dc97-48dd-b7b4-446f24a5895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d175e30-fbbc-4556-87c2-745f2a726387",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9a19163-ef4f-4448-9833-8968c8b88165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0f86b7-9561-4bfa-88fc-43c145c80847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
