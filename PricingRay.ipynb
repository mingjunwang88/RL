{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mingjunwang/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'Envs.SinglePriceEnv' from '/Users/mingjunwang/Documents/Backup/RL/Envs/SinglePriceEnv.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "from ray.rllib.agents import dqn\n",
    "from ray import tune\n",
    "\n",
    "from Envs import SinglePriceEnv as p\n",
    "\n",
    "import importlib\n",
    "importlib.reload(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File descriptor limit 256 is too low for production servers and may result in connection errors. At least 8192 is recommended. --- Fix with 'ulimit -n 8192'\n",
      "2021-02-20 16:16:10,459\tINFO services.py:1171 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.0.23',\n",
       " 'raylet_ip_address': '192.168.0.23',\n",
       " 'redis_address': '192.168.0.23:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-02-20_16-16-09_964235_94145/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-02-20_16-16-09_964235_94145/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-02-20_16-16-09_964235_94145',\n",
       " 'metrics_export_port': 62359,\n",
       " 'node_id': '7c3e739dc065bfa854f01387bf18d9deff9da463'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 1/2 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=94173)\u001b[0m WARNING:tensorflow:From /Users/mingjunwang/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=94173)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=94173)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=94172)\u001b[0m WARNING:tensorflow:From /Users/mingjunwang/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=94172)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=94172)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=94173)\u001b[0m 2021-02-20 16:16:17,066\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=94173)\u001b[0m 2021-02-20 16:16:17,066\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=94172)\u001b[0m 2021-02-20 16:16:17,066\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=94172)\u001b[0m 2021-02-20 16:16:17,066\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=94167)\u001b[0m WARNING:tensorflow:From /Users/mingjunwang/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=94167)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=94167)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=94175)\u001b[0m WARNING:tensorflow:From /Users/mingjunwang/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=94175)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=94175)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=94167)\u001b[0m /Users/mingjunwang/opt/miniconda3/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=94167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=94175)\u001b[0m /Users/mingjunwang/opt/miniconda3/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=94175)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=94173)\u001b[0m 2021-02-20 16:16:23,601\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=94172)\u001b[0m 2021-02-20 16:16:23,606\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=94167)\u001b[0m 2021-02-20 16:16:23,649\tWARNING deprecation.py:29 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=94175)\u001b[0m 2021-02-20 16:16:23,649\tWARNING deprecation.py:29 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-16-25\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 1052955.8628854658\n",
      "  episode_reward_mean: -425211.76962473034\n",
      "  episode_reward_min: -1893816.4362563416\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 50\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 1000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1.1597323417663574\n",
      "        mean_q: -0.3099154233932495\n",
      "        mean_td_error: 782.5152587890625\n",
      "        min_q: -1.955712080001831\n",
      "        model: {}\n",
      "    num_steps_sampled: 1000\n",
      "    num_steps_trained: 32\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.46666666666667\n",
      "    ram_util_percent: 66.5\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043884738461001896\n",
      "    mean_env_wait_ms: 0.06239064089901798\n",
      "    mean_inference_ms: 0.6067145478118073\n",
      "    mean_raw_obs_processing_ms: 0.08605934165931726\n",
      "  time_since_restore: 1.4499709606170654\n",
      "  time_this_iter_s: 1.4499709606170654\n",
      "  time_total_s: 1.4499709606170654\n",
      "  timers:\n",
      "    learn_throughput: 173.258\n",
      "    learn_time_ms: 184.696\n",
      "    update_time_ms: 4.077\n",
      "  timestamp: 1613859385\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1000\n",
      "  training_iteration: 1\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=94173)\u001b[0m WARNING:tensorflow:From /Users/mingjunwang/opt/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=94173)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=94173)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=94172)\u001b[0m WARNING:tensorflow:From /Users/mingjunwang/opt/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=94172)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=94172)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=94167)\u001b[0m WARNING:tensorflow:From /Users/mingjunwang/opt/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=94167)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=94167)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=94175)\u001b[0m WARNING:tensorflow:From /Users/mingjunwang/opt/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=94175)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=94175)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.44997</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\"> -425212</td><td style=\"text-align: right;\">         1.05296e+06</td><td style=\"text-align: right;\">        -1.89382e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-16-25\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 868349.6971789792\n",
      "  episode_reward_mean: -296899.954201545\n",
      "  episode_reward_min: -1495124.3480619413\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 50\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 1000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 0.43436968326568604\n",
      "        mean_q: -0.8602994680404663\n",
      "        mean_td_error: -14731.7890625\n",
      "        min_q: -1.664108395576477\n",
      "        model: {}\n",
      "    num_steps_sampled: 1000\n",
      "    num_steps_trained: 32\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.46666666666667\n",
      "    ram_util_percent: 66.5\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04318305900642327\n",
      "    mean_env_wait_ms: 0.06363775346662613\n",
      "    mean_inference_ms: 0.6082553368110162\n",
      "    mean_raw_obs_processing_ms: 0.08384069124540011\n",
      "  time_since_restore: 1.4450030326843262\n",
      "  time_this_iter_s: 1.4450030326843262\n",
      "  time_total_s: 1.4450030326843262\n",
      "  timers:\n",
      "    learn_throughput: 172.313\n",
      "    learn_time_ms: 185.709\n",
      "    update_time_ms: 4.107\n",
      "  timestamp: 1613859385\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1000\n",
      "  training_iteration: 1\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-16-32\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 1759684.482778468\n",
      "  episode_reward_mean: 55728.846822873\n",
      "  episode_reward_min: -1514151.989802309\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 150\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 2512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 7030.52099609375\n",
      "        mean_q: 2353.947265625\n",
      "        mean_td_error: 33146.55078125\n",
      "        min_q: -3051.548583984375\n",
      "        model: {}\n",
      "    num_steps_sampled: 3000\n",
      "    num_steps_trained: 16032\n",
      "    num_target_updates: 4\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.519999999999996\n",
      "    ram_util_percent: 66.62\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04839667563274163\n",
      "    mean_env_wait_ms: 0.06793501704896066\n",
      "    mean_inference_ms: 0.6289157551447074\n",
      "    mean_raw_obs_processing_ms: 0.09162479632890391\n",
      "  time_since_restore: 8.844235181808472\n",
      "  time_this_iter_s: 3.5355870723724365\n",
      "  time_total_s: 8.844235181808472\n",
      "  timers:\n",
      "    learn_throughput: 10726.263\n",
      "    learn_time_ms: 2.983\n",
      "    update_time_ms: 2.055\n",
      "  timestamp: 1613859392\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3000\n",
      "  training_iteration: 3\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         5.30596</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">-231686  </td><td style=\"text-align: right;\">         1.09628e+06</td><td style=\"text-align: right;\">        -1.81004e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         8.84424</td><td style=\"text-align: right;\">3000</td><td style=\"text-align: right;\">  55728.8</td><td style=\"text-align: right;\">         1.75968e+06</td><td style=\"text-align: right;\">        -1.51415e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-16-32\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 1296080.16232332\n",
      "  episode_reward_mean: -59309.24384907845\n",
      "  episode_reward_min: -1810041.7185610232\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 150\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 2512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 4325.38134765625\n",
      "        mean_q: -1111.682861328125\n",
      "        mean_td_error: 147207.0625\n",
      "        min_q: -5325.3681640625\n",
      "        model: {}\n",
      "    num_steps_sampled: 3000\n",
      "    num_steps_trained: 16032\n",
      "    num_target_updates: 4\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.22\n",
      "    ram_util_percent: 66.62\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04721075732081585\n",
      "    mean_env_wait_ms: 0.06857704686947877\n",
      "    mean_inference_ms: 0.6339092552291414\n",
      "    mean_raw_obs_processing_ms: 0.0895829262984374\n",
      "  time_since_restore: 8.83692216873169\n",
      "  time_this_iter_s: 3.5309629440307617\n",
      "  time_total_s: 8.83692216873169\n",
      "  timers:\n",
      "    learn_throughput: 10953.062\n",
      "    learn_time_ms: 2.922\n",
      "    update_time_ms: 2.048\n",
      "  timestamp: 1613859392\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3000\n",
      "  training_iteration: 3\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-16-39\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2039727.9378263676\n",
      "  episode_reward_mean: 585791.3843367292\n",
      "  episode_reward_min: -1650966.7982997985\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 250\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 4528\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 34746.7265625\n",
      "        mean_q: 12809.375\n",
      "        mean_td_error: 34323.49609375\n",
      "        min_q: -10885.3515625\n",
      "        model: {}\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 32032\n",
      "    num_target_updates: 8\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.8\n",
      "    ram_util_percent: 66.28\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04918178038207302\n",
      "    mean_env_wait_ms: 0.06920916025515188\n",
      "    mean_inference_ms: 0.6306980548774165\n",
      "    mean_raw_obs_processing_ms: 0.09255549515297697\n",
      "  time_since_restore: 16.061152458190918\n",
      "  time_this_iter_s: 3.7254979610443115\n",
      "  time_total_s: 16.061152458190918\n",
      "  timers:\n",
      "    learn_throughput: 8884.237\n",
      "    learn_time_ms: 3.602\n",
      "    update_time_ms: 2.722\n",
      "  timestamp: 1613859399\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 5\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         12.3262</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">  328356</td><td style=\"text-align: right;\">         1.65436e+06</td><td style=\"text-align: right;\">        -1.46504e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         16.0612</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">  585791</td><td style=\"text-align: right;\">         2.03973e+06</td><td style=\"text-align: right;\">        -1.65097e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-16-39\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 1862133.8983262535\n",
      "  episode_reward_mean: 712040.3577526892\n",
      "  episode_reward_min: -1499337.2921698126\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 250\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 4528\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 22687.802734375\n",
      "        mean_q: 639.836669921875\n",
      "        mean_td_error: 59851.7890625\n",
      "        min_q: -20099.3671875\n",
      "        model: {}\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 32032\n",
      "    num_target_updates: 8\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 43.18333333333333\n",
      "    ram_util_percent: 66.26666666666668\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04812376759357538\n",
      "    mean_env_wait_ms: 0.06977495872195254\n",
      "    mean_inference_ms: 0.6374189419342364\n",
      "    mean_raw_obs_processing_ms: 0.09071434693434974\n",
      "  time_since_restore: 16.062910318374634\n",
      "  time_this_iter_s: 3.7367541790008545\n",
      "  time_total_s: 16.062910318374634\n",
      "  timers:\n",
      "    learn_throughput: 9034.52\n",
      "    learn_time_ms: 3.542\n",
      "    update_time_ms: 2.729\n",
      "  timestamp: 1613859399\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 5\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-16-46\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 1940242.2101863082\n",
      "  episode_reward_mean: 1004068.3138450719\n",
      "  episode_reward_min: -1228934.4521568464\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 350\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 6544\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 80301.453125\n",
      "        mean_q: 34727.5390625\n",
      "        mean_td_error: -10730.1875\n",
      "        min_q: -17355.126953125\n",
      "        model: {}\n",
      "    num_steps_sampled: 7000\n",
      "    num_steps_trained: 48032\n",
      "    num_target_updates: 12\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.9\n",
      "    ram_util_percent: 66.78\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04968837910560065\n",
      "    mean_env_wait_ms: 0.06993896795082827\n",
      "    mean_inference_ms: 0.6343994625409016\n",
      "    mean_raw_obs_processing_ms: 0.0929644776976113\n",
      "  time_since_restore: 23.06233835220337\n",
      "  time_this_iter_s: 3.346000909805298\n",
      "  time_total_s: 23.06233835220337\n",
      "  timers:\n",
      "    learn_throughput: 11682.281\n",
      "    learn_time_ms: 2.739\n",
      "    update_time_ms: 1.976\n",
      "  timestamp: 1613859406\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7000\n",
      "  training_iteration: 7\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">          reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         19.7021</td><td style=\"text-align: right;\">6000</td><td style=\"text-align: right;\">921701          </td><td style=\"text-align: right;\">         1.90552e+06</td><td style=\"text-align: right;\">        -1.49934e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         23.0623</td><td style=\"text-align: right;\">7000</td><td style=\"text-align: right;\">     1.00407e+06</td><td style=\"text-align: right;\">         1.94024e+06</td><td style=\"text-align: right;\">        -1.22893e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-16-46\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2080415.8277398082\n",
      "  episode_reward_mean: 1166054.0765666794\n",
      "  episode_reward_min: -1344363.9210608548\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 350\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 6544\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 58043.125\n",
      "        mean_q: 25112.80859375\n",
      "        mean_td_error: -18046.1328125\n",
      "        min_q: -32470.01171875\n",
      "        model: {}\n",
      "    num_steps_sampled: 7000\n",
      "    num_steps_trained: 48032\n",
      "    num_target_updates: 12\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.52\n",
      "    ram_util_percent: 66.78\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048540349651699094\n",
      "    mean_env_wait_ms: 0.0703316592337528\n",
      "    mean_inference_ms: 0.6403374781445822\n",
      "    mean_raw_obs_processing_ms: 0.09115566927204904\n",
      "  time_since_restore: 23.051748037338257\n",
      "  time_this_iter_s: 3.3496718406677246\n",
      "  time_total_s: 23.051748037338257\n",
      "  timers:\n",
      "    learn_throughput: 11947.882\n",
      "    learn_time_ms: 2.678\n",
      "    update_time_ms: 2.024\n",
      "  timestamp: 1613859406\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7000\n",
      "  training_iteration: 7\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-16-53\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2155525.7871422074\n",
      "  episode_reward_mean: 1443183.2744124606\n",
      "  episode_reward_min: -465394.98625053314\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 450\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 8560\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 138773.828125\n",
      "        mean_q: 68379.40625\n",
      "        mean_td_error: -63222.97265625\n",
      "        min_q: -21915.59765625\n",
      "        model: {}\n",
      "    num_steps_sampled: 9000\n",
      "    num_steps_trained: 64032\n",
      "    num_target_updates: 16\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.239999999999995\n",
      "    ram_util_percent: 66.44000000000001\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049195622011878194\n",
      "    mean_env_wait_ms: 0.06930024625437986\n",
      "    mean_inference_ms: 0.6257049199179808\n",
      "    mean_raw_obs_processing_ms: 0.09190451615177718\n",
      "  time_since_restore: 29.80067014694214\n",
      "  time_this_iter_s: 3.348644733428955\n",
      "  time_total_s: 29.80067014694214\n",
      "  timers:\n",
      "    learn_throughput: 11484.951\n",
      "    learn_time_ms: 2.786\n",
      "    update_time_ms: 1.98\n",
      "  timestamp: 1613859413\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9000\n",
      "  training_iteration: 9\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         26.4377</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">1.43895e+06</td><td style=\"text-align: right;\">         2.14003e+06</td><td style=\"text-align: right;\">             -174266</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         29.8007</td><td style=\"text-align: right;\">9000</td><td style=\"text-align: right;\">1.44318e+06</td><td style=\"text-align: right;\">         2.15553e+06</td><td style=\"text-align: right;\">             -465395</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-16-53\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2217732.926238144\n",
      "  episode_reward_mean: 1673499.315862487\n",
      "  episode_reward_min: 169624.78518359357\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 450\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 8560\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 109733.2890625\n",
      "        mean_q: 44337.2265625\n",
      "        mean_td_error: -16239.189453125\n",
      "        min_q: -42477.27734375\n",
      "        model: {}\n",
      "    num_steps_sampled: 9000\n",
      "    num_steps_trained: 64032\n",
      "    num_target_updates: 16\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.6\n",
      "    ram_util_percent: 66.44000000000001\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048045876556877115\n",
      "    mean_env_wait_ms: 0.06975978681480671\n",
      "    mean_inference_ms: 0.6319908240514879\n",
      "    mean_raw_obs_processing_ms: 0.09023602660814188\n",
      "  time_since_restore: 29.787429094314575\n",
      "  time_this_iter_s: 3.349769115447998\n",
      "  time_total_s: 29.787429094314575\n",
      "  timers:\n",
      "    learn_throughput: 12071.785\n",
      "    learn_time_ms: 2.651\n",
      "    update_time_ms: 2.028\n",
      "  timestamp: 1613859413\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9000\n",
      "  training_iteration: 9\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-00\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2063895.8433764684\n",
      "  episode_reward_mean: 1824117.9644098124\n",
      "  episode_reward_min: 1057961.103741102\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 550\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 10576\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 209570.421875\n",
      "        mean_q: 119988.71875\n",
      "        mean_td_error: -97076.1328125\n",
      "        min_q: -26162.546875\n",
      "        model: {}\n",
      "    num_steps_sampled: 11000\n",
      "    num_steps_trained: 80032\n",
      "    num_target_updates: 20\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.92\n",
      "    ram_util_percent: 66.47999999999999\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04884540002570725\n",
      "    mean_env_wait_ms: 0.0689231060434878\n",
      "    mean_inference_ms: 0.6204972811127889\n",
      "    mean_raw_obs_processing_ms: 0.09130565292524274\n",
      "  time_since_restore: 36.54598021507263\n",
      "  time_this_iter_s: 3.3990280628204346\n",
      "  time_total_s: 36.54598021507263\n",
      "  timers:\n",
      "    learn_throughput: 11200.678\n",
      "    learn_time_ms: 2.857\n",
      "    update_time_ms: 2.156\n",
      "  timestamp: 1613859420\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11000\n",
      "  training_iteration: 11\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         33.1363</td><td style=\"text-align: right;\">10000</td><td style=\"text-align: right;\">1.83622e+06</td><td style=\"text-align: right;\">         2.25194e+06</td><td style=\"text-align: right;\">    409226          </td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         36.546 </td><td style=\"text-align: right;\">11000</td><td style=\"text-align: right;\">1.82412e+06</td><td style=\"text-align: right;\">         2.0639e+06 </td><td style=\"text-align: right;\">         1.05796e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-00\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2251935.4670786373\n",
      "  episode_reward_mean: 1998796.3040161992\n",
      "  episode_reward_min: 409226.38321793196\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 550\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 10576\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 177930.40625\n",
      "        mean_q: 98795.828125\n",
      "        mean_td_error: -78743.5234375\n",
      "        min_q: -54086.171875\n",
      "        model: {}\n",
      "    num_steps_sampled: 11000\n",
      "    num_steps_trained: 80032\n",
      "    num_target_updates: 20\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.82\n",
      "    ram_util_percent: 66.44\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.047709634657231624\n",
      "    mean_env_wait_ms: 0.06935581934972167\n",
      "    mean_inference_ms: 0.6266957947540156\n",
      "    mean_raw_obs_processing_ms: 0.08959983761654641\n",
      "  time_since_restore: 36.54020810127258\n",
      "  time_this_iter_s: 3.4038760662078857\n",
      "  time_total_s: 36.54020810127258\n",
      "  timers:\n",
      "    learn_throughput: 11506.514\n",
      "    learn_time_ms: 2.781\n",
      "    update_time_ms: 2.295\n",
      "  timestamp: 1613859420\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11000\n",
      "  training_iteration: 11\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-07\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2006158.9224278652\n",
      "  episode_reward_mean: 1861151.015457365\n",
      "  episode_reward_min: 1214237.424890452\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 650\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 12592\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 291505.5\n",
      "        mean_q: 173418.40625\n",
      "        mean_td_error: -128544.375\n",
      "        min_q: -28142.8203125\n",
      "        model: {}\n",
      "    num_steps_sampled: 13000\n",
      "    num_steps_trained: 96032\n",
      "    num_target_updates: 24\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.04\n",
      "    ram_util_percent: 66.14000000000001\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04890351712313477\n",
      "    mean_env_wait_ms: 0.06902718692685259\n",
      "    mean_inference_ms: 0.620990170695775\n",
      "    mean_raw_obs_processing_ms: 0.09135614737251753\n",
      "  time_since_restore: 43.771981954574585\n",
      "  time_this_iter_s: 3.804912805557251\n",
      "  time_total_s: 43.771981954574585\n",
      "  timers:\n",
      "    learn_throughput: 10728.921\n",
      "    learn_time_ms: 2.983\n",
      "    update_time_ms: 2.053\n",
      "  timestamp: 1613859427\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13000\n",
      "  training_iteration: 13\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         39.9583</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">2.08712e+06</td><td style=\"text-align: right;\">         2.24393e+06</td><td style=\"text-align: right;\">         1.34696e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         43.772 </td><td style=\"text-align: right;\">13000</td><td style=\"text-align: right;\">1.86115e+06</td><td style=\"text-align: right;\">         2.00616e+06</td><td style=\"text-align: right;\">         1.21424e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-07\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2156854.534893272\n",
      "  episode_reward_mean: 2064711.0289166935\n",
      "  episode_reward_min: 1346961.5951895947\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 650\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 12592\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 257303.4375\n",
      "        mean_q: 139055.375\n",
      "        mean_td_error: -97410.78125\n",
      "        min_q: -57077.0\n",
      "        model: {}\n",
      "    num_steps_sampled: 13000\n",
      "    num_steps_trained: 96032\n",
      "    num_target_updates: 24\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.160000000000004\n",
      "    ram_util_percent: 66.22\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04779030848772348\n",
      "    mean_env_wait_ms: 0.06952249323345917\n",
      "    mean_inference_ms: 0.6272771042918822\n",
      "    mean_raw_obs_processing_ms: 0.08969402324585442\n",
      "  time_since_restore: 43.76439309120178\n",
      "  time_this_iter_s: 3.8060760498046875\n",
      "  time_total_s: 43.76439309120178\n",
      "  timers:\n",
      "    learn_throughput: 11342.375\n",
      "    learn_time_ms: 2.821\n",
      "    update_time_ms: 1.984\n",
      "  timestamp: 1613859427\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13000\n",
      "  training_iteration: 13\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-15\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2058113.883008419\n",
      "  episode_reward_mean: 1853003.1214487148\n",
      "  episode_reward_min: 616048.897387147\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 750\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 14608\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 385187.0625\n",
      "        mean_q: 234496.3125\n",
      "        mean_td_error: -171162.25\n",
      "        min_q: -21381.15625\n",
      "        model: {}\n",
      "    num_steps_sampled: 15000\n",
      "    num_steps_trained: 112032\n",
      "    num_target_updates: 28\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.333333333333336\n",
      "    ram_util_percent: 66.78333333333333\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04935861000904416\n",
      "    mean_env_wait_ms: 0.0696994365919365\n",
      "    mean_inference_ms: 0.627124669914943\n",
      "    mean_raw_obs_processing_ms: 0.09209399110994618\n",
      "  time_since_restore: 51.41881251335144\n",
      "  time_this_iter_s: 4.076612710952759\n",
      "  time_total_s: 51.41881251335144\n",
      "  timers:\n",
      "    learn_throughput: 11403.86\n",
      "    learn_time_ms: 2.806\n",
      "    update_time_ms: 2.07\n",
      "  timestamp: 1613859435\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15000\n",
      "  training_iteration: 15\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         47.3299</td><td style=\"text-align: right;\">14000</td><td style=\"text-align: right;\">2.07893e+06</td><td style=\"text-align: right;\">         2.26656e+06</td><td style=\"text-align: right;\">         1.35465e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         51.4188</td><td style=\"text-align: right;\">15000</td><td style=\"text-align: right;\">1.853e+06  </td><td style=\"text-align: right;\">         2.05811e+06</td><td style=\"text-align: right;\">    616049          </td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-15\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2266564.0646055103\n",
      "  episode_reward_mean: 2096077.7663214875\n",
      "  episode_reward_min: 1354654.3567063524\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 750\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 14608\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 347003.1875\n",
      "        mean_q: 189448.09375\n",
      "        mean_td_error: -126350.546875\n",
      "        min_q: -68843.1953125\n",
      "        model: {}\n",
      "    num_steps_sampled: 15000\n",
      "    num_steps_trained: 112032\n",
      "    num_target_updates: 28\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.28333333333334\n",
      "    ram_util_percent: 66.8\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04830584053523813\n",
      "    mean_env_wait_ms: 0.07022928650446764\n",
      "    mean_inference_ms: 0.6333007778941474\n",
      "    mean_raw_obs_processing_ms: 0.09041515031326322\n",
      "  time_since_restore: 51.40841197967529\n",
      "  time_this_iter_s: 4.078490734100342\n",
      "  time_total_s: 51.40841197967529\n",
      "  timers:\n",
      "    learn_throughput: 11621.79\n",
      "    learn_time_ms: 2.753\n",
      "    update_time_ms: 2.007\n",
      "  timestamp: 1613859435\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15000\n",
      "  training_iteration: 15\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-22\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2109230.5347134443\n",
      "  episode_reward_mean: 1845430.5898022219\n",
      "  episode_reward_min: 1114654.2393498428\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 850\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 16624\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 487076.03125\n",
      "        mean_q: 283796.625\n",
      "        mean_td_error: -162473.921875\n",
      "        min_q: 54727.734375\n",
      "        model: {}\n",
      "    num_steps_sampled: 17000\n",
      "    num_steps_trained: 128032\n",
      "    num_target_updates: 32\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.12\n",
      "    ram_util_percent: 67.38\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0499617592178106\n",
      "    mean_env_wait_ms: 0.070485258814574\n",
      "    mean_inference_ms: 0.6351063402247642\n",
      "    mean_raw_obs_processing_ms: 0.09298705064974634\n",
      "  time_since_restore: 58.92002773284912\n",
      "  time_this_iter_s: 3.5741701126098633\n",
      "  time_total_s: 58.92002773284912\n",
      "  timers:\n",
      "    learn_throughput: 11110.831\n",
      "    learn_time_ms: 2.88\n",
      "    update_time_ms: 2.028\n",
      "  timestamp: 1613859442\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17000\n",
      "  training_iteration: 17\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">          55.332</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">2.09104e+06</td><td style=\"text-align: right;\">         2.1786e+06 </td><td style=\"text-align: right;\">         1.35465e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">          58.92 </td><td style=\"text-align: right;\">17000</td><td style=\"text-align: right;\">1.84543e+06</td><td style=\"text-align: right;\">         2.10923e+06</td><td style=\"text-align: right;\">         1.11465e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-22\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2199554.1752799936\n",
      "  episode_reward_mean: 2083081.697908619\n",
      "  episode_reward_min: 1354654.3567063524\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 850\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 16624\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 440018.0625\n",
      "        mean_q: 225132.28125\n",
      "        mean_td_error: -191927.21875\n",
      "        min_q: -50700.96875\n",
      "        model: {}\n",
      "    num_steps_sampled: 17000\n",
      "    num_steps_trained: 128032\n",
      "    num_target_updates: 32\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.279999999999994\n",
      "    ram_util_percent: 67.35999999999999\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04891528081624017\n",
      "    mean_env_wait_ms: 0.07110266589750816\n",
      "    mean_inference_ms: 0.6417348714394671\n",
      "    mean_raw_obs_processing_ms: 0.09137250392035476\n",
      "  time_since_restore: 58.906705141067505\n",
      "  time_this_iter_s: 3.574747085571289\n",
      "  time_total_s: 58.906705141067505\n",
      "  timers:\n",
      "    learn_throughput: 11455.25\n",
      "    learn_time_ms: 2.793\n",
      "    update_time_ms: 2.03\n",
      "  timestamp: 1613859442\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17000\n",
      "  training_iteration: 17\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-29\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2081410.440255032\n",
      "  episode_reward_mean: 1851649.343425528\n",
      "  episode_reward_min: 1041043.3620272102\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 950\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 18640\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 592028.125\n",
      "        mean_q: 320013.25\n",
      "        mean_td_error: -231600.875\n",
      "        min_q: 67204.609375\n",
      "        model: {}\n",
      "    num_steps_sampled: 19000\n",
      "    num_steps_trained: 144032\n",
      "    num_target_updates: 36\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.699999999999996\n",
      "    ram_util_percent: 67.6\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04985173903293403\n",
      "    mean_env_wait_ms: 0.07036228565561892\n",
      "    mean_inference_ms: 0.6331291827107814\n",
      "    mean_raw_obs_processing_ms: 0.09276647814876551\n",
      "  time_since_restore: 65.78442454338074\n",
      "  time_this_iter_s: 3.4190380573272705\n",
      "  time_total_s: 65.78442454338074\n",
      "  timers:\n",
      "    learn_throughput: 11346.019\n",
      "    learn_time_ms: 2.82\n",
      "    update_time_ms: 2.074\n",
      "  timestamp: 1613859449\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19000\n",
      "  training_iteration: 19\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         62.3497</td><td style=\"text-align: right;\">18000</td><td style=\"text-align: right;\">2.06974e+06</td><td style=\"text-align: right;\">         2.19955e+06</td><td style=\"text-align: right;\">         1.42621e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         65.7844</td><td style=\"text-align: right;\">19000</td><td style=\"text-align: right;\">1.85165e+06</td><td style=\"text-align: right;\">         2.08141e+06</td><td style=\"text-align: right;\">         1.04104e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-29\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2154564.0646055103\n",
      "  episode_reward_mean: 2044573.8382150293\n",
      "  episode_reward_min: 1354654.3567063524\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 950\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 18640\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 541874.125\n",
      "        mean_q: 234074.28125\n",
      "        mean_td_error: -247755.578125\n",
      "        min_q: -58498.421875\n",
      "        model: {}\n",
      "    num_steps_sampled: 19000\n",
      "    num_steps_trained: 144032\n",
      "    num_target_updates: 36\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.67999999999999\n",
      "    ram_util_percent: 67.6\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048826275682380994\n",
      "    mean_env_wait_ms: 0.07100833613334567\n",
      "    mean_inference_ms: 0.6397541346791271\n",
      "    mean_raw_obs_processing_ms: 0.09118639221484265\n",
      "  time_since_restore: 65.77082586288452\n",
      "  time_this_iter_s: 3.4211068153381348\n",
      "  time_total_s: 65.77082586288452\n",
      "  timers:\n",
      "    learn_throughput: 11641.446\n",
      "    learn_time_ms: 2.749\n",
      "    update_time_ms: 2.028\n",
      "  timestamp: 1613859449\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19000\n",
      "  training_iteration: 19\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-37\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2064316.7672515498\n",
      "  episode_reward_mean: 1878382.6719761353\n",
      "  episode_reward_min: 1197095.5912141434\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1050\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 20656\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 701356.75\n",
      "        mean_q: 454769.875\n",
      "        mean_td_error: -211929.703125\n",
      "        min_q: 56565.46875\n",
      "        model: {}\n",
      "    num_steps_sampled: 21000\n",
      "    num_steps_trained: 160032\n",
      "    num_target_updates: 40\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.5\n",
      "    ram_util_percent: 66.96\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04997228890974139\n",
      "    mean_env_wait_ms: 0.07055925040912499\n",
      "    mean_inference_ms: 0.634397693721728\n",
      "    mean_raw_obs_processing_ms: 0.09295927167157625\n",
      "  time_since_restore: 73.3860969543457\n",
      "  time_this_iter_s: 3.942639112472534\n",
      "  time_total_s: 73.3860969543457\n",
      "  timers:\n",
      "    learn_throughput: 9799.06\n",
      "    learn_time_ms: 3.266\n",
      "    update_time_ms: 2.973\n",
      "  timestamp: 1613859457\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 21000\n",
      "  training_iteration: 21\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         69.4266</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">2.02836e+06</td><td style=\"text-align: right;\">         2.25194e+06</td><td style=\"text-align: right;\">         1.19405e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         73.3861</td><td style=\"text-align: right;\">21000</td><td style=\"text-align: right;\">1.87838e+06</td><td style=\"text-align: right;\">         2.06432e+06</td><td style=\"text-align: right;\">         1.1971e+06 </td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-37\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2251935.4670786373\n",
      "  episode_reward_mean: 2051134.7670106902\n",
      "  episode_reward_min: 1194048.199768728\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1050\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 20656\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 655411.4375\n",
      "        mean_q: 371182.875\n",
      "        mean_td_error: -287562.375\n",
      "        min_q: -6845.859375\n",
      "        model: {}\n",
      "    num_steps_sampled: 21000\n",
      "    num_steps_trained: 160032\n",
      "    num_target_updates: 40\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.620000000000005\n",
      "    ram_util_percent: 66.96\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048955663273084295\n",
      "    mean_env_wait_ms: 0.07119112106706113\n",
      "    mean_inference_ms: 0.6412845270876185\n",
      "    mean_raw_obs_processing_ms: 0.09142482475933622\n",
      "  time_since_restore: 73.40203189849854\n",
      "  time_this_iter_s: 3.975429058074951\n",
      "  time_total_s: 73.40203189849854\n",
      "  timers:\n",
      "    learn_throughput: 8591.694\n",
      "    learn_time_ms: 3.725\n",
      "    update_time_ms: 3.877\n",
      "  timestamp: 1613859457\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 21000\n",
      "  training_iteration: 21\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-44\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2037840.4875209022\n",
      "  episode_reward_mean: 1862773.9870891408\n",
      "  episode_reward_min: 1371025.029986427\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1150\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 22672\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 822975.9375\n",
      "        mean_q: 456706.4375\n",
      "        mean_td_error: -354066.1875\n",
      "        min_q: 90283.015625\n",
      "        model: {}\n",
      "    num_steps_sampled: 23000\n",
      "    num_steps_trained: 176032\n",
      "    num_target_updates: 44\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.32000000000001\n",
      "    ram_util_percent: 67.53999999999999\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050252668269154636\n",
      "    mean_env_wait_ms: 0.07095510939172665\n",
      "    mean_inference_ms: 0.6375885304948503\n",
      "    mean_raw_obs_processing_ms: 0.0934352699732156\n",
      "  time_since_restore: 80.85501599311829\n",
      "  time_this_iter_s: 3.641824960708618\n",
      "  time_total_s: 80.85501599311829\n",
      "  timers:\n",
      "    learn_throughput: 10925.512\n",
      "    learn_time_ms: 2.929\n",
      "    update_time_ms: 2.091\n",
      "  timestamp: 1613859464\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 23000\n",
      "  training_iteration: 23\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         77.2126</td><td style=\"text-align: right;\">22000</td><td style=\"text-align: right;\">2.06533e+06</td><td style=\"text-align: right;\">         2.23283e+06</td><td style=\"text-align: right;\">         1.35465e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         80.855 </td><td style=\"text-align: right;\">23000</td><td style=\"text-align: right;\">1.86277e+06</td><td style=\"text-align: right;\">         2.03784e+06</td><td style=\"text-align: right;\">         1.37103e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-44\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2156854.534893272\n",
      "  episode_reward_mean: 2069179.8613724457\n",
      "  episode_reward_min: 1354654.3567063524\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1150\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 22672\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 773265.75\n",
      "        mean_q: 445328.9375\n",
      "        mean_td_error: -286017.75\n",
      "        min_q: 20400.84375\n",
      "        model: {}\n",
      "    num_steps_sampled: 23000\n",
      "    num_steps_trained: 176032\n",
      "    num_target_updates: 44\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.239999999999995\n",
      "    ram_util_percent: 67.53999999999999\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049313514937940325\n",
      "    mean_env_wait_ms: 0.07163554460669264\n",
      "    mean_inference_ms: 0.6450766004184526\n",
      "    mean_raw_obs_processing_ms: 0.09193034010547006\n",
      "  time_since_restore: 80.84675073623657\n",
      "  time_this_iter_s: 3.6341378688812256\n",
      "  time_total_s: 80.84675073623657\n",
      "  timers:\n",
      "    learn_throughput: 11511.349\n",
      "    learn_time_ms: 2.78\n",
      "    update_time_ms: 2.105\n",
      "  timestamp: 1613859464\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 23000\n",
      "  training_iteration: 23\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-51\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2018321.5956619922\n",
      "  episode_reward_mean: 1878449.4995114072\n",
      "  episode_reward_min: 1224668.7370800101\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1250\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 24688\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 945394.0\n",
      "        mean_q: 439178.375\n",
      "        mean_td_error: -301415.96875\n",
      "        min_q: 9854.5625\n",
      "        model: {}\n",
      "    num_steps_sampled: 25000\n",
      "    num_steps_trained: 192032\n",
      "    num_target_updates: 48\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.0\n",
      "    ram_util_percent: 67.3\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05022543440999877\n",
      "    mean_env_wait_ms: 0.07094971483566419\n",
      "    mean_inference_ms: 0.6372156722515492\n",
      "    mean_raw_obs_processing_ms: 0.09339467610488716\n",
      "  time_since_restore: 87.94870018959045\n",
      "  time_this_iter_s: 3.5076732635498047\n",
      "  time_total_s: 87.94870018959045\n",
      "  timers:\n",
      "    learn_throughput: 10682.553\n",
      "    learn_time_ms: 2.996\n",
      "    update_time_ms: 2.249\n",
      "  timestamp: 1613859471\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 25000\n",
      "  training_iteration: 25\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         84.43  </td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">2.05818e+06</td><td style=\"text-align: right;\">         2.15224e+06</td><td style=\"text-align: right;\">         1.35465e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         87.9487</td><td style=\"text-align: right;\">25000</td><td style=\"text-align: right;\">1.87845e+06</td><td style=\"text-align: right;\">         2.01832e+06</td><td style=\"text-align: right;\">         1.22467e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-52\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2185705.6274847714\n",
      "  episode_reward_mean: 2068637.2995920097\n",
      "  episode_reward_min: 1422991.228745043\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1250\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 24688\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 898838.375\n",
      "        mean_q: 439102.59375\n",
      "        mean_td_error: -304886.3125\n",
      "        min_q: -112.34375\n",
      "        model: {}\n",
      "    num_steps_sampled: 25000\n",
      "    num_steps_trained: 192032\n",
      "    num_target_updates: 48\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.9\n",
      "    ram_util_percent: 67.3\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04929721103777479\n",
      "    mean_env_wait_ms: 0.07163872950937283\n",
      "    mean_inference_ms: 0.644485771347342\n",
      "    mean_raw_obs_processing_ms: 0.09188196703192726\n",
      "  time_since_restore: 87.94338846206665\n",
      "  time_this_iter_s: 3.51338791847229\n",
      "  time_total_s: 87.94338846206665\n",
      "  timers:\n",
      "    learn_throughput: 11647.71\n",
      "    learn_time_ms: 2.747\n",
      "    update_time_ms: 2.254\n",
      "  timestamp: 1613859472\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 25000\n",
      "  training_iteration: 25\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-58\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 1964316.7672515498\n",
      "  episode_reward_mean: 1866259.0191658216\n",
      "  episode_reward_min: 1243943.561231188\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1350\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 26704\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1081375.75\n",
      "        mean_q: 567032.3125\n",
      "        mean_td_error: -419910.5\n",
      "        min_q: 61561.59375\n",
      "        model: {}\n",
      "    num_steps_sampled: 27000\n",
      "    num_steps_trained: 208032\n",
      "    num_target_updates: 52\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.980000000000004\n",
      "    ram_util_percent: 67.38\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050115502673225884\n",
      "    mean_env_wait_ms: 0.07083885393061028\n",
      "    mean_inference_ms: 0.6357837549405444\n",
      "    mean_raw_obs_processing_ms: 0.09319413606397753\n",
      "  time_since_restore: 94.85836911201477\n",
      "  time_this_iter_s: 3.4640231132507324\n",
      "  time_total_s: 94.85836911201477\n",
      "  timers:\n",
      "    learn_throughput: 11113.591\n",
      "    learn_time_ms: 2.879\n",
      "    update_time_ms: 2.017\n",
      "  timestamp: 1613859478\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 27000\n",
      "  training_iteration: 27\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         91.3819</td><td style=\"text-align: right;\">26000</td><td style=\"text-align: right;\">2.09008e+06</td><td style=\"text-align: right;\">         2.18571e+06</td><td style=\"text-align: right;\">         1.43481e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         94.8584</td><td style=\"text-align: right;\">27000</td><td style=\"text-align: right;\">1.86626e+06</td><td style=\"text-align: right;\">         1.96432e+06</td><td style=\"text-align: right;\">         1.24394e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-17-58\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2262287.3671901133\n",
      "  episode_reward_mean: 2101820.504389241\n",
      "  episode_reward_min: 1510267.8590025888\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1350\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 26704\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1030652.3125\n",
      "        mean_q: 530174.6875\n",
      "        mean_td_error: -435999.4375\n",
      "        min_q: 188250.359375\n",
      "        model: {}\n",
      "    num_steps_sampled: 27000\n",
      "    num_steps_trained: 208032\n",
      "    num_target_updates: 52\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.96\n",
      "    ram_util_percent: 67.38\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04919623015258916\n",
      "    mean_env_wait_ms: 0.07152073623817723\n",
      "    mean_inference_ms: 0.6429046670620524\n",
      "    mean_raw_obs_processing_ms: 0.09169927812691968\n",
      "  time_since_restore: 94.84757232666016\n",
      "  time_this_iter_s: 3.4656739234924316\n",
      "  time_total_s: 94.84757232666016\n",
      "  timers:\n",
      "    learn_throughput: 11566.505\n",
      "    learn_time_ms: 2.767\n",
      "    update_time_ms: 1.972\n",
      "  timestamp: 1613859478\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 27000\n",
      "  training_iteration: 27\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-18-06\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2022474.4871391589\n",
      "  episode_reward_mean: 1878267.5104692099\n",
      "  episode_reward_min: 1300731.1663271629\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1450\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 28720\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1213528.375\n",
      "        mean_q: 586539.625\n",
      "        mean_td_error: -524142.09375\n",
      "        min_q: 96611.28125\n",
      "        model: {}\n",
      "    num_steps_sampled: 29000\n",
      "    num_steps_trained: 224032\n",
      "    num_target_updates: 56\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.583333333333336\n",
      "    ram_util_percent: 70.08333333333333\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050265498409762105\n",
      "    mean_env_wait_ms: 0.07105376224666515\n",
      "    mean_inference_ms: 0.6370782822821534\n",
      "    mean_raw_obs_processing_ms: 0.09346464072009156\n",
      "  time_since_restore: 102.78508472442627\n",
      "  time_this_iter_s: 4.206658840179443\n",
      "  time_total_s: 102.78508472442627\n",
      "  timers:\n",
      "    learn_throughput: 10348.321\n",
      "    learn_time_ms: 3.092\n",
      "    update_time_ms: 2.469\n",
      "  timestamp: 1613859486\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 29000\n",
      "  training_iteration: 29\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         98.5801</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">2.10803e+06</td><td style=\"text-align: right;\">         2.26229e+06</td><td style=\"text-align: right;\">         1.64699e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">        102.785 </td><td style=\"text-align: right;\">29000</td><td style=\"text-align: right;\">1.87827e+06</td><td style=\"text-align: right;\">         2.02247e+06</td><td style=\"text-align: right;\">         1.30073e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-18-06\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2251511.811422866\n",
      "  episode_reward_mean: 2090056.6860822102\n",
      "  episode_reward_min: 1466654.3567063524\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1450\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 28720\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1165027.875\n",
      "        mean_q: 540751.125\n",
      "        mean_td_error: -443938.625\n",
      "        min_q: 30311.5\n",
      "        model: {}\n",
      "    num_steps_sampled: 29000\n",
      "    num_steps_trained: 224032\n",
      "    num_target_updates: 56\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.51666666666667\n",
      "    ram_util_percent: 69.38333333333333\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04933794027429137\n",
      "    mean_env_wait_ms: 0.07173308262298646\n",
      "    mean_inference_ms: 0.6447105122426484\n",
      "    mean_raw_obs_processing_ms: 0.09193655645010551\n",
      "  time_since_restore: 102.74097299575806\n",
      "  time_this_iter_s: 4.160869836807251\n",
      "  time_total_s: 102.74097299575806\n",
      "  timers:\n",
      "    learn_throughput: 11034.738\n",
      "    learn_time_ms: 2.9\n",
      "    update_time_ms: 2.498\n",
      "  timestamp: 1613859486\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 29000\n",
      "  training_iteration: 29\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-18-14\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2034164.0786499875\n",
      "  episode_reward_mean: 1877606.2108140397\n",
      "  episode_reward_min: 1372105.336155959\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1550\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 30736\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1356604.375\n",
      "        mean_q: 695248.75\n",
      "        mean_td_error: -492115.625\n",
      "        min_q: 29473.1171875\n",
      "        model: {}\n",
      "    num_steps_sampled: 31000\n",
      "    num_steps_trained: 240032\n",
      "    num_target_updates: 60\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.56666666666667\n",
      "    ram_util_percent: 72.53333333333333\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050622763604584585\n",
      "    mean_env_wait_ms: 0.07152263364298142\n",
      "    mean_inference_ms: 0.6409838198164602\n",
      "    mean_raw_obs_processing_ms: 0.09406979525281887\n",
      "  time_since_restore: 110.57054257392883\n",
      "  time_this_iter_s: 3.8644070625305176\n",
      "  time_total_s: 110.57054257392883\n",
      "  timers:\n",
      "    learn_throughput: 10483.221\n",
      "    learn_time_ms: 3.052\n",
      "    update_time_ms: 2.149\n",
      "  timestamp: 1613859494\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 31000\n",
      "  training_iteration: 31\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         106.675</td><td style=\"text-align: right;\">30000</td><td style=\"text-align: right;\">2.07149e+06</td><td style=\"text-align: right;\">         2.16779e+06</td><td style=\"text-align: right;\">         1.43481e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         110.571</td><td style=\"text-align: right;\">31000</td><td style=\"text-align: right;\">1.87761e+06</td><td style=\"text-align: right;\">         2.03416e+06</td><td style=\"text-align: right;\">         1.37211e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-18-14\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2199554.1752799936\n",
      "  episode_reward_mean: 2084601.316921298\n",
      "  episode_reward_min: 1434807.1148746118\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1550\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 30736\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1307633.125\n",
      "        mean_q: 681460.9375\n",
      "        mean_td_error: -514569.5625\n",
      "        min_q: 26531.40625\n",
      "        model: {}\n",
      "    num_steps_sampled: 31000\n",
      "    num_steps_trained: 240032\n",
      "    num_target_updates: 60\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 35.38333333333333\n",
      "    ram_util_percent: 72.55\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04968838248638066\n",
      "    mean_env_wait_ms: 0.07220256754892353\n",
      "    mean_inference_ms: 0.6490916740906897\n",
      "    mean_raw_obs_processing_ms: 0.09252532039440148\n",
      "  time_since_restore: 110.54230189323425\n",
      "  time_this_iter_s: 3.8677818775177\n",
      "  time_total_s: 110.54230189323425\n",
      "  timers:\n",
      "    learn_throughput: 10929.337\n",
      "    learn_time_ms: 2.928\n",
      "    update_time_ms: 2.165\n",
      "  timestamp: 1613859494\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 31000\n",
      "  training_iteration: 31\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-18-22\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2017672.5843321767\n",
      "  episode_reward_mean: 1871778.2494650937\n",
      "  episode_reward_min: 1224668.7370800101\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1650\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 32752\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1515724.75\n",
      "        mean_q: 813880.4375\n",
      "        mean_td_error: -547259.25\n",
      "        min_q: 30460.5390625\n",
      "        model: {}\n",
      "    num_steps_sampled: 33000\n",
      "    num_steps_trained: 256032\n",
      "    num_target_updates: 64\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.28333333333333\n",
      "    ram_util_percent: 70.65\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05080013923926334\n",
      "    mean_env_wait_ms: 0.07179017505607241\n",
      "    mean_inference_ms: 0.6435166115164853\n",
      "    mean_raw_obs_processing_ms: 0.09433874851306027\n",
      "  time_since_restore: 118.4827835559845\n",
      "  time_this_iter_s: 4.237218141555786\n",
      "  time_total_s: 118.4827835559845\n",
      "  timers:\n",
      "    learn_throughput: 10454.315\n",
      "    learn_time_ms: 3.061\n",
      "    update_time_ms: 2.2\n",
      "  timestamp: 1613859502\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 33000\n",
      "  training_iteration: 33\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         114.214</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">2.09896e+06</td><td style=\"text-align: right;\">         2.22266e+06</td><td style=\"text-align: right;\">         1.29922e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         118.483</td><td style=\"text-align: right;\">33000</td><td style=\"text-align: right;\">1.87178e+06</td><td style=\"text-align: right;\">         2.01767e+06</td><td style=\"text-align: right;\">         1.22467e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-18-22\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2222657.276529594\n",
      "  episode_reward_mean: 2061966.461641726\n",
      "  episode_reward_min: 1299222.8992012762\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1650\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 32752\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1460597.5\n",
      "        mean_q: 713458.875\n",
      "        mean_td_error: -568925.5\n",
      "        min_q: 103254.78125\n",
      "        model: {}\n",
      "    num_steps_sampled: 33000\n",
      "    num_steps_trained: 256032\n",
      "    num_target_updates: 64\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.26666666666667\n",
      "    ram_util_percent: 70.61666666666666\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04990356260998497\n",
      "    mean_env_wait_ms: 0.07248674576410466\n",
      "    mean_inference_ms: 0.6516649171896831\n",
      "    mean_raw_obs_processing_ms: 0.09285169349760675\n",
      "  time_since_restore: 118.45218396186829\n",
      "  time_this_iter_s: 4.237945079803467\n",
      "  time_total_s: 118.45218396186829\n",
      "  timers:\n",
      "    learn_throughput: 10597.28\n",
      "    learn_time_ms: 3.02\n",
      "    update_time_ms: 2.193\n",
      "  timestamp: 1613859502\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 33000\n",
      "  training_iteration: 33\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-18-30\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2070293.863659264\n",
      "  episode_reward_mean: 1849438.3019518114\n",
      "  episode_reward_min: 1143943.561231188\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1750\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 34768\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1659497.0\n",
      "        mean_q: 742315.5\n",
      "        mean_td_error: -595792.5\n",
      "        min_q: 5925.0185546875\n",
      "        model: {}\n",
      "    num_steps_sampled: 35000\n",
      "    num_steps_trained: 272032\n",
      "    num_target_updates: 68\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.080000000000005\n",
      "    ram_util_percent: 69.05999999999999\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.051015996795274285\n",
      "    mean_env_wait_ms: 0.07206558167006193\n",
      "    mean_inference_ms: 0.6459237548018095\n",
      "    mean_raw_obs_processing_ms: 0.09469899877308567\n",
      "  time_since_restore: 125.84234046936035\n",
      "  time_this_iter_s: 3.629124879837036\n",
      "  time_total_s: 125.84234046936035\n",
      "  timers:\n",
      "    learn_throughput: 10771.715\n",
      "    learn_time_ms: 2.971\n",
      "    update_time_ms: 2.229\n",
      "  timestamp: 1613859510\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 35000\n",
      "  training_iteration: 35\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         122.147</td><td style=\"text-align: right;\">34000</td><td style=\"text-align: right;\">2.06707e+06</td><td style=\"text-align: right;\">         2.15224e+06</td><td style=\"text-align: right;\">         1.35465e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         125.842</td><td style=\"text-align: right;\">35000</td><td style=\"text-align: right;\">1.84944e+06</td><td style=\"text-align: right;\">         2.07029e+06</td><td style=\"text-align: right;\">         1.14394e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-18-30\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2152235.0909274113\n",
      "  episode_reward_mean: 2084270.9094617667\n",
      "  episode_reward_min: 1354654.3567063524\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1750\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 34768\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1613109.25\n",
      "        mean_q: 899843.375\n",
      "        mean_td_error: -534782.1875\n",
      "        min_q: 201714.71875\n",
      "        model: {}\n",
      "    num_steps_sampled: 35000\n",
      "    num_steps_trained: 272032\n",
      "    num_target_updates: 68\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.019999999999996\n",
      "    ram_util_percent: 69.08\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050119057344079926\n",
      "    mean_env_wait_ms: 0.07274517412426547\n",
      "    mean_inference_ms: 0.6539987283399432\n",
      "    mean_raw_obs_processing_ms: 0.09313150454715056\n",
      "  time_since_restore: 125.77592611312866\n",
      "  time_this_iter_s: 3.628847122192383\n",
      "  time_total_s: 125.77592611312866\n",
      "  timers:\n",
      "    learn_throughput: 12428.143\n",
      "    learn_time_ms: 2.575\n",
      "    update_time_ms: 2.895\n",
      "  timestamp: 1613859510\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 35000\n",
      "  training_iteration: 35\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-18-37\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 1952982.2128134703\n",
      "  episode_reward_mean: 1862161.159992993\n",
      "  episode_reward_min: 1133386.2803311795\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1850\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 36784\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1786977.5\n",
      "        mean_q: 952862.25\n",
      "        mean_td_error: -539651.875\n",
      "        min_q: 157304.40625\n",
      "        model: {}\n",
      "    num_steps_sampled: 37000\n",
      "    num_steps_trained: 288032\n",
      "    num_target_updates: 72\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.4\n",
      "    ram_util_percent: 68.52000000000001\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.051057638705134106\n",
      "    mean_env_wait_ms: 0.07213599672708924\n",
      "    mean_inference_ms: 0.6459065456532831\n",
      "    mean_raw_obs_processing_ms: 0.09473571910094628\n",
      "  time_since_restore: 133.14276337623596\n",
      "  time_this_iter_s: 3.7029640674591064\n",
      "  time_total_s: 133.14276337623596\n",
      "  timers:\n",
      "    learn_throughput: 7441.822\n",
      "    learn_time_ms: 4.3\n",
      "    update_time_ms: 2.965\n",
      "  timestamp: 1613859517\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 37000\n",
      "  training_iteration: 37\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         129.365</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">2.05529e+06</td><td style=\"text-align: right;\">         2.15224e+06</td><td style=\"text-align: right;\">         1.29922e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         133.143</td><td style=\"text-align: right;\">37000</td><td style=\"text-align: right;\">1.86216e+06</td><td style=\"text-align: right;\">         1.95298e+06</td><td style=\"text-align: right;\">         1.13339e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-18-37\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2243931.0139695155\n",
      "  episode_reward_mean: 2058794.9548354403\n",
      "  episode_reward_min: 1299222.8992012762\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1850\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 36784\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1763934.75\n",
      "        mean_q: 905508.4375\n",
      "        mean_td_error: -664959.875\n",
      "        min_q: 66306.703125\n",
      "        model: {}\n",
      "    num_steps_sampled: 37000\n",
      "    num_steps_trained: 288032\n",
      "    num_target_updates: 72\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.800000000000004\n",
      "    ram_util_percent: 68.55\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050177518086696245\n",
      "    mean_env_wait_ms: 0.0728286091376875\n",
      "    mean_inference_ms: 0.6541656731049715\n",
      "    mean_raw_obs_processing_ms: 0.09318799490581707\n",
      "  time_since_restore: 133.07144379615784\n",
      "  time_this_iter_s: 3.705974817276001\n",
      "  time_total_s: 133.07144379615784\n",
      "  timers:\n",
      "    learn_throughput: 8635.752\n",
      "    learn_time_ms: 3.706\n",
      "    update_time_ms: 2.813\n",
      "  timestamp: 1613859517\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 37000\n",
      "  training_iteration: 37\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-18-45\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2070798.4568810721\n",
      "  episode_reward_mean: 1856833.5466334168\n",
      "  episode_reward_min: 1143943.561231188\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1950\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 38800\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1913768.5\n",
      "        mean_q: 963439.375\n",
      "        mean_td_error: -685476.4375\n",
      "        min_q: 129764.125\n",
      "        model: {}\n",
      "    num_steps_sampled: 39000\n",
      "    num_steps_trained: 304032\n",
      "    num_target_updates: 76\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 43.76\n",
      "    ram_util_percent: 68.96000000000001\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0511667252496286\n",
      "    mean_env_wait_ms: 0.07233457872866189\n",
      "    mean_inference_ms: 0.6475396690898348\n",
      "    mean_raw_obs_processing_ms: 0.09496006356517568\n",
      "  time_since_restore: 141.01399874687195\n",
      "  time_this_iter_s: 3.9158921241760254\n",
      "  time_total_s: 141.01399874687195\n",
      "  timers:\n",
      "    learn_throughput: 10274.412\n",
      "    learn_time_ms: 3.115\n",
      "    update_time_ms: 2.291\n",
      "  timestamp: 1613859525\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 39000\n",
      "  training_iteration: 39\n",
      "  trial_id: 3d98d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>RUNNING </td><td>192.168.0.23:94172</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         137.045</td><td style=\"text-align: right;\">38000</td><td style=\"text-align: right;\">2.0909e+06 </td><td style=\"text-align: right;\">         2.24393e+06</td><td style=\"text-align: right;\">         1.35465e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>RUNNING </td><td>192.168.0.23:94173</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         141.014</td><td style=\"text-align: right;\">39000</td><td style=\"text-align: right;\">1.85683e+06</td><td style=\"text-align: right;\">         2.0708e+06 </td><td style=\"text-align: right;\">         1.14394e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-18-45\n",
      "  done: false\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2225979.589711327\n",
      "  episode_reward_mean: 2093898.4153961309\n",
      "  episode_reward_min: 1244781.0260220836\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1950\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 38800\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1918086.25\n",
      "        mean_q: 899784.0\n",
      "        mean_td_error: -931158.1875\n",
      "        min_q: 363463.3125\n",
      "        model: {}\n",
      "    num_steps_sampled: 39000\n",
      "    num_steps_trained: 304032\n",
      "    num_target_updates: 76\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 43.5\n",
      "    ram_util_percent: 68.96666666666667\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05032327909996562\n",
      "    mean_env_wait_ms: 0.07303506552940951\n",
      "    mean_inference_ms: 0.6558540604485905\n",
      "    mean_raw_obs_processing_ms: 0.09340817766901276\n",
      "  time_since_restore: 140.9301290512085\n",
      "  time_this_iter_s: 3.8852570056915283\n",
      "  time_total_s: 140.9301290512085\n",
      "  timers:\n",
      "    learn_throughput: 10485.924\n",
      "    learn_time_ms: 3.052\n",
      "    update_time_ms: 2.251\n",
      "  timestamp: 1613859525\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 39000\n",
      "  training_iteration: 39\n",
      "  trial_id: 3d98d_00000\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-18-49\n",
      "  done: true\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 1970293.863659264\n",
      "  episode_reward_mean: 1873229.2402273684\n",
      "  episode_reward_min: 1300731.1663271629\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 2000\n",
      "  experiment_id: ae539141d47241e787c4412d439bb7d3\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 39808\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1979708.0\n",
      "        mean_q: 1100980.875\n",
      "        mean_td_error: -676833.9375\n",
      "        min_q: 225728.5625\n",
      "        model: {}\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 312032\n",
      "    num_target_updates: 78\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.083333333333336\n",
      "    ram_util_percent: 69.1\n",
      "  pid: 94173\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.051301788100067934\n",
      "    mean_env_wait_ms: 0.0725319134932424\n",
      "    mean_inference_ms: 0.6489508933067663\n",
      "    mean_raw_obs_processing_ms: 0.0952247892483927\n",
      "  time_since_restore: 145.10633778572083\n",
      "  time_this_iter_s: 4.092339038848877\n",
      "  time_total_s: 145.10633778572083\n",
      "  timers:\n",
      "    learn_throughput: 8508.525\n",
      "    learn_time_ms: 3.761\n",
      "    update_time_ms: 2.964\n",
      "  timestamp: 1613859529\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 40\n",
      "  trial_id: 3d98d_00001\n",
      "  \n",
      "Result for DQN_PriceEnv_3d98d_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-18-49\n",
      "  done: true\n",
      "  episode_len_mean: 20.0\n",
      "  episode_reward_max: 2189967.7335393187\n",
      "  episode_reward_mean: 2095445.5886946884\n",
      "  episode_reward_min: 1244781.0260220836\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 2000\n",
      "  experiment_id: 501f51f57d16491bbd6113368468c489\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 39808\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1994266.5\n",
      "        mean_q: 1083705.625\n",
      "        mean_td_error: -840130.0\n",
      "        min_q: 235103.125\n",
      "        model: {}\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 312032\n",
      "    num_target_updates: 78\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 36.2\n",
      "    ram_util_percent: 69.11666666666666\n",
      "  pid: 94172\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05047070543853991\n",
      "    mean_env_wait_ms: 0.0732314398835971\n",
      "    mean_inference_ms: 0.6576553374192677\n",
      "    mean_raw_obs_processing_ms: 0.09361524238697784\n",
      "  time_since_restore: 145.04262495040894\n",
      "  time_this_iter_s: 4.1124958992004395\n",
      "  time_total_s: 145.04262495040894\n",
      "  timers:\n",
      "    learn_throughput: 9619.619\n",
      "    learn_time_ms: 3.327\n",
      "    update_time_ms: 3.467\n",
      "  timestamp: 1613859529\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 40\n",
      "  trial_id: 3d98d_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/4.1 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DQN<br>Number of trials: 2/2 (2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         145.043</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">2.09545e+06</td><td style=\"text-align: right;\">         2.18997e+06</td><td style=\"text-align: right;\">         1.24478e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "<tr><td>DQN_PriceEnv_3d98d_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         145.106</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">1.87323e+06</td><td style=\"text-align: right;\">         1.97029e+06</td><td style=\"text-align: right;\">         1.30073e+06</td><td style=\"text-align: right;\">                20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-20 16:18:49,836\tINFO tune.py:448 -- Total run time: 157.45 seconds (156.99 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    ## Environment parameters\n",
    "    T = 20\n",
    "    price_max = 500\n",
    "    price_step = 10\n",
    "    q_0 = 5000\n",
    "    k = 20\n",
    "    unit_cost = 100\n",
    "    a_q = 300\n",
    "    b_q = 100\n",
    "\n",
    "    stop = {\n",
    "            \"training_iteration\": 40,\n",
    "            \"episode_reward_mean\": 10000000,\n",
    "        }\n",
    "\n",
    "    config = {\n",
    "            \"env\": p.PriceEnv, \n",
    "            # Use GPUs iff `RLLIB_NUM_GPUS` env var set to > 0.\n",
    "            \"num_gpus\": 0,\n",
    "            \"num_workers\": 1  # parallelism\n",
    "        }\n",
    "    \n",
    "    tune.run('DQN',num_samples=2,\n",
    "        stop=stop,\n",
    "        config=config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(iters =20, path='checkpoint'):\n",
    "    config = {\n",
    "        \"env\": p.PriceEnv, \n",
    "        # Use GPUs iff `RLLIB_NUM_GPUS` env var set to > 0.\n",
    "        \"num_gpus\": 0,\n",
    "        \"num_workers\": 2  # parallelism\n",
    "    }\n",
    "\n",
    "    trainer = dqn.DQNTrainer(env=p.PriceEnv, config=config)\n",
    "    n=0\n",
    "    while True:\n",
    "        if n>=iters:\n",
    "            break\n",
    "        trainer.train()\n",
    "        chkpt = trainer.save(path)\n",
    "        \n",
    "        n=+1\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    pass\n",
    "    #main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
