{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To view the tensorboard: \n",
    "    1: tensorboard --logdir ray_results \n",
    "    2: see http://localhost:6006/ in browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "from ray.tune.logger import pretty_print\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0: RLlib Training APIs: \n",
    "1: At a high level, RLlib provides an Trainer class which holds a policy for environment interaction. Through the trainer interface, the policy can be trained, checkpointed, or an action computed. In multi-agent training, the trainer manages the querying and optimization of multiple policies at once.\n",
    "\n",
    "2: rllib train --run DQN --env CartPole-v0  --config '{\"num_workers\": 8}'\n",
    "    To see the tensorboard: tensorboard --logdir=~/ray_results\n",
    "\n",
    "3: rllib rollout ~/ray_results/default/DQN_CartPole-v0_0upjmdgr0/checkpoint_1/checkpoint-1 \\\n",
    "    --run DQN --env CartPole-v0 --steps 10000\n",
    "\n",
    "4: Loading and restoring a trained agent from a checkpoint is simple:\n",
    "    \n",
    "    agent = ppo.PPOTrainer(config=config, env=env_class)\n",
    "    agent.restore(checkpoint_path)\n",
    "    \n",
    "5: Computing Actions\n",
    "\n",
    "The simplest way to programmatically compute actions from a trained agent is to use trainer.compute_action(). This method preprocesses and filters the observation before passing it to the agent policy. Here is a simple example of testing a trained agent for one episode:\n",
    "\n",
    "    # instantiate env class\n",
    "    env = env_class(env_config)\n",
    "\n",
    "    # run until episode ends\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    while not done:\n",
    "        action = agent.compute_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_reward += reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 10:50:05,689\tINFO services.py:1263 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.0.42',\n",
       " 'raylet_ip_address': '192.168.0.42',\n",
       " 'redis_address': '192.168.0.42:27869',\n",
       " 'object_store_address': '/tmp/ray/session_2021-10-15_10-50-04_282399_1061/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-10-15_10-50-04_282399_1061/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8266',\n",
       " 'session_dir': '/tmp/ray/session_2021-10-15_10-50-04_282399_1061',\n",
       " 'metrics_export_port': 57969,\n",
       " 'node_id': '7d4c98cc3697a0840fae3f832d847c4bc04e4aae4ee62657176f6e19'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Example of Traing a PPO Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-30 21:13:18,338\tINFO trainer.py:714 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2021-09-30 21:13:18,341\tINFO ppo.py:158 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "2021-09-30 21:13:18,342\tINFO trainer.py:726 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2021-09-30 21:13:23,657\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-09-30 21:13:24,896\tWARNING deprecation.py:38 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved\n",
      "checkpoint saved\n",
      "checkpoint saved\n"
     ]
    }
   ],
   "source": [
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "config['num_gpus'] = 0\n",
    "config['num_workers'] = 2\n",
    "trainer = ppo.PPOTrainer(config = config, env='CartPole-v0') \n",
    "\n",
    "for i in range(30):\n",
    "    result = trainer.train()\n",
    "    if i % 10 ==0:\n",
    "        checkpoint = trainer.save()\n",
    "        print('checkpoint saved')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Example of Using Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.3/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (3 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.01  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.001 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1096)\u001b[0m 2021-10-15 10:50:22,046\tINFO trainer.py:714 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=1096)\u001b[0m 2021-10-15 10:50:22,046\tINFO ppo.py:158 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=1096)\u001b[0m 2021-10-15 10:50:22,046\tINFO trainer.py:726 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=1100)\u001b[0m 2021-10-15 10:50:22,046\tINFO trainer.py:714 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=1100)\u001b[0m 2021-10-15 10:50:22,046\tINFO ppo.py:158 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=1100)\u001b[0m 2021-10-15 10:50:22,046\tINFO trainer.py:726 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=1099)\u001b[0m 2021-10-15 10:50:22,046\tINFO trainer.py:714 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=1099)\u001b[0m 2021-10-15 10:50:22,046\tINFO ppo.py:158 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=1099)\u001b[0m 2021-10-15 10:50:22,046\tINFO trainer.py:726 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=1096)\u001b[0m 2021-10-15 10:50:27,567\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=1100)\u001b[0m 2021-10-15 10:50:27,567\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=1099)\u001b[0m 2021-10-15 10:50:27,567\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=1096)\u001b[0m 2021-10-15 10:50:29,161\tWARNING deprecation.py:38 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=1100)\u001b[0m 2021-10-15 10:50:29,158\tWARNING deprecation.py:38 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=1099)\u001b[0m 2021-10-15 10:50:29,153\tWARNING deprecation.py:38 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00001:\n",
      "  agent_timesteps_total: 4000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-50-31\n",
      "  done: false\n",
      "  episode_len_mean: 23.023121387283236\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 64.0\n",
      "  episode_reward_mean: 23.023121387283236\n",
      "  episode_reward_min: 8.0\n",
      "  episodes_this_iter: 173\n",
      "  episodes_total: 173\n",
      "  experiment_id: a7d670197b8449aca715ca10f26be361\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.6616495251655579\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.032735127955675125\n",
      "          model: {}\n",
      "          policy_loss: -0.05019322782754898\n",
      "          total_loss: 91.09257507324219\n",
      "          vf_explained_var: 0.28667253255844116\n",
      "          vf_loss: 91.13622283935547\n",
      "    num_agent_steps_sampled: 4000\n",
      "    num_agent_steps_trained: 4000\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.36666666666667\n",
      "    ram_util_percent: 66.43333333333334\n",
      "  pid: 1099\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03723515983584827\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.044942834352198494\n",
      "    mean_inference_ms: 0.6238586854621045\n",
      "    mean_raw_obs_processing_ms: 0.05864134756988786\n",
      "  time_since_restore: 3.872073173522949\n",
      "  time_this_iter_s: 3.872073173522949\n",
      "  time_total_s: 3.872073173522949\n",
      "  timers:\n",
      "    learn_throughput: 1756.099\n",
      "    learn_time_ms: 2277.776\n",
      "    load_throughput: 114130721.088\n",
      "    load_time_ms: 0.035\n",
      "    sample_throughput: 2531.518\n",
      "    sample_time_ms: 1580.08\n",
      "    update_time_ms: 1.616\n",
      "  timestamp: 1634313031\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: 97f47_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.3/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 9.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING </td><td>                 </td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>RUNNING </td><td>192.168.0.42:1099</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.87207</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\"> 23.0231</td><td style=\"text-align: right;\">                  64</td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">           23.0231</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>RUNNING </td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 4000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-50-31\n",
      "  done: false\n",
      "  episode_len_mean: 23.53846153846154\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 80.0\n",
      "  episode_reward_mean: 23.53846153846154\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 169\n",
      "  episodes_total: 169\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.6601420640945435\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03442293405532837\n",
      "          model: {}\n",
      "          policy_loss: -0.03388642519712448\n",
      "          total_loss: 99.54802703857422\n",
      "          vf_explained_var: 0.3093220889568329\n",
      "          vf_loss: 99.57502746582031\n",
      "    num_agent_steps_sampled: 4000\n",
      "    num_agent_steps_trained: 4000\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.36666666666667\n",
      "    ram_util_percent: 66.43333333333334\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.038625333379739814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04508713896509079\n",
      "    mean_inference_ms: 0.6285009610074415\n",
      "    mean_raw_obs_processing_ms: 0.05938767808012915\n",
      "  time_since_restore: 3.8729240894317627\n",
      "  time_this_iter_s: 3.8729240894317627\n",
      "  time_total_s: 3.8729240894317627\n",
      "  timers:\n",
      "    learn_throughput: 1761.865\n",
      "    learn_time_ms: 2270.321\n",
      "    load_throughput: 223696213.333\n",
      "    load_time_ms: 0.018\n",
      "    sample_throughput: 2515.361\n",
      "    sample_time_ms: 1590.229\n",
      "    update_time_ms: 2.15\n",
      "  timestamp: 1634313031\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: 97f47_00000\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00002:\n",
      "  agent_timesteps_total: 4000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-50-31\n",
      "  done: false\n",
      "  episode_len_mean: 20.647668393782382\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 50.0\n",
      "  episode_reward_mean: 20.647668393782382\n",
      "  episode_reward_min: 8.0\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 193\n",
      "  experiment_id: d20693eb10024d9ab0f562ddf7dfc3be\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.6631982326507568\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.030527537688612938\n",
      "          model: {}\n",
      "          policy_loss: -0.04670911282300949\n",
      "          total_loss: 100.88372039794922\n",
      "          vf_explained_var: 0.11864408850669861\n",
      "          vf_loss: 100.92431640625\n",
      "    num_agent_steps_sampled: 4000\n",
      "    num_agent_steps_trained: 4000\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.36666666666667\n",
      "    ram_util_percent: 66.43333333333334\n",
      "  pid: 1100\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03778553662689772\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.044095380170431735\n",
      "    mean_inference_ms: 0.6291657759621718\n",
      "    mean_raw_obs_processing_ms: 0.06008342907452713\n",
      "  time_since_restore: 3.8730578422546387\n",
      "  time_this_iter_s: 3.8730578422546387\n",
      "  time_total_s: 3.8730578422546387\n",
      "  timers:\n",
      "    learn_throughput: 1761.346\n",
      "    learn_time_ms: 2270.991\n",
      "    load_throughput: 220752842.105\n",
      "    load_time_ms: 0.018\n",
      "    sample_throughput: 2517.65\n",
      "    sample_time_ms: 1588.783\n",
      "    update_time_ms: 1.755\n",
      "  timestamp: 1634313031\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: 97f47_00002\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00001:\n",
      "  agent_timesteps_total: 12000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-50-38\n",
      "  done: false\n",
      "  episode_len_mean: 74.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 74.56\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 280\n",
      "  experiment_id: a7d670197b8449aca715ca10f26be361\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5792536735534668\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007844598032534122\n",
      "          model: {}\n",
      "          policy_loss: -0.014843439683318138\n",
      "          total_loss: 532.12255859375\n",
      "          vf_explained_var: 0.13959193229675293\n",
      "          vf_loss: 532.1339111328125\n",
      "    num_agent_steps_sampled: 12000\n",
      "    num_agent_steps_trained: 12000\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 12000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.9\n",
      "    ram_util_percent: 67.63333333333334\n",
      "  pid: 1099\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.038306859212926495\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04640040591142011\n",
      "    mean_inference_ms: 0.6378516977298668\n",
      "    mean_raw_obs_processing_ms: 0.05658387753120432\n",
      "  time_since_restore: 11.261813879013062\n",
      "  time_this_iter_s: 3.6260719299316406\n",
      "  time_total_s: 11.261813879013062\n",
      "  timers:\n",
      "    learn_throughput: 1869.061\n",
      "    learn_time_ms: 2140.112\n",
      "    load_throughput: 170615755.932\n",
      "    load_time_ms: 0.023\n",
      "    sample_throughput: 2493.498\n",
      "    sample_time_ms: 1604.172\n",
      "    update_time_ms: 2.011\n",
      "  timestamp: 1634313038\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 3\n",
      "  trial_id: 97f47_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.4/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 9.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         7.7063 </td><td style=\"text-align: right;\"> 8000</td><td style=\"text-align: right;\">   42.69</td><td style=\"text-align: right;\">                 151</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             42.69</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>RUNNING </td><td>192.168.0.42:1099</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        11.2618 </td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">   74.56</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             74.56</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>RUNNING </td><td>192.168.0.42:1100</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         7.69307</td><td style=\"text-align: right;\"> 8000</td><td style=\"text-align: right;\">   43.16</td><td style=\"text-align: right;\">                 148</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             43.16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00002:\n",
      "  agent_timesteps_total: 12000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-50-39\n",
      "  done: false\n",
      "  episode_len_mean: 73.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 73.29\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 305\n",
      "  experiment_id: d20693eb10024d9ab0f562ddf7dfc3be\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.5829192996025085\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008481566794216633\n",
      "          model: {}\n",
      "          policy_loss: -0.0166219063103199\n",
      "          total_loss: 716.9107666015625\n",
      "          vf_explained_var: 0.12892436981201172\n",
      "          vf_loss: 716.9248657226562\n",
      "    num_agent_steps_sampled: 12000\n",
      "    num_agent_steps_trained: 12000\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 12000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.64\n",
      "    ram_util_percent: 67.66\n",
      "  pid: 1100\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04012023919230964\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04622103933069527\n",
      "    mean_inference_ms: 0.6485285967295382\n",
      "    mean_raw_obs_processing_ms: 0.05771911498764944\n",
      "  time_since_restore: 11.345820665359497\n",
      "  time_this_iter_s: 3.65275502204895\n",
      "  time_total_s: 11.345820665359497\n",
      "  timers:\n",
      "    learn_throughput: 1859.397\n",
      "    learn_time_ms: 2151.235\n",
      "    load_throughput: 217885922.078\n",
      "    load_time_ms: 0.018\n",
      "    sample_throughput: 2464.969\n",
      "    sample_time_ms: 1622.738\n",
      "    update_time_ms: 1.611\n",
      "  timestamp: 1634313039\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 3\n",
      "  trial_id: 97f47_00002\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 12000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-50-39\n",
      "  done: false\n",
      "  episode_len_mean: 62.47\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 62.47\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 302\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.5669329762458801\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03120461106300354\n",
      "          model: {}\n",
      "          policy_loss: -0.013125050812959671\n",
      "          total_loss: 442.0694885253906\n",
      "          vf_explained_var: 0.32932621240615845\n",
      "          vf_loss: 442.06854248046875\n",
      "    num_agent_steps_sampled: 12000\n",
      "    num_agent_steps_trained: 12000\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 12000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.64\n",
      "    ram_util_percent: 67.66\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04121871967969224\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04688870272795818\n",
      "    mean_inference_ms: 0.6499587487281279\n",
      "    mean_raw_obs_processing_ms: 0.05806138965511441\n",
      "  time_since_restore: 11.376895427703857\n",
      "  time_this_iter_s: 3.670598268508911\n",
      "  time_total_s: 11.376895427703857\n",
      "  timers:\n",
      "    learn_throughput: 1856.704\n",
      "    learn_time_ms: 2154.355\n",
      "    load_throughput: 203771854.251\n",
      "    load_time_ms: 0.02\n",
      "    sample_throughput: 2453.61\n",
      "    sample_time_ms: 1630.251\n",
      "    update_time_ms: 1.745\n",
      "  timestamp: 1634313039\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 3\n",
      "  trial_id: 97f47_00000\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00001:\n",
      "  agent_timesteps_total: 20000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-50-46\n",
      "  done: false\n",
      "  episode_len_mean: 126.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 126.87\n",
      "  episode_reward_min: 14.0\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 335\n",
      "  experiment_id: a7d670197b8449aca715ca10f26be361\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5548067688941956\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00861319899559021\n",
      "          model: {}\n",
      "          policy_loss: -0.01585177332162857\n",
      "          total_loss: 371.5794372558594\n",
      "          vf_explained_var: 0.32944339513778687\n",
      "          vf_loss: 371.5914001464844\n",
      "    num_agent_steps_sampled: 20000\n",
      "    num_agent_steps_trained: 20000\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.580000000000005\n",
      "    ram_util_percent: 68.8\n",
      "  pid: 1099\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.038883651353165814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04697261840029279\n",
      "    mean_inference_ms: 0.6407507763001032\n",
      "    mean_raw_obs_processing_ms: 0.05501466844824079\n",
      "  time_since_restore: 18.693442821502686\n",
      "  time_this_iter_s: 3.7126688957214355\n",
      "  time_total_s: 18.693442821502686\n",
      "  timers:\n",
      "    learn_throughput: 1889.614\n",
      "    learn_time_ms: 2116.834\n",
      "    load_throughput: 191520730.594\n",
      "    load_time_ms: 0.021\n",
      "    sample_throughput: 2480.368\n",
      "    sample_time_ms: 1612.664\n",
      "    update_time_ms: 2.105\n",
      "  timestamp: 1634313046\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 5\n",
      "  trial_id: 97f47_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.5/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 9.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         15.1435</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">   93.33</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             93.33</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>RUNNING </td><td>192.168.0.42:1099</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.6934</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">  126.87</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  14</td><td style=\"text-align: right;\">            126.87</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>RUNNING </td><td>192.168.0.42:1100</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         15.0983</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">  101.77</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            101.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00002:\n",
      "  agent_timesteps_total: 20000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-50-46\n",
      "  done: false\n",
      "  episode_len_mean: 129.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 129.05\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 350\n",
      "  experiment_id: d20693eb10024d9ab0f562ddf7dfc3be\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.15000000596046448\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.5596845746040344\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00785556435585022\n",
      "          model: {}\n",
      "          policy_loss: -0.009856896474957466\n",
      "          total_loss: 341.8866271972656\n",
      "          vf_explained_var: 0.37634173035621643\n",
      "          vf_loss: 341.8952941894531\n",
      "    num_agent_steps_sampled: 20000\n",
      "    num_agent_steps_trained: 20000\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.580000000000005\n",
      "    ram_util_percent: 68.8\n",
      "  pid: 1100\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0402038818480567\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0463368233193802\n",
      "    mean_inference_ms: 0.6486236670310161\n",
      "    mean_raw_obs_processing_ms: 0.05581274032648301\n",
      "  time_since_restore: 18.793498754501343\n",
      "  time_this_iter_s: 3.6951990127563477\n",
      "  time_total_s: 18.793498754501343\n",
      "  timers:\n",
      "    learn_throughput: 1872.659\n",
      "    learn_time_ms: 2136.0\n",
      "    load_throughput: 217321450.777\n",
      "    load_time_ms: 0.018\n",
      "    sample_throughput: 2476.383\n",
      "    sample_time_ms: 1615.259\n",
      "    update_time_ms: 1.647\n",
      "  timestamp: 1634313046\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 5\n",
      "  trial_id: 97f47_00002\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 20000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-50-46\n",
      "  done: false\n",
      "  episode_len_mean: 124.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 124.14\n",
      "  episode_reward_min: 15.0\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 349\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.5549951195716858\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010575810447335243\n",
      "          model: {}\n",
      "          policy_loss: -0.006955898366868496\n",
      "          total_loss: 276.2513732910156\n",
      "          vf_explained_var: 0.662449836730957\n",
      "          vf_loss: 276.2511901855469\n",
      "    num_agent_steps_sampled: 20000\n",
      "    num_agent_steps_trained: 20000\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.03333333333334\n",
      "    ram_util_percent: 68.81666666666666\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041094118405513386\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04703332212165057\n",
      "    mean_inference_ms: 0.6505602891038512\n",
      "    mean_raw_obs_processing_ms: 0.05648431954483625\n",
      "  time_since_restore: 18.856932640075684\n",
      "  time_this_iter_s: 3.713475227355957\n",
      "  time_total_s: 18.856932640075684\n",
      "  timers:\n",
      "    learn_throughput: 1873.455\n",
      "    learn_time_ms: 2135.092\n",
      "    load_throughput: 157090037.453\n",
      "    load_time_ms: 0.025\n",
      "    sample_throughput: 2454.988\n",
      "    sample_time_ms: 1629.336\n",
      "    update_time_ms: 1.641\n",
      "  timestamp: 1634313046\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 5\n",
      "  trial_id: 97f47_00000\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00001:\n",
      "  agent_timesteps_total: 28000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-50-53\n",
      "  done: false\n",
      "  episode_len_mean: 159.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 159.84\n",
      "  episode_reward_min: 15.0\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 380\n",
      "  experiment_id: a7d670197b8449aca715ca10f26be361\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5464768409729004\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006622851826250553\n",
      "          model: {}\n",
      "          policy_loss: -0.00778953405097127\n",
      "          total_loss: 274.103515625\n",
      "          vf_explained_var: 0.5200914740562439\n",
      "          vf_loss: 274.1083068847656\n",
      "    num_agent_steps_sampled: 28000\n",
      "    num_agent_steps_trained: 28000\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 28000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.440000000000005\n",
      "    ram_util_percent: 70.72\n",
      "  pid: 1099\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039239616250851726\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04739970996773717\n",
      "    mean_inference_ms: 0.6444520132766192\n",
      "    mean_raw_obs_processing_ms: 0.0540071519660016\n",
      "  time_since_restore: 25.7850558757782\n",
      "  time_this_iter_s: 3.4784669876098633\n",
      "  time_total_s: 25.7850558757782\n",
      "  timers:\n",
      "    learn_throughput: 1932.812\n",
      "    learn_time_ms: 2069.524\n",
      "    load_throughput: 202483641.379\n",
      "    load_time_ms: 0.02\n",
      "    sample_throughput: 2491.881\n",
      "    sample_time_ms: 1605.213\n",
      "    update_time_ms: 2.172\n",
      "  timestamp: 1634313053\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 7\n",
      "  trial_id: 97f47_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 9.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         22.5009</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">  148.91</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">            148.91</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>RUNNING </td><td>192.168.0.42:1099</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         25.7851</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">  159.84</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  15</td><td style=\"text-align: right;\">            159.84</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>RUNNING </td><td>192.168.0.42:1100</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         22.4216</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">  158.32</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            158.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00002:\n",
      "  agent_timesteps_total: 28000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-50-53\n",
      "  done: false\n",
      "  episode_len_mean: 169.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 169.02\n",
      "  episode_reward_min: 16.0\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 394\n",
      "  experiment_id: d20693eb10024d9ab0f562ddf7dfc3be\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.15000000596046448\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.567983865737915\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0063636647537350655\n",
      "          model: {}\n",
      "          policy_loss: -0.0028207108844071627\n",
      "          total_loss: 323.7685546875\n",
      "          vf_explained_var: 0.38853269815444946\n",
      "          vf_loss: 323.7704162597656\n",
      "    num_agent_steps_sampled: 28000\n",
      "    num_agent_steps_trained: 28000\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 28000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.339999999999996\n",
      "    ram_util_percent: 70.7\n",
      "  pid: 1100\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04020279061588099\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04653719315055391\n",
      "    mean_inference_ms: 0.6488308940233339\n",
      "    mean_raw_obs_processing_ms: 0.05391011819992701\n",
      "  time_since_restore: 25.925601482391357\n",
      "  time_this_iter_s: 3.5040040016174316\n",
      "  time_total_s: 25.925601482391357\n",
      "  timers:\n",
      "    learn_throughput: 1911.615\n",
      "    learn_time_ms: 2092.472\n",
      "    load_throughput: 180400172.043\n",
      "    load_time_ms: 0.022\n",
      "    sample_throughput: 2493.691\n",
      "    sample_time_ms: 1604.048\n",
      "    update_time_ms: 1.73\n",
      "  timestamp: 1634313053\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 7\n",
      "  trial_id: 97f47_00002\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 28000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-50-53\n",
      "  done: false\n",
      "  episode_len_mean: 170.31\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 170.31\n",
      "  episode_reward_min: 22.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 391\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.45143720507621765\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.10432516038417816\n",
      "          model: {}\n",
      "          policy_loss: 0.01528583001345396\n",
      "          total_loss: 116.87007904052734\n",
      "          vf_explained_var: 0.8816660046577454\n",
      "          vf_loss: 116.78437805175781\n",
      "    num_agent_steps_sampled: 28000\n",
      "    num_agent_steps_trained: 28000\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 28000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.339999999999996\n",
      "    ram_util_percent: 70.7\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041242695702453085\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04717677591856021\n",
      "    mean_inference_ms: 0.6514438707975161\n",
      "    mean_raw_obs_processing_ms: 0.0551737776239196\n",
      "  time_since_restore: 26.023024082183838\n",
      "  time_this_iter_s: 3.5221240520477295\n",
      "  time_total_s: 26.023024082183838\n",
      "  timers:\n",
      "    learn_throughput: 1914.42\n",
      "    learn_time_ms: 2089.406\n",
      "    load_throughput: 125874075.027\n",
      "    load_time_ms: 0.032\n",
      "    sample_throughput: 2467.008\n",
      "    sample_time_ms: 1621.397\n",
      "    update_time_ms: 1.642\n",
      "  timestamp: 1634313053\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 7\n",
      "  trial_id: 97f47_00000\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00001:\n",
      "  agent_timesteps_total: 36000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-00\n",
      "  done: false\n",
      "  episode_len_mean: 180.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 180.46\n",
      "  episode_reward_min: 26.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 422\n",
      "  experiment_id: a7d670197b8449aca715ca10f26be361\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5235627293586731\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007078239694237709\n",
      "          model: {}\n",
      "          policy_loss: -0.008573651313781738\n",
      "          total_loss: 310.1233215332031\n",
      "          vf_explained_var: 0.41668635606765747\n",
      "          vf_loss: 310.1286926269531\n",
      "    num_agent_steps_sampled: 36000\n",
      "    num_agent_steps_trained: 36000\n",
      "    num_steps_sampled: 36000\n",
      "    num_steps_trained: 36000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.739999999999995\n",
      "    ram_util_percent: 70.66\n",
      "  pid: 1099\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039345323873545085\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.047442794632551626\n",
      "    mean_inference_ms: 0.6436388108701688\n",
      "    mean_raw_obs_processing_ms: 0.05324449626159387\n",
      "  time_since_restore: 32.776865005493164\n",
      "  time_this_iter_s: 3.4680421352386475\n",
      "  time_total_s: 32.776865005493164\n",
      "  timers:\n",
      "    learn_throughput: 1961.098\n",
      "    learn_time_ms: 2039.674\n",
      "    load_throughput: 210006876.217\n",
      "    load_time_ms: 0.019\n",
      "    sample_throughput: 2509.839\n",
      "    sample_time_ms: 1593.728\n",
      "    update_time_ms: 2.187\n",
      "  timestamp: 1634313060\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 9\n",
      "  trial_id: 97f47_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 9.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         29.5732</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">  178.08</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  22</td><td style=\"text-align: right;\">            178.08</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>RUNNING </td><td>192.168.0.42:1099</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         32.7769</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">  180.46</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  26</td><td style=\"text-align: right;\">            180.46</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>RUNNING </td><td>192.168.0.42:1100</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         29.4613</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">  183.15</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  57</td><td style=\"text-align: right;\">            183.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00002:\n",
      "  agent_timesteps_total: 36000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-00\n",
      "  done: false\n",
      "  episode_len_mean: 188.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 188.57\n",
      "  episode_reward_min: 92.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 435\n",
      "  experiment_id: d20693eb10024d9ab0f562ddf7dfc3be\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.15000000596046448\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.5437036156654358\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0033580162562429905\n",
      "          model: {}\n",
      "          policy_loss: 0.0004592960758600384\n",
      "          total_loss: 577.7265014648438\n",
      "          vf_explained_var: 0.09605903178453445\n",
      "          vf_loss: 577.7254638671875\n",
      "    num_agent_steps_sampled: 36000\n",
      "    num_agent_steps_trained: 36000\n",
      "    num_steps_sampled: 36000\n",
      "    num_steps_trained: 36000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.7\n",
      "    ram_util_percent: 70.67999999999999\n",
      "  pid: 1100\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04016618096561432\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0465507532340575\n",
      "    mean_inference_ms: 0.6469531571649944\n",
      "    mean_raw_obs_processing_ms: 0.05273267284473802\n",
      "  time_since_restore: 32.96321415901184\n",
      "  time_this_iter_s: 3.5018768310546875\n",
      "  time_total_s: 32.96321415901184\n",
      "  timers:\n",
      "    learn_throughput: 1937.652\n",
      "    learn_time_ms: 2064.354\n",
      "    load_throughput: 169848080.99\n",
      "    load_time_ms: 0.024\n",
      "    sample_throughput: 2513.639\n",
      "    sample_time_ms: 1591.318\n",
      "    update_time_ms: 1.761\n",
      "  timestamp: 1634313060\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 9\n",
      "  trial_id: 97f47_00002\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 36000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-00\n",
      "  done: false\n",
      "  episode_len_mean: 178.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 178.63\n",
      "  episode_reward_min: 22.0\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 437\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187499523162842\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.3891277015209198\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014465512707829475\n",
      "          model: {}\n",
      "          policy_loss: 0.0027902028523385525\n",
      "          total_loss: 43.56397247314453\n",
      "          vf_explained_var: 0.9473764300346375\n",
      "          vf_loss: 43.539215087890625\n",
      "    num_agent_steps_sampled: 36000\n",
      "    num_agent_steps_trained: 36000\n",
      "    num_steps_sampled: 36000\n",
      "    num_steps_trained: 36000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.7\n",
      "    ram_util_percent: 70.67999999999999\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041291355635016014\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04721698937732183\n",
      "    mean_inference_ms: 0.6506921427726734\n",
      "    mean_raw_obs_processing_ms: 0.054119462410520874\n",
      "  time_since_restore: 33.08992290496826\n",
      "  time_this_iter_s: 3.516726016998291\n",
      "  time_total_s: 33.08992290496826\n",
      "  timers:\n",
      "    learn_throughput: 1942.642\n",
      "    learn_time_ms: 2059.052\n",
      "    load_throughput: 120506739.026\n",
      "    load_time_ms: 0.033\n",
      "    sample_throughput: 2482.815\n",
      "    sample_time_ms: 1611.074\n",
      "    update_time_ms: 1.614\n",
      "  timestamp: 1634313060\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 9\n",
      "  trial_id: 97f47_00000\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00001:\n",
      "  agent_timesteps_total: 44000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-07\n",
      "  done: false\n",
      "  episode_len_mean: 194.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.15\n",
      "  episode_reward_min: 90.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 462\n",
      "  experiment_id: a7d670197b8449aca715ca10f26be361\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5175709128379822\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0057332562282681465\n",
      "          model: {}\n",
      "          policy_loss: -0.006628242786973715\n",
      "          total_loss: 416.60845947265625\n",
      "          vf_explained_var: 0.24792709946632385\n",
      "          vf_loss: 416.61248779296875\n",
      "    num_agent_steps_sampled: 44000\n",
      "    num_agent_steps_trained: 44000\n",
      "    num_steps_sampled: 44000\n",
      "    num_steps_trained: 44000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.54\n",
      "    ram_util_percent: 70.6\n",
      "  pid: 1099\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03913172830812253\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.047238238777598675\n",
      "    mean_inference_ms: 0.6412161407854653\n",
      "    mean_raw_obs_processing_ms: 0.052512759554417233\n",
      "  time_since_restore: 39.78448510169983\n",
      "  time_this_iter_s: 3.4878101348876953\n",
      "  time_total_s: 39.78448510169983\n",
      "  timers:\n",
      "    learn_throughput: 2004.683\n",
      "    learn_time_ms: 1995.328\n",
      "    load_throughput: 232371412.742\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 2518.41\n",
      "    sample_time_ms: 1588.304\n",
      "    update_time_ms: 2.234\n",
      "  timestamp: 1634313067\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 44000\n",
      "  training_iteration: 11\n",
      "  trial_id: 97f47_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 9.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         36.6239</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">  176.5 </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  64</td><td style=\"text-align: right;\">            176.5 </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>RUNNING </td><td>192.168.0.42:1099</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         39.7845</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\">  194.15</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  90</td><td style=\"text-align: right;\">            194.15</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>RUNNING </td><td>192.168.0.42:1100</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         36.4843</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">  192.06</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  92</td><td style=\"text-align: right;\">            192.06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00002:\n",
      "  agent_timesteps_total: 44000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-07\n",
      "  done: false\n",
      "  episode_len_mean: 196.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.19\n",
      "  episode_reward_min: 92.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 475\n",
      "  experiment_id: d20693eb10024d9ab0f562ddf7dfc3be\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.07500000298023224\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.5528479814529419\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.003560141660273075\n",
      "          model: {}\n",
      "          policy_loss: -0.0008763718069531024\n",
      "          total_loss: 568.4649658203125\n",
      "          vf_explained_var: -0.00033595471177250147\n",
      "          vf_loss: 568.465576171875\n",
      "    num_agent_steps_sampled: 44000\n",
      "    num_agent_steps_trained: 44000\n",
      "    num_steps_sampled: 44000\n",
      "    num_steps_trained: 44000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.54\n",
      "    ram_util_percent: 70.6\n",
      "  pid: 1100\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039963837577432486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04632341909939866\n",
      "    mean_inference_ms: 0.643077572105857\n",
      "    mean_raw_obs_processing_ms: 0.051798885440735826\n",
      "  time_since_restore: 40.01220917701721\n",
      "  time_this_iter_s: 3.5279219150543213\n",
      "  time_total_s: 40.01220917701721\n",
      "  timers:\n",
      "    learn_throughput: 1973.843\n",
      "    learn_time_ms: 2026.503\n",
      "    load_throughput: 173497580.145\n",
      "    load_time_ms: 0.023\n",
      "    sample_throughput: 2529.663\n",
      "    sample_time_ms: 1581.238\n",
      "    update_time_ms: 1.777\n",
      "  timestamp: 1634313067\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 44000\n",
      "  training_iteration: 11\n",
      "  trial_id: 97f47_00002\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 44000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-07\n",
      "  done: false\n",
      "  episode_len_mean: 172.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 172.21\n",
      "  episode_reward_min: 64.0\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 484\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.278125047683716\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.29876622557640076\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007487551309168339\n",
      "          model: {}\n",
      "          policy_loss: -0.001649671234190464\n",
      "          total_loss: 59.00946807861328\n",
      "          vf_explained_var: 0.9383375644683838\n",
      "          vf_loss: 58.99406051635742\n",
      "    num_agent_steps_sampled: 44000\n",
      "    num_agent_steps_trained: 44000\n",
      "    num_steps_sampled: 44000\n",
      "    num_steps_trained: 44000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.54\n",
      "    ram_util_percent: 70.6\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041019300253400635\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04703039430164997\n",
      "    mean_inference_ms: 0.6472174293782795\n",
      "    mean_raw_obs_processing_ms: 0.05330417296509779\n",
      "  time_since_restore: 40.151145696640015\n",
      "  time_this_iter_s: 3.527261972427368\n",
      "  time_total_s: 40.151145696640015\n",
      "  timers:\n",
      "    learn_throughput: 1982.622\n",
      "    learn_time_ms: 2017.53\n",
      "    load_throughput: 123908537.666\n",
      "    load_time_ms: 0.032\n",
      "    sample_throughput: 2492.908\n",
      "    sample_time_ms: 1604.552\n",
      "    update_time_ms: 1.544\n",
      "  timestamp: 1634313067\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 44000\n",
      "  training_iteration: 11\n",
      "  trial_id: 97f47_00000\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00001:\n",
      "  agent_timesteps_total: 52000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-14\n",
      "  done: false\n",
      "  episode_len_mean: 197.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.19\n",
      "  episode_reward_min: 114.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 502\n",
      "  experiment_id: a7d670197b8449aca715ca10f26be361\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.4956778287887573\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006263433955609798\n",
      "          model: {}\n",
      "          policy_loss: -0.009091125801205635\n",
      "          total_loss: 383.4473876953125\n",
      "          vf_explained_var: 0.3142635226249695\n",
      "          vf_loss: 383.4537048339844\n",
      "    num_agent_steps_sampled: 52000\n",
      "    num_agent_steps_trained: 52000\n",
      "    num_steps_sampled: 52000\n",
      "    num_steps_trained: 52000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.55\n",
      "    ram_util_percent: 70.6\n",
      "  pid: 1099\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.038950762352618955\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.047076847888697815\n",
      "    mean_inference_ms: 0.6389701529946369\n",
      "    mean_raw_obs_processing_ms: 0.0520070796425432\n",
      "  time_since_restore: 46.71498727798462\n",
      "  time_this_iter_s: 3.427819013595581\n",
      "  time_total_s: 46.71498727798462\n",
      "  timers:\n",
      "    learn_throughput: 2038.972\n",
      "    learn_time_ms: 1961.773\n",
      "    load_throughput: 235635056.18\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 2538.161\n",
      "    sample_time_ms: 1575.944\n",
      "    update_time_ms: 2.222\n",
      "  timestamp: 1634313074\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 52000\n",
      "  training_iteration: 13\n",
      "  trial_id: 97f47_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 9.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (3 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         43.6388</td><td style=\"text-align: right;\">48000</td><td style=\"text-align: right;\">  174.65</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  64</td><td style=\"text-align: right;\">            174.65</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>RUNNING </td><td>192.168.0.42:1099</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         46.715 </td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\">  197.19</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 114</td><td style=\"text-align: right;\">            197.19</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>RUNNING </td><td>192.168.0.42:1100</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         43.5018</td><td style=\"text-align: right;\">48000</td><td style=\"text-align: right;\">  197.25</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  92</td><td style=\"text-align: right;\">            197.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00002:\n",
      "  agent_timesteps_total: 52000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-14\n",
      "  done: false\n",
      "  episode_len_mean: 198.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.77\n",
      "  episode_reward_min: 126.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 515\n",
      "  experiment_id: d20693eb10024d9ab0f562ddf7dfc3be\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.03750000149011612\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.5157675743103027\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.003722771303728223\n",
      "          model: {}\n",
      "          policy_loss: -0.004048094619065523\n",
      "          total_loss: 462.3150939941406\n",
      "          vf_explained_var: 0.15132272243499756\n",
      "          vf_loss: 462.31903076171875\n",
      "    num_agent_steps_sampled: 52000\n",
      "    num_agent_steps_trained: 52000\n",
      "    num_steps_sampled: 52000\n",
      "    num_steps_trained: 52000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.36\n",
      "    ram_util_percent: 70.6\n",
      "  pid: 1100\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03974632412073288\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04605394984855876\n",
      "    mean_inference_ms: 0.6394880568023956\n",
      "    mean_raw_obs_processing_ms: 0.05108600436395502\n",
      "  time_since_restore: 46.96794652938843\n",
      "  time_this_iter_s: 3.46610426902771\n",
      "  time_total_s: 46.96794652938843\n",
      "  timers:\n",
      "    learn_throughput: 2002.15\n",
      "    learn_time_ms: 1997.852\n",
      "    load_throughput: 157828936.971\n",
      "    load_time_ms: 0.025\n",
      "    sample_throughput: 2567.429\n",
      "    sample_time_ms: 1557.979\n",
      "    update_time_ms: 1.834\n",
      "  timestamp: 1634313074\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 52000\n",
      "  training_iteration: 13\n",
      "  trial_id: 97f47_00002\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 52000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-14\n",
      "  done: false\n",
      "  episode_len_mean: 177.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 177.38\n",
      "  episode_reward_min: 64.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 526\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.278125047683716\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.2604526877403259\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007170080207288265\n",
      "          model: {}\n",
      "          policy_loss: 0.0007588683511130512\n",
      "          total_loss: 119.31275177001953\n",
      "          vf_explained_var: 0.8591522574424744\n",
      "          vf_loss: 119.29566192626953\n",
      "    num_agent_steps_sampled: 52000\n",
      "    num_agent_steps_trained: 52000\n",
      "    num_steps_sampled: 52000\n",
      "    num_steps_trained: 52000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.36\n",
      "    ram_util_percent: 70.6\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040889311286141095\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04686505244051416\n",
      "    mean_inference_ms: 0.6448555001741408\n",
      "    mean_raw_obs_processing_ms: 0.05280220992576579\n",
      "  time_since_restore: 47.11837077140808\n",
      "  time_this_iter_s: 3.4795498847961426\n",
      "  time_total_s: 47.11837077140808\n",
      "  timers:\n",
      "    learn_throughput: 2017.723\n",
      "    learn_time_ms: 1982.433\n",
      "    load_throughput: 121927441.86\n",
      "    load_time_ms: 0.033\n",
      "    sample_throughput: 2522.172\n",
      "    sample_time_ms: 1585.934\n",
      "    update_time_ms: 1.505\n",
      "  timestamp: 1634313074\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 52000\n",
      "  training_iteration: 13\n",
      "  trial_id: 97f47_00000\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00001:\n",
      "  agent_timesteps_total: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-21\n",
      "  done: true\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 200.0\n",
      "  episode_reward_min: 200.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 542\n",
      "  experiment_id: a7d670197b8449aca715ca10f26be361\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 0.0010000000474974513\n",
      "          entropy: 0.5014790892601013\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008911572396755219\n",
      "          model: {}\n",
      "          policy_loss: -0.01807117462158203\n",
      "          total_loss: 368.3330078125\n",
      "          vf_explained_var: 0.4595029950141907\n",
      "          vf_loss: 368.3470458984375\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_agent_steps_trained: 60000\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.04\n",
      "    ram_util_percent: 70.6\n",
      "  pid: 1099\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.038846327750973644\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04696298641482479\n",
      "    mean_inference_ms: 0.6369509283704322\n",
      "    mean_raw_obs_processing_ms: 0.05165187167118271\n",
      "  time_since_restore: 53.58707332611084\n",
      "  time_this_iter_s: 3.4351580142974854\n",
      "  time_total_s: 53.58707332611084\n",
      "  timers:\n",
      "    learn_throughput: 2085.126\n",
      "    learn_time_ms: 1918.349\n",
      "    load_throughput: 213179364.676\n",
      "    load_time_ms: 0.019\n",
      "    sample_throughput: 2558.217\n",
      "    sample_time_ms: 1563.589\n",
      "    update_time_ms: 2.216\n",
      "  timestamp: 1634313081\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 15\n",
      "  trial_id: 97f47_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (2 RUNNING, 1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         50.5949</td><td style=\"text-align: right;\">56000</td><td style=\"text-align: right;\">  182.13</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                  64</td><td style=\"text-align: right;\">            182.13</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>RUNNING   </td><td>192.168.0.42:1100</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         50.4287</td><td style=\"text-align: right;\">56000</td><td style=\"text-align: right;\">  199.51</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 151</td><td style=\"text-align: right;\">            199.51</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00002:\n",
      "  agent_timesteps_total: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-21\n",
      "  done: false\n",
      "  episode_len_mean: 199.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.51\n",
      "  episode_reward_min: 151.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 555\n",
      "  experiment_id: d20693eb10024d9ab0f562ddf7dfc3be\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.01875000074505806\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.49684691429138184\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007127116899937391\n",
      "          model: {}\n",
      "          policy_loss: -0.0019269874319434166\n",
      "          total_loss: 472.16656494140625\n",
      "          vf_explained_var: 0.22081834077835083\n",
      "          vf_loss: 472.1683349609375\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_agent_steps_trained: 60000\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.08\n",
      "    ram_util_percent: 70.6\n",
      "  pid: 1100\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039550128765295255\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04582343335543668\n",
      "    mean_inference_ms: 0.6364505591377543\n",
      "    mean_raw_obs_processing_ms: 0.050579591266986926\n",
      "  time_since_restore: 53.86611461639404\n",
      "  time_this_iter_s: 3.4374489784240723\n",
      "  time_total_s: 53.86611461639404\n",
      "  timers:\n",
      "    learn_throughput: 2044.406\n",
      "    learn_time_ms: 1956.559\n",
      "    load_throughput: 152381616.712\n",
      "    load_time_ms: 0.026\n",
      "    sample_throughput: 2590.122\n",
      "    sample_time_ms: 1544.329\n",
      "    update_time_ms: 1.886\n",
      "  timestamp: 1634313081\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 15\n",
      "  trial_id: 97f47_00002\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-21\n",
      "  done: false\n",
      "  episode_len_mean: 190.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 190.34\n",
      "  episode_reward_min: 120.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 567\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.417187452316284\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.2011292427778244\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018535763025283813\n",
      "          model: {}\n",
      "          policy_loss: 0.00835613813251257\n",
      "          total_loss: 379.0834045410156\n",
      "          vf_explained_var: 0.5219901204109192\n",
      "          vf_loss: 379.0116882324219\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_agent_steps_trained: 60000\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.1\n",
      "    ram_util_percent: 70.6\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040712395261973434\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04673157619457651\n",
      "    mean_inference_ms: 0.642728415035086\n",
      "    mean_raw_obs_processing_ms: 0.05244295248553121\n",
      "  time_since_restore: 54.029690742492676\n",
      "  time_this_iter_s: 3.4347829818725586\n",
      "  time_total_s: 54.029690742492676\n",
      "  timers:\n",
      "    learn_throughput: 2066.499\n",
      "    learn_time_ms: 1935.641\n",
      "    load_throughput: 133152507.937\n",
      "    load_time_ms: 0.03\n",
      "    sample_throughput: 2538.148\n",
      "    sample_time_ms: 1575.952\n",
      "    update_time_ms: 1.508\n",
      "  timestamp: 1634313081\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 15\n",
      "  trial_id: 97f47_00000\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00002:\n",
      "  agent_timesteps_total: 68000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-27\n",
      "  done: true\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 200.0\n",
      "  episode_reward_min: 200.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 595\n",
      "  experiment_id: d20693eb10024d9ab0f562ddf7dfc3be\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.00937500037252903\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.5201832056045532\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00477631576359272\n",
      "          model: {}\n",
      "          policy_loss: -0.0010758202988654375\n",
      "          total_loss: 473.7513427734375\n",
      "          vf_explained_var: 0.004122511949390173\n",
      "          vf_loss: 473.7523498535156\n",
      "    num_agent_steps_sampled: 68000\n",
      "    num_agent_steps_trained: 68000\n",
      "    num_steps_sampled: 68000\n",
      "    num_steps_trained: 68000\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.525\n",
      "    ram_util_percent: 63.55\n",
      "  pid: 1100\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03924982877523528\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.045462851999974116\n",
      "    mean_inference_ms: 0.6315054705864332\n",
      "    mean_raw_obs_processing_ms: 0.04999529776448159\n",
      "  time_since_restore: 59.40174651145935\n",
      "  time_this_iter_s: 2.741175889968872\n",
      "  time_total_s: 59.40174651145935\n",
      "  timers:\n",
      "    learn_throughput: 2168.093\n",
      "    learn_time_ms: 1844.939\n",
      "    load_throughput: 171546175.869\n",
      "    load_time_ms: 0.023\n",
      "    sample_throughput: 2672.944\n",
      "    sample_time_ms: 1496.477\n",
      "    update_time_ms: 1.845\n",
      "  timestamp: 1634313087\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 68000\n",
      "  training_iteration: 17\n",
      "  trial_id: 97f47_00002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         56.8174</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\">  191.99</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 146</td><td style=\"text-align: right;\">            191.99</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 68000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-27\n",
      "  done: false\n",
      "  episode_len_mean: 193.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 193.3\n",
      "  episode_reward_min: 146.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 608\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.417187452316284\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.15705595910549164\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017499247565865517\n",
      "          model: {}\n",
      "          policy_loss: 0.006452866364270449\n",
      "          total_loss: 406.8672180175781\n",
      "          vf_explained_var: 0.4457138180732727\n",
      "          vf_loss: 406.8009033203125\n",
      "    num_agent_steps_sampled: 68000\n",
      "    num_agent_steps_trained: 68000\n",
      "    num_steps_sampled: 68000\n",
      "    num_steps_trained: 68000\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.5\n",
      "    ram_util_percent: 63.55\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04037296824262139\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.046395218379665926\n",
      "    mean_inference_ms: 0.6381913251083231\n",
      "    mean_raw_obs_processing_ms: 0.05191552672670126\n",
      "  time_since_restore: 59.55553364753723\n",
      "  time_this_iter_s: 2.7380878925323486\n",
      "  time_total_s: 59.55553364753723\n",
      "  timers:\n",
      "    learn_throughput: 2192.543\n",
      "    learn_time_ms: 1824.365\n",
      "    load_throughput: 165292768.473\n",
      "    load_time_ms: 0.024\n",
      "    sample_throughput: 2625.338\n",
      "    sample_time_ms: 1523.614\n",
      "    update_time_ms: 1.412\n",
      "  timestamp: 1634313087\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 68000\n",
      "  training_iteration: 17\n",
      "  trial_id: 97f47_00000\n",
      "  \n",
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 80000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-34\n",
      "  done: false\n",
      "  episode_len_mean: 192.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 192.34\n",
      "  episode_reward_min: 140.0\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 672\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.417187452316284\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.11133085936307907\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024230340495705605\n",
      "          model: {}\n",
      "          policy_loss: -9.778879029909149e-05\n",
      "          total_loss: 369.7532653808594\n",
      "          vf_explained_var: 0.4515882134437561\n",
      "          vf_loss: 369.6705322265625\n",
      "    num_agent_steps_sampled: 80000\n",
      "    num_agent_steps_trained: 80000\n",
      "    num_steps_sampled: 80000\n",
      "    num_steps_trained: 80000\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.25\n",
      "    ram_util_percent: 56.425\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03930975618605393\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04512003294506609\n",
      "    mean_inference_ms: 0.6205280283850112\n",
      "    mean_raw_obs_processing_ms: 0.050268523781942104\n",
      "  time_since_restore: 66.49216961860657\n",
      "  time_this_iter_s: 2.3046810626983643\n",
      "  time_total_s: 66.49216961860657\n",
      "  timers:\n",
      "    learn_throughput: 2532.057\n",
      "    learn_time_ms: 1579.743\n",
      "    load_throughput: 206615960.591\n",
      "    load_time_ms: 0.019\n",
      "    sample_throughput: 2852.485\n",
      "    sample_time_ms: 1402.286\n",
      "    update_time_ms: 1.307\n",
      "  timestamp: 1634313094\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 80000\n",
      "  training_iteration: 20\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.5/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         66.4922</td><td style=\"text-align: right;\">80000</td><td style=\"text-align: right;\">  192.34</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 140</td><td style=\"text-align: right;\">            192.34</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 92000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-41\n",
      "  done: false\n",
      "  episode_len_mean: 192.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 192.1\n",
      "  episode_reward_min: 140.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 734\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.5628905296325684\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.09845804423093796\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012499627657234669\n",
      "          model: {}\n",
      "          policy_loss: 0.0034497424494475126\n",
      "          total_loss: 256.9383544921875\n",
      "          vf_explained_var: 0.629697859287262\n",
      "          vf_loss: 256.9028625488281\n",
      "    num_agent_steps_sampled: 92000\n",
      "    num_agent_steps_trained: 92000\n",
      "    num_steps_sampled: 92000\n",
      "    num_steps_trained: 92000\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.275\n",
      "    ram_util_percent: 56.7\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03805735751481929\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04367009753814493\n",
      "    mean_inference_ms: 0.599865159563216\n",
      "    mean_raw_obs_processing_ms: 0.048462325730420926\n",
      "  time_since_restore: 73.4116063117981\n",
      "  time_this_iter_s: 2.3002398014068604\n",
      "  time_total_s: 73.4116063117981\n",
      "  timers:\n",
      "    learn_throughput: 2982.842\n",
      "    learn_time_ms: 1341.003\n",
      "    load_throughput: 225197530.201\n",
      "    load_time_ms: 0.018\n",
      "    sample_throughput: 3115.24\n",
      "    sample_time_ms: 1284.01\n",
      "    update_time_ms: 1.199\n",
      "  timestamp: 1634313101\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 92000\n",
      "  training_iteration: 23\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.5/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         73.4116</td><td style=\"text-align: right;\">92000</td><td style=\"text-align: right;\">   192.1</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 140</td><td style=\"text-align: right;\">             192.1</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 104000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-48\n",
      "  done: false\n",
      "  episode_len_mean: 193.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 193.52\n",
      "  episode_reward_min: 141.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 795\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.8443360328674316\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.0751693919301033\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0021325002890080214\n",
      "          model: {}\n",
      "          policy_loss: 0.005034258123487234\n",
      "          total_loss: 212.39666748046875\n",
      "          vf_explained_var: 0.7189307808876038\n",
      "          vf_loss: 212.38343811035156\n",
      "    num_agent_steps_sampled: 104000\n",
      "    num_agent_steps_trained: 104000\n",
      "    num_steps_sampled: 104000\n",
      "    num_steps_trained: 104000\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.2\n",
      "    ram_util_percent: 56.8\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03705680726550208\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04253220387270282\n",
      "    mean_inference_ms: 0.583582376418758\n",
      "    mean_raw_obs_processing_ms: 0.0470575712100179\n",
      "  time_since_restore: 80.3134777545929\n",
      "  time_this_iter_s: 2.298121213912964\n",
      "  time_total_s: 80.3134777545929\n",
      "  timers:\n",
      "    learn_throughput: 3430.598\n",
      "    learn_time_ms: 1165.978\n",
      "    load_throughput: 236298816.901\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3390.783\n",
      "    sample_time_ms: 1179.669\n",
      "    update_time_ms: 1.095\n",
      "  timestamp: 1634313108\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 104000\n",
      "  training_iteration: 26\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.5/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         80.3135</td><td style=\"text-align: right;\">104000</td><td style=\"text-align: right;\">  193.52</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 141</td><td style=\"text-align: right;\">            193.52</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 116000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-51-55\n",
      "  done: false\n",
      "  episode_len_mean: 195.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.38\n",
      "  episode_reward_min: 146.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 856\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610840082168579\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.07955187559127808\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011995332315564156\n",
      "          model: {}\n",
      "          policy_loss: 0.0031312373466789722\n",
      "          total_loss: 193.80494689941406\n",
      "          vf_explained_var: 0.6406446099281311\n",
      "          vf_loss: 193.790283203125\n",
      "    num_agent_steps_sampled: 116000\n",
      "    num_agent_steps_trained: 116000\n",
      "    num_steps_sampled: 116000\n",
      "    num_steps_trained: 116000\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.775\n",
      "    ram_util_percent: 56.9\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.036281233606438444\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04163301514635642\n",
      "    mean_inference_ms: 0.5707776362584087\n",
      "    mean_raw_obs_processing_ms: 0.0459478692972891\n",
      "  time_since_restore: 87.29702711105347\n",
      "  time_this_iter_s: 2.3013250827789307\n",
      "  time_total_s: 87.29702711105347\n",
      "  timers:\n",
      "    learn_throughput: 3491.138\n",
      "    learn_time_ms: 1145.758\n",
      "    load_throughput: 235635056.18\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3444.624\n",
      "    sample_time_ms: 1161.23\n",
      "    update_time_ms: 1.087\n",
      "  timestamp: 1634313115\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 116000\n",
      "  training_iteration: 29\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         87.297 </td><td style=\"text-align: right;\">116000</td><td style=\"text-align: right;\">  195.38</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 146</td><td style=\"text-align: right;\">            195.38</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 128000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-52-02\n",
      "  done: false\n",
      "  episode_len_mean: 193.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 193.17\n",
      "  episode_reward_min: 144.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 919\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610840082168579\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.06383916735649109\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009253853000700474\n",
      "          model: {}\n",
      "          policy_loss: 0.000588017632253468\n",
      "          total_loss: 278.4478454589844\n",
      "          vf_explained_var: 0.6496924757957458\n",
      "          vf_loss: 278.4383850097656\n",
      "    num_agent_steps_sampled: 128000\n",
      "    num_agent_steps_trained: 128000\n",
      "    num_steps_sampled: 128000\n",
      "    num_steps_trained: 128000\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.0\n",
      "    ram_util_percent: 56.9\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.035667870544059045\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04089827362889153\n",
      "    mean_inference_ms: 0.5603760671090388\n",
      "    mean_raw_obs_processing_ms: 0.04503611087260486\n",
      "  time_since_restore: 94.22678112983704\n",
      "  time_this_iter_s: 2.306859016418457\n",
      "  time_total_s: 94.22678112983704\n",
      "  timers:\n",
      "    learn_throughput: 3485.177\n",
      "    learn_time_ms: 1147.718\n",
      "    load_throughput: 227951304.348\n",
      "    load_time_ms: 0.018\n",
      "    sample_throughput: 3448.597\n",
      "    sample_time_ms: 1159.892\n",
      "    update_time_ms: 1.093\n",
      "  timestamp: 1634313122\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 128000\n",
      "  training_iteration: 32\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         94.2268</td><td style=\"text-align: right;\">128000</td><td style=\"text-align: right;\">  193.17</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 144</td><td style=\"text-align: right;\">            193.17</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 140000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-52-09\n",
      "  done: false\n",
      "  episode_len_mean: 195.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.02\n",
      "  episode_reward_min: 143.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 980\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.441625952720642\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.0636262446641922\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.030850810930132866\n",
      "          model: {}\n",
      "          policy_loss: 0.008732305839657784\n",
      "          total_loss: 293.4499206542969\n",
      "          vf_explained_var: 0.5388401746749878\n",
      "          vf_loss: 293.3966979980469\n",
      "    num_agent_steps_sampled: 140000\n",
      "    num_agent_steps_trained: 140000\n",
      "    num_steps_sampled: 140000\n",
      "    num_steps_trained: 140000\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.200000000000001\n",
      "    ram_util_percent: 57.0\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03514792431452182\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04031568899555281\n",
      "    mean_inference_ms: 0.552049091433639\n",
      "    mean_raw_obs_processing_ms: 0.04432692751316376\n",
      "  time_since_restore: 101.13064193725586\n",
      "  time_this_iter_s: 2.2950079441070557\n",
      "  time_total_s: 101.13064193725586\n",
      "  timers:\n",
      "    learn_throughput: 3483.967\n",
      "    learn_time_ms: 1148.116\n",
      "    load_throughput: 228572425.068\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3449.803\n",
      "    sample_time_ms: 1159.486\n",
      "    update_time_ms: 1.105\n",
      "  timestamp: 1634313129\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 140000\n",
      "  training_iteration: 35\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">        101.131 </td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">  195.02</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 143</td><td style=\"text-align: right;\">            195.02</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 152000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-52-16\n",
      "  done: false\n",
      "  episode_len_mean: 194.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.35\n",
      "  episode_reward_min: 132.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 1042\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.865487575531006\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.07182817161083221\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014971381984651089\n",
      "          model: {}\n",
      "          policy_loss: 0.003922880627214909\n",
      "          total_loss: 193.9669647216797\n",
      "          vf_explained_var: 0.7505271434783936\n",
      "          vf_loss: 193.89019775390625\n",
      "    num_agent_steps_sampled: 152000\n",
      "    num_agent_steps_trained: 152000\n",
      "    num_steps_sampled: 152000\n",
      "    num_steps_trained: 152000\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.433333333333334\n",
      "    ram_util_percent: 57.0\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.034737324468936744\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03981969725373725\n",
      "    mean_inference_ms: 0.5450568278493755\n",
      "    mean_raw_obs_processing_ms: 0.04370710852715803\n",
      "  time_since_restore: 108.04631996154785\n",
      "  time_this_iter_s: 2.3031539916992188\n",
      "  time_total_s: 108.04631996154785\n",
      "  timers:\n",
      "    learn_throughput: 3504.047\n",
      "    learn_time_ms: 1141.537\n",
      "    load_throughput: 228261442.177\n",
      "    load_time_ms: 0.018\n",
      "    sample_throughput: 3449.547\n",
      "    sample_time_ms: 1159.573\n",
      "    update_time_ms: 1.123\n",
      "  timestamp: 1634313136\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 152000\n",
      "  training_iteration: 38\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">        108.046 </td><td style=\"text-align: right;\">152000</td><td style=\"text-align: right;\">  194.35</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 132</td><td style=\"text-align: right;\">            194.35</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 164000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-52-23\n",
      "  done: false\n",
      "  episode_len_mean: 195.06\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.06\n",
      "  episode_reward_min: 132.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1103\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.865487575531006\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.07145307213068008\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01787406951189041\n",
      "          model: {}\n",
      "          policy_loss: 0.0057264831848442554\n",
      "          total_loss: 162.24905395507812\n",
      "          vf_explained_var: 0.673206090927124\n",
      "          vf_loss: 162.1563720703125\n",
      "    num_agent_steps_sampled: 164000\n",
      "    num_agent_steps_trained: 164000\n",
      "    num_steps_sampled: 164000\n",
      "    num_steps_trained: 164000\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.3\n",
      "    ram_util_percent: 57.06666666666666\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.034360806599324084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0394058504036381\n",
      "    mean_inference_ms: 0.539108572376518\n",
      "    mean_raw_obs_processing_ms: 0.043204778907442905\n",
      "  time_since_restore: 114.96520829200745\n",
      "  time_this_iter_s: 2.3143651485443115\n",
      "  time_total_s: 114.96520829200745\n",
      "  timers:\n",
      "    learn_throughput: 3505.816\n",
      "    learn_time_ms: 1140.961\n",
      "    load_throughput: 230140137.174\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3449.405\n",
      "    sample_time_ms: 1159.62\n",
      "    update_time_ms: 1.116\n",
      "  timestamp: 1634313143\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 164000\n",
      "  training_iteration: 41\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">        114.965 </td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\">  195.06</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 132</td><td style=\"text-align: right;\">            195.06</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 176000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-52-30\n",
      "  done: false\n",
      "  episode_len_mean: 195.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.08\n",
      "  episode_reward_min: 135.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1165\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.865487575531006\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.07095066457986832\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018658123910427094\n",
      "          model: {}\n",
      "          policy_loss: 0.010569063015282154\n",
      "          total_loss: 266.86920166015625\n",
      "          vf_explained_var: 0.629869282245636\n",
      "          vf_loss: 266.7678527832031\n",
      "    num_agent_steps_sampled: 176000\n",
      "    num_agent_steps_trained: 176000\n",
      "    num_steps_sampled: 176000\n",
      "    num_steps_trained: 176000\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.266666666666666\n",
      "    ram_util_percent: 57.20000000000001\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03405253959557853\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03905106870483498\n",
      "    mean_inference_ms: 0.5340037746179728\n",
      "    mean_raw_obs_processing_ms: 0.042765832365134565\n",
      "  time_since_restore: 121.87742209434509\n",
      "  time_this_iter_s: 2.303410768508911\n",
      "  time_total_s: 121.87742209434509\n",
      "  timers:\n",
      "    learn_throughput: 3506.66\n",
      "    learn_time_ms: 1140.687\n",
      "    load_throughput: 234646377.622\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3449.687\n",
      "    sample_time_ms: 1159.526\n",
      "    update_time_ms: 1.113\n",
      "  timestamp: 1634313150\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 176000\n",
      "  training_iteration: 44\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">        121.877 </td><td style=\"text-align: right;\">176000</td><td style=\"text-align: right;\">  195.08</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 135</td><td style=\"text-align: right;\">            195.08</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 188000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-52-37\n",
      "  done: false\n",
      "  episode_len_mean: 193.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 193.63\n",
      "  episode_reward_min: 135.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1227\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.865487575531006\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.05926322564482689\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02037595957517624\n",
      "          model: {}\n",
      "          policy_loss: 0.004495890345424414\n",
      "          total_loss: 164.83383178710938\n",
      "          vf_explained_var: 0.7539454102516174\n",
      "          vf_loss: 164.73020935058594\n",
      "    num_agent_steps_sampled: 188000\n",
      "    num_agent_steps_trained: 188000\n",
      "    num_steps_sampled: 188000\n",
      "    num_steps_trained: 188000\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.399999999999995\n",
      "    ram_util_percent: 57.29999999999999\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03380260207887512\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03874487486443104\n",
      "    mean_inference_ms: 0.5296723063311155\n",
      "    mean_raw_obs_processing_ms: 0.0423764525495304\n",
      "  time_since_restore: 128.78210997581482\n",
      "  time_this_iter_s: 2.3023931980133057\n",
      "  time_total_s: 128.78210997581482\n",
      "  timers:\n",
      "    learn_throughput: 3508.1\n",
      "    learn_time_ms: 1140.218\n",
      "    load_throughput: 228261442.177\n",
      "    load_time_ms: 0.018\n",
      "    sample_throughput: 3449.146\n",
      "    sample_time_ms: 1159.707\n",
      "    update_time_ms: 1.113\n",
      "  timestamp: 1634313157\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 188000\n",
      "  training_iteration: 47\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">        128.782 </td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\">  193.63</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 135</td><td style=\"text-align: right;\">            193.63</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 200000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-52-44\n",
      "  done: false\n",
      "  episode_len_mean: 194.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.7\n",
      "  episode_reward_min: 137.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1289\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 16.4210205078125\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.06893593072891235\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01765809766948223\n",
      "          model: {}\n",
      "          policy_loss: 0.0012831453932449222\n",
      "          total_loss: 185.15457153320312\n",
      "          vf_explained_var: 0.7418593764305115\n",
      "          vf_loss: 184.8633270263672\n",
      "    num_agent_steps_sampled: 200000\n",
      "    num_agent_steps_trained: 200000\n",
      "    num_steps_sampled: 200000\n",
      "    num_steps_trained: 200000\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.8\n",
      "    ram_util_percent: 57.333333333333336\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03356612788205179\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03847697346172775\n",
      "    mean_inference_ms: 0.5258221764516912\n",
      "    mean_raw_obs_processing_ms: 0.04203859605274425\n",
      "  time_since_restore: 135.6884469985962\n",
      "  time_this_iter_s: 2.3081278800964355\n",
      "  time_total_s: 135.6884469985962\n",
      "  timers:\n",
      "    learn_throughput: 3510.164\n",
      "    learn_time_ms: 1139.548\n",
      "    load_throughput: 231729502.762\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3447.548\n",
      "    sample_time_ms: 1160.245\n",
      "    update_time_ms: 1.117\n",
      "  timestamp: 1634313164\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 200000\n",
      "  training_iteration: 50\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        135.688 </td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">   194.7</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 137</td><td style=\"text-align: right;\">             194.7</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 212000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-52-50\n",
      "  done: false\n",
      "  episode_len_mean: 190.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 190.78\n",
      "  episode_reward_min: 136.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 1353\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8.21051025390625\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.06738966703414917\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0019532055594027042\n",
      "          model: {}\n",
      "          policy_loss: 0.0035769108217209578\n",
      "          total_loss: 259.8935241699219\n",
      "          vf_explained_var: 0.5878764390945435\n",
      "          vf_loss: 259.8739318847656\n",
      "    num_agent_steps_sampled: 212000\n",
      "    num_agent_steps_trained: 212000\n",
      "    num_steps_sampled: 212000\n",
      "    num_steps_trained: 212000\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.333333333333334\n",
      "    ram_util_percent: 57.6\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03335447171539976\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.038239390716351684\n",
      "    mean_inference_ms: 0.5224042905093897\n",
      "    mean_raw_obs_processing_ms: 0.041732525400498675\n",
      "  time_since_restore: 142.59683203697205\n",
      "  time_this_iter_s: 2.3000848293304443\n",
      "  time_total_s: 142.59683203697205\n",
      "  timers:\n",
      "    learn_throughput: 3516.752\n",
      "    learn_time_ms: 1137.413\n",
      "    load_throughput: 235304572.23\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3445.601\n",
      "    sample_time_ms: 1160.9\n",
      "    update_time_ms: 1.123\n",
      "  timestamp: 1634313170\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 212000\n",
      "  training_iteration: 53\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">        142.597 </td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\">  190.78</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 136</td><td style=\"text-align: right;\">            190.78</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 224000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-52-57\n",
      "  done: false\n",
      "  episode_len_mean: 191.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 191.46\n",
      "  episode_reward_min: 123.0\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 1416\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0263137817382812\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.06617111712694168\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00456637516617775\n",
      "          model: {}\n",
      "          policy_loss: 0.001747599570080638\n",
      "          total_loss: 217.2114715576172\n",
      "          vf_explained_var: 0.7338910698890686\n",
      "          vf_loss: 217.20504760742188\n",
      "    num_agent_steps_sampled: 224000\n",
      "    num_agent_steps_trained: 224000\n",
      "    num_steps_sampled: 224000\n",
      "    num_steps_trained: 224000\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 10.466666666666667\n",
      "    ram_util_percent: 57.6\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03319061795050185\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03803319145179469\n",
      "    mean_inference_ms: 0.519483601086123\n",
      "    mean_raw_obs_processing_ms: 0.041445081715291335\n",
      "  time_since_restore: 149.49856185913086\n",
      "  time_this_iter_s: 2.298335075378418\n",
      "  time_total_s: 149.49856185913086\n",
      "  timers:\n",
      "    learn_throughput: 3519.2\n",
      "    learn_time_ms: 1136.622\n",
      "    load_throughput: 233991854.951\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3444.392\n",
      "    sample_time_ms: 1161.308\n",
      "    update_time_ms: 1.119\n",
      "  timestamp: 1634313177\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 224000\n",
      "  training_iteration: 56\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">        149.499 </td><td style=\"text-align: right;\">224000</td><td style=\"text-align: right;\">  191.46</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 123</td><td style=\"text-align: right;\">            191.46</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 236000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-53-04\n",
      "  done: false\n",
      "  episode_len_mean: 192.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 192.94\n",
      "  episode_reward_min: 121.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1477\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7697353363037109\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.053205594420433044\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.035875000059604645\n",
      "          model: {}\n",
      "          policy_loss: 0.009056166745722294\n",
      "          total_loss: 283.8392333984375\n",
      "          vf_explained_var: 0.43887683749198914\n",
      "          vf_loss: 283.80255126953125\n",
      "    num_agent_steps_sampled: 236000\n",
      "    num_agent_steps_trained: 236000\n",
      "    num_steps_sampled: 236000\n",
      "    num_steps_trained: 236000\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.224999999999998\n",
      "    ram_util_percent: 57.6\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03301393208560083\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.037850414693826676\n",
      "    mean_inference_ms: 0.5168367841172493\n",
      "    mean_raw_obs_processing_ms: 0.041218198294735685\n",
      "  time_since_restore: 156.4133276939392\n",
      "  time_this_iter_s: 2.304961919784546\n",
      "  time_total_s: 156.4133276939392\n",
      "  timers:\n",
      "    learn_throughput: 3515.73\n",
      "    learn_time_ms: 1137.744\n",
      "    load_throughput: 238991680.912\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3443.541\n",
      "    sample_time_ms: 1161.595\n",
      "    update_time_ms: 1.123\n",
      "  timestamp: 1634313184\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 236000\n",
      "  training_iteration: 59\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">        156.413 </td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\">  192.94</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 121</td><td style=\"text-align: right;\">            192.94</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 248000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-53-11\n",
      "  done: false\n",
      "  episode_len_mean: 192.18\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 192.18\n",
      "  episode_reward_min: 107.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 1540\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.5978567600250244\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.045058246701955795\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026448369026184082\n",
      "          model: {}\n",
      "          policy_loss: 0.0026669239159673452\n",
      "          total_loss: 308.12518310546875\n",
      "          vf_explained_var: 0.5753390192985535\n",
      "          vf_loss: 308.0538330078125\n",
      "    num_agent_steps_sampled: 248000\n",
      "    num_agent_steps_trained: 248000\n",
      "    num_steps_sampled: 248000\n",
      "    num_steps_trained: 248000\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.275\n",
      "    ram_util_percent: 57.7\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03286306393602843\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.037677982913482115\n",
      "    mean_inference_ms: 0.5144055433604686\n",
      "    mean_raw_obs_processing_ms: 0.04100298719149981\n",
      "  time_since_restore: 163.3015275001526\n",
      "  time_this_iter_s: 2.2946150302886963\n",
      "  time_total_s: 163.3015275001526\n",
      "  timers:\n",
      "    learn_throughput: 3521.453\n",
      "    learn_time_ms: 1135.895\n",
      "    load_throughput: 237637620.397\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3446.427\n",
      "    sample_time_ms: 1160.622\n",
      "    update_time_ms: 1.113\n",
      "  timestamp: 1634313191\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 248000\n",
      "  training_iteration: 62\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">        163.302 </td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\">  192.18</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 107</td><td style=\"text-align: right;\">            192.18</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 260000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-53-18\n",
      "  done: false\n",
      "  episode_len_mean: 193.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 193.17\n",
      "  episode_reward_min: 118.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1601\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5.84517765045166\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.036678045988082886\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010560956783592701\n",
      "          model: {}\n",
      "          policy_loss: 0.0032543730922043324\n",
      "          total_loss: 260.6420593261719\n",
      "          vf_explained_var: 0.6794266700744629\n",
      "          vf_loss: 260.57708740234375\n",
      "    num_agent_steps_sampled: 260000\n",
      "    num_agent_steps_trained: 260000\n",
      "    num_steps_sampled: 260000\n",
      "    num_steps_trained: 260000\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.63333333333333\n",
      "    ram_util_percent: 57.70000000000001\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.032712720592245906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0375250137656862\n",
      "    mean_inference_ms: 0.5122011432050124\n",
      "    mean_raw_obs_processing_ms: 0.04082133739711422\n",
      "  time_since_restore: 170.20714831352234\n",
      "  time_this_iter_s: 2.298011064529419\n",
      "  time_total_s: 170.20714831352234\n",
      "  timers:\n",
      "    learn_throughput: 3516.941\n",
      "    learn_time_ms: 1137.352\n",
      "    load_throughput: 235966469.761\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3450.113\n",
      "    sample_time_ms: 1159.382\n",
      "    update_time_ms: 1.123\n",
      "  timestamp: 1634313198\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 260000\n",
      "  training_iteration: 65\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">        170.207 </td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\">  193.17</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 118</td><td style=\"text-align: right;\">            193.17</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 272000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-53-25\n",
      "  done: false\n",
      "  episode_len_mean: 192.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 192.73\n",
      "  episode_reward_min: 143.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 1665\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5.84517765045166\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.03346505016088486\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020436739549040794\n",
      "          model: {}\n",
      "          policy_loss: 0.002027573063969612\n",
      "          total_loss: 152.76043701171875\n",
      "          vf_explained_var: 0.6178138852119446\n",
      "          vf_loss: 152.63893127441406\n",
      "    num_agent_steps_sampled: 272000\n",
      "    num_agent_steps_trained: 272000\n",
      "    num_steps_sampled: 272000\n",
      "    num_steps_trained: 272000\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.46666666666667\n",
      "    ram_util_percent: 57.9\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03260522546859283\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03738403194648596\n",
      "    mean_inference_ms: 0.5102093389370852\n",
      "    mean_raw_obs_processing_ms: 0.0406386801286469\n",
      "  time_since_restore: 177.1225779056549\n",
      "  time_this_iter_s: 2.300778865814209\n",
      "  time_total_s: 177.1225779056549\n",
      "  timers:\n",
      "    learn_throughput: 3517.075\n",
      "    learn_time_ms: 1137.309\n",
      "    load_throughput: 234975014.006\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3447.787\n",
      "    sample_time_ms: 1160.165\n",
      "    update_time_ms: 1.13\n",
      "  timestamp: 1634313205\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 272000\n",
      "  training_iteration: 68\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">        177.123 </td><td style=\"text-align: right;\">272000</td><td style=\"text-align: right;\">  192.73</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 143</td><td style=\"text-align: right;\">            192.73</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 284000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-53-32\n",
      "  done: false\n",
      "  episode_len_mean: 194.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.15\n",
      "  episode_reward_min: 143.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1725\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8.767766952514648\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.03575684875249863\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02222457528114319\n",
      "          model: {}\n",
      "          policy_loss: 0.009206690825521946\n",
      "          total_loss: 203.05517578125\n",
      "          vf_explained_var: 0.6771593689918518\n",
      "          vf_loss: 202.85108947753906\n",
      "    num_agent_steps_sampled: 284000\n",
      "    num_agent_steps_trained: 284000\n",
      "    num_steps_sampled: 284000\n",
      "    num_steps_trained: 284000\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.366666666666664\n",
      "    ram_util_percent: 58.0\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03248010512218695\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03726293685386465\n",
      "    mean_inference_ms: 0.5084472038850949\n",
      "    mean_raw_obs_processing_ms: 0.04049461324026793\n",
      "  time_since_restore: 184.02733993530273\n",
      "  time_this_iter_s: 2.2986390590667725\n",
      "  time_total_s: 184.02733993530273\n",
      "  timers:\n",
      "    learn_throughput: 3513.189\n",
      "    learn_time_ms: 1138.567\n",
      "    load_throughput: 235304572.23\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3449.665\n",
      "    sample_time_ms: 1159.533\n",
      "    update_time_ms: 1.131\n",
      "  timestamp: 1634313212\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 284000\n",
      "  training_iteration: 71\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.6/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">        184.027 </td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\">  194.15</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 143</td><td style=\"text-align: right;\">            194.15</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 296000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-53-39\n",
      "  done: false\n",
      "  episode_len_mean: 197.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.72\n",
      "  episode_reward_min: 146.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 1786\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 13.151650428771973\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.02526565082371235\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009685052558779716\n",
      "          model: {}\n",
      "          policy_loss: 0.005840488243848085\n",
      "          total_loss: 415.63616943359375\n",
      "          vf_explained_var: 0.3977401852607727\n",
      "          vf_loss: 415.5029602050781\n",
      "    num_agent_steps_sampled: 296000\n",
      "    num_agent_steps_trained: 296000\n",
      "    num_steps_sampled: 296000\n",
      "    num_steps_trained: 296000\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.366666666666664\n",
      "    ram_util_percent: 58.29999999999999\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03237605549479712\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03714555869708464\n",
      "    mean_inference_ms: 0.5067599240694309\n",
      "    mean_raw_obs_processing_ms: 0.04034543808502627\n",
      "  time_since_restore: 190.97406888008118\n",
      "  time_this_iter_s: 2.31748104095459\n",
      "  time_total_s: 190.97406888008118\n",
      "  timers:\n",
      "    learn_throughput: 3500.171\n",
      "    learn_time_ms: 1142.801\n",
      "    load_throughput: 234646377.622\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3448.978\n",
      "    sample_time_ms: 1159.764\n",
      "    update_time_ms: 1.11\n",
      "  timestamp: 1634313219\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 296000\n",
      "  training_iteration: 74\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">        190.974 </td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\">  197.72</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 146</td><td style=\"text-align: right;\">            197.72</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 308000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-53-46\n",
      "  done: false\n",
      "  episode_len_mean: 196.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.62\n",
      "  episode_reward_min: 142.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 1847\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 19.727476119995117\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.019349191337823868\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022581012919545174\n",
      "          model: {}\n",
      "          policy_loss: 0.006893371231853962\n",
      "          total_loss: 226.9624786376953\n",
      "          vf_explained_var: 0.6425521969795227\n",
      "          vf_loss: 226.51011657714844\n",
      "    num_agent_steps_sampled: 308000\n",
      "    num_agent_steps_trained: 308000\n",
      "    num_steps_sampled: 308000\n",
      "    num_steps_trained: 308000\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.433333333333334\n",
      "    ram_util_percent: 58.5\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03228256413858403\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03703923241420583\n",
      "    mean_inference_ms: 0.5052229178720169\n",
      "    mean_raw_obs_processing_ms: 0.04021079691138249\n",
      "  time_since_restore: 197.8871192932129\n",
      "  time_this_iter_s: 2.3081140518188477\n",
      "  time_total_s: 197.8871192932129\n",
      "  timers:\n",
      "    learn_throughput: 3497.792\n",
      "    learn_time_ms: 1143.579\n",
      "    load_throughput: 236298816.901\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3451.22\n",
      "    sample_time_ms: 1159.01\n",
      "    update_time_ms: 1.099\n",
      "  timestamp: 1634313226\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 308000\n",
      "  training_iteration: 77\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">        197.887 </td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  196.62</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 142</td><td style=\"text-align: right;\">            196.62</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 320000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-53-53\n",
      "  done: false\n",
      "  episode_len_mean: 195.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.41\n",
      "  episode_reward_min: 142.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1908\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 66.58023071289062\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.01946626417338848\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02720554545521736\n",
      "          model: {}\n",
      "          policy_loss: 0.007632967084646225\n",
      "          total_loss: 381.4862976074219\n",
      "          vf_explained_var: 0.5989806652069092\n",
      "          vf_loss: 379.66729736328125\n",
      "    num_agent_steps_sampled: 320000\n",
      "    num_agent_steps_trained: 320000\n",
      "    num_steps_sampled: 320000\n",
      "    num_steps_trained: 320000\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.266666666666666\n",
      "    ram_util_percent: 58.5\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03219661499674208\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03694235293490245\n",
      "    mean_inference_ms: 0.5038415795607802\n",
      "    mean_raw_obs_processing_ms: 0.04008769214338371\n",
      "  time_since_restore: 204.7948362827301\n",
      "  time_this_iter_s: 2.3009450435638428\n",
      "  time_total_s: 204.7948362827301\n",
      "  timers:\n",
      "    learn_throughput: 3501.185\n",
      "    learn_time_ms: 1142.47\n",
      "    load_throughput: 215922985.843\n",
      "    load_time_ms: 0.019\n",
      "    sample_throughput: 3447.648\n",
      "    sample_time_ms: 1160.211\n",
      "    update_time_ms: 1.087\n",
      "  timestamp: 1634313233\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 320000\n",
      "  training_iteration: 80\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">        204.795 </td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\">  195.41</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 142</td><td style=\"text-align: right;\">            195.41</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 332000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-54-00\n",
      "  done: false\n",
      "  episode_len_mean: 196.24\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.24\n",
      "  episode_reward_min: 140.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 1970\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 224.70826721191406\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.021055147051811218\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016842177137732506\n",
      "          model: {}\n",
      "          policy_loss: 0.0024194265715777874\n",
      "          total_loss: 196.8347930908203\n",
      "          vf_explained_var: 0.6409368515014648\n",
      "          vf_loss: 193.0478057861328\n",
      "    num_agent_steps_sampled: 332000\n",
      "    num_agent_steps_trained: 332000\n",
      "    num_steps_sampled: 332000\n",
      "    num_steps_trained: 332000\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.433333333333334\n",
      "    ram_util_percent: 58.4\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.032116246558934636\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03685113184719522\n",
      "    mean_inference_ms: 0.5025333590695569\n",
      "    mean_raw_obs_processing_ms: 0.039970018172197405\n",
      "  time_since_restore: 211.6960906982422\n",
      "  time_this_iter_s: 2.292962074279785\n",
      "  time_total_s: 211.6960906982422\n",
      "  timers:\n",
      "    learn_throughput: 3509.288\n",
      "    learn_time_ms: 1139.832\n",
      "    load_throughput: 213995102.041\n",
      "    load_time_ms: 0.019\n",
      "    sample_throughput: 3447.77\n",
      "    sample_time_ms: 1160.17\n",
      "    update_time_ms: 1.107\n",
      "  timestamp: 1634313240\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 332000\n",
      "  training_iteration: 83\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">        211.696 </td><td style=\"text-align: right;\">332000</td><td style=\"text-align: right;\">  196.24</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 140</td><td style=\"text-align: right;\">            196.24</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 344000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-54-07\n",
      "  done: false\n",
      "  episode_len_mean: 195.69\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.69\n",
      "  episode_reward_min: 140.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2031\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 224.70826721191406\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.027449363842606544\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01374414935708046\n",
      "          model: {}\n",
      "          policy_loss: 0.004829069133847952\n",
      "          total_loss: 185.62564086914062\n",
      "          vf_explained_var: 0.7453989386558533\n",
      "          vf_loss: 182.5323944091797\n",
      "    num_agent_steps_sampled: 344000\n",
      "    num_agent_steps_trained: 344000\n",
      "    num_steps_sampled: 344000\n",
      "    num_steps_trained: 344000\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.36666666666667\n",
      "    ram_util_percent: 58.4\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.032042348360668764\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03676711930845139\n",
      "    mean_inference_ms: 0.5013255631554977\n",
      "    mean_raw_obs_processing_ms: 0.03985810106593053\n",
      "  time_since_restore: 218.61331343650818\n",
      "  time_this_iter_s: 2.297098159790039\n",
      "  time_total_s: 218.61331343650818\n",
      "  timers:\n",
      "    learn_throughput: 3509.062\n",
      "    learn_time_ms: 1139.906\n",
      "    load_throughput: 215092512.821\n",
      "    load_time_ms: 0.019\n",
      "    sample_throughput: 3449.564\n",
      "    sample_time_ms: 1159.567\n",
      "    update_time_ms: 1.111\n",
      "  timestamp: 1634313247\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 344000\n",
      "  training_iteration: 86\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">        218.613 </td><td style=\"text-align: right;\">344000</td><td style=\"text-align: right;\">  195.69</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 140</td><td style=\"text-align: right;\">            195.69</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 356000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-54-14\n",
      "  done: false\n",
      "  episode_len_mean: 196.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.21\n",
      "  episode_reward_min: 146.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2093\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 224.70826721191406\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.028140677139163017\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024204334244132042\n",
      "          model: {}\n",
      "          policy_loss: 0.006712507456541061\n",
      "          total_loss: 247.04502868652344\n",
      "          vf_explained_var: 0.5732285380363464\n",
      "          vf_loss: 241.59939575195312\n",
      "    num_agent_steps_sampled: 356000\n",
      "    num_agent_steps_trained: 356000\n",
      "    num_steps_sampled: 356000\n",
      "    num_steps_trained: 356000\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.725\n",
      "    ram_util_percent: 58.4\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03197073437195822\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03668687677826919\n",
      "    mean_inference_ms: 0.500176884915584\n",
      "    mean_raw_obs_processing_ms: 0.039755921371942296\n",
      "  time_since_restore: 225.5176043510437\n",
      "  time_this_iter_s: 2.2984299659729004\n",
      "  time_total_s: 225.5176043510437\n",
      "  timers:\n",
      "    learn_throughput: 3510.306\n",
      "    learn_time_ms: 1139.502\n",
      "    load_throughput: 235304572.23\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3451.46\n",
      "    sample_time_ms: 1158.93\n",
      "    update_time_ms: 1.115\n",
      "  timestamp: 1634313254\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 356000\n",
      "  training_iteration: 89\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">        225.518 </td><td style=\"text-align: right;\">356000</td><td style=\"text-align: right;\">  196.21</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 146</td><td style=\"text-align: right;\">            196.21</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 368000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-54-21\n",
      "  done: false\n",
      "  episode_len_mean: 194.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.39\n",
      "  episode_reward_min: 142.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2154\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 758.3904418945312\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.023459644988179207\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02090902253985405\n",
      "          model: {}\n",
      "          policy_loss: 0.0016999930376186967\n",
      "          total_loss: 182.66595458984375\n",
      "          vf_explained_var: 0.7748510241508484\n",
      "          vf_loss: 166.80706787109375\n",
      "    num_agent_steps_sampled: 368000\n",
      "    num_agent_steps_trained: 368000\n",
      "    num_steps_sampled: 368000\n",
      "    num_steps_trained: 368000\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.474999999999998\n",
      "    ram_util_percent: 58.45\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0319215777446857\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03661408406487724\n",
      "    mean_inference_ms: 0.4991863612609748\n",
      "    mean_raw_obs_processing_ms: 0.03965616788285803\n",
      "  time_since_restore: 232.41780257225037\n",
      "  time_this_iter_s: 2.298780918121338\n",
      "  time_total_s: 232.41780257225037\n",
      "  timers:\n",
      "    learn_throughput: 3513.518\n",
      "    learn_time_ms: 1138.46\n",
      "    load_throughput: 233016888.889\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3450.985\n",
      "    sample_time_ms: 1159.089\n",
      "    update_time_ms: 1.095\n",
      "  timestamp: 1634313261\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 368000\n",
      "  training_iteration: 92\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">        232.418 </td><td style=\"text-align: right;\">368000</td><td style=\"text-align: right;\">  194.39</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 142</td><td style=\"text-align: right;\">            194.39</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 380000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-54-28\n",
      "  done: false\n",
      "  episode_len_mean: 191.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 191.99\n",
      "  episode_reward_min: 128.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2218\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1706.37841796875\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.02332630567252636\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018093610182404518\n",
      "          model: {}\n",
      "          policy_loss: 0.0061448197811841965\n",
      "          total_loss: 292.1915283203125\n",
      "          vf_explained_var: 0.6776750683784485\n",
      "          vf_loss: 261.31085205078125\n",
      "    num_agent_steps_sampled: 380000\n",
      "    num_agent_steps_trained: 380000\n",
      "    num_steps_sampled: 380000\n",
      "    num_steps_trained: 380000\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.275\n",
      "    ram_util_percent: 58.5\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03187440728031661\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.036542299449832935\n",
      "    mean_inference_ms: 0.4982149173141879\n",
      "    mean_raw_obs_processing_ms: 0.03955929645146432\n",
      "  time_since_restore: 239.341646194458\n",
      "  time_this_iter_s: 2.316429853439331\n",
      "  time_total_s: 239.341646194458\n",
      "  timers:\n",
      "    learn_throughput: 3511.973\n",
      "    learn_time_ms: 1138.961\n",
      "    load_throughput: 234975014.006\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3449.189\n",
      "    sample_time_ms: 1159.693\n",
      "    update_time_ms: 1.086\n",
      "  timestamp: 1634313268\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 380000\n",
      "  training_iteration: 95\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">        239.342 </td><td style=\"text-align: right;\">380000</td><td style=\"text-align: right;\">  191.99</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">            191.99</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 392000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-54-35\n",
      "  done: false\n",
      "  episode_len_mean: 194.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.3\n",
      "  episode_reward_min: 141.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2279\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3839.3515625\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.023386547341942787\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017789440229535103\n",
      "          model: {}\n",
      "          policy_loss: 0.001947210170328617\n",
      "          total_loss: 348.0703430175781\n",
      "          vf_explained_var: 0.5118612051010132\n",
      "          vf_loss: 279.7684326171875\n",
      "    num_agent_steps_sampled: 392000\n",
      "    num_agent_steps_trained: 392000\n",
      "    num_steps_sampled: 392000\n",
      "    num_steps_trained: 392000\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.3\n",
      "    ram_util_percent: 58.5\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.031799272952670626\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03647757627118785\n",
      "    mean_inference_ms: 0.49727611959040074\n",
      "    mean_raw_obs_processing_ms: 0.03948903504297667\n",
      "  time_since_restore: 246.2428903579712\n",
      "  time_this_iter_s: 2.2994072437286377\n",
      "  time_total_s: 246.2428903579712\n",
      "  timers:\n",
      "    learn_throughput: 3513.201\n",
      "    learn_time_ms: 1138.563\n",
      "    load_throughput: 232371412.742\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3448.528\n",
      "    sample_time_ms: 1159.915\n",
      "    update_time_ms: 1.103\n",
      "  timestamp: 1634313275\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 392000\n",
      "  training_iteration: 98\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">        246.243 </td><td style=\"text-align: right;\">392000</td><td style=\"text-align: right;\">   194.3</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 141</td><td style=\"text-align: right;\">             194.3</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 404000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-54-42\n",
      "  done: false\n",
      "  episode_len_mean: 195.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.03\n",
      "  episode_reward_min: 142.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2342\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8638.541015625\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.022322041913866997\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017135147005319595\n",
      "          model: {}\n",
      "          policy_loss: 0.010686936788260937\n",
      "          total_loss: 350.6269836425781\n",
      "          vf_explained_var: 0.7103278040885925\n",
      "          vf_loss: 202.59361267089844\n",
      "    num_agent_steps_sampled: 404000\n",
      "    num_agent_steps_trained: 404000\n",
      "    num_steps_sampled: 404000\n",
      "    num_steps_trained: 404000\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.233333333333334\n",
      "    ram_util_percent: 58.5\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.031743155133170865\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03641644777217625\n",
      "    mean_inference_ms: 0.49638646293289496\n",
      "    mean_raw_obs_processing_ms: 0.03941291635491345\n",
      "  time_since_restore: 253.13014340400696\n",
      "  time_this_iter_s: 2.2947871685028076\n",
      "  time_total_s: 253.13014340400696\n",
      "  timers:\n",
      "    learn_throughput: 3515.781\n",
      "    learn_time_ms: 1137.727\n",
      "    load_throughput: 235635056.18\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3449.85\n",
      "    sample_time_ms: 1159.471\n",
      "    update_time_ms: 1.115\n",
      "  timestamp: 1634313282\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 404000\n",
      "  training_iteration: 101\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">        253.13  </td><td style=\"text-align: right;\">404000</td><td style=\"text-align: right;\">  195.03</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 142</td><td style=\"text-align: right;\">            195.03</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 416000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-54-49\n",
      "  done: false\n",
      "  episode_len_mean: 198.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.79\n",
      "  episode_reward_min: 160.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2402\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 19436.716796875\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.021654171869158745\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022682569921016693\n",
      "          model: {}\n",
      "          policy_loss: -0.004589298274368048\n",
      "          total_loss: 691.1602783203125\n",
      "          vf_explained_var: 0.6154492497444153\n",
      "          vf_loss: 250.29017639160156\n",
      "    num_agent_steps_sampled: 416000\n",
      "    num_agent_steps_trained: 416000\n",
      "    num_steps_sampled: 416000\n",
      "    num_steps_trained: 416000\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 19.566666666666666\n",
      "    ram_util_percent: 58.5\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.031676354350305254\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0363606003248584\n",
      "    mean_inference_ms: 0.4955755481165935\n",
      "    mean_raw_obs_processing_ms: 0.039351253021284824\n",
      "  time_since_restore: 260.0474662780762\n",
      "  time_this_iter_s: 2.301872968673706\n",
      "  time_total_s: 260.0474662780762\n",
      "  timers:\n",
      "    learn_throughput: 3518.098\n",
      "    learn_time_ms: 1136.978\n",
      "    load_throughput: 234975014.006\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3444.38\n",
      "    sample_time_ms: 1161.312\n",
      "    update_time_ms: 1.125\n",
      "  timestamp: 1634313289\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 416000\n",
      "  training_iteration: 104\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">        260.047 </td><td style=\"text-align: right;\">416000</td><td style=\"text-align: right;\">  198.79</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 160</td><td style=\"text-align: right;\">            198.79</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 428000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-54-56\n",
      "  done: false\n",
      "  episode_len_mean: 198.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.13\n",
      "  episode_reward_min: 169.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2462\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 29155.076171875\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.022679787129163742\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02036457695066929\n",
      "          model: {}\n",
      "          policy_loss: 0.0032970828469842672\n",
      "          total_loss: 728.3359985351562\n",
      "          vf_explained_var: 0.8014825582504272\n",
      "          vf_loss: 134.60195922851562\n",
      "    num_agent_steps_sampled: 428000\n",
      "    num_agent_steps_trained: 428000\n",
      "    num_steps_sampled: 428000\n",
      "    num_steps_trained: 428000\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.6\n",
      "    ram_util_percent: 58.53333333333333\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03161148417643263\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.036306302256268734\n",
      "    mean_inference_ms: 0.49480188632954536\n",
      "    mean_raw_obs_processing_ms: 0.039292396249348494\n",
      "  time_since_restore: 266.95774817466736\n",
      "  time_this_iter_s: 2.294442892074585\n",
      "  time_total_s: 266.95774817466736\n",
      "  timers:\n",
      "    learn_throughput: 3520.196\n",
      "    learn_time_ms: 1136.3\n",
      "    load_throughput: 236632101.551\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3444.728\n",
      "    sample_time_ms: 1161.195\n",
      "    update_time_ms: 1.118\n",
      "  timestamp: 1634313296\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 428000\n",
      "  training_iteration: 107\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">        266.958 </td><td style=\"text-align: right;\">428000</td><td style=\"text-align: right;\">  198.13</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 169</td><td style=\"text-align: right;\">            198.13</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 440000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-55-02\n",
      "  done: false\n",
      "  episode_len_mean: 196.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.82\n",
      "  episode_reward_min: 146.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2524\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 43732.61328125\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.02334582805633545\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012013006955385208\n",
      "          model: {}\n",
      "          policy_loss: 0.003686140524223447\n",
      "          total_loss: 674.8966674804688\n",
      "          vf_explained_var: 0.7558326125144958\n",
      "          vf_loss: 149.5327911376953\n",
      "    num_agent_steps_sampled: 440000\n",
      "    num_agent_steps_trained: 440000\n",
      "    num_steps_sampled: 440000\n",
      "    num_steps_trained: 440000\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.233333333333334\n",
      "    ram_util_percent: 58.6\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03158080188656487\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03625494919503414\n",
      "    mean_inference_ms: 0.4940924937137734\n",
      "    mean_raw_obs_processing_ms: 0.03921965832220521\n",
      "  time_since_restore: 273.8527591228485\n",
      "  time_this_iter_s: 2.3045270442962646\n",
      "  time_total_s: 273.8527591228485\n",
      "  timers:\n",
      "    learn_throughput: 3519.201\n",
      "    learn_time_ms: 1136.622\n",
      "    load_throughput: 234975014.006\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3444.688\n",
      "    sample_time_ms: 1161.208\n",
      "    update_time_ms: 1.109\n",
      "  timestamp: 1634313302\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 440000\n",
      "  training_iteration: 110\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">        273.853 </td><td style=\"text-align: right;\">440000</td><td style=\"text-align: right;\">  196.82</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 146</td><td style=\"text-align: right;\">            196.82</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 452000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-55-09\n",
      "  done: false\n",
      "  episode_len_mean: 194.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.98\n",
      "  episode_reward_min: 141.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2585\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 65598.921875\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.02137686498463154\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0178182665258646\n",
      "          model: {}\n",
      "          policy_loss: 0.005861296784132719\n",
      "          total_loss: 1397.6710205078125\n",
      "          vf_explained_var: 0.6271872520446777\n",
      "          vf_loss: 228.80621337890625\n",
      "    num_agent_steps_sampled: 452000\n",
      "    num_agent_steps_trained: 452000\n",
      "    num_steps_sampled: 452000\n",
      "    num_steps_trained: 452000\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.466666666666665\n",
      "    ram_util_percent: 58.6\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03155436686790368\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0362092536628841\n",
      "    mean_inference_ms: 0.49345352056874275\n",
      "    mean_raw_obs_processing_ms: 0.03915271538356969\n",
      "  time_since_restore: 280.7600169181824\n",
      "  time_this_iter_s: 2.299868106842041\n",
      "  time_total_s: 280.7600169181824\n",
      "  timers:\n",
      "    learn_throughput: 3518.702\n",
      "    learn_time_ms: 1136.783\n",
      "    load_throughput: 237637620.397\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3446.028\n",
      "    sample_time_ms: 1160.757\n",
      "    update_time_ms: 1.107\n",
      "  timestamp: 1634313309\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 452000\n",
      "  training_iteration: 113\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">        280.76  </td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\">  194.98</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 141</td><td style=\"text-align: right;\">            194.98</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 464000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-55-16\n",
      "  done: false\n",
      "  episode_len_mean: 194.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.45\n",
      "  episode_reward_min: 123.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2647\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 32799.4609375\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.025732535868883133\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0010122357634827495\n",
      "          model: {}\n",
      "          policy_loss: 0.002971413778141141\n",
      "          total_loss: 297.4949645996094\n",
      "          vf_explained_var: 0.6478614807128906\n",
      "          vf_loss: 264.29119873046875\n",
      "    num_agent_steps_sampled: 464000\n",
      "    num_agent_steps_trained: 464000\n",
      "    num_steps_sampled: 464000\n",
      "    num_steps_trained: 464000\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.466666666666665\n",
      "    ram_util_percent: 58.6\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03151339050982826\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.036164680505221786\n",
      "    mean_inference_ms: 0.4928154904809873\n",
      "    mean_raw_obs_processing_ms: 0.03909546100753663\n",
      "  time_since_restore: 287.66381764411926\n",
      "  time_this_iter_s: 2.298473834991455\n",
      "  time_total_s: 287.66381764411926\n",
      "  timers:\n",
      "    learn_throughput: 3521.891\n",
      "    learn_time_ms: 1135.754\n",
      "    load_throughput: 236966327.684\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3447.098\n",
      "    sample_time_ms: 1160.397\n",
      "    update_time_ms: 1.118\n",
      "  timestamp: 1634313316\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 464000\n",
      "  training_iteration: 116\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">        287.664 </td><td style=\"text-align: right;\">464000</td><td style=\"text-align: right;\">  194.45</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 123</td><td style=\"text-align: right;\">            194.45</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 476000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-55-23\n",
      "  done: false\n",
      "  episode_len_mean: 193.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 193.32\n",
      "  episode_reward_min: 129.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2709\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4099.9326171875\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.021833982318639755\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 4.932177034788765e-05\n",
      "          model: {}\n",
      "          policy_loss: 0.0017498948145657778\n",
      "          total_loss: 214.48110961914062\n",
      "          vf_explained_var: 0.6783857345581055\n",
      "          vf_loss: 214.2771453857422\n",
      "    num_agent_steps_sampled: 476000\n",
      "    num_agent_steps_trained: 476000\n",
      "    num_steps_sampled: 476000\n",
      "    num_steps_trained: 476000\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.966666666666665\n",
      "    ram_util_percent: 58.6\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03147383226676362\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03612114190196903\n",
      "    mean_inference_ms: 0.49220336643534923\n",
      "    mean_raw_obs_processing_ms: 0.03904114679461519\n",
      "  time_since_restore: 294.5769729614258\n",
      "  time_this_iter_s: 2.301964044570923\n",
      "  time_total_s: 294.5769729614258\n",
      "  timers:\n",
      "    learn_throughput: 3515.186\n",
      "    learn_time_ms: 1137.92\n",
      "    load_throughput: 233991854.951\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3445.198\n",
      "    sample_time_ms: 1161.036\n",
      "    update_time_ms: 1.103\n",
      "  timestamp: 1634313323\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 476000\n",
      "  training_iteration: 119\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">        294.577 </td><td style=\"text-align: right;\">476000</td><td style=\"text-align: right;\">  193.32</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 129</td><td style=\"text-align: right;\">            193.32</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 488000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-55-30\n",
      "  done: false\n",
      "  episode_len_mean: 191.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 191.34\n",
      "  episode_reward_min: 117.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2772\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 512.4915771484375\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.02447798289358616\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.5047836541270954e-06\n",
      "          model: {}\n",
      "          policy_loss: 0.0010183107806369662\n",
      "          total_loss: 280.0281982421875\n",
      "          vf_explained_var: 0.5318291187286377\n",
      "          vf_loss: 280.0263977050781\n",
      "    num_agent_steps_sampled: 488000\n",
      "    num_agent_steps_trained: 488000\n",
      "    num_steps_sampled: 488000\n",
      "    num_steps_trained: 488000\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.65\n",
      "    ram_util_percent: 58.7\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03145391527015848\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03608188880202449\n",
      "    mean_inference_ms: 0.49167400284047624\n",
      "    mean_raw_obs_processing_ms: 0.03898209678669016\n",
      "  time_since_restore: 301.4835629463196\n",
      "  time_this_iter_s: 2.2984938621520996\n",
      "  time_total_s: 301.4835629463196\n",
      "  timers:\n",
      "    learn_throughput: 3518.113\n",
      "    learn_time_ms: 1136.973\n",
      "    load_throughput: 233991854.951\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3444.032\n",
      "    sample_time_ms: 1161.429\n",
      "    update_time_ms: 1.108\n",
      "  timestamp: 1634313330\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 488000\n",
      "  training_iteration: 122\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">        301.484 </td><td style=\"text-align: right;\">488000</td><td style=\"text-align: right;\">  191.34</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 117</td><td style=\"text-align: right;\">            191.34</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 500000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-55-37\n",
      "  done: false\n",
      "  episode_len_mean: 193.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 193.39\n",
      "  episode_reward_min: 125.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2834\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 64.06144714355469\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.026976358145475388\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 7.330835160246352e-06\n",
      "          model: {}\n",
      "          policy_loss: -0.0073959254659712315\n",
      "          total_loss: 251.12245178222656\n",
      "          vf_explained_var: 0.6693288683891296\n",
      "          vf_loss: 251.12936401367188\n",
      "    num_agent_steps_sampled: 500000\n",
      "    num_agent_steps_trained: 500000\n",
      "    num_steps_sampled: 500000\n",
      "    num_steps_trained: 500000\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.35\n",
      "    ram_util_percent: 58.8\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03140266242586946\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03604274659018219\n",
      "    mean_inference_ms: 0.49110349533676184\n",
      "    mean_raw_obs_processing_ms: 0.03894335416701714\n",
      "  time_since_restore: 308.4029622077942\n",
      "  time_this_iter_s: 2.3006131649017334\n",
      "  time_total_s: 308.4029622077942\n",
      "  timers:\n",
      "    learn_throughput: 3512.526\n",
      "    learn_time_ms: 1138.782\n",
      "    load_throughput: 231409875.862\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3445.203\n",
      "    sample_time_ms: 1161.035\n",
      "    update_time_ms: 1.112\n",
      "  timestamp: 1634313337\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 500000\n",
      "  training_iteration: 125\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">        308.403 </td><td style=\"text-align: right;\">500000</td><td style=\"text-align: right;\">  193.39</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 125</td><td style=\"text-align: right;\">            193.39</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 512000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-55-44\n",
      "  done: false\n",
      "  episode_len_mean: 195.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.45\n",
      "  episode_reward_min: 141.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2895\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8.007680892944336\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.022639010101556778\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.507618384901434e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.004638582468032837\n",
      "          total_loss: 223.90518188476562\n",
      "          vf_explained_var: 0.6234924793243408\n",
      "          vf_loss: 223.90953063964844\n",
      "    num_agent_steps_sampled: 512000\n",
      "    num_agent_steps_trained: 512000\n",
      "    num_steps_sampled: 512000\n",
      "    num_steps_trained: 512000\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.425\n",
      "    ram_util_percent: 58.8\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03135280315366284\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03600516699183562\n",
      "    mean_inference_ms: 0.4905586949561683\n",
      "    mean_raw_obs_processing_ms: 0.03890651359570431\n",
      "  time_since_restore: 315.32587909698486\n",
      "  time_this_iter_s: 2.3143038749694824\n",
      "  time_total_s: 315.32587909698486\n",
      "  timers:\n",
      "    learn_throughput: 3511.661\n",
      "    learn_time_ms: 1139.062\n",
      "    load_throughput: 233016888.889\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3442.108\n",
      "    sample_time_ms: 1162.078\n",
      "    update_time_ms: 1.121\n",
      "  timestamp: 1634313344\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 512000\n",
      "  training_iteration: 128\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">        315.326 </td><td style=\"text-align: right;\">512000</td><td style=\"text-align: right;\">  195.45</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 141</td><td style=\"text-align: right;\">            195.45</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 524000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-55-51\n",
      "  done: false\n",
      "  episode_len_mean: 194.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.36\n",
      "  episode_reward_min: 126.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2957\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.000960111618042\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.0245366208255291\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0003373818763066083\n",
      "          model: {}\n",
      "          policy_loss: 0.0012311121681705117\n",
      "          total_loss: 187.77406311035156\n",
      "          vf_explained_var: 0.6041390299797058\n",
      "          vf_loss: 187.77249145507812\n",
      "    num_agent_steps_sampled: 524000\n",
      "    num_agent_steps_trained: 524000\n",
      "    num_steps_sampled: 524000\n",
      "    num_steps_trained: 524000\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.075000000000003\n",
      "    ram_util_percent: 59.05\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.031321290649358326\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03596980815439454\n",
      "    mean_inference_ms: 0.4900635826727371\n",
      "    mean_raw_obs_processing_ms: 0.03886392583439399\n",
      "  time_since_restore: 322.3214964866638\n",
      "  time_this_iter_s: 2.304582118988037\n",
      "  time_total_s: 322.3214964866638\n",
      "  timers:\n",
      "    learn_throughput: 3482.098\n",
      "    learn_time_ms: 1148.733\n",
      "    load_throughput: 233016888.889\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3445.446\n",
      "    sample_time_ms: 1160.953\n",
      "    update_time_ms: 1.109\n",
      "  timestamp: 1634313351\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 524000\n",
      "  training_iteration: 131\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">        322.321 </td><td style=\"text-align: right;\">524000</td><td style=\"text-align: right;\">  194.36</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 126</td><td style=\"text-align: right;\">            194.36</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 536000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-55-58\n",
      "  done: false\n",
      "  episode_len_mean: 193.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 193.43\n",
      "  episode_reward_min: 136.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3019\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.12512001395225525\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.02591009996831417\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0021655333694070578\n",
      "          model: {}\n",
      "          policy_loss: -0.001225546351633966\n",
      "          total_loss: 260.375732421875\n",
      "          vf_explained_var: 0.6275671720504761\n",
      "          vf_loss: 260.3766784667969\n",
      "    num_agent_steps_sampled: 536000\n",
      "    num_agent_steps_trained: 536000\n",
      "    num_steps_sampled: 536000\n",
      "    num_steps_trained: 536000\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.333333333333332\n",
      "    ram_util_percent: 59.1\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03132558809160753\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03594069117949277\n",
      "    mean_inference_ms: 0.4896958701965985\n",
      "    mean_raw_obs_processing_ms: 0.038806323947464666\n",
      "  time_since_restore: 329.2546184062958\n",
      "  time_this_iter_s: 2.3060061931610107\n",
      "  time_total_s: 329.2546184062958\n",
      "  timers:\n",
      "    learn_throughput: 3483.05\n",
      "    learn_time_ms: 1148.419\n",
      "    load_throughput: 233991854.951\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3439.8\n",
      "    sample_time_ms: 1162.858\n",
      "    update_time_ms: 1.11\n",
      "  timestamp: 1634313358\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 536000\n",
      "  training_iteration: 134\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">        329.255 </td><td style=\"text-align: right;\">536000</td><td style=\"text-align: right;\">  193.43</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 136</td><td style=\"text-align: right;\">            193.43</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 548000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-56-05\n",
      "  done: false\n",
      "  episode_len_mean: 191.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 191.78\n",
      "  episode_reward_min: 136.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3082\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.03128000348806381\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.030147982761263847\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021021060645580292\n",
      "          model: {}\n",
      "          policy_loss: 0.007217974402010441\n",
      "          total_loss: 259.5378112792969\n",
      "          vf_explained_var: 0.6014902591705322\n",
      "          vf_loss: 259.52996826171875\n",
      "    num_agent_steps_sampled: 548000\n",
      "    num_agent_steps_trained: 548000\n",
      "    num_steps_sampled: 548000\n",
      "    num_steps_trained: 548000\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 14.566666666666668\n",
      "    ram_util_percent: 59.1\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.031299923127399466\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03591159481122471\n",
      "    mean_inference_ms: 0.48926839711994047\n",
      "    mean_raw_obs_processing_ms: 0.03876786813196083\n",
      "  time_since_restore: 336.17435908317566\n",
      "  time_this_iter_s: 2.3036789894104004\n",
      "  time_total_s: 336.17435908317566\n",
      "  timers:\n",
      "    learn_throughput: 3481.318\n",
      "    learn_time_ms: 1148.99\n",
      "    load_throughput: 233340973.574\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3438.402\n",
      "    sample_time_ms: 1163.331\n",
      "    update_time_ms: 1.104\n",
      "  timestamp: 1634313365\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 548000\n",
      "  training_iteration: 137\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">        336.174 </td><td style=\"text-align: right;\">548000</td><td style=\"text-align: right;\">  191.78</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 136</td><td style=\"text-align: right;\">            191.78</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 560000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-56-12\n",
      "  done: false\n",
      "  episode_len_mean: 193.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 193.44\n",
      "  episode_reward_min: 136.0\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 3144\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10557001084089279\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.017136044800281525\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03332974761724472\n",
      "          model: {}\n",
      "          policy_loss: 0.0011737802997231483\n",
      "          total_loss: 181.55380249023438\n",
      "          vf_explained_var: 0.6397672295570374\n",
      "          vf_loss: 181.54910278320312\n",
      "    num_agent_steps_sampled: 560000\n",
      "    num_agent_steps_trained: 560000\n",
      "    num_steps_sampled: 560000\n",
      "    num_steps_trained: 560000\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.633333333333336\n",
      "    ram_util_percent: 59.1\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03126024440057084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03588235770096876\n",
      "    mean_inference_ms: 0.4888208329598278\n",
      "    mean_raw_obs_processing_ms: 0.03873997958169765\n",
      "  time_since_restore: 343.114328622818\n",
      "  time_this_iter_s: 2.314314126968384\n",
      "  time_total_s: 343.114328622818\n",
      "  timers:\n",
      "    learn_throughput: 3504.909\n",
      "    learn_time_ms: 1141.256\n",
      "    load_throughput: 232050013.831\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3434.775\n",
      "    sample_time_ms: 1164.56\n",
      "    update_time_ms: 1.105\n",
      "  timestamp: 1634313372\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 560000\n",
      "  training_iteration: 140\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">        343.114 </td><td style=\"text-align: right;\">560000</td><td style=\"text-align: right;\">  193.44</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 136</td><td style=\"text-align: right;\">            193.44</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 572000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-56-19\n",
      "  done: false\n",
      "  episode_len_mean: 193.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 193.98\n",
      "  episode_reward_min: 128.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3205\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3562987744808197\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.021979190409183502\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.050189364701509476\n",
      "          model: {}\n",
      "          policy_loss: -0.017488112673163414\n",
      "          total_loss: 262.1922912597656\n",
      "          vf_explained_var: 0.6160300374031067\n",
      "          vf_loss: 262.19189453125\n",
      "    num_agent_steps_sampled: 572000\n",
      "    num_agent_steps_trained: 572000\n",
      "    num_steps_sampled: 572000\n",
      "    num_steps_trained: 572000\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 14.200000000000001\n",
      "    ram_util_percent: 59.1\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.031236412625758426\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03585417300368663\n",
      "    mean_inference_ms: 0.48843136241111723\n",
      "    mean_raw_obs_processing_ms: 0.038703849587836424\n",
      "  time_since_restore: 350.0354006290436\n",
      "  time_this_iter_s: 2.3060970306396484\n",
      "  time_total_s: 350.0354006290436\n",
      "  timers:\n",
      "    learn_throughput: 3508.035\n",
      "    learn_time_ms: 1140.239\n",
      "    load_throughput: 233340973.574\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3434.9\n",
      "    sample_time_ms: 1164.517\n",
      "    update_time_ms: 1.104\n",
      "  timestamp: 1634313379\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 572000\n",
      "  training_iteration: 143\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">        350.035 </td><td style=\"text-align: right;\">572000</td><td style=\"text-align: right;\">  193.98</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">            193.98</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 584000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-56-26\n",
      "  done: false\n",
      "  episode_len_mean: 194.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.68\n",
      "  episode_reward_min: 128.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3267\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2025083303451538\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.034568868577480316\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.037081968039274216\n",
      "          model: {}\n",
      "          policy_loss: 0.0033723257947713137\n",
      "          total_loss: 250.09112548828125\n",
      "          vf_explained_var: 0.6437906622886658\n",
      "          vf_loss: 250.0431671142578\n",
      "    num_agent_steps_sampled: 584000\n",
      "    num_agent_steps_trained: 584000\n",
      "    num_steps_sampled: 584000\n",
      "    num_steps_trained: 584000\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.333333333333332\n",
      "    ram_util_percent: 59.1\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0312133113256351\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03582664718300585\n",
      "    mean_inference_ms: 0.48805007330102584\n",
      "    mean_raw_obs_processing_ms: 0.03866911828917902\n",
      "  time_since_restore: 356.9494354724884\n",
      "  time_this_iter_s: 2.303025960922241\n",
      "  time_total_s: 356.9494354724884\n",
      "  timers:\n",
      "    learn_throughput: 3509.674\n",
      "    learn_time_ms: 1139.707\n",
      "    load_throughput: 231091129.477\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3435.794\n",
      "    sample_time_ms: 1164.214\n",
      "    update_time_ms: 1.112\n",
      "  timestamp: 1634313386\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 584000\n",
      "  training_iteration: 146\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">        356.949 </td><td style=\"text-align: right;\">584000</td><td style=\"text-align: right;\">  194.68</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">            194.68</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 596000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-56-33\n",
      "  done: false\n",
      "  episode_len_mean: 196.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.82\n",
      "  episode_reward_min: 133.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3327\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.058465957641602\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.03258999064564705\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01804187148809433\n",
      "          model: {}\n",
      "          policy_loss: 0.007334898225963116\n",
      "          total_loss: 375.8227844238281\n",
      "          vf_explained_var: 0.43233582377433777\n",
      "          vf_loss: 375.7422790527344\n",
      "    num_agent_steps_sampled: 596000\n",
      "    num_agent_steps_trained: 596000\n",
      "    num_steps_sampled: 596000\n",
      "    num_steps_trained: 596000\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 11.933333333333332\n",
      "    ram_util_percent: 59.166666666666664\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.031173756911773803\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03579918225182549\n",
      "    mean_inference_ms: 0.487636869953225\n",
      "    mean_raw_obs_processing_ms: 0.038644571765865436\n",
      "  time_since_restore: 363.85910820961\n",
      "  time_this_iter_s: 2.30416202545166\n",
      "  time_total_s: 363.85910820961\n",
      "  timers:\n",
      "    learn_throughput: 3510.813\n",
      "    learn_time_ms: 1139.337\n",
      "    load_throughput: 234646377.622\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3440.498\n",
      "    sample_time_ms: 1162.622\n",
      "    update_time_ms: 1.111\n",
      "  timestamp: 1634313393\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 596000\n",
      "  training_iteration: 149\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">        363.859 </td><td style=\"text-align: right;\">596000</td><td style=\"text-align: right;\">  196.82</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 133</td><td style=\"text-align: right;\">            196.82</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 608000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-56-40\n",
      "  done: false\n",
      "  episode_len_mean: 198.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.85\n",
      "  episode_reward_min: 171.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3387\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 9.131547927856445\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.03856142982840538\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.041313789784908295\n",
      "          model: {}\n",
      "          policy_loss: 0.011208759620785713\n",
      "          total_loss: 225.64028930664062\n",
      "          vf_explained_var: 0.6634702682495117\n",
      "          vf_loss: 225.2518310546875\n",
      "    num_agent_steps_sampled: 608000\n",
      "    num_agent_steps_trained: 608000\n",
      "    num_steps_sampled: 608000\n",
      "    num_steps_trained: 608000\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.53333333333333\n",
      "    ram_util_percent: 62.29999999999999\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03114309581630833\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03578111758312275\n",
      "    mean_inference_ms: 0.48739630406762635\n",
      "    mean_raw_obs_processing_ms: 0.03863710193273248\n",
      "  time_since_restore: 370.9347791671753\n",
      "  time_this_iter_s: 2.30354905128479\n",
      "  time_total_s: 370.9347791671753\n",
      "  timers:\n",
      "    learn_throughput: 3511.05\n",
      "    learn_time_ms: 1139.26\n",
      "    load_throughput: 232050013.831\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3397.555\n",
      "    sample_time_ms: 1177.317\n",
      "    update_time_ms: 1.102\n",
      "  timestamp: 1634313400\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 608000\n",
      "  training_iteration: 152\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">        370.935 </td><td style=\"text-align: right;\">608000</td><td style=\"text-align: right;\">  198.85</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 171</td><td style=\"text-align: right;\">            198.85</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 620000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-56-47\n",
      "  done: false\n",
      "  episode_len_mean: 199.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.8\n",
      "  episode_reward_min: 180.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3447\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 20.545982360839844\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.03140302747488022\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03467385843396187\n",
      "          model: {}\n",
      "          policy_loss: 0.009347275830805302\n",
      "          total_loss: 164.9791259765625\n",
      "          vf_explained_var: 0.775076150894165\n",
      "          vf_loss: 164.25738525390625\n",
      "    num_agent_steps_sampled: 620000\n",
      "    num_agent_steps_trained: 620000\n",
      "    num_steps_sampled: 620000\n",
      "    num_steps_trained: 620000\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.5\n",
      "    ram_util_percent: 62.29999999999999\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03113359372700709\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0357691816507966\n",
      "    mean_inference_ms: 0.4872834730099829\n",
      "    mean_raw_obs_processing_ms: 0.038630048204127694\n",
      "  time_since_restore: 377.83895540237427\n",
      "  time_this_iter_s: 2.3034610748291016\n",
      "  time_total_s: 377.83895540237427\n",
      "  timers:\n",
      "    learn_throughput: 3512.971\n",
      "    learn_time_ms: 1138.637\n",
      "    load_throughput: 228572425.068\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3399.464\n",
      "    sample_time_ms: 1176.656\n",
      "    update_time_ms: 1.088\n",
      "  timestamp: 1634313407\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 620000\n",
      "  training_iteration: 155\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">        377.839 </td><td style=\"text-align: right;\">620000</td><td style=\"text-align: right;\">   199.8</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 180</td><td style=\"text-align: right;\">             199.8</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 632000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-56-54\n",
      "  done: false\n",
      "  episode_len_mean: 199.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.3\n",
      "  episode_reward_min: 164.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3507\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 46.22846221923828\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.03377624601125717\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029570963233709335\n",
      "          model: {}\n",
      "          policy_loss: 0.0057837641797959805\n",
      "          total_loss: 214.0142364501953\n",
      "          vf_explained_var: 0.8016908168792725\n",
      "          vf_loss: 212.6414337158203\n",
      "    num_agent_steps_sampled: 632000\n",
      "    num_agent_steps_trained: 632000\n",
      "    num_steps_sampled: 632000\n",
      "    num_steps_trained: 632000\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.53333333333333\n",
      "    ram_util_percent: 62.29999999999999\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.031111506739459272\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03574439200219987\n",
      "    mean_inference_ms: 0.4869294801783292\n",
      "    mean_raw_obs_processing_ms: 0.03859848529985993\n",
      "  time_since_restore: 384.7592103481293\n",
      "  time_this_iter_s: 2.306906223297119\n",
      "  time_total_s: 384.7592103481293\n",
      "  timers:\n",
      "    learn_throughput: 3510.601\n",
      "    learn_time_ms: 1139.406\n",
      "    load_throughput: 226413171.39\n",
      "    load_time_ms: 0.018\n",
      "    sample_throughput: 3398.275\n",
      "    sample_time_ms: 1177.068\n",
      "    update_time_ms: 1.089\n",
      "  timestamp: 1634313414\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 632000\n",
      "  training_iteration: 158\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">        384.759 </td><td style=\"text-align: right;\">632000</td><td style=\"text-align: right;\">   199.3</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 164</td><td style=\"text-align: right;\">             199.3</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 644000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-57-01\n",
      "  done: false\n",
      "  episode_len_mean: 195.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.46\n",
      "  episode_reward_min: 111.0\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 3570\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 104.0140380859375\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.028327936306595802\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023265670984983444\n",
      "          model: {}\n",
      "          policy_loss: 0.0018994394922628999\n",
      "          total_loss: 230.52706909179688\n",
      "          vf_explained_var: 0.5045852661132812\n",
      "          vf_loss: 228.10520935058594\n",
      "    num_agent_steps_sampled: 644000\n",
      "    num_agent_steps_trained: 644000\n",
      "    num_steps_sampled: 644000\n",
      "    num_steps_trained: 644000\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.275\n",
      "    ram_util_percent: 62.3\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03112158157233118\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03572248939393214\n",
      "    mean_inference_ms: 0.48666580767711953\n",
      "    mean_raw_obs_processing_ms: 0.03855024531010169\n",
      "  time_since_restore: 391.68570947647095\n",
      "  time_this_iter_s: 2.306751012802124\n",
      "  time_total_s: 391.68570947647095\n",
      "  timers:\n",
      "    learn_throughput: 3510.891\n",
      "    learn_time_ms: 1139.312\n",
      "    load_throughput: 233016888.889\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3441.696\n",
      "    sample_time_ms: 1162.218\n",
      "    update_time_ms: 1.085\n",
      "  timestamp: 1634313421\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 644000\n",
      "  training_iteration: 161\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   161</td><td style=\"text-align: right;\">        391.686 </td><td style=\"text-align: right;\">644000</td><td style=\"text-align: right;\">  195.46</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 111</td><td style=\"text-align: right;\">            195.46</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 656000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-57-08\n",
      "  done: false\n",
      "  episode_len_mean: 194.23\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.23\n",
      "  episode_reward_min: 111.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3631\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 351.0473937988281\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.024887733161449432\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018525080755352974\n",
      "          model: {}\n",
      "          policy_loss: 0.008267736993730068\n",
      "          total_loss: 251.63320922851562\n",
      "          vf_explained_var: 0.5858461260795593\n",
      "          vf_loss: 245.1217498779297\n",
      "    num_agent_steps_sampled: 656000\n",
      "    num_agent_steps_trained: 656000\n",
      "    num_steps_sampled: 656000\n",
      "    num_steps_trained: 656000\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.325000000000003\n",
      "    ram_util_percent: 62.375\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03110330966397798\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03570081336421884\n",
      "    mean_inference_ms: 0.4863765274194083\n",
      "    mean_raw_obs_processing_ms: 0.03852220551174598\n",
      "  time_since_restore: 398.62400221824646\n",
      "  time_this_iter_s: 2.3140530586242676\n",
      "  time_total_s: 398.62400221824646\n",
      "  timers:\n",
      "    learn_throughput: 3504.275\n",
      "    learn_time_ms: 1141.463\n",
      "    load_throughput: 240017396.28\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3438.071\n",
      "    sample_time_ms: 1163.443\n",
      "    update_time_ms: 1.102\n",
      "  timestamp: 1634313428\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 656000\n",
      "  training_iteration: 164\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   164</td><td style=\"text-align: right;\">        398.624 </td><td style=\"text-align: right;\">656000</td><td style=\"text-align: right;\">  194.23</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 111</td><td style=\"text-align: right;\">            194.23</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 668000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-57-15\n",
      "  done: false\n",
      "  episode_len_mean: 194.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.95\n",
      "  episode_reward_min: 103.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3692\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 351.0473937988281\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.025736594572663307\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01904536969959736\n",
      "          model: {}\n",
      "          policy_loss: 0.001065110438503325\n",
      "          total_loss: 205.11697387695312\n",
      "          vf_explained_var: 0.6688538193702698\n",
      "          vf_loss: 198.43008422851562\n",
      "    num_agent_steps_sampled: 668000\n",
      "    num_agent_steps_trained: 668000\n",
      "    num_steps_sampled: 668000\n",
      "    num_steps_trained: 668000\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.100000000000005\n",
      "    ram_util_percent: 62.5\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03106950686490566\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03567888656000634\n",
      "    mean_inference_ms: 0.48605326057436593\n",
      "    mean_raw_obs_processing_ms: 0.038503932851147595\n",
      "  time_since_restore: 405.53260111808777\n",
      "  time_this_iter_s: 2.3012890815734863\n",
      "  time_total_s: 405.53260111808777\n",
      "  timers:\n",
      "    learn_throughput: 3506.109\n",
      "    learn_time_ms: 1140.866\n",
      "    load_throughput: 238312727.273\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3438.822\n",
      "    sample_time_ms: 1163.189\n",
      "    update_time_ms: 1.11\n",
      "  timestamp: 1634313435\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 668000\n",
      "  training_iteration: 167\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   167</td><td style=\"text-align: right;\">        405.533 </td><td style=\"text-align: right;\">668000</td><td style=\"text-align: right;\">  194.95</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 103</td><td style=\"text-align: right;\">            194.95</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 680000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-57-22\n",
      "  done: false\n",
      "  episode_len_mean: 195.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.29\n",
      "  episode_reward_min: 103.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3754\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 789.8566284179688\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.023882951587438583\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021309973672032356\n",
      "          model: {}\n",
      "          policy_loss: 0.0005092198844067752\n",
      "          total_loss: 341.5623779296875\n",
      "          vf_explained_var: 0.4555712640285492\n",
      "          vf_loss: 324.7300109863281\n",
      "    num_agent_steps_sampled: 680000\n",
      "    num_agent_steps_trained: 680000\n",
      "    num_steps_sampled: 680000\n",
      "    num_steps_trained: 680000\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.53333333333333\n",
      "    ram_util_percent: 62.5\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.031067311367693504\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03565948930924256\n",
      "    mean_inference_ms: 0.48579523086650794\n",
      "    mean_raw_obs_processing_ms: 0.03846959507448172\n",
      "  time_since_restore: 412.4515891075134\n",
      "  time_this_iter_s: 2.3029592037200928\n",
      "  time_total_s: 412.4515891075134\n",
      "  timers:\n",
      "    learn_throughput: 3509.225\n",
      "    learn_time_ms: 1139.853\n",
      "    load_throughput: 237301499.293\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3438.019\n",
      "    sample_time_ms: 1163.461\n",
      "    update_time_ms: 1.114\n",
      "  timestamp: 1634313442\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 680000\n",
      "  training_iteration: 170\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   170</td><td style=\"text-align: right;\">        412.452 </td><td style=\"text-align: right;\">680000</td><td style=\"text-align: right;\">  195.29</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 103</td><td style=\"text-align: right;\">            195.29</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 692000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-57-29\n",
      "  done: false\n",
      "  episode_len_mean: 194.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.57\n",
      "  episode_reward_min: 110.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3816\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2665.76611328125\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.027045657858252525\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01053878478705883\n",
      "          model: {}\n",
      "          policy_loss: 0.001407517702318728\n",
      "          total_loss: 383.3592834472656\n",
      "          vf_explained_var: 0.1400946080684662\n",
      "          vf_loss: 355.2639465332031\n",
      "    num_agent_steps_sampled: 692000\n",
      "    num_agent_steps_trained: 692000\n",
      "    num_steps_sampled: 692000\n",
      "    num_steps_trained: 692000\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.299999999999999\n",
      "    ram_util_percent: 62.5\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.031034095961312454\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035639022033610517\n",
      "    mean_inference_ms: 0.4854738649333846\n",
      "    mean_raw_obs_processing_ms: 0.03845330737701145\n",
      "  time_since_restore: 419.3700761795044\n",
      "  time_this_iter_s: 2.312509059906006\n",
      "  time_total_s: 419.3700761795044\n",
      "  timers:\n",
      "    learn_throughput: 3511.314\n",
      "    learn_time_ms: 1139.175\n",
      "    load_throughput: 234318659.218\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3439.683\n",
      "    sample_time_ms: 1162.898\n",
      "    update_time_ms: 1.112\n",
      "  timestamp: 1634313449\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 692000\n",
      "  training_iteration: 173\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   173</td><td style=\"text-align: right;\">        419.37  </td><td style=\"text-align: right;\">692000</td><td style=\"text-align: right;\">  194.57</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 110</td><td style=\"text-align: right;\">            194.57</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 704000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-57-36\n",
      "  done: false\n",
      "  episode_len_mean: 192.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 192.76\n",
      "  episode_reward_min: 103.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3879\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3998.649169921875\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.03227750584483147\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014185648411512375\n",
      "          model: {}\n",
      "          policy_loss: 0.005689940880984068\n",
      "          total_loss: 415.17218017578125\n",
      "          vf_explained_var: 0.5092543959617615\n",
      "          vf_loss: 358.4430236816406\n",
      "    num_agent_steps_sampled: 704000\n",
      "    num_agent_steps_trained: 704000\n",
      "    num_steps_sampled: 704000\n",
      "    num_steps_trained: 704000\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.23333333333333\n",
      "    ram_util_percent: 62.5\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03103181156016133\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03562076748663632\n",
      "    mean_inference_ms: 0.48523434190287623\n",
      "    mean_raw_obs_processing_ms: 0.03841932438521148\n",
      "  time_since_restore: 426.3120994567871\n",
      "  time_this_iter_s: 2.323544979095459\n",
      "  time_total_s: 426.3120994567871\n",
      "  timers:\n",
      "    learn_throughput: 3502.083\n",
      "    learn_time_ms: 1142.177\n",
      "    load_throughput: 237301499.293\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3442.42\n",
      "    sample_time_ms: 1161.973\n",
      "    update_time_ms: 1.126\n",
      "  timestamp: 1634313456\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 704000\n",
      "  training_iteration: 176\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   176</td><td style=\"text-align: right;\">        426.312 </td><td style=\"text-align: right;\">704000</td><td style=\"text-align: right;\">  192.76</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 103</td><td style=\"text-align: right;\">            192.76</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 716000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-57-43\n",
      "  done: false\n",
      "  episode_len_mean: 193.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 193.36\n",
      "  episode_reward_min: 103.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3940\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5997.9736328125\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.030675478279590607\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03457265719771385\n",
      "          model: {}\n",
      "          policy_loss: 0.009151836857199669\n",
      "          total_loss: 443.317138671875\n",
      "          vf_explained_var: 0.5839788913726807\n",
      "          vf_loss: 235.94204711914062\n",
      "    num_agent_steps_sampled: 716000\n",
      "    num_agent_steps_trained: 716000\n",
      "    num_steps_sampled: 716000\n",
      "    num_steps_trained: 716000\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.466666666666665\n",
      "    ram_util_percent: 62.5\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.031014958075723693\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035602607996832195\n",
      "    mean_inference_ms: 0.484976313942148\n",
      "    mean_raw_obs_processing_ms: 0.03839542803878072\n",
      "  time_since_restore: 433.22097659111023\n",
      "  time_this_iter_s: 2.3010518550872803\n",
      "  time_total_s: 433.22097659111023\n",
      "  timers:\n",
      "    learn_throughput: 3503.467\n",
      "    learn_time_ms: 1141.726\n",
      "    load_throughput: 238312727.273\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3443.588\n",
      "    sample_time_ms: 1161.579\n",
      "    update_time_ms: 1.121\n",
      "  timestamp: 1634313463\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 716000\n",
      "  training_iteration: 179\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   179</td><td style=\"text-align: right;\">        433.221 </td><td style=\"text-align: right;\">716000</td><td style=\"text-align: right;\">  193.36</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 103</td><td style=\"text-align: right;\">            193.36</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 728000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-57-50\n",
      "  done: false\n",
      "  episode_len_mean: 194.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.37\n",
      "  episode_reward_min: 137.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4002\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 20243.16015625\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.02080993354320526\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01546079758554697\n",
      "          model: {}\n",
      "          policy_loss: 0.0073468307964503765\n",
      "          total_loss: 564.1886596679688\n",
      "          vf_explained_var: 0.5882787704467773\n",
      "          vf_loss: 251.2059326171875\n",
      "    num_agent_steps_sampled: 728000\n",
      "    num_agent_steps_trained: 728000\n",
      "    num_steps_sampled: 728000\n",
      "    num_steps_trained: 728000\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 11.933333333333332\n",
      "    ram_util_percent: 62.56666666666666\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030999026431511617\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03558493350851489\n",
      "    mean_inference_ms: 0.4847287606960583\n",
      "    mean_raw_obs_processing_ms: 0.03837256068985218\n",
      "  time_since_restore: 440.145653963089\n",
      "  time_this_iter_s: 2.306581974029541\n",
      "  time_total_s: 440.145653963089\n",
      "  timers:\n",
      "    learn_throughput: 3501.662\n",
      "    learn_time_ms: 1142.315\n",
      "    load_throughput: 236632101.551\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3440.721\n",
      "    sample_time_ms: 1162.547\n",
      "    update_time_ms: 1.122\n",
      "  timestamp: 1634313470\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 728000\n",
      "  training_iteration: 182\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   182</td><td style=\"text-align: right;\">        440.146 </td><td style=\"text-align: right;\">728000</td><td style=\"text-align: right;\">  194.37</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 137</td><td style=\"text-align: right;\">            194.37</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 740000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-57-57\n",
      "  done: false\n",
      "  episode_len_mean: 194.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.77\n",
      "  episode_reward_min: 124.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4063\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 45547.11328125\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.019286973401904106\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03301788121461868\n",
      "          model: {}\n",
      "          policy_loss: 0.009217972867190838\n",
      "          total_loss: 1910.1221923828125\n",
      "          vf_explained_var: 0.36658698320388794\n",
      "          vf_loss: 406.2437744140625\n",
      "    num_agent_steps_sampled: 740000\n",
      "    num_agent_steps_trained: 740000\n",
      "    num_steps_sampled: 740000\n",
      "    num_steps_trained: 740000\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.666666666666668\n",
      "    ram_util_percent: 62.666666666666664\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030968471336605595\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03556674161313667\n",
      "    mean_inference_ms: 0.4844642602383682\n",
      "    mean_raw_obs_processing_ms: 0.03836012658510036\n",
      "  time_since_restore: 447.07071185112\n",
      "  time_this_iter_s: 2.3041038513183594\n",
      "  time_total_s: 447.07071185112\n",
      "  timers:\n",
      "    learn_throughput: 3505.631\n",
      "    learn_time_ms: 1141.021\n",
      "    load_throughput: 240361260.745\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3438.601\n",
      "    sample_time_ms: 1163.264\n",
      "    update_time_ms: 1.098\n",
      "  timestamp: 1634313477\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 740000\n",
      "  training_iteration: 185\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   185</td><td style=\"text-align: right;\">        447.071 </td><td style=\"text-align: right;\">740000</td><td style=\"text-align: right;\">  194.77</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 124</td><td style=\"text-align: right;\">            194.77</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 752000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-58-04\n",
      "  done: false\n",
      "  episode_len_mean: 196.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.2\n",
      "  episode_reward_min: 124.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4124\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 153721.5\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.023309336975216866\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04794064164161682\n",
      "          model: {}\n",
      "          policy_loss: 0.013489311560988426\n",
      "          total_loss: 7566.92236328125\n",
      "          vf_explained_var: 0.6164832711219788\n",
      "          vf_loss: 197.40150451660156\n",
      "    num_agent_steps_sampled: 752000\n",
      "    num_agent_steps_trained: 752000\n",
      "    num_steps_sampled: 752000\n",
      "    num_steps_trained: 752000\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.85\n",
      "    ram_util_percent: 62.7\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030953938413851283\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03555039893082435\n",
      "    mean_inference_ms: 0.48423696788489806\n",
      "    mean_raw_obs_processing_ms: 0.03833978190309467\n",
      "  time_since_restore: 453.9991500377655\n",
      "  time_this_iter_s: 2.310343027114868\n",
      "  time_total_s: 453.9991500377655\n",
      "  timers:\n",
      "    learn_throughput: 3508.321\n",
      "    learn_time_ms: 1140.147\n",
      "    load_throughput: 236632101.551\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3436.937\n",
      "    sample_time_ms: 1163.827\n",
      "    update_time_ms: 1.107\n",
      "  timestamp: 1634313484\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 752000\n",
      "  training_iteration: 188\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   188</td><td style=\"text-align: right;\">        453.999 </td><td style=\"text-align: right;\">752000</td><td style=\"text-align: right;\">   196.2</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 124</td><td style=\"text-align: right;\">             196.2</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 764000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-58-11\n",
      "  done: false\n",
      "  episode_len_mean: 195.69\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.69\n",
      "  episode_reward_min: 119.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4186\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 518810.0625\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.021534398198127747\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026961898431181908\n",
      "          model: {}\n",
      "          policy_loss: 0.006563364062458277\n",
      "          total_loss: 14330.7802734375\n",
      "          vf_explained_var: 0.595470666885376\n",
      "          vf_loss: 342.6692199707031\n",
      "    num_agent_steps_sampled: 764000\n",
      "    num_agent_steps_trained: 764000\n",
      "    num_steps_sampled: 764000\n",
      "    num_steps_trained: 764000\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.325\n",
      "    ram_util_percent: 62.72500000000001\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03094099817830398\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03553546456031352\n",
      "    mean_inference_ms: 0.48401467409497445\n",
      "    mean_raw_obs_processing_ms: 0.038319783472699404\n",
      "  time_since_restore: 460.93615078926086\n",
      "  time_this_iter_s: 2.3077828884124756\n",
      "  time_total_s: 460.93615078926086\n",
      "  timers:\n",
      "    learn_throughput: 3504.297\n",
      "    learn_time_ms: 1141.456\n",
      "    load_throughput: 237974695.035\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3435.468\n",
      "    sample_time_ms: 1164.325\n",
      "    update_time_ms: 1.094\n",
      "  timestamp: 1634313491\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 764000\n",
      "  training_iteration: 191\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   191</td><td style=\"text-align: right;\">        460.936 </td><td style=\"text-align: right;\">764000</td><td style=\"text-align: right;\">  195.69</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 119</td><td style=\"text-align: right;\">            195.69</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 776000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-58-18\n",
      "  done: false\n",
      "  episode_len_mean: 192.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 192.75\n",
      "  episode_reward_min: 104.0\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 4249\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1750984.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.031994014978408813\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021958844736218452\n",
      "          model: {}\n",
      "          policy_loss: -0.01428163144737482\n",
      "          total_loss: 38739.5859375\n",
      "          vf_explained_var: 0.5673038363456726\n",
      "          vf_loss: 290.0136413574219\n",
      "    num_agent_steps_sampled: 776000\n",
      "    num_agent_steps_trained: 776000\n",
      "    num_steps_sampled: 776000\n",
      "    num_steps_trained: 776000\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.625\n",
      "    ram_util_percent: 62.7\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030943928191444297\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03552203996259576\n",
      "    mean_inference_ms: 0.48383725702069214\n",
      "    mean_raw_obs_processing_ms: 0.038292414751668356\n",
      "  time_since_restore: 467.87214183807373\n",
      "  time_this_iter_s: 2.310871124267578\n",
      "  time_total_s: 467.87214183807373\n",
      "  timers:\n",
      "    learn_throughput: 3504.11\n",
      "    learn_time_ms: 1141.517\n",
      "    load_throughput: 233665961.003\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3433.168\n",
      "    sample_time_ms: 1165.105\n",
      "    update_time_ms: 1.089\n",
      "  timestamp: 1634313498\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 776000\n",
      "  training_iteration: 194\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   194</td><td style=\"text-align: right;\">        467.872 </td><td style=\"text-align: right;\">776000</td><td style=\"text-align: right;\">  192.75</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 104</td><td style=\"text-align: right;\">            192.75</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 788000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-58-25\n",
      "  done: false\n",
      "  episode_len_mean: 189.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 189.91\n",
      "  episode_reward_min: 104.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4312\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5909571.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.017025498673319817\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016995375975966454\n",
      "          model: {}\n",
      "          policy_loss: 0.002879914827644825\n",
      "          total_loss: 100704.0859375\n",
      "          vf_explained_var: 0.49949559569358826\n",
      "          vf_loss: 268.6899108886719\n",
      "    num_agent_steps_sampled: 788000\n",
      "    num_agent_steps_trained: 788000\n",
      "    num_steps_sampled: 788000\n",
      "    num_steps_trained: 788000\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.366666666666667\n",
      "    ram_util_percent: 62.666666666666664\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030946207483384745\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035508146294221075\n",
      "    mean_inference_ms: 0.48366439545697004\n",
      "    mean_raw_obs_processing_ms: 0.038265611417965265\n",
      "  time_since_restore: 474.8038914203644\n",
      "  time_this_iter_s: 2.303093910217285\n",
      "  time_total_s: 474.8038914203644\n",
      "  timers:\n",
      "    learn_throughput: 3500.224\n",
      "    learn_time_ms: 1142.784\n",
      "    load_throughput: 234318659.218\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3434.039\n",
      "    sample_time_ms: 1164.809\n",
      "    update_time_ms: 1.085\n",
      "  timestamp: 1634313505\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 788000\n",
      "  training_iteration: 197\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   197</td><td style=\"text-align: right;\">        474.804 </td><td style=\"text-align: right;\">788000</td><td style=\"text-align: right;\">  189.91</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 104</td><td style=\"text-align: right;\">            189.91</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 800000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-58-32\n",
      "  done: false\n",
      "  episode_len_mean: 189.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 189.88\n",
      "  episode_reward_min: 112.0\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 4376\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 13296535.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.02348567359149456\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04315152391791344\n",
      "          model: {}\n",
      "          policy_loss: 0.001680226530879736\n",
      "          total_loss: 573934.4375\n",
      "          vf_explained_var: 0.7847064137458801\n",
      "          vf_loss: 168.73873901367188\n",
      "    num_agent_steps_sampled: 800000\n",
      "    num_agent_steps_trained: 800000\n",
      "    num_steps_sampled: 800000\n",
      "    num_steps_trained: 800000\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.733333333333334\n",
      "    ram_util_percent: 62.6\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030932981246427797\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035493333590979066\n",
      "    mean_inference_ms: 0.4834586412300507\n",
      "    mean_raw_obs_processing_ms: 0.03824701610864763\n",
      "  time_since_restore: 481.72008514404297\n",
      "  time_this_iter_s: 2.3002307415008545\n",
      "  time_total_s: 481.72008514404297\n",
      "  timers:\n",
      "    learn_throughput: 3507.431\n",
      "    learn_time_ms: 1140.436\n",
      "    load_throughput: 233016888.889\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3434.073\n",
      "    sample_time_ms: 1164.798\n",
      "    update_time_ms: 1.098\n",
      "  timestamp: 1634313512\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 800000\n",
      "  training_iteration: 200\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   200</td><td style=\"text-align: right;\">        481.72  </td><td style=\"text-align: right;\">800000</td><td style=\"text-align: right;\">  189.88</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 112</td><td style=\"text-align: right;\">            189.88</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 812000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-58-39\n",
      "  done: false\n",
      "  episode_len_mean: 191.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 191.33\n",
      "  episode_reward_min: 116.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4438\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 29917204.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.02115635573863983\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027731379494071007\n",
      "          model: {}\n",
      "          policy_loss: 0.019519612193107605\n",
      "          total_loss: 829976.6875\n",
      "          vf_explained_var: 0.4529228210449219\n",
      "          vf_loss: 331.32989501953125\n",
      "    num_agent_steps_sampled: 812000\n",
      "    num_agent_steps_trained: 812000\n",
      "    num_steps_sampled: 812000\n",
      "    num_steps_trained: 812000\n",
      "  iterations_since_restore: 203\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.900000000000002\n",
      "    ram_util_percent: 62.70000000000001\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030920953451937887\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035479557722956655\n",
      "    mean_inference_ms: 0.4832732504612924\n",
      "    mean_raw_obs_processing_ms: 0.03822941839086275\n",
      "  time_since_restore: 488.65019369125366\n",
      "  time_this_iter_s: 2.3051047325134277\n",
      "  time_total_s: 488.65019369125366\n",
      "  timers:\n",
      "    learn_throughput: 3508.874\n",
      "    learn_time_ms: 1139.967\n",
      "    load_throughput: 228572425.068\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3433.465\n",
      "    sample_time_ms: 1165.004\n",
      "    update_time_ms: 1.095\n",
      "  timestamp: 1634313519\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 812000\n",
      "  training_iteration: 203\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   203</td><td style=\"text-align: right;\">        488.65  </td><td style=\"text-align: right;\">812000</td><td style=\"text-align: right;\">  191.33</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 116</td><td style=\"text-align: right;\">            191.33</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 824000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-58-45\n",
      "  done: false\n",
      "  episode_len_mean: 192.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 192.21\n",
      "  episode_reward_min: 116.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4499\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 67313704.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.021896956488490105\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03206692636013031\n",
      "          model: {}\n",
      "          policy_loss: 0.0048996577970683575\n",
      "          total_loss: 2158780.75\n",
      "          vf_explained_var: 0.5775529742240906\n",
      "          vf_loss: 237.25743103027344\n",
      "    num_agent_steps_sampled: 824000\n",
      "    num_agent_steps_trained: 824000\n",
      "    num_steps_sampled: 824000\n",
      "    num_steps_trained: 824000\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.3\n",
      "    ram_util_percent: 62.63333333333333\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03089373025695536\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03546454892662144\n",
      "    mean_inference_ms: 0.4830575879156828\n",
      "    mean_raw_obs_processing_ms: 0.038220518050173354\n",
      "  time_since_restore: 495.56931376457214\n",
      "  time_this_iter_s: 2.3166279792785645\n",
      "  time_total_s: 495.56931376457214\n",
      "  timers:\n",
      "    learn_throughput: 3513.885\n",
      "    learn_time_ms: 1138.341\n",
      "    load_throughput: 233016888.889\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3434.657\n",
      "    sample_time_ms: 1164.6\n",
      "    update_time_ms: 1.098\n",
      "  timestamp: 1634313525\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 824000\n",
      "  training_iteration: 206\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   206</td><td style=\"text-align: right;\">        495.569 </td><td style=\"text-align: right;\">824000</td><td style=\"text-align: right;\">  192.21</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 116</td><td style=\"text-align: right;\">            192.21</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 836000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-58-52\n",
      "  done: false\n",
      "  episode_len_mean: 192.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 192.71\n",
      "  episode_reward_min: 125.0\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 4562\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 227183760.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.0352695994079113\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024791201576590538\n",
      "          model: {}\n",
      "          policy_loss: 0.004102627281099558\n",
      "          total_loss: 5632440.5\n",
      "          vf_explained_var: 0.6282277703285217\n",
      "          vf_loss: 281.7555236816406\n",
      "    num_agent_steps_sampled: 836000\n",
      "    num_agent_steps_trained: 836000\n",
      "    num_steps_sampled: 836000\n",
      "    num_steps_trained: 836000\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.96666666666667\n",
      "    ram_util_percent: 62.666666666666664\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030898000612833095\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035452465971982566\n",
      "    mean_inference_ms: 0.4829010769528614\n",
      "    mean_raw_obs_processing_ms: 0.038195149273657504\n",
      "  time_since_restore: 502.4963240623474\n",
      "  time_this_iter_s: 2.3108887672424316\n",
      "  time_total_s: 502.4963240623474\n",
      "  timers:\n",
      "    learn_throughput: 3508.364\n",
      "    learn_time_ms: 1140.132\n",
      "    load_throughput: 232050013.831\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3437.641\n",
      "    sample_time_ms: 1163.589\n",
      "    update_time_ms: 1.101\n",
      "  timestamp: 1634313532\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 836000\n",
      "  training_iteration: 209\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   209</td><td style=\"text-align: right;\">        502.496 </td><td style=\"text-align: right;\">836000</td><td style=\"text-align: right;\">  192.71</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 125</td><td style=\"text-align: right;\">            192.71</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 848000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-58-59\n",
      "  done: false\n",
      "  episode_len_mean: 196.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.93\n",
      "  episode_reward_min: 127.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4622\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 511163456.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.030641235411167145\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017854493111371994\n",
      "          model: {}\n",
      "          policy_loss: 0.007640997413545847\n",
      "          total_loss: 9126719.0\n",
      "          vf_explained_var: 0.7636121511459351\n",
      "          vf_loss: 153.9801788330078\n",
      "    num_agent_steps_sampled: 848000\n",
      "    num_agent_steps_trained: 848000\n",
      "    num_steps_sampled: 848000\n",
      "    num_steps_trained: 848000\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.900000000000002\n",
      "    ram_util_percent: 62.70000000000001\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030857233652926076\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03543768611257057\n",
      "    mean_inference_ms: 0.48265207241303465\n",
      "    mean_raw_obs_processing_ms: 0.038196775132786326\n",
      "  time_since_restore: 509.4981973171234\n",
      "  time_this_iter_s: 2.304826259613037\n",
      "  time_total_s: 509.4981973171234\n",
      "  timers:\n",
      "    learn_throughput: 3485.042\n",
      "    learn_time_ms: 1147.762\n",
      "    load_throughput: 236298816.901\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3437.733\n",
      "    sample_time_ms: 1163.558\n",
      "    update_time_ms: 1.152\n",
      "  timestamp: 1634313539\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 848000\n",
      "  training_iteration: 212\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   212</td><td style=\"text-align: right;\">        509.498 </td><td style=\"text-align: right;\">848000</td><td style=\"text-align: right;\">  196.93</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 127</td><td style=\"text-align: right;\">            196.93</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 860000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-59-06\n",
      "  done: false\n",
      "  episode_len_mean: 198.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.25\n",
      "  episode_reward_min: 150.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4683\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1150117760.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.027932295575737953\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03444070369005203\n",
      "          model: {}\n",
      "          policy_loss: 0.009583555161952972\n",
      "          total_loss: 39611084.0\n",
      "          vf_explained_var: 0.6858659386634827\n",
      "          vf_loss: 223.56442260742188\n",
      "    num_agent_steps_sampled: 860000\n",
      "    num_agent_steps_trained: 860000\n",
      "    num_steps_sampled: 860000\n",
      "    num_steps_trained: 860000\n",
      "  iterations_since_restore: 215\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.8\n",
      "    ram_util_percent: 62.79999999999999\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030832847033761414\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035425916104363374\n",
      "    mean_inference_ms: 0.4824784062920445\n",
      "    mean_raw_obs_processing_ms: 0.038191831519745284\n",
      "  time_since_restore: 516.4695672988892\n",
      "  time_this_iter_s: 2.317981004714966\n",
      "  time_total_s: 516.4695672988892\n",
      "  timers:\n",
      "    learn_throughput: 3477.182\n",
      "    learn_time_ms: 1150.357\n",
      "    load_throughput: 224895656.836\n",
      "    load_time_ms: 0.018\n",
      "    sample_throughput: 3426.629\n",
      "    sample_time_ms: 1167.328\n",
      "    update_time_ms: 1.161\n",
      "  timestamp: 1634313546\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 860000\n",
      "  training_iteration: 215\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   215</td><td style=\"text-align: right;\">        516.47  </td><td style=\"text-align: right;\">860000</td><td style=\"text-align: right;\">  198.25</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 150</td><td style=\"text-align: right;\">            198.25</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 872000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-59-14\n",
      "  done: false\n",
      "  episode_len_mean: 197.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.64\n",
      "  episode_reward_min: 136.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4744\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3881647616.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.019189799204468727\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01766931638121605\n",
      "          model: {}\n",
      "          policy_loss: -0.00022242992417886853\n",
      "          total_loss: 68586368.0\n",
      "          vf_explained_var: 0.6173312067985535\n",
      "          vf_loss: 311.75860595703125\n",
      "    num_agent_steps_sampled: 872000\n",
      "    num_agent_steps_trained: 872000\n",
      "    num_steps_sampled: 872000\n",
      "    num_steps_trained: 872000\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.73333333333333\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030839772476584985\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03541767298894141\n",
      "    mean_inference_ms: 0.4823863585293868\n",
      "    mean_raw_obs_processing_ms: 0.03817044593013756\n",
      "  time_since_restore: 523.481433391571\n",
      "  time_this_iter_s: 2.312227964401245\n",
      "  time_total_s: 523.481433391571\n",
      "  timers:\n",
      "    learn_throughput: 3458.818\n",
      "    learn_time_ms: 1156.465\n",
      "    load_throughput: 222804993.36\n",
      "    load_time_ms: 0.018\n",
      "    sample_throughput: 3421.306\n",
      "    sample_time_ms: 1169.144\n",
      "    update_time_ms: 1.156\n",
      "  timestamp: 1634313554\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 872000\n",
      "  training_iteration: 218\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   218</td><td style=\"text-align: right;\">        523.481 </td><td style=\"text-align: right;\">872000</td><td style=\"text-align: right;\">  197.64</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 136</td><td style=\"text-align: right;\">            197.64</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 884000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-59-21\n",
      "  done: false\n",
      "  episode_len_mean: 195.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.57\n",
      "  episode_reward_min: 119.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4805\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5822471168.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.02485632710158825\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.034962113946676254\n",
      "          model: {}\n",
      "          policy_loss: 0.006677574012428522\n",
      "          total_loss: 203566096.0\n",
      "          vf_explained_var: 0.680285632610321\n",
      "          vf_loss: 192.2202606201172\n",
      "    num_agent_steps_sampled: 884000\n",
      "    num_agent_steps_trained: 884000\n",
      "    num_steps_sampled: 884000\n",
      "    num_steps_trained: 884000\n",
      "  iterations_since_restore: 221\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.400000000000002\n",
      "    ram_util_percent: 63.70000000000001\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03083159073824854\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03540816211202829\n",
      "    mean_inference_ms: 0.4822495908038961\n",
      "    mean_raw_obs_processing_ms: 0.03815848070502589\n",
      "  time_since_restore: 530.4223172664642\n",
      "  time_this_iter_s: 2.309250831604004\n",
      "  time_total_s: 530.4223172664642\n",
      "  timers:\n",
      "    learn_throughput: 3482.764\n",
      "    learn_time_ms: 1148.513\n",
      "    load_throughput: 219597068.063\n",
      "    load_time_ms: 0.018\n",
      "    sample_throughput: 3417.581\n",
      "    sample_time_ms: 1170.418\n",
      "    update_time_ms: 1.132\n",
      "  timestamp: 1634313561\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 884000\n",
      "  training_iteration: 221\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   221</td><td style=\"text-align: right;\">        530.422 </td><td style=\"text-align: right;\">884000</td><td style=\"text-align: right;\">  195.57</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 119</td><td style=\"text-align: right;\">            195.57</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 896000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-59-27\n",
      "  done: false\n",
      "  episode_len_mean: 194.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.4\n",
      "  episode_reward_min: 119.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4867\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8733707264.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.03407536819577217\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012303782626986504\n",
      "          model: {}\n",
      "          policy_loss: 0.008334421552717686\n",
      "          total_loss: 107457832.0\n",
      "          vf_explained_var: 0.5875982046127319\n",
      "          vf_loss: 197.11773681640625\n",
      "    num_agent_steps_sampled: 896000\n",
      "    num_agent_steps_trained: 896000\n",
      "    num_steps_sampled: 896000\n",
      "    num_steps_trained: 896000\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.7\n",
      "    ram_util_percent: 63.70000000000001\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0308225156918266\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035397781063376675\n",
      "    mean_inference_ms: 0.4821039990275524\n",
      "    mean_raw_obs_processing_ms: 0.038145984607926946\n",
      "  time_since_restore: 537.357216835022\n",
      "  time_this_iter_s: 2.310213088989258\n",
      "  time_total_s: 537.357216835022\n",
      "  timers:\n",
      "    learn_throughput: 3483.797\n",
      "    learn_time_ms: 1148.172\n",
      "    load_throughput: 222804993.36\n",
      "    load_time_ms: 0.018\n",
      "    sample_throughput: 3423.454\n",
      "    sample_time_ms: 1168.41\n",
      "    update_time_ms: 1.123\n",
      "  timestamp: 1634313567\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 896000\n",
      "  training_iteration: 224\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   224</td><td style=\"text-align: right;\">        537.357 </td><td style=\"text-align: right;\">896000</td><td style=\"text-align: right;\">   194.4</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 119</td><td style=\"text-align: right;\">             194.4</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 908000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-59-34\n",
      "  done: false\n",
      "  episode_len_mean: 190.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 190.88\n",
      "  episode_reward_min: 111.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4931\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8733707264.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.024730896577239037\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009019691497087479\n",
      "          model: {}\n",
      "          policy_loss: -0.0017479113303124905\n",
      "          total_loss: 78775504.0\n",
      "          vf_explained_var: 0.7395049333572388\n",
      "          vf_loss: 156.16004943847656\n",
      "    num_agent_steps_sampled: 908000\n",
      "    num_agent_steps_trained: 908000\n",
      "    num_steps_sampled: 908000\n",
      "    num_steps_trained: 908000\n",
      "  iterations_since_restore: 227\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.025\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030844666547618294\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03538987747196296\n",
      "    mean_inference_ms: 0.4820303833334974\n",
      "    mean_raw_obs_processing_ms: 0.038115282998684136\n",
      "  time_since_restore: 544.3003749847412\n",
      "  time_this_iter_s: 2.3052351474761963\n",
      "  time_total_s: 544.3003749847412\n",
      "  timers:\n",
      "    learn_throughput: 3505.801\n",
      "    learn_time_ms: 1140.966\n",
      "    load_throughput: 232371412.742\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3424.165\n",
      "    sample_time_ms: 1168.168\n",
      "    update_time_ms: 1.12\n",
      "  timestamp: 1634313574\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 908000\n",
      "  training_iteration: 227\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   227</td><td style=\"text-align: right;\">        544.3   </td><td style=\"text-align: right;\">908000</td><td style=\"text-align: right;\">  190.88</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 111</td><td style=\"text-align: right;\">            190.88</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 920000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-59-41\n",
      "  done: false\n",
      "  episode_len_mean: 193.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 193.41\n",
      "  episode_reward_min: 112.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4992\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8733707264.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.028100520372390747\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013197510503232479\n",
      "          model: {}\n",
      "          policy_loss: 0.0031167808920145035\n",
      "          total_loss: 115263456.0\n",
      "          vf_explained_var: 0.5506707429885864\n",
      "          vf_loss: 261.7149353027344\n",
      "    num_agent_steps_sampled: 920000\n",
      "    num_agent_steps_trained: 920000\n",
      "    num_steps_sampled: 920000\n",
      "    num_steps_trained: 920000\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.6\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0308078019855055\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03537931968197018\n",
      "    mean_inference_ms: 0.48184673416668433\n",
      "    mean_raw_obs_processing_ms: 0.03812175372015359\n",
      "  time_since_restore: 551.2484149932861\n",
      "  time_this_iter_s: 2.3042681217193604\n",
      "  time_total_s: 551.2484149932861\n",
      "  timers:\n",
      "    learn_throughput: 3504.382\n",
      "    learn_time_ms: 1141.428\n",
      "    load_throughput: 234646377.622\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3424.251\n",
      "    sample_time_ms: 1168.139\n",
      "    update_time_ms: 1.099\n",
      "  timestamp: 1634313581\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 920000\n",
      "  training_iteration: 230\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   230</td><td style=\"text-align: right;\">        551.248 </td><td style=\"text-align: right;\">920000</td><td style=\"text-align: right;\">  193.41</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 112</td><td style=\"text-align: right;\">            193.41</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 932000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-59-48\n",
      "  done: false\n",
      "  episode_len_mean: 196.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.37\n",
      "  episode_reward_min: 131.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5053\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8733707264.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.023616168648004532\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.004240493290126324\n",
      "          model: {}\n",
      "          policy_loss: 0.00014298449968919158\n",
      "          total_loss: 37035564.0\n",
      "          vf_explained_var: 0.4620436728000641\n",
      "          vf_loss: 343.8981628417969\n",
      "    num_agent_steps_sampled: 932000\n",
      "    num_agent_steps_trained: 932000\n",
      "    num_steps_sampled: 932000\n",
      "    num_steps_trained: 932000\n",
      "  iterations_since_restore: 233\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.325\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030784548396674813\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035368499771338095\n",
      "    mean_inference_ms: 0.4816701119885984\n",
      "    mean_raw_obs_processing_ms: 0.03811797422658619\n",
      "  time_since_restore: 558.1565790176392\n",
      "  time_this_iter_s: 2.304047107696533\n",
      "  time_total_s: 558.1565790176392\n",
      "  timers:\n",
      "    learn_throughput: 3510.519\n",
      "    learn_time_ms: 1139.433\n",
      "    load_throughput: 239332610.556\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3425.92\n",
      "    sample_time_ms: 1167.569\n",
      "    update_time_ms: 1.111\n",
      "  timestamp: 1634313588\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 932000\n",
      "  training_iteration: 233\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   233</td><td style=\"text-align: right;\">        558.157 </td><td style=\"text-align: right;\">932000</td><td style=\"text-align: right;\">  196.37</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 131</td><td style=\"text-align: right;\">            196.37</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 944000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_10-59-55\n",
      "  done: false\n",
      "  episode_len_mean: 196.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.78\n",
      "  episode_reward_min: 134.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5116\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1091713408.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.025478346273303032\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00023892277386039495\n",
      "          model: {}\n",
      "          policy_loss: 0.0026462336536496878\n",
      "          total_loss: 261046.03125\n",
      "          vf_explained_var: 0.7254422307014465\n",
      "          vf_loss: 210.84754943847656\n",
      "    num_agent_steps_sampled: 944000\n",
      "    num_agent_steps_trained: 944000\n",
      "    num_steps_sampled: 944000\n",
      "    num_steps_trained: 944000\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.333333333333332\n",
      "    ram_util_percent: 63.70000000000001\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0307910740866323\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035358935916247634\n",
      "    mean_inference_ms: 0.48155145259882837\n",
      "    mean_raw_obs_processing_ms: 0.03809589432161641\n",
      "  time_since_restore: 565.0766067504883\n",
      "  time_this_iter_s: 2.307846784591675\n",
      "  time_total_s: 565.0766067504883\n",
      "  timers:\n",
      "    learn_throughput: 3514.191\n",
      "    learn_time_ms: 1138.242\n",
      "    load_throughput: 238651721.195\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3430.674\n",
      "    sample_time_ms: 1165.952\n",
      "    update_time_ms: 1.121\n",
      "  timestamp: 1634313595\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 944000\n",
      "  training_iteration: 236\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   236</td><td style=\"text-align: right;\">        565.077 </td><td style=\"text-align: right;\">944000</td><td style=\"text-align: right;\">  196.78</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 134</td><td style=\"text-align: right;\">            196.78</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 956000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-00-02\n",
      "  done: false\n",
      "  episode_len_mean: 195.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.98\n",
      "  episode_reward_min: 128.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5176\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 136464176.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.022412654012441635\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.7414913600077853e-05\n",
      "          model: {}\n",
      "          policy_loss: 0.008121867664158344\n",
      "          total_loss: 2536.642578125\n",
      "          vf_explained_var: 0.6902815103530884\n",
      "          vf_loss: 160.12290954589844\n",
      "    num_agent_steps_sampled: 956000\n",
      "    num_agent_steps_trained: 956000\n",
      "    num_steps_sampled: 956000\n",
      "    num_steps_trained: 956000\n",
      "  iterations_since_restore: 239\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.799999999999999\n",
      "    ram_util_percent: 63.9\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030783399987005813\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035349255621066916\n",
      "    mean_inference_ms: 0.48142452903257005\n",
      "    mean_raw_obs_processing_ms: 0.038083118494423224\n",
      "  time_since_restore: 572.0191330909729\n",
      "  time_this_iter_s: 2.3189172744750977\n",
      "  time_total_s: 572.0191330909729\n",
      "  timers:\n",
      "    learn_throughput: 3511.161\n",
      "    learn_time_ms: 1139.224\n",
      "    load_throughput: 238312727.273\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3435.509\n",
      "    sample_time_ms: 1164.311\n",
      "    update_time_ms: 1.124\n",
      "  timestamp: 1634313602\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 956000\n",
      "  training_iteration: 239\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   239</td><td style=\"text-align: right;\">        572.019 </td><td style=\"text-align: right;\">956000</td><td style=\"text-align: right;\">  195.98</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">            195.98</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 968000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-00-09\n",
      "  done: false\n",
      "  episode_len_mean: 196.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.73\n",
      "  episode_reward_min: 128.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5237\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 17058022.0\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.026489922776818275\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 8.358487684745342e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.003357628360390663\n",
      "          total_loss: 1659.3350830078125\n",
      "          vf_explained_var: 0.5304856300354004\n",
      "          vf_loss: 233.54586791992188\n",
      "    num_agent_steps_sampled: 968000\n",
      "    num_agent_steps_trained: 968000\n",
      "    num_steps_sampled: 968000\n",
      "    num_steps_trained: 968000\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.333333333333334\n",
      "    ram_util_percent: 63.9\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030775900432383124\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03533985179075739\n",
      "    mean_inference_ms: 0.4814157160826161\n",
      "    mean_raw_obs_processing_ms: 0.03807035665548773\n",
      "  time_since_restore: 579.0902953147888\n",
      "  time_this_iter_s: 2.2938501834869385\n",
      "  time_total_s: 579.0902953147888\n",
      "  timers:\n",
      "    learn_throughput: 3504.92\n",
      "    learn_time_ms: 1141.253\n",
      "    load_throughput: 236966327.684\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3393.888\n",
      "    sample_time_ms: 1178.589\n",
      "    update_time_ms: 1.101\n",
      "  timestamp: 1634313609\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 968000\n",
      "  training_iteration: 242\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   242</td><td style=\"text-align: right;\">        579.09  </td><td style=\"text-align: right;\">968000</td><td style=\"text-align: right;\">  196.73</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">            196.73</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 980000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-00-16\n",
      "  done: false\n",
      "  episode_len_mean: 195.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.71\n",
      "  episode_reward_min: 149.0\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 5299\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2132252.75\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.026114661246538162\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.811305082810577e-05\n",
      "          model: {}\n",
      "          policy_loss: -0.010423549450933933\n",
      "          total_loss: 239.53477478027344\n",
      "          vf_explained_var: 0.5148080587387085\n",
      "          vf_loss: 200.92359924316406\n",
      "    num_agent_steps_sampled: 980000\n",
      "    num_agent_steps_trained: 980000\n",
      "    num_steps_sampled: 980000\n",
      "    num_steps_trained: 980000\n",
      "  iterations_since_restore: 245\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 19.7\n",
      "    ram_util_percent: 63.96666666666667\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030783554514903624\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035331284917038415\n",
      "    mean_inference_ms: 0.4814716015464871\n",
      "    mean_raw_obs_processing_ms: 0.038049475821474624\n",
      "  time_since_restore: 586.0112776756287\n",
      "  time_this_iter_s: 2.304050922393799\n",
      "  time_total_s: 586.0112776756287\n",
      "  timers:\n",
      "    learn_throughput: 3501.723\n",
      "    learn_time_ms: 1142.295\n",
      "    load_throughput: 231409875.862\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3395.501\n",
      "    sample_time_ms: 1178.029\n",
      "    update_time_ms: 1.103\n",
      "  timestamp: 1634313616\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 980000\n",
      "  training_iteration: 245\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   245</td><td style=\"text-align: right;\">        586.011 </td><td style=\"text-align: right;\">980000</td><td style=\"text-align: right;\">  195.71</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 149</td><td style=\"text-align: right;\">            195.71</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 992000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-00-23\n",
      "  done: false\n",
      "  episode_len_mean: 195.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.88\n",
      "  episode_reward_min: 144.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5359\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 266531.59375\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.028410296887159348\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.7436437283489e-10\n",
      "          model: {}\n",
      "          policy_loss: 0.003789838869124651\n",
      "          total_loss: 318.15093994140625\n",
      "          vf_explained_var: 0.5341739654541016\n",
      "          vf_loss: 318.1470031738281\n",
      "    num_agent_steps_sampled: 992000\n",
      "    num_agent_steps_trained: 992000\n",
      "    num_steps_sampled: 992000\n",
      "    num_steps_trained: 992000\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.366666666666664\n",
      "    ram_util_percent: 63.9\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030761033725276513\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035320728787457706\n",
      "    mean_inference_ms: 0.48127733822123114\n",
      "    mean_raw_obs_processing_ms: 0.03804621739077591\n",
      "  time_since_restore: 592.9246008396149\n",
      "  time_this_iter_s: 2.3044800758361816\n",
      "  time_total_s: 592.9246008396149\n",
      "  timers:\n",
      "    learn_throughput: 3501.477\n",
      "    learn_time_ms: 1142.375\n",
      "    load_throughput: 228572425.068\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3400.911\n",
      "    sample_time_ms: 1176.155\n",
      "    update_time_ms: 1.103\n",
      "  timestamp: 1634313623\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 992000\n",
      "  training_iteration: 248\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   248</td><td style=\"text-align: right;\">        592.925 </td><td style=\"text-align: right;\">992000</td><td style=\"text-align: right;\">  195.88</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 144</td><td style=\"text-align: right;\">            195.88</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\"> 68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1004000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-00-30\n",
      "  done: false\n",
      "  episode_len_mean: 197.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.64\n",
      "  episode_reward_min: 134.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5421\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 33316.44921875\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.025386707857251167\n",
      "          entropy_coeff: 0.0\n",
      "          kl: -2.981513091970811e-10\n",
      "          model: {}\n",
      "          policy_loss: -0.005782286170870066\n",
      "          total_loss: 343.87481689453125\n",
      "          vf_explained_var: 0.6897535920143127\n",
      "          vf_loss: 343.8806457519531\n",
      "    num_agent_steps_sampled: 1004000\n",
      "    num_agent_steps_trained: 1004000\n",
      "    num_steps_sampled: 1004000\n",
      "    num_steps_trained: 1004000\n",
      "  iterations_since_restore: 251\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.46666666666667\n",
      "    ram_util_percent: 63.9\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030752989720491203\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03531078537916004\n",
      "    mean_inference_ms: 0.48111398867118443\n",
      "    mean_raw_obs_processing_ms: 0.03803358526881422\n",
      "  time_since_restore: 599.8541631698608\n",
      "  time_this_iter_s: 2.3199386596679688\n",
      "  time_total_s: 599.8541631698608\n",
      "  timers:\n",
      "    learn_throughput: 3505.525\n",
      "    learn_time_ms: 1141.056\n",
      "    load_throughput: 228884256.48\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3445.974\n",
      "    sample_time_ms: 1160.775\n",
      "    update_time_ms: 1.112\n",
      "  timestamp: 1634313630\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1004000\n",
      "  training_iteration: 251\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   251</td><td style=\"text-align: right;\">        599.854 </td><td style=\"text-align: right;\">1004000</td><td style=\"text-align: right;\">  197.64</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 134</td><td style=\"text-align: right;\">            197.64</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1016000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-00-37\n",
      "  done: false\n",
      "  episode_len_mean: 198.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.03\n",
      "  episode_reward_min: 134.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5481\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4164.55615234375\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.023829441517591476\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.6749061859666625e-10\n",
      "          model: {}\n",
      "          policy_loss: 0.008326556533575058\n",
      "          total_loss: 254.33033752441406\n",
      "          vf_explained_var: 0.6106386184692383\n",
      "          vf_loss: 254.322021484375\n",
      "    num_agent_steps_sampled: 1016000\n",
      "    num_agent_steps_trained: 1016000\n",
      "    num_steps_sampled: 1016000\n",
      "    num_steps_trained: 1016000\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 11.833333333333334\n",
      "    ram_util_percent: 63.9\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03074577136704002\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03530175287105669\n",
      "    mean_inference_ms: 0.48097172978603203\n",
      "    mean_raw_obs_processing_ms: 0.03802147389463742\n",
      "  time_since_restore: 606.7788481712341\n",
      "  time_this_iter_s: 2.309190034866333\n",
      "  time_total_s: 606.7788481712341\n",
      "  timers:\n",
      "    learn_throughput: 3504.531\n",
      "    learn_time_ms: 1141.379\n",
      "    load_throughput: 228884256.48\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3442.867\n",
      "    sample_time_ms: 1161.823\n",
      "    update_time_ms: 1.117\n",
      "  timestamp: 1634313637\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1016000\n",
      "  training_iteration: 254\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   254</td><td style=\"text-align: right;\">        606.779 </td><td style=\"text-align: right;\">1016000</td><td style=\"text-align: right;\">  198.03</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 134</td><td style=\"text-align: right;\">            198.03</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1028000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-00-44\n",
      "  done: false\n",
      "  episode_len_mean: 197.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.46\n",
      "  episode_reward_min: 128.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5541\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 520.5695190429688\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.027320418506860733\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 8.933809803046699e-10\n",
      "          model: {}\n",
      "          policy_loss: 0.0029551705811172724\n",
      "          total_loss: 147.1508331298828\n",
      "          vf_explained_var: 0.7828692197799683\n",
      "          vf_loss: 147.14788818359375\n",
      "    num_agent_steps_sampled: 1028000\n",
      "    num_agent_steps_trained: 1028000\n",
      "    num_steps_sampled: 1028000\n",
      "    num_steps_trained: 1028000\n",
      "  iterations_since_restore: 257\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.633333333333336\n",
      "    ram_util_percent: 63.9\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030723416742442167\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035291664714646516\n",
      "    mean_inference_ms: 0.4807911759082712\n",
      "    mean_raw_obs_processing_ms: 0.03801810251719199\n",
      "  time_since_restore: 613.6863770484924\n",
      "  time_this_iter_s: 2.3006479740142822\n",
      "  time_total_s: 613.6863770484924\n",
      "  timers:\n",
      "    learn_throughput: 3502.208\n",
      "    learn_time_ms: 1142.137\n",
      "    load_throughput: 235304572.23\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3446.66\n",
      "    sample_time_ms: 1160.544\n",
      "    update_time_ms: 1.106\n",
      "  timestamp: 1634313644\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1028000\n",
      "  training_iteration: 257\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   257</td><td style=\"text-align: right;\">        613.686 </td><td style=\"text-align: right;\">1028000</td><td style=\"text-align: right;\">  197.46</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">            197.46</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1040000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-00-51\n",
      "  done: false\n",
      "  episode_len_mean: 197.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.21\n",
      "  episode_reward_min: 128.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5603\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 65.0711898803711\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.026989445090293884\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.9392402350604243e-08\n",
      "          model: {}\n",
      "          policy_loss: 0.005751763936132193\n",
      "          total_loss: 375.0908508300781\n",
      "          vf_explained_var: 0.6021448373794556\n",
      "          vf_loss: 375.0850830078125\n",
      "    num_agent_steps_sampled: 1040000\n",
      "    num_agent_steps_trained: 1040000\n",
      "    num_steps_sampled: 1040000\n",
      "    num_steps_trained: 1040000\n",
      "  iterations_since_restore: 260\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.025\n",
      "    ram_util_percent: 63.9\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030731443628740904\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035283640140782634\n",
      "    mean_inference_ms: 0.4806691581141825\n",
      "    mean_raw_obs_processing_ms: 0.0379976056656232\n",
      "  time_since_restore: 620.5912008285522\n",
      "  time_this_iter_s: 2.2995309829711914\n",
      "  time_total_s: 620.5912008285522\n",
      "  timers:\n",
      "    learn_throughput: 3503.026\n",
      "    learn_time_ms: 1141.87\n",
      "    load_throughput: 236632101.551\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3448.581\n",
      "    sample_time_ms: 1159.897\n",
      "    update_time_ms: 1.122\n",
      "  timestamp: 1634313651\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1040000\n",
      "  training_iteration: 260\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   260</td><td style=\"text-align: right;\">        620.591 </td><td style=\"text-align: right;\">1040000</td><td style=\"text-align: right;\">  197.21</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">            197.21</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1052000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-00-58\n",
      "  done: false\n",
      "  episode_len_mean: 197.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.4\n",
      "  episode_reward_min: 126.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5663\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8.133898735046387\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.026945369318127632\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.3249793937575305e-06\n",
      "          model: {}\n",
      "          policy_loss: 0.000999676063656807\n",
      "          total_loss: 325.82733154296875\n",
      "          vf_explained_var: 0.561767578125\n",
      "          vf_loss: 325.82635498046875\n",
      "    num_agent_steps_sampled: 1052000\n",
      "    num_agent_steps_trained: 1052000\n",
      "    num_steps_sampled: 1052000\n",
      "    num_steps_trained: 1052000\n",
      "  iterations_since_restore: 263\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.375\n",
      "    ram_util_percent: 63.9\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03072512831204812\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03527493744851072\n",
      "    mean_inference_ms: 0.4805289419649158\n",
      "    mean_raw_obs_processing_ms: 0.037986684239133914\n",
      "  time_since_restore: 627.5107762813568\n",
      "  time_this_iter_s: 2.2966060638427734\n",
      "  time_total_s: 627.5107762813568\n",
      "  timers:\n",
      "    learn_throughput: 3505.072\n",
      "    learn_time_ms: 1141.203\n",
      "    load_throughput: 229824876.712\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3451.312\n",
      "    sample_time_ms: 1158.98\n",
      "    update_time_ms: 1.131\n",
      "  timestamp: 1634313658\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1052000\n",
      "  training_iteration: 263\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.1/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   263</td><td style=\"text-align: right;\">        627.511 </td><td style=\"text-align: right;\">1052000</td><td style=\"text-align: right;\">   197.4</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 126</td><td style=\"text-align: right;\">             197.4</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1064000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-01-05\n",
      "  done: false\n",
      "  episode_len_mean: 198.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.02\n",
      "  episode_reward_min: 161.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5724\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0167373418807983\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.023746836930513382\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.557523086783476e-05\n",
      "          model: {}\n",
      "          policy_loss: 0.0023269110824912786\n",
      "          total_loss: 165.41827392578125\n",
      "          vf_explained_var: 0.7044664025306702\n",
      "          vf_loss: 165.41592407226562\n",
      "    num_agent_steps_sampled: 1064000\n",
      "    num_agent_steps_trained: 1064000\n",
      "    num_steps_sampled: 1064000\n",
      "    num_steps_trained: 1064000\n",
      "  iterations_since_restore: 266\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.75\n",
      "    ram_util_percent: 64.175\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03071889238874716\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03526629256017088\n",
      "    mean_inference_ms: 0.48039261151627555\n",
      "    mean_raw_obs_processing_ms: 0.037974679643298294\n",
      "  time_since_restore: 634.5731513500214\n",
      "  time_this_iter_s: 2.4509830474853516\n",
      "  time_total_s: 634.5731513500214\n",
      "  timers:\n",
      "    learn_throughput: 3463.711\n",
      "    learn_time_ms: 1154.831\n",
      "    load_throughput: 229196939.891\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3448.725\n",
      "    sample_time_ms: 1159.849\n",
      "    update_time_ms: 1.192\n",
      "  timestamp: 1634313665\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1064000\n",
      "  training_iteration: 266\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.2/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   266</td><td style=\"text-align: right;\">        634.573 </td><td style=\"text-align: right;\">1064000</td><td style=\"text-align: right;\">  198.02</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 161</td><td style=\"text-align: right;\">            198.02</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1076000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-01-12\n",
      "  done: false\n",
      "  episode_len_mean: 198.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.7\n",
      "  episode_reward_min: 155.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5784\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.1270921677350998\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.02892422303557396\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00016042716742958874\n",
      "          model: {}\n",
      "          policy_loss: 0.0010385289788246155\n",
      "          total_loss: 219.11968994140625\n",
      "          vf_explained_var: 0.6915619969367981\n",
      "          vf_loss: 219.11862182617188\n",
      "    num_agent_steps_sampled: 1076000\n",
      "    num_agent_steps_trained: 1076000\n",
      "    num_steps_sampled: 1076000\n",
      "    num_steps_trained: 1076000\n",
      "  iterations_since_restore: 269\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.075\n",
      "    ram_util_percent: 65.4\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030700648955226794\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03526070689255405\n",
      "    mean_inference_ms: 0.480272077190741\n",
      "    mean_raw_obs_processing_ms: 0.03797674701505881\n",
      "  time_since_restore: 641.5699362754822\n",
      "  time_this_iter_s: 2.3044281005859375\n",
      "  time_total_s: 641.5699362754822\n",
      "  timers:\n",
      "    learn_throughput: 3456.916\n",
      "    learn_time_ms: 1157.101\n",
      "    load_throughput: 228884256.48\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3428.601\n",
      "    sample_time_ms: 1166.657\n",
      "    update_time_ms: 1.183\n",
      "  timestamp: 1634313672\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1076000\n",
      "  training_iteration: 269\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.2/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   269</td><td style=\"text-align: right;\">        641.57  </td><td style=\"text-align: right;\">1076000</td><td style=\"text-align: right;\">   198.7</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 155</td><td style=\"text-align: right;\">             198.7</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1088000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-01-19\n",
      "  done: false\n",
      "  episode_len_mean: 199.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 199.17\n",
      "  episode_reward_min: 155.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5844\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.015886520966887474\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.028329340741038322\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00047230214113369584\n",
      "          model: {}\n",
      "          policy_loss: -0.0011466203723102808\n",
      "          total_loss: 305.0863342285156\n",
      "          vf_explained_var: 0.40951842069625854\n",
      "          vf_loss: 305.08746337890625\n",
      "    num_agent_steps_sampled: 1088000\n",
      "    num_agent_steps_trained: 1088000\n",
      "    num_steps_sampled: 1088000\n",
      "    num_steps_trained: 1088000\n",
      "  iterations_since_restore: 272\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.075\n",
      "    ram_util_percent: 65.4\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030696021236545596\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03525445720932334\n",
      "    mean_inference_ms: 0.480164402848541\n",
      "    mean_raw_obs_processing_ms: 0.037968264113159164\n",
      "  time_since_restore: 648.4671139717102\n",
      "  time_this_iter_s: 2.300797939300537\n",
      "  time_total_s: 648.4671139717102\n",
      "  timers:\n",
      "    learn_throughput: 3460.572\n",
      "    learn_time_ms: 1155.878\n",
      "    load_throughput: 233665961.003\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3432.477\n",
      "    sample_time_ms: 1165.339\n",
      "    update_time_ms: 1.182\n",
      "  timestamp: 1634313679\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1088000\n",
      "  training_iteration: 272\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.2/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   272</td><td style=\"text-align: right;\">        648.467 </td><td style=\"text-align: right;\">1088000</td><td style=\"text-align: right;\">  199.17</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 155</td><td style=\"text-align: right;\">            199.17</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1100000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-01-51\n",
      "  done: false\n",
      "  episode_len_mean: 198.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 198.01\n",
      "  episode_reward_min: 144.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5905\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0019858151208609343\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.024646740406751633\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0007612459594383836\n",
      "          model: {}\n",
      "          policy_loss: -0.000705285114236176\n",
      "          total_loss: 305.65521240234375\n",
      "          vf_explained_var: 0.5105039477348328\n",
      "          vf_loss: 305.6559143066406\n",
      "    num_agent_steps_sampled: 1100000\n",
      "    num_agent_steps_trained: 1100000\n",
      "    num_steps_sampled: 1100000\n",
      "    num_steps_trained: 1100000\n",
      "  iterations_since_restore: 275\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.96\n",
      "    ram_util_percent: 67.0\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030690079732589127\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035246589104066264\n",
      "    mean_inference_ms: 0.48886852939998926\n",
      "    mean_raw_obs_processing_ms: 0.03795808971675303\n",
      "  time_since_restore: 679.7500469684601\n",
      "  time_this_iter_s: 26.613884925842285\n",
      "  time_total_s: 679.7500469684601\n",
      "  timers:\n",
      "    learn_throughput: 3451.722\n",
      "    learn_time_ms: 1158.842\n",
      "    load_throughput: 230140137.174\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3090.826\n",
      "    sample_time_ms: 1294.152\n",
      "    update_time_ms: 1.189\n",
      "  timestamp: 1634313711\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1100000\n",
      "  training_iteration: 275\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.4/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   275</td><td style=\"text-align: right;\">        679.75  </td><td style=\"text-align: right;\">1100000</td><td style=\"text-align: right;\">  198.01</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 144</td><td style=\"text-align: right;\">            198.01</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1112000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-01-58\n",
      "  done: false\n",
      "  episode_len_mean: 197.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 197.38\n",
      "  episode_reward_min: 144.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5966\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0002482268901076168\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.0356253907084465\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0038500267546623945\n",
      "          model: {}\n",
      "          policy_loss: 0.0024661272764205933\n",
      "          total_loss: 334.39520263671875\n",
      "          vf_explained_var: 0.4850882291793823\n",
      "          vf_loss: 334.3927001953125\n",
      "    num_agent_steps_sampled: 1112000\n",
      "    num_agent_steps_trained: 1112000\n",
      "    num_steps_sampled: 1112000\n",
      "    num_steps_trained: 1112000\n",
      "  iterations_since_restore: 278\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.599999999999998\n",
      "    ram_util_percent: 67.66666666666667\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030703681425408056\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035246223706783625\n",
      "    mean_inference_ms: 0.5155954047229903\n",
      "    mean_raw_obs_processing_ms: 0.03794615815736561\n",
      "  time_since_restore: 686.6943137645721\n",
      "  time_this_iter_s: 2.2975378036499023\n",
      "  time_total_s: 686.6943137645721\n",
      "  timers:\n",
      "    learn_throughput: 3502.559\n",
      "    learn_time_ms: 1142.022\n",
      "    load_throughput: 232050013.831\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3098.022\n",
      "    sample_time_ms: 1291.146\n",
      "    update_time_ms: 1.153\n",
      "  timestamp: 1634313718\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1112000\n",
      "  training_iteration: 278\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.4/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   278</td><td style=\"text-align: right;\">        686.694 </td><td style=\"text-align: right;\">1112000</td><td style=\"text-align: right;\">  197.38</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 144</td><td style=\"text-align: right;\">            197.38</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1124000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-02-07\n",
      "  done: false\n",
      "  episode_len_mean: 196.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.3\n",
      "  episode_reward_min: 130.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6027\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.00018617016030475497\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.023129213601350784\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03502307087182999\n",
      "          model: {}\n",
      "          policy_loss: 0.008444827049970627\n",
      "          total_loss: 198.7564239501953\n",
      "          vf_explained_var: 0.6857905983924866\n",
      "          vf_loss: 198.7479705810547\n",
      "    num_agent_steps_sampled: 1124000\n",
      "    num_agent_steps_trained: 1124000\n",
      "    num_steps_sampled: 1124000\n",
      "    num_steps_trained: 1124000\n",
      "  iterations_since_restore: 281\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.171428571428574\n",
      "    ram_util_percent: 65.7\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03069816744379323\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035240094593294836\n",
      "    mean_inference_ms: 0.5234368139049284\n",
      "    mean_raw_obs_processing_ms: 0.037938199558774206\n",
      "  time_since_restore: 696.412008523941\n",
      "  time_this_iter_s: 5.120935916900635\n",
      "  time_total_s: 696.412008523941\n",
      "  timers:\n",
      "    learn_throughput: 2810.989\n",
      "    learn_time_ms: 1422.987\n",
      "    load_throughput: 230456263.736\n",
      "    load_time_ms: 0.017\n",
      "    sample_throughput: 3100.155\n",
      "    sample_time_ms: 1290.258\n",
      "    update_time_ms: 1.671\n",
      "  timestamp: 1634313727\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1124000\n",
      "  training_iteration: 281\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.3/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   281</td><td style=\"text-align: right;\">        696.412 </td><td style=\"text-align: right;\">1124000</td><td style=\"text-align: right;\">   196.3</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 130</td><td style=\"text-align: right;\">             196.3</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1128000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-02-16\n",
      "  done: false\n",
      "  episode_len_mean: 196.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 196.07\n",
      "  episode_reward_min: 130.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6048\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.00027925524045713246\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.020569102838635445\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.05568401515483856\n",
      "          model: {}\n",
      "          policy_loss: 0.0036334909964352846\n",
      "          total_loss: 256.29388427734375\n",
      "          vf_explained_var: 0.6911838054656982\n",
      "          vf_loss: 256.2902526855469\n",
      "    num_agent_steps_sampled: 1128000\n",
      "    num_agent_steps_trained: 1128000\n",
      "    num_steps_sampled: 1128000\n",
      "    num_steps_trained: 1128000\n",
      "  iterations_since_restore: 282\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.958333333333332\n",
      "    ram_util_percent: 65.70000000000002\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.030774568758374095\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03534462885941612\n",
      "    mean_inference_ms: 0.5247075951559457\n",
      "    mean_raw_obs_processing_ms: 0.03805582236062692\n",
      "  time_since_restore: 704.7614345550537\n",
      "  time_this_iter_s: 8.349426031112671\n",
      "  time_total_s: 704.7614345550537\n",
      "  timers:\n",
      "    learn_throughput: 2619.258\n",
      "    learn_time_ms: 1527.15\n",
      "    load_throughput: 211833535.354\n",
      "    load_time_ms: 0.019\n",
      "    sample_throughput: 2233.837\n",
      "    sample_time_ms: 1790.641\n",
      "    update_time_ms: 1.745\n",
      "  timestamp: 1634313736\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1128000\n",
      "  training_iteration: 282\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.3/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   282</td><td style=\"text-align: right;\">        704.761 </td><td style=\"text-align: right;\">1128000</td><td style=\"text-align: right;\">  196.07</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 130</td><td style=\"text-align: right;\">            196.07</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1136000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-02-23\n",
      "  done: false\n",
      "  episode_len_mean: 194.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.01\n",
      "  episode_reward_min: 130.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6089\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0006283242837525904\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.012516897171735764\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.503638505935669\n",
      "          model: {}\n",
      "          policy_loss: 0.012160060927271843\n",
      "          total_loss: 365.1748046875\n",
      "          vf_explained_var: 0.40124407410621643\n",
      "          vf_loss: 365.162353515625\n",
      "    num_agent_steps_sampled: 1136000\n",
      "    num_agent_steps_trained: 1136000\n",
      "    num_steps_sampled: 1136000\n",
      "    num_steps_trained: 1136000\n",
      "  iterations_since_restore: 284\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.479999999999997\n",
      "    ram_util_percent: 65.7\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.031013323437774413\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035604431011747276\n",
      "    mean_inference_ms: 0.5280055140046331\n",
      "    mean_raw_obs_processing_ms: 0.038313431241429725\n",
      "  time_since_restore: 712.0698478221893\n",
      "  time_this_iter_s: 3.653698205947876\n",
      "  time_total_s: 712.0698478221893\n",
      "  timers:\n",
      "    learn_throughput: 2456.002\n",
      "    learn_time_ms: 1628.663\n",
      "    load_throughput: 200444635.603\n",
      "    load_time_ms: 0.02\n",
      "    sample_throughput: 2048.547\n",
      "    sample_time_ms: 1952.604\n",
      "    update_time_ms: 1.877\n",
      "  timestamp: 1634313743\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1136000\n",
      "  training_iteration: 284\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.3/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   284</td><td style=\"text-align: right;\">        712.07  </td><td style=\"text-align: right;\">1136000</td><td style=\"text-align: right;\">  194.01</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 130</td><td style=\"text-align: right;\">            194.01</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1144000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-02-31\n",
      "  done: false\n",
      "  episode_len_mean: 192.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 192.6\n",
      "  episode_reward_min: 132.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6131\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0014137296238914132\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.014949028380215168\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.5027269124984741\n",
      "          model: {}\n",
      "          policy_loss: 0.01573752798140049\n",
      "          total_loss: 262.5810546875\n",
      "          vf_explained_var: 0.6576183438301086\n",
      "          vf_loss: 262.5646057128906\n",
      "    num_agent_steps_sampled: 1144000\n",
      "    num_agent_steps_trained: 1144000\n",
      "    num_steps_sampled: 1144000\n",
      "    num_steps_trained: 1144000\n",
      "  iterations_since_restore: 286\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.8\n",
      "    ram_util_percent: 65.74999999999999\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03130118617057967\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.035921738454501764\n",
      "    mean_inference_ms: 0.5320738337431056\n",
      "    mean_raw_obs_processing_ms: 0.03863117902451569\n",
      "  time_since_restore: 719.5825343132019\n",
      "  time_this_iter_s: 3.7640886306762695\n",
      "  time_total_s: 719.5825343132019\n",
      "  timers:\n",
      "    learn_throughput: 2284.114\n",
      "    learn_time_ms: 1751.226\n",
      "    load_throughput: 190650181.818\n",
      "    load_time_ms: 0.021\n",
      "    sample_throughput: 2010.608\n",
      "    sample_time_ms: 1989.448\n",
      "    update_time_ms: 2.009\n",
      "  timestamp: 1634313751\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1144000\n",
      "  training_iteration: 286\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.3/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   286</td><td style=\"text-align: right;\">        719.583 </td><td style=\"text-align: right;\">1144000</td><td style=\"text-align: right;\">   192.6</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 132</td><td style=\"text-align: right;\">             192.6</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">   200  </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">             200  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1152000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-02-38\n",
      "  done: false\n",
      "  episode_len_mean: 194.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 194.77\n",
      "  episode_reward_min: 132.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6171\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.003180891741067171\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.014601812697947025\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.0165799856185913\n",
      "          model: {}\n",
      "          policy_loss: 0.03437485918402672\n",
      "          total_loss: 228.48565673828125\n",
      "          vf_explained_var: 0.628554105758667\n",
      "          vf_loss: 228.4480438232422\n",
      "    num_agent_steps_sampled: 1152000\n",
      "    num_agent_steps_trained: 1152000\n",
      "    num_steps_sampled: 1152000\n",
      "    num_steps_trained: 1152000\n",
      "  iterations_since_restore: 288\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.84\n",
      "    ram_util_percent: 66.04\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.031424501008328186\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03608339951033173\n",
      "    mean_inference_ms: 0.5339346778065748\n",
      "    mean_raw_obs_processing_ms: 0.03880909316908988\n",
      "  time_since_restore: 727.1062104701996\n",
      "  time_this_iter_s: 3.787734031677246\n",
      "  time_total_s: 727.1062104701996\n",
      "  timers:\n",
      "    learn_throughput: 2139.364\n",
      "    learn_time_ms: 1869.715\n",
      "    load_throughput: 177536677.249\n",
      "    load_time_ms: 0.023\n",
      "    sample_throughput: 1848.379\n",
      "    sample_time_ms: 2164.059\n",
      "    update_time_ms: 2.141\n",
      "  timestamp: 1634313758\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1152000\n",
      "  training_iteration: 288\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.4/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   288</td><td style=\"text-align: right;\">        727.106 </td><td style=\"text-align: right;\">1152000</td><td style=\"text-align: right;\">  194.77</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 132</td><td style=\"text-align: right;\">            194.77</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1156000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-31-24\n",
      "  done: false\n",
      "  episode_len_mean: 195.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 195.87\n",
      "  episode_reward_min: 139.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6191\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0047713378444314\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.007644451688975096\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.001596689224243\n",
      "          model: {}\n",
      "          policy_loss: 0.028907151892781258\n",
      "          total_loss: 223.6616973876953\n",
      "          vf_explained_var: 0.6034905910491943\n",
      "          vf_loss: 223.6232452392578\n",
      "    num_agent_steps_sampled: 1156000\n",
      "    num_agent_steps_trained: 1156000\n",
      "    num_steps_sampled: 1156000\n",
      "    num_steps_trained: 1156000\n",
      "  iterations_since_restore: 289\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.9\n",
      "    ram_util_percent: 66.8\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03148242641501097\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03615144113253774\n",
      "    mean_inference_ms: 1.1310375000150716\n",
      "    mean_raw_obs_processing_ms: 0.0388795532056085\n",
      "  time_since_restore: 2452.945130586624\n",
      "  time_this_iter_s: 1725.8389201164246\n",
      "  time_total_s: 2452.945130586624\n",
      "  timers:\n",
      "    learn_throughput: 2143.206\n",
      "    learn_time_ms: 1866.363\n",
      "    load_throughput: 174944900.938\n",
      "    load_time_ms: 0.023\n",
      "    sample_throughput: 1717.223\n",
      "    sample_time_ms: 2329.343\n",
      "    update_time_ms: 2.129\n",
      "  timestamp: 1634315484\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1156000\n",
      "  training_iteration: 289\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.3/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>RUNNING   </td><td>192.168.0.42:1096</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   289</td><td style=\"text-align: right;\">       2452.95  </td><td style=\"text-align: right;\">1156000</td><td style=\"text-align: right;\">  195.87</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 139</td><td style=\"text-align: right;\">            195.87</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>                 </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">  200   </td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">            200   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_CartPole-v0_97f47_00000:\n",
      "  agent_timesteps_total: 1168000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-15_11-31-31\n",
      "  done: true\n",
      "  episode_len_mean: 200.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 200.0\n",
      "  episode_reward_min: 200.0\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6251\n",
      "  experiment_id: f750806d183f44688b827b772469e4d4\n",
      "  hostname: Liweis-iMac.local\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.016103263944387436\n",
      "          cur_lr: 0.009999999776482582\n",
      "          entropy: 0.008555091917514801\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.10656091570854187\n",
      "          model: {}\n",
      "          policy_loss: 0.005454843398183584\n",
      "          total_loss: 164.05479431152344\n",
      "          vf_explained_var: 0.5440415740013123\n",
      "          vf_loss: 164.047607421875\n",
      "    num_agent_steps_sampled: 1168000\n",
      "    num_agent_steps_trained: 1168000\n",
      "    num_steps_sampled: 1168000\n",
      "    num_steps_trained: 1168000\n",
      "  iterations_since_restore: 292\n",
      "  node_ip: 192.168.0.42\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.75\n",
      "    ram_util_percent: 66.775\n",
      "  pid: 1096\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03155005457616579\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.03624899804036986\n",
      "    mean_inference_ms: 2.908594268070004\n",
      "    mean_raw_obs_processing_ms: 0.038989957989425866\n",
      "  time_since_restore: 2459.612660884857\n",
      "  time_this_iter_s: 2.222151279449463\n",
      "  time_total_s: 2459.612660884857\n",
      "  timers:\n",
      "    learn_throughput: 2731.898\n",
      "    learn_time_ms: 1464.183\n",
      "    load_throughput: 188085381.166\n",
      "    load_time_ms: 0.021\n",
      "    sample_throughput: 2191.838\n",
      "    sample_time_ms: 1824.952\n",
      "    update_time_ms: 1.541\n",
      "  timestamp: 1634315491\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1168000\n",
      "  training_iteration: 292\n",
      "  trial_id: 97f47_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.3/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (3 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   292</td><td style=\"text-align: right;\">       2459.61  </td><td style=\"text-align: right;\">1168000</td><td style=\"text-align: right;\">     200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">     200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">     200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.3/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/2.09 GiB heap, 0.0/1.05 GiB objects<br>Result logdir: /Users/liwei/ray_results/PPO<br>Number of trials: 3/3 (3 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">   292</td><td style=\"text-align: right;\">       2459.61  </td><td style=\"text-align: right;\">1168000</td><td style=\"text-align: right;\">     200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         53.5871</td><td style=\"text-align: right;\">  60000</td><td style=\"text-align: right;\">     200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "<tr><td>PPO_CartPole-v0_97f47_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         59.4017</td><td style=\"text-align: right;\">  68000</td><td style=\"text-align: right;\">     200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">                 200</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 11:31:32,087\tINFO tune.py:561 -- Total run time: 2474.84 seconds (2474.02 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7fcba3e1e9a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg = 'PPO'\n",
    "tune.run(alg,\n",
    "    stop={'episode_reward_mean':200},\n",
    "    config={\n",
    "        'env':'CartPole-v0',\n",
    "        'num_gpus':0,\n",
    "        'num_workers':2,\n",
    "        'lr':tune.grid_search([.01,.001,.0001])     \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=17553)\u001b[0m WARNING:tensorflow:From /Users/mingjunwang/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=17553)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=17553)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=17553)\u001b[0m 2021-07-13 20:54:31,552\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=17553)\u001b[0m 2021-07-13 20:54:31,552\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=17556)\u001b[0m WARNING:tensorflow:From /Users/mingjunwang/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=17556)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=17556)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=17555)\u001b[0m WARNING:tensorflow:From /Users/mingjunwang/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=17555)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=17555)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=17555)\u001b[0m 2021-07-13 20:54:38,692\tWARNING deprecation.py:29 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-54-41\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -781.1207639597676\n",
      "  episode_reward_mean: -1131.8902231793475\n",
      "  episode_reward_min: -1410.9375467664963\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 6\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 1500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 0.1796478033065796\n",
      "        mean_q: -0.10519210994243622\n",
      "        min_q: -0.6069953441619873\n",
      "        model: {}\n",
      "    num_steps_sampled: 1500\n",
      "    num_steps_trained: 256\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.799999999999997\n",
      "    ram_util_percent: 63.55\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0973585918644932\n",
      "    mean_env_wait_ms: 0.14473166510204818\n",
      "    mean_inference_ms: 0.7737403544541523\n",
      "    mean_raw_obs_processing_ms: 0.22314836118573675\n",
      "  time_since_restore: 2.5313608646392822\n",
      "  time_this_iter_s: 2.5313608646392822\n",
      "  time_total_s: 2.5313608646392822\n",
      "  timers:\n",
      "    learn_throughput: 1305.163\n",
      "    learn_time_ms: 196.144\n",
      "    update_time_ms: 4.681\n",
      "  timestamp: 1626227681\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1500\n",
      "  training_iteration: 1\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.53136</td><td style=\"text-align: right;\">1500</td><td style=\"text-align: right;\">-1131.89</td><td style=\"text-align: right;\">            -781.121</td><td style=\"text-align: right;\">            -1410.94</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-54-58\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -781.1207639597676\n",
      "  episode_reward_mean: -1331.3202113249129\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 12\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 2500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: -0.50157630443573\n",
      "        mean_q: -11.473435401916504\n",
      "        min_q: -24.651611328125\n",
      "        model: {}\n",
      "    num_steps_sampled: 2500\n",
      "    num_steps_trained: 128256\n",
      "    num_target_updates: 501\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.545833333333334\n",
      "    ram_util_percent: 63.48333333333334\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09797157483190518\n",
      "    mean_env_wait_ms: 0.14469709336634642\n",
      "    mean_inference_ms: 0.7615721799224051\n",
      "    mean_raw_obs_processing_ms: 0.22257846912676293\n",
      "  time_since_restore: 19.607420921325684\n",
      "  time_this_iter_s: 17.0760600566864\n",
      "  time_total_s: 19.607420921325684\n",
      "  timers:\n",
      "    learn_throughput: 58299.452\n",
      "    learn_time_ms: 4.391\n",
      "    update_time_ms: 2.605\n",
      "  timestamp: 1626227698\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2500\n",
      "  training_iteration: 2\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         19.6074</td><td style=\"text-align: right;\">2500</td><td style=\"text-align: right;\">-1331.32</td><td style=\"text-align: right;\">            -781.121</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-55-15\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -781.1207639597676\n",
      "  episode_reward_mean: -1398.030697460801\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 16\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 3500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: -0.1660407930612564\n",
      "        mean_q: -18.283344268798828\n",
      "        min_q: -33.41071319580078\n",
      "        model: {}\n",
      "    num_steps_sampled: 3500\n",
      "    num_steps_trained: 256256\n",
      "    num_target_updates: 1001\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.1125\n",
      "    ram_util_percent: 64.00416666666666\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09813306505833767\n",
      "    mean_env_wait_ms: 0.1444267892224933\n",
      "    mean_inference_ms: 0.7552609488782389\n",
      "    mean_raw_obs_processing_ms: 0.22187214395356114\n",
      "  time_since_restore: 36.444782733917236\n",
      "  time_this_iter_s: 16.837361812591553\n",
      "  time_total_s: 36.444782733917236\n",
      "  timers:\n",
      "    learn_throughput: 67208.837\n",
      "    learn_time_ms: 3.809\n",
      "    update_time_ms: 2.164\n",
      "  timestamp: 1626227715\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3500\n",
      "  training_iteration: 3\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         36.4448</td><td style=\"text-align: right;\">3500</td><td style=\"text-align: right;\">-1398.03</td><td style=\"text-align: right;\">            -781.121</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-55-32\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -781.1207639597676\n",
      "  episode_reward_mean: -1425.8668538197078\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 22\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 4500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: -0.6811314225196838\n",
      "        mean_q: -23.862667083740234\n",
      "        min_q: -44.24247360229492\n",
      "        model: {}\n",
      "    num_steps_sampled: 4500\n",
      "    num_steps_trained: 384256\n",
      "    num_target_updates: 1501\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.125\n",
      "    ram_util_percent: 64.6375\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09838679174479754\n",
      "    mean_env_wait_ms: 0.1443084430306832\n",
      "    mean_inference_ms: 0.7492579731789636\n",
      "    mean_raw_obs_processing_ms: 0.22119187406960872\n",
      "  time_since_restore: 53.642000675201416\n",
      "  time_this_iter_s: 17.19721794128418\n",
      "  time_total_s: 53.642000675201416\n",
      "  timers:\n",
      "    learn_throughput: 69144.745\n",
      "    learn_time_ms: 3.702\n",
      "    update_time_ms: 2.206\n",
      "  timestamp: 1626227732\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4500\n",
      "  training_iteration: 4\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">          53.642</td><td style=\"text-align: right;\">4500</td><td style=\"text-align: right;\">-1425.87</td><td style=\"text-align: right;\">            -781.121</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-55-50\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -781.1207639597676\n",
      "  episode_reward_mean: -1444.8272991160627\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 26\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 5500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 0.3510587811470032\n",
      "        mean_q: -29.40019416809082\n",
      "        min_q: -47.306602478027344\n",
      "        model: {}\n",
      "    num_steps_sampled: 5500\n",
      "    num_steps_trained: 512256\n",
      "    num_target_updates: 2001\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.332000000000004\n",
      "    ram_util_percent: 64.232\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09862273063120153\n",
      "    mean_env_wait_ms: 0.14439809792260078\n",
      "    mean_inference_ms: 0.7471738745456697\n",
      "    mean_raw_obs_processing_ms: 0.22106400627231673\n",
      "  time_since_restore: 71.59774255752563\n",
      "  time_this_iter_s: 17.95574188232422\n",
      "  time_total_s: 71.59774255752563\n",
      "  timers:\n",
      "    learn_throughput: 66434.142\n",
      "    learn_time_ms: 3.853\n",
      "    update_time_ms: 2.271\n",
      "  timestamp: 1626227750\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5500\n",
      "  training_iteration: 5\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         71.5977</td><td style=\"text-align: right;\">5500</td><td style=\"text-align: right;\">-1444.83</td><td style=\"text-align: right;\">            -781.121</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-56-07\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -781.1207639597676\n",
      "  episode_reward_mean: -1436.744265061477\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 32\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 6500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: -0.09803511202335358\n",
      "        mean_q: -34.90961456298828\n",
      "        min_q: -63.530277252197266\n",
      "        model: {}\n",
      "    num_steps_sampled: 6500\n",
      "    num_steps_trained: 640256\n",
      "    num_target_updates: 2501\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.962500000000002\n",
      "    ram_util_percent: 63.50416666666667\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09891302519653711\n",
      "    mean_env_wait_ms: 0.1445202853097181\n",
      "    mean_inference_ms: 0.7445685789103453\n",
      "    mean_raw_obs_processing_ms: 0.22094713838037758\n",
      "  time_since_restore: 89.20183849334717\n",
      "  time_this_iter_s: 17.604095935821533\n",
      "  time_total_s: 89.20183849334717\n",
      "  timers:\n",
      "    learn_throughput: 66701.153\n",
      "    learn_time_ms: 3.838\n",
      "    update_time_ms: 2.108\n",
      "  timestamp: 1626227767\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6500\n",
      "  training_iteration: 6\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         89.2018</td><td style=\"text-align: right;\">6500</td><td style=\"text-align: right;\">-1436.74</td><td style=\"text-align: right;\">            -781.121</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-56-26\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -781.1207639597676\n",
      "  episode_reward_mean: -1438.6196838828807\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 36\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 7500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 0.008759599179029465\n",
      "        mean_q: -40.90607452392578\n",
      "        min_q: -63.068790435791016\n",
      "        model: {}\n",
      "    num_steps_sampled: 7500\n",
      "    num_steps_trained: 768256\n",
      "    num_target_updates: 3001\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.47307692307692\n",
      "    ram_util_percent: 65.36153846153846\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09913483847547423\n",
      "    mean_env_wait_ms: 0.14468110819074503\n",
      "    mean_inference_ms: 0.7435151127284532\n",
      "    mean_raw_obs_processing_ms: 0.2210145012650037\n",
      "  time_since_restore: 107.37493371963501\n",
      "  time_this_iter_s: 18.173095226287842\n",
      "  time_total_s: 107.37493371963501\n",
      "  timers:\n",
      "    learn_throughput: 55955.82\n",
      "    learn_time_ms: 4.575\n",
      "    update_time_ms: 2.636\n",
      "  timestamp: 1626227786\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7500\n",
      "  training_iteration: 7\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         107.375</td><td style=\"text-align: right;\">7500</td><td style=\"text-align: right;\">-1438.62</td><td style=\"text-align: right;\">            -781.121</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-56-44\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -781.1207639597676\n",
      "  episode_reward_mean: -1412.6190355939557\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 42\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 8500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 1.5346838235855103\n",
      "        mean_q: -44.83782958984375\n",
      "        min_q: -71.63545227050781\n",
      "        model: {}\n",
      "    num_steps_sampled: 8500\n",
      "    num_steps_trained: 896256\n",
      "    num_target_updates: 3501\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.483999999999995\n",
      "    ram_util_percent: 60.803999999999995\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09941605964921256\n",
      "    mean_env_wait_ms: 0.14489890198444585\n",
      "    mean_inference_ms: 0.742334410942045\n",
      "    mean_raw_obs_processing_ms: 0.2211894070115637\n",
      "  time_since_restore: 125.71777677536011\n",
      "  time_this_iter_s: 18.342843055725098\n",
      "  time_total_s: 125.71777677536011\n",
      "  timers:\n",
      "    learn_throughput: 66089.841\n",
      "    learn_time_ms: 3.874\n",
      "    update_time_ms: 2.326\n",
      "  timestamp: 1626227804\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8500\n",
      "  training_iteration: 8\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         125.718</td><td style=\"text-align: right;\">8500</td><td style=\"text-align: right;\">-1412.62</td><td style=\"text-align: right;\">            -781.121</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-57-02\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -781.1207639597676\n",
      "  episode_reward_mean: -1398.6154951909177\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 46\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 9500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: -0.022161278873682022\n",
      "        mean_q: -50.20433044433594\n",
      "        min_q: -73.2963638305664\n",
      "        model: {}\n",
      "    num_steps_sampled: 9500\n",
      "    num_steps_trained: 1024256\n",
      "    num_target_updates: 4001\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.676\n",
      "    ram_util_percent: 60.964\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09955409264438625\n",
      "    mean_env_wait_ms: 0.14501209496502157\n",
      "    mean_inference_ms: 0.7415564006076368\n",
      "    mean_raw_obs_processing_ms: 0.22126649260221518\n",
      "  time_since_restore: 143.43251085281372\n",
      "  time_this_iter_s: 17.714734077453613\n",
      "  time_total_s: 143.43251085281372\n",
      "  timers:\n",
      "    learn_throughput: 63325.184\n",
      "    learn_time_ms: 4.043\n",
      "    update_time_ms: 2.284\n",
      "  timestamp: 1626227822\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9500\n",
      "  training_iteration: 9\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         143.433</td><td style=\"text-align: right;\">9500</td><td style=\"text-align: right;\">-1398.62</td><td style=\"text-align: right;\">            -781.121</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-57-20\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -11.722382280782014\n",
      "  episode_reward_mean: -1348.1319338104424\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 52\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 10500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 0.9547820687294006\n",
      "        mean_q: -53.53691864013672\n",
      "        min_q: -75.73155975341797\n",
      "        model: {}\n",
      "    num_steps_sampled: 10500\n",
      "    num_steps_trained: 1152256\n",
      "    num_target_updates: 4501\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.58076923076923\n",
      "    ram_util_percent: 62.80384615384616\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09973805000463255\n",
      "    mean_env_wait_ms: 0.14517130740979722\n",
      "    mean_inference_ms: 0.7405815724945874\n",
      "    mean_raw_obs_processing_ms: 0.221378329083068\n",
      "  time_since_restore: 161.5978705883026\n",
      "  time_this_iter_s: 18.16535973548889\n",
      "  time_total_s: 161.5978705883026\n",
      "  timers:\n",
      "    learn_throughput: 61002.512\n",
      "    learn_time_ms: 4.197\n",
      "    update_time_ms: 2.488\n",
      "  timestamp: 1626227840\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10500\n",
      "  training_iteration: 10\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.4/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         161.598</td><td style=\"text-align: right;\">10500</td><td style=\"text-align: right;\">-1348.13</td><td style=\"text-align: right;\">            -11.7224</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-57-38\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -11.722382280782014\n",
      "  episode_reward_mean: -1336.2461581544399\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 56\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 11500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: -1.291930079460144\n",
      "        mean_q: -56.992698669433594\n",
      "        min_q: -83.67649841308594\n",
      "        model: {}\n",
      "    num_steps_sampled: 11500\n",
      "    num_steps_trained: 1280256\n",
      "    num_target_updates: 5001\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.019999999999996\n",
      "    ram_util_percent: 63.53200000000001\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09984162821424539\n",
      "    mean_env_wait_ms: 0.1452610650848398\n",
      "    mean_inference_ms: 0.7400414020223257\n",
      "    mean_raw_obs_processing_ms: 0.22145066812292358\n",
      "  time_since_restore: 179.77703475952148\n",
      "  time_this_iter_s: 18.179164171218872\n",
      "  time_total_s: 179.77703475952148\n",
      "  timers:\n",
      "    learn_throughput: 55744.915\n",
      "    learn_time_ms: 4.592\n",
      "    update_time_ms: 2.283\n",
      "  timestamp: 1626227858\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11500\n",
      "  training_iteration: 11\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         179.777</td><td style=\"text-align: right;\">11500</td><td style=\"text-align: right;\">-1336.25</td><td style=\"text-align: right;\">            -11.7224</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-57-57\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -11.722382280782014\n",
      "  episode_reward_mean: -1288.7165801323201\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 62\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 12500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 1.1449592113494873\n",
      "        mean_q: -62.394222259521484\n",
      "        min_q: -90.33869934082031\n",
      "        model: {}\n",
      "    num_steps_sampled: 12500\n",
      "    num_steps_trained: 1408256\n",
      "    num_target_updates: 5501\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.78846153846154\n",
      "    ram_util_percent: 61.83461538461539\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09998511732421295\n",
      "    mean_env_wait_ms: 0.14538881263770745\n",
      "    mean_inference_ms: 0.7394246003424146\n",
      "    mean_raw_obs_processing_ms: 0.22156465250994076\n",
      "  time_since_restore: 198.1817545890808\n",
      "  time_this_iter_s: 18.404719829559326\n",
      "  time_total_s: 198.1817545890808\n",
      "  timers:\n",
      "    learn_throughput: 54282.297\n",
      "    learn_time_ms: 4.716\n",
      "    update_time_ms: 2.672\n",
      "  timestamp: 1626227877\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12500\n",
      "  training_iteration: 12\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         198.182</td><td style=\"text-align: right;\">12500</td><td style=\"text-align: right;\">-1288.72</td><td style=\"text-align: right;\">            -11.7224</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-58-14\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -11.722382280782014\n",
      "  episode_reward_mean: -1269.864064156319\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 66\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 13500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 0.9233301877975464\n",
      "        mean_q: -62.598182678222656\n",
      "        min_q: -89.0087890625\n",
      "        model: {}\n",
      "    num_steps_sampled: 13500\n",
      "    num_steps_trained: 1536256\n",
      "    num_target_updates: 6001\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.896\n",
      "    ram_util_percent: 62.232\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10005915854217143\n",
      "    mean_env_wait_ms: 0.14545422921286064\n",
      "    mean_inference_ms: 0.739005902172205\n",
      "    mean_raw_obs_processing_ms: 0.22161749281606014\n",
      "  time_since_restore: 216.09442567825317\n",
      "  time_this_iter_s: 17.912671089172363\n",
      "  time_total_s: 216.09442567825317\n",
      "  timers:\n",
      "    learn_throughput: 66939.841\n",
      "    learn_time_ms: 3.824\n",
      "    update_time_ms: 2.219\n",
      "  timestamp: 1626227894\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13500\n",
      "  training_iteration: 13\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         216.094</td><td style=\"text-align: right;\">13500</td><td style=\"text-align: right;\">-1269.86</td><td style=\"text-align: right;\">            -11.7224</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-58-33\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -3.1396012759307346\n",
      "  episode_reward_mean: -1193.5720942077833\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 72\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 14500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 2.8817272186279297\n",
      "        mean_q: -63.85460662841797\n",
      "        min_q: -94.13409423828125\n",
      "        model: {}\n",
      "    num_steps_sampled: 14500\n",
      "    num_steps_trained: 1664256\n",
      "    num_target_updates: 6501\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.12\n",
      "    ram_util_percent: 63.36\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1001575898790833\n",
      "    mean_env_wait_ms: 0.14555066669231087\n",
      "    mean_inference_ms: 0.7384886316517281\n",
      "    mean_raw_obs_processing_ms: 0.22168737744292352\n",
      "  time_since_restore: 234.4201078414917\n",
      "  time_this_iter_s: 18.325682163238525\n",
      "  time_total_s: 234.4201078414917\n",
      "  timers:\n",
      "    learn_throughput: 70082.554\n",
      "    learn_time_ms: 3.653\n",
      "    update_time_ms: 2.176\n",
      "  timestamp: 1626227913\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14500\n",
      "  training_iteration: 14\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">          234.42</td><td style=\"text-align: right;\">14500</td><td style=\"text-align: right;\">-1193.57</td><td style=\"text-align: right;\">             -3.1396</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-58-51\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -3.1396012759307346\n",
      "  episode_reward_mean: -1179.2687786561391\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 76\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 15500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 2.4560861587524414\n",
      "        mean_q: -63.485443115234375\n",
      "        min_q: -99.68254089355469\n",
      "        model: {}\n",
      "    num_steps_sampled: 15500\n",
      "    num_steps_trained: 1792256\n",
      "    num_target_updates: 7001\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.6\n",
      "    ram_util_percent: 63.26\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10020802807056446\n",
      "    mean_env_wait_ms: 0.14559826169718723\n",
      "    mean_inference_ms: 0.7381199811772466\n",
      "    mean_raw_obs_processing_ms: 0.22171206407209648\n",
      "  time_since_restore: 252.2317407131195\n",
      "  time_this_iter_s: 17.811632871627808\n",
      "  time_total_s: 252.2317407131195\n",
      "  timers:\n",
      "    learn_throughput: 72884.011\n",
      "    learn_time_ms: 3.512\n",
      "    update_time_ms: 2.139\n",
      "  timestamp: 1626227931\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15500\n",
      "  training_iteration: 15\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         252.232</td><td style=\"text-align: right;\">15500</td><td style=\"text-align: right;\">-1179.27</td><td style=\"text-align: right;\">             -3.1396</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-59-08\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -1.8323446584304053\n",
      "  episode_reward_mean: -1113.7970069430512\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 82\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 16500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 3.410090684890747\n",
      "        mean_q: -70.59851837158203\n",
      "        min_q: -103.12985229492188\n",
      "        model: {}\n",
      "    num_steps_sampled: 16500\n",
      "    num_steps_trained: 1920256\n",
      "    num_target_updates: 7501\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.516\n",
      "    ram_util_percent: 63.868\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10026239466162451\n",
      "    mean_env_wait_ms: 0.14564343205419253\n",
      "    mean_inference_ms: 0.7375129405851482\n",
      "    mean_raw_obs_processing_ms: 0.22171667486775146\n",
      "  time_since_restore: 269.8548905849457\n",
      "  time_this_iter_s: 17.623149871826172\n",
      "  time_total_s: 269.8548905849457\n",
      "  timers:\n",
      "    learn_throughput: 68509.454\n",
      "    learn_time_ms: 3.737\n",
      "    update_time_ms: 2.178\n",
      "  timestamp: 1626227948\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16500\n",
      "  training_iteration: 16\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         269.855</td><td style=\"text-align: right;\">16500</td><td style=\"text-align: right;\"> -1113.8</td><td style=\"text-align: right;\">            -1.83234</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-59-26\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -1.8323446584304053\n",
      "  episode_reward_mean: -1085.0581441625716\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 86\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 17500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 3.329087018966675\n",
      "        mean_q: -69.15478515625\n",
      "        min_q: -105.27165222167969\n",
      "        model: {}\n",
      "    num_steps_sampled: 17500\n",
      "    num_steps_trained: 2048256\n",
      "    num_target_updates: 8001\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.852000000000004\n",
      "    ram_util_percent: 61.42\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10029038455152726\n",
      "    mean_env_wait_ms: 0.145662359366662\n",
      "    mean_inference_ms: 0.7371023761861941\n",
      "    mean_raw_obs_processing_ms: 0.22170672561481933\n",
      "  time_since_restore: 287.5606265068054\n",
      "  time_this_iter_s: 17.70573592185974\n",
      "  time_total_s: 287.5606265068054\n",
      "  timers:\n",
      "    learn_throughput: 68548.818\n",
      "    learn_time_ms: 3.735\n",
      "    update_time_ms: 2.23\n",
      "  timestamp: 1626227966\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17500\n",
      "  training_iteration: 17\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         287.561</td><td style=\"text-align: right;\">17500</td><td style=\"text-align: right;\">-1085.06</td><td style=\"text-align: right;\">            -1.83234</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_20-59-44\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -1.1116457547643066\n",
      "  episode_reward_mean: -1034.789899227471\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 92\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 18500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 3.6690609455108643\n",
      "        mean_q: -67.78599548339844\n",
      "        min_q: -111.97421264648438\n",
      "        model: {}\n",
      "    num_steps_sampled: 18500\n",
      "    num_steps_trained: 2176256\n",
      "    num_target_updates: 8501\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.984\n",
      "    ram_util_percent: 61.907999999999994\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10032541318647033\n",
      "    mean_env_wait_ms: 0.14568362066268506\n",
      "    mean_inference_ms: 0.7365277332727878\n",
      "    mean_raw_obs_processing_ms: 0.22168686968758322\n",
      "  time_since_restore: 305.71143412590027\n",
      "  time_this_iter_s: 18.15080761909485\n",
      "  time_total_s: 305.71143412590027\n",
      "  timers:\n",
      "    learn_throughput: 69610.491\n",
      "    learn_time_ms: 3.678\n",
      "    update_time_ms: 2.14\n",
      "  timestamp: 1626227984\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 18500\n",
      "  training_iteration: 18\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         305.711</td><td style=\"text-align: right;\">18500</td><td style=\"text-align: right;\">-1034.79</td><td style=\"text-align: right;\">            -1.11165</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_21-00-02\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -1.1116457547643066\n",
      "  episode_reward_mean: -997.122177864407\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 96\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 19500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 5.729738235473633\n",
      "        mean_q: -72.16944122314453\n",
      "        min_q: -117.57238006591797\n",
      "        model: {}\n",
      "    num_steps_sampled: 19500\n",
      "    num_steps_trained: 2304256\n",
      "    num_target_updates: 9001\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.772\n",
      "    ram_util_percent: 63.343999999999994\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10034120140496124\n",
      "    mean_env_wait_ms: 0.1456915975727191\n",
      "    mean_inference_ms: 0.7361423802744369\n",
      "    mean_raw_obs_processing_ms: 0.22166756125687728\n",
      "  time_since_restore: 323.59876918792725\n",
      "  time_this_iter_s: 17.887335062026978\n",
      "  time_total_s: 323.59876918792725\n",
      "  timers:\n",
      "    learn_throughput: 71712.349\n",
      "    learn_time_ms: 3.57\n",
      "    update_time_ms: 2.143\n",
      "  timestamp: 1626228002\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19500\n",
      "  training_iteration: 19\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         323.599</td><td style=\"text-align: right;\">19500</td><td style=\"text-align: right;\">-997.122</td><td style=\"text-align: right;\">            -1.11165</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_21-00-20\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -1.1116457547643066\n",
      "  episode_reward_mean: -962.5109391533188\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 102\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 20500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 5.6856279373168945\n",
      "        mean_q: -70.61603546142578\n",
      "        min_q: -114.73045349121094\n",
      "        model: {}\n",
      "    num_steps_sampled: 20500\n",
      "    num_steps_trained: 2432256\n",
      "    num_target_updates: 9501\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.34\n",
      "    ram_util_percent: 63.876\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10039843358964308\n",
      "    mean_env_wait_ms: 0.14570528559035256\n",
      "    mean_inference_ms: 0.7345797772574815\n",
      "    mean_raw_obs_processing_ms: 0.22154705123683371\n",
      "  time_since_restore: 341.51777505874634\n",
      "  time_this_iter_s: 17.919005870819092\n",
      "  time_total_s: 341.51777505874634\n",
      "  timers:\n",
      "    learn_throughput: 74080.281\n",
      "    learn_time_ms: 3.456\n",
      "    update_time_ms: 2.081\n",
      "  timestamp: 1626228020\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20500\n",
      "  training_iteration: 20\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         341.518</td><td style=\"text-align: right;\">20500</td><td style=\"text-align: right;\">-962.511</td><td style=\"text-align: right;\">            -1.11165</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_21-00-38\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -1.1116457547643066\n",
      "  episode_reward_mean: -926.8117919657061\n",
      "  episode_reward_min: -1796.9534032278605\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 106\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 21500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 4.623827934265137\n",
      "        mean_q: -73.03113555908203\n",
      "        min_q: -121.44898986816406\n",
      "        model: {}\n",
      "    num_steps_sampled: 21500\n",
      "    num_steps_trained: 2560256\n",
      "    num_target_updates: 10001\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.892\n",
      "    ram_util_percent: 64.264\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10054363674887985\n",
      "    mean_env_wait_ms: 0.14575424884632088\n",
      "    mean_inference_ms: 0.7328909911016142\n",
      "    mean_raw_obs_processing_ms: 0.22151258708781435\n",
      "  time_since_restore: 359.28413009643555\n",
      "  time_this_iter_s: 17.76635503768921\n",
      "  time_total_s: 359.28413009643555\n",
      "  timers:\n",
      "    learn_throughput: 71191.236\n",
      "    learn_time_ms: 3.596\n",
      "    update_time_ms: 2.169\n",
      "  timestamp: 1626228038\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 21500\n",
      "  training_iteration: 21\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         359.284</td><td style=\"text-align: right;\">21500</td><td style=\"text-align: right;\">-926.812</td><td style=\"text-align: right;\">            -1.11165</td><td style=\"text-align: right;\">            -1796.95</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_21-00-56\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -1.1116457547643066\n",
      "  episode_reward_mean: -845.3818124377199\n",
      "  episode_reward_min: -1702.4878189939052\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 112\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 22500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 5.559916973114014\n",
      "        mean_q: -77.15824890136719\n",
      "        min_q: -124.76898956298828\n",
      "        model: {}\n",
      "    num_steps_sampled: 22500\n",
      "    num_steps_trained: 2688256\n",
      "    num_target_updates: 10501\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.011538461538464\n",
      "    ram_util_percent: 62.280769230769245\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10065893392522074\n",
      "    mean_env_wait_ms: 0.14581588006225654\n",
      "    mean_inference_ms: 0.731451783940171\n",
      "    mean_raw_obs_processing_ms: 0.2214408051532333\n",
      "  time_since_restore: 377.5080909729004\n",
      "  time_this_iter_s: 18.223960876464844\n",
      "  time_total_s: 377.5080909729004\n",
      "  timers:\n",
      "    learn_throughput: 70330.438\n",
      "    learn_time_ms: 3.64\n",
      "    update_time_ms: 2.2\n",
      "  timestamp: 1626228056\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 22500\n",
      "  training_iteration: 22\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         377.508</td><td style=\"text-align: right;\">22500</td><td style=\"text-align: right;\">-845.382</td><td style=\"text-align: right;\">            -1.11165</td><td style=\"text-align: right;\">            -1702.49</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_21-01-14\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -1.1116457547643066\n",
      "  episode_reward_mean: -789.2500149746359\n",
      "  episode_reward_min: -1702.4878189939052\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 116\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 23500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 5.940964221954346\n",
      "        mean_q: -75.83016967773438\n",
      "        min_q: -128.67138671875\n",
      "        model: {}\n",
      "    num_steps_sampled: 23500\n",
      "    num_steps_trained: 2816256\n",
      "    num_target_updates: 11001\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.7\n",
      "    ram_util_percent: 61.724\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1007344092037897\n",
      "    mean_env_wait_ms: 0.14590177367580778\n",
      "    mean_inference_ms: 0.7310117294745901\n",
      "    mean_raw_obs_processing_ms: 0.2214846485799835\n",
      "  time_since_restore: 395.6538829803467\n",
      "  time_this_iter_s: 18.14579200744629\n",
      "  time_total_s: 395.6538829803467\n",
      "  timers:\n",
      "    learn_throughput: 64673.113\n",
      "    learn_time_ms: 3.958\n",
      "    update_time_ms: 2.452\n",
      "  timestamp: 1626228074\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 23500\n",
      "  training_iteration: 23\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         395.654</td><td style=\"text-align: right;\">23500</td><td style=\"text-align: right;\"> -789.25</td><td style=\"text-align: right;\">            -1.11165</td><td style=\"text-align: right;\">            -1702.49</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_21-01-33\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -1.1116457547643066\n",
      "  episode_reward_mean: -711.1807312858703\n",
      "  episode_reward_min: -1702.4878189939052\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 122\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 24500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 5.302407264709473\n",
      "        mean_q: -76.78132629394531\n",
      "        min_q: -129.2058563232422\n",
      "        model: {}\n",
      "    num_steps_sampled: 24500\n",
      "    num_steps_trained: 2944256\n",
      "    num_target_updates: 11501\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.71153846153846\n",
      "    ram_util_percent: 63.11538461538461\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10082041446917875\n",
      "    mean_env_wait_ms: 0.1460076409820115\n",
      "    mean_inference_ms: 0.7305336008668726\n",
      "    mean_raw_obs_processing_ms: 0.22157216103520583\n",
      "  time_since_restore: 414.03240990638733\n",
      "  time_this_iter_s: 18.37852692604065\n",
      "  time_total_s: 414.03240990638733\n",
      "  timers:\n",
      "    learn_throughput: 69906.887\n",
      "    learn_time_ms: 3.662\n",
      "    update_time_ms: 2.684\n",
      "  timestamp: 1626228093\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 24500\n",
      "  training_iteration: 24\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         414.032</td><td style=\"text-align: right;\">24500</td><td style=\"text-align: right;\">-711.181</td><td style=\"text-align: right;\">            -1.11165</td><td style=\"text-align: right;\">            -1702.49</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_21-01-50\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -1.1116457547643066\n",
      "  episode_reward_mean: -654.9789331537673\n",
      "  episode_reward_min: -1543.9091369921614\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 126\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 25500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 8.509936332702637\n",
      "        mean_q: -74.9183349609375\n",
      "        min_q: -133.55616760253906\n",
      "        model: {}\n",
      "    num_steps_sampled: 25500\n",
      "    num_steps_trained: 3072256\n",
      "    num_target_updates: 12001\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.025000000000002\n",
      "    ram_util_percent: 63.50416666666666\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10083697897637284\n",
      "    mean_env_wait_ms: 0.14602871486581848\n",
      "    mean_inference_ms: 0.7300545922472584\n",
      "    mean_raw_obs_processing_ms: 0.22157011281195912\n",
      "  time_since_restore: 431.3214418888092\n",
      "  time_this_iter_s: 17.289031982421875\n",
      "  time_total_s: 431.3214418888092\n",
      "  timers:\n",
      "    learn_throughput: 75198.324\n",
      "    learn_time_ms: 3.404\n",
      "    update_time_ms: 1.789\n",
      "  timestamp: 1626228110\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 25500\n",
      "  training_iteration: 25\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         431.321</td><td style=\"text-align: right;\">25500</td><td style=\"text-align: right;\">-654.979</td><td style=\"text-align: right;\">            -1.11165</td><td style=\"text-align: right;\">            -1543.91</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_21-02-09\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -1.1116457547643066\n",
      "  episode_reward_mean: -581.5873670837315\n",
      "  episode_reward_min: -1519.854635629977\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 132\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 26500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 5.026442050933838\n",
      "        mean_q: -76.33003234863281\n",
      "        min_q: -136.049560546875\n",
      "        model: {}\n",
      "    num_steps_sampled: 26500\n",
      "    num_steps_trained: 3200256\n",
      "    num_target_updates: 12501\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.35\n",
      "    ram_util_percent: 62.79615384615385\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10085566443925359\n",
      "    mean_env_wait_ms: 0.14606064681301018\n",
      "    mean_inference_ms: 0.729549470409917\n",
      "    mean_raw_obs_processing_ms: 0.22157791304227836\n",
      "  time_since_restore: 450.27890610694885\n",
      "  time_this_iter_s: 18.95746421813965\n",
      "  time_total_s: 450.27890610694885\n",
      "  timers:\n",
      "    learn_throughput: 64951.657\n",
      "    learn_time_ms: 3.941\n",
      "    update_time_ms: 2.259\n",
      "  timestamp: 1626228129\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 26500\n",
      "  training_iteration: 26\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         450.279</td><td style=\"text-align: right;\">26500</td><td style=\"text-align: right;\">-581.587</td><td style=\"text-align: right;\">            -1.11165</td><td style=\"text-align: right;\">            -1519.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_21-02-28\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -1.1116457547643066\n",
      "  episode_reward_mean: -543.6693148351875\n",
      "  episode_reward_min: -1519.854635629977\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 136\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 27500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 4.031546592712402\n",
      "        mean_q: -76.26606750488281\n",
      "        min_q: -138.93124389648438\n",
      "        model: {}\n",
      "    num_steps_sampled: 27500\n",
      "    num_steps_trained: 3328256\n",
      "    num_target_updates: 13001\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.355555555555558\n",
      "    ram_util_percent: 62.829629629629636\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10084317243518033\n",
      "    mean_env_wait_ms: 0.14605039801312864\n",
      "    mean_inference_ms: 0.7291718178633722\n",
      "    mean_raw_obs_processing_ms: 0.2215448771838519\n",
      "  time_since_restore: 469.2216773033142\n",
      "  time_this_iter_s: 18.942771196365356\n",
      "  time_total_s: 469.2216773033142\n",
      "  timers:\n",
      "    learn_throughput: 66035.376\n",
      "    learn_time_ms: 3.877\n",
      "    update_time_ms: 2.228\n",
      "  timestamp: 1626228148\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 27500\n",
      "  training_iteration: 27\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         469.222</td><td style=\"text-align: right;\">27500</td><td style=\"text-align: right;\">-543.669</td><td style=\"text-align: right;\">            -1.11165</td><td style=\"text-align: right;\">            -1519.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_21-02-47\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -1.1116457547643066\n",
      "  episode_reward_mean: -503.3479170812064\n",
      "  episode_reward_min: -1519.854635629977\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 142\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 28500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 8.385159492492676\n",
      "        mean_q: -79.76459503173828\n",
      "        min_q: -143.51950073242188\n",
      "        model: {}\n",
      "    num_steps_sampled: 28500\n",
      "    num_steps_trained: 3456256\n",
      "    num_target_updates: 13501\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.71153846153846\n",
      "    ram_util_percent: 62.20384615384616\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10081609962945773\n",
      "    mean_env_wait_ms: 0.14602355893903582\n",
      "    mean_inference_ms: 0.7286173247160681\n",
      "    mean_raw_obs_processing_ms: 0.2214595482753488\n",
      "  time_since_restore: 488.01311016082764\n",
      "  time_this_iter_s: 18.791432857513428\n",
      "  time_total_s: 488.01311016082764\n",
      "  timers:\n",
      "    learn_throughput: 64560.344\n",
      "    learn_time_ms: 3.965\n",
      "    update_time_ms: 2.323\n",
      "  timestamp: 1626228167\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28500\n",
      "  training_iteration: 28\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         488.013</td><td style=\"text-align: right;\">28500</td><td style=\"text-align: right;\">-503.348</td><td style=\"text-align: right;\">            -1.11165</td><td style=\"text-align: right;\">            -1519.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_21-03-06\n",
      "  done: false\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -1.1116457547643066\n",
      "  episode_reward_mean: -461.2358136139652\n",
      "  episode_reward_min: -1519.854635629977\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 146\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 29500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 6.932671070098877\n",
      "        mean_q: -74.86430358886719\n",
      "        min_q: -146.92617797851562\n",
      "        model: {}\n",
      "    num_steps_sampled: 29500\n",
      "    num_steps_trained: 3584256\n",
      "    num_target_updates: 14001\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.81851851851852\n",
      "    ram_util_percent: 62.31481481481482\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10080769151659849\n",
      "    mean_env_wait_ms: 0.1460119840536429\n",
      "    mean_inference_ms: 0.7283629026092139\n",
      "    mean_raw_obs_processing_ms: 0.2214165201194093\n",
      "  time_since_restore: 507.24014711380005\n",
      "  time_this_iter_s: 19.227036952972412\n",
      "  time_total_s: 507.24014711380005\n",
      "  timers:\n",
      "    learn_throughput: 52636.467\n",
      "    learn_time_ms: 4.864\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1626228186\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 29500\n",
      "  training_iteration: 29\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>RUNNING </td><td>192.168.0.23:17553</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">          507.24</td><td style=\"text-align: right;\">29500</td><td style=\"text-align: right;\">-461.236</td><td style=\"text-align: right;\">            -1.11165</td><td style=\"text-align: right;\">            -1519.85</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DDPG_Pendulum-v0_6b1dd_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-07-13_21-03-25\n",
      "  done: true\n",
      "  episode_len_mean: 200.0\n",
      "  episode_reward_max: -1.1116457547643066\n",
      "  episode_reward_mean: -444.3119269581459\n",
      "  episode_reward_min: -1524.5879513507703\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 152\n",
      "  experiment_id: 43107a19371e49529eb221515032f0aa\n",
      "  hostname: Mingjuns-MacBook-Pro.local\n",
      "  info:\n",
      "    last_target_update_ts: 30500\n",
      "    learner:\n",
      "      default_policy:\n",
      "        max_q: 5.001977920532227\n",
      "        mean_q: -80.31802368164062\n",
      "        min_q: -147.42247009277344\n",
      "        model: {}\n",
      "    num_steps_sampled: 30500\n",
      "    num_steps_trained: 3712256\n",
      "    num_target_updates: 14501\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.0.23\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.751851851851853\n",
      "    ram_util_percent: 63.059259259259264\n",
      "  pid: 17553\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10079419357209049\n",
      "    mean_env_wait_ms: 0.14599417996490968\n",
      "    mean_inference_ms: 0.7280488494211115\n",
      "    mean_raw_obs_processing_ms: 0.22135616529126742\n",
      "  time_since_restore: 526.4707138538361\n",
      "  time_this_iter_s: 19.23056674003601\n",
      "  time_total_s: 526.4707138538361\n",
      "  timers:\n",
      "    learn_throughput: 65008.284\n",
      "    learn_time_ms: 3.938\n",
      "    update_time_ms: 2.475\n",
      "  timestamp: 1626228205\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 30500\n",
      "  training_iteration: 30\n",
      "  trial_id: 6b1dd_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         526.471</td><td style=\"text-align: right;\">30500</td><td style=\"text-align: right;\">-444.312</td><td style=\"text-align: right;\">            -1.11165</td><td style=\"text-align: right;\">            -1524.59</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects<br>Result logdir: /Users/mingjunwang/ray_results/DDPG<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DDPG_Pendulum-v0_6b1dd_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         526.471</td><td style=\"text-align: right;\">30500</td><td style=\"text-align: right;\">-444.312</td><td style=\"text-align: right;\">            -1.11165</td><td style=\"text-align: right;\">            -1524.59</td><td style=\"text-align: right;\">               200</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 21:03:26,318\tINFO tune.py:448 -- Total run time: 540.24 seconds (539.55 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7fadfcd0d490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg = 'DDPG'\n",
    "tune.run(alg,\n",
    "    stop={\"training_iteration\": 30},\n",
    "    config={\n",
    "        'env':'Pendulum-v0',\n",
    "        'num_gpus':0,\n",
    "        'num_workers':2,\n",
    "        'lr':tune.grid_search([.001,])     \n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: RLlib Environments\n",
    "\n",
    "1: RLlib works with several different types of environments, including OpenAI Gym, user-defined, multi-agent, and also batched environments.\n",
    "\n",
    "2: RLlib uses Gym as its environment interface for single-agent training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: Configuring Environments\n",
    "\n",
    "    https://github.com/ray-project/ray/blob/master/rllib/examples/custom_env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-7352217a18a1>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-7352217a18a1>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    self.action_space = <gym.Space>\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import gym, ray\n",
    "from ray.rllib.agents import ppo\n",
    "\n",
    "class MyEnv(gym.Env):\n",
    "    def __init__(self, env_config):\n",
    "        self.action_space = <gym.Space>\n",
    "        self.observation_space = <gym.Space>\n",
    "    def reset(self):\n",
    "        return <obs>\n",
    "    def step(self, action):\n",
    "        return <obs>, <reward: float>, <done: bool>, <info: dict>\n",
    "\n",
    "ray.init()\n",
    "trainer = ppo.PPOTrainer(env=MyEnv, config={\n",
    "    \"env_config\": {},  # config to pass to env class\n",
    "})\n",
    "\n",
    "while True:\n",
    "    print(trainer.train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
